{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 03-02: 옵티마이저 (Optimizers)\n",
    "\n",
    "## 학습 목표\n",
    "- SGD, Adam, RMSprop, AdamW의 동작 원리를 수식으로 이해한다\n",
    "- 학습률(Learning Rate)의 중요성과 적절한 설정 방법을 안다\n",
    "- Learning Rate Scheduler를 활용하여 동적으로 학습률을 조정할 수 있다\n",
    "- 동일한 모델에 여러 옵티마이저를 적용하고 수렴 속도를 비교할 수 있다\n",
    "\n",
    "## 목차\n",
    "1. [수학적 기초](#1.-수학적-기초)\n",
    "2. [옵티마이저 생성 및 기본 사용법](#2.-옵티마이저-생성-및-기본-사용법)\n",
    "3. [학습률의 영향](#3.-학습률의-영향)\n",
    "4. [Learning Rate Scheduler](#4.-Learning-Rate-Scheduler)\n",
    "5. [ReduceLROnPlateau 콜백](#5.-ReduceLROnPlateau-콜백)\n",
    "6. [옵티마이저 수렴 속도 비교](#6.-옵티마이저-수렴-속도-비교)\n",
    "7. [정리](#7.-정리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "print(\"TensorFlow 버전:\", tf.__version__)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 수학적 기초\n",
    "\n",
    "### SGD (Stochastic Gradient Descent)\n",
    "\n",
    "$$\\theta \\leftarrow \\theta - \\eta \\nabla L(\\theta)$$\n",
    "\n",
    "- $\\theta$: 모델 파라미터\n",
    "- $\\eta$: 학습률 (learning rate)\n",
    "- $\\nabla L(\\theta)$: 손실에 대한 그래디언트\n",
    "\n",
    "### SGD with Momentum\n",
    "\n",
    "$$v_t = \\gamma v_{t-1} + \\eta \\nabla L(\\theta)$$\n",
    "$$\\theta \\leftarrow \\theta - v_t$$\n",
    "\n",
    "- $v_t$: 속도 벡터 (이전 그래디언트 정보 누적)\n",
    "- $\\gamma$: 모멘텀 계수 (보통 0.9)\n",
    "\n",
    "### Adam (Adaptive Moment Estimation)\n",
    "\n",
    "**1차 모멘트 (그래디언트 평균):**\n",
    "$$m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t$$\n",
    "\n",
    "**2차 모멘트 (그래디언트 제곱 평균):**\n",
    "$$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2$$\n",
    "\n",
    "**편향 보정 (초기 0으로 초기화된 편향 수정):**\n",
    "$$\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$$\n",
    "\n",
    "**파라미터 업데이트:**\n",
    "$$\\theta \\leftarrow \\theta - \\frac{\\eta \\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$$\n",
    "\n",
    "- 기본값: $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, $\\epsilon = 10^{-7}$\n",
    "- 각 파라미터마다 적응적 학습률을 사용 → 빠른 수렴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 옵티마이저 생성 및 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 주요 옵티마이저 생성\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# SGD: 가장 기본적인 옵티마이저\n",
    "sgd = tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.9,       # 모멘텀 적용 (기본값 0.0)\n",
    "    nesterov=True       # Nesterov 모멘텀 사용 여부\n",
    ")\n",
    "\n",
    "# Adam: 가장 널리 사용되는 옵티마이저\n",
    "adam = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,         # 1차 모멘트 감쇠율\n",
    "    beta_2=0.999,       # 2차 모멘트 감쇠율\n",
    "    epsilon=1e-7        # 수치 안정성을 위한 작은 값\n",
    ")\n",
    "\n",
    "# RMSprop: 순환 신경망에 자주 사용\n",
    "rmsprop = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.9,            # 이동 평균 감쇠율\n",
    "    momentum=0.0,\n",
    "    epsilon=1e-7\n",
    ")\n",
    "\n",
    "# AdamW: Adam + Weight Decay (L2 정규화와 다름, 디커플된 가중치 감쇠)\n",
    "adamw = tf.keras.optimizers.AdamW(\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.004  # 가중치 감쇠 계수\n",
    ")\n",
    "\n",
    "print(\"생성된 옵티마이저:\")\n",
    "for opt in [sgd, adam, rmsprop, adamw]:\n",
    "    print(f\"  {opt.__class__.__name__}: lr={opt.learning_rate.numpy():.4f}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 수동 그래디언트 적용 예시\n",
    "# ---------------------------------------------------\n",
    "print(\"\\n=== 수동 그래디언트 적용 ===\")\n",
    "\n",
    "# 간단한 변수\n",
    "w = tf.Variable(3.0, name='w')\n",
    "b = tf.Variable(0.0, name='b')\n",
    "\n",
    "# 목표: w=2.0, b=1.0 찾기\n",
    "with tf.GradientTape() as tape:\n",
    "    y_pred = w * 2.0 + b\n",
    "    loss = (y_pred - 5.0) ** 2  # 목표값 5.0 (= 2*2 + 1)\n",
    "\n",
    "gradients = tape.gradient(loss, [w, b])\n",
    "adam.apply_gradients(zip(gradients, [w, b]))\n",
    "\n",
    "print(f\"업데이트 전: w=3.0, b=0.0\")\n",
    "print(f\"업데이트 후: w={w.numpy():.4f}, b={b.numpy():.4f}\")\n",
    "print(f\"그래디언트: dw={gradients[0].numpy():.4f}, db={gradients[1].numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습률의 영향\n",
    "\n",
    "학습률은 모델 학습에서 가장 중요한 하이퍼파라미터 중 하나이다.\n",
    "- **너무 큰 학습률**: 발산 (loss가 폭발적으로 증가)\n",
    "- **너무 작은 학습률**: 수렴 속도가 느림 (학습 시간 증가)\n",
    "- **적절한 학습률**: 빠르고 안정적인 수렴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 학습률 크기에 따른 학습 곡선 비교\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def train_with_lr(learning_rate, epochs=50):\n",
    "    \"\"\"주어진 학습률로 간단한 회귀 문제 학습\"\"\"\n",
    "    # 간단한 데이터 생성: y = 2x + 1\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(100, 1).astype(np.float32)\n",
    "    y = 2 * X + 1 + 0.1 * np.random.randn(100, 1).astype(np.float32)\n",
    "    \n",
    "    # 간단한 선형 모델\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1, input_shape=(1,))\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "        loss='mse'\n",
    "    )\n",
    "    \n",
    "    history = model.fit(X, y, epochs=epochs, verbose=0, batch_size=32)\n",
    "    return history.history['loss']\n",
    "\n",
    "# 세 가지 학습률 비교\n",
    "lr_configs = {\n",
    "    'lr=0.5 (너무 큼)': 0.5,\n",
    "    'lr=0.01 (적절)': 0.01,\n",
    "    'lr=0.0001 (너무 작음)': 0.0001,\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for label, lr in lr_configs.items():\n",
    "    losses = train_with_lr(lr)\n",
    "    # NaN이나 inf 방지를 위해 클리핑\n",
    "    losses = [min(l, 50) if not np.isnan(l) else 50 for l in losses]\n",
    "    plt.plot(losses, label=label, linewidth=2)\n",
    "\n",
    "plt.xlabel('에포크')\n",
    "plt.ylabel('MSE 손실')\n",
    "plt.title('학습률 크기에 따른 수렴 비교 (SGD)')\n",
    "plt.legend()\n",
    "plt.ylim(0, 20)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"학습률 0.5: 발산 가능성 높음\")\n",
    "print(\"학습률 0.01: 빠르고 안정적인 수렴\")\n",
    "print(\"학습률 0.0001: 수렴하지만 매우 느림\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learning Rate Scheduler\n",
    "\n",
    "학습 초기에는 큰 학습률로 빠르게 진행하고, 후반부에는 작은 학습률로 세밀하게 수렴시키는 전략이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Learning Rate Scheduler 종류와 시각화\n",
    "# ---------------------------------------------------\n",
    "\n",
    "steps = np.arange(0, 1000)\n",
    "\n",
    "# 1. ExponentialDecay: lr = initial_lr * decay_rate ^ (step / decay_steps)\n",
    "exp_decay = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=200,    # 200 스텝마다 감쇠\n",
    "    decay_rate=0.5,     # 50%씩 감소\n",
    "    staircase=False     # 연속적 감쇠 (True면 계단형)\n",
    ")\n",
    "\n",
    "# 2. CosineDecay: 코사인 함수 형태로 학습률 감소\n",
    "cosine_decay = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=1000,\n",
    "    alpha=0.0           # 최소 학습률 비율 (0 = 완전히 0까지 감소)\n",
    ")\n",
    "\n",
    "# 3. CosineDecayRestarts: 주기적으로 학습률을 리셋 (웜 리스타트)\n",
    "cosine_restarts = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "    initial_learning_rate=0.1,\n",
    "    first_decay_steps=200,  # 첫 번째 사이클 길이\n",
    "    t_mul=2.0,              # 각 사이클마다 길이 2배\n",
    "    m_mul=0.9               # 각 사이클마다 초기 lr 90%\n",
    ")\n",
    "\n",
    "# 학습률 값 계산\n",
    "exp_lrs = [exp_decay(s).numpy() for s in steps]\n",
    "cos_lrs = [cosine_decay(s).numpy() for s in steps]\n",
    "cos_restart_lrs = [cosine_restarts(s).numpy() for s in steps]\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(steps, exp_lrs, color='blue', linewidth=2)\n",
    "axes[0].set_title('ExponentialDecay')\n",
    "axes[0].set_xlabel('학습 스텝')\n",
    "axes[0].set_ylabel('학습률')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(steps, cos_lrs, color='green', linewidth=2)\n",
    "axes[1].set_title('CosineDecay')\n",
    "axes[1].set_xlabel('학습 스텝')\n",
    "axes[1].set_ylabel('학습률')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(steps, cos_restart_lrs, color='red', linewidth=2)\n",
    "axes[2].set_title('CosineDecayRestarts (Warm Restarts)')\n",
    "axes[2].set_xlabel('학습 스텝')\n",
    "axes[2].set_ylabel('학습률')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 옵티마이저에 스케줄러 적용 예시\n",
    "print(\"=== 옵티마이저에 스케줄러 적용 ===\")\n",
    "print(\"\"\"\n",
    "# 스케줄러를 옵티마이저의 learning_rate에 직접 전달\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ReduceLROnPlateau 콜백\n",
    "\n",
    "검증 손실이 개선되지 않을 때 학습률을 자동으로 줄이는 콜백이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# ReduceLROnPlateau 콜백 예시\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# 간단한 MNIST 모델로 테스트\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 784).astype('float32') / 255.0\n",
    "X_test  = X_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "# 빠른 실험을 위해 일부 데이터만 사용\n",
    "X_small = X_train[:5000]\n",
    "y_small = y_train[:5000]\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"간단한 MLP 분류 모델 생성\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),  # 의도적으로 큰 lr\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau 콜백 설정\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',   # 모니터할 지표\n",
    "    factor=0.5,           # 학습률 감소 배율 (lr = lr * factor)\n",
    "    patience=3,           # 개선 없이 기다릴 에포크 수\n",
    "    min_lr=1e-6,          # 최소 학습률 하한선\n",
    "    min_delta=0.001,      # 개선으로 인정할 최소 변화량\n",
    "    verbose=1             # 학습률 변경 시 출력\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_small, y_small,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 학습률 변화 추적 (콜백 내부에서 기록)\n",
    "print(f\"\\n최종 학습률: {model.optimizer.learning_rate.numpy():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 옵티마이저 수렴 속도 비교\n",
    "\n",
    "동일한 MNIST 모델에 SGD, Adam, RMSprop을 적용하고 수렴 속도를 비교한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# SGD / Adam / RMSprop 수렴 속도 비교\n",
    "# ---------------------------------------------------\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 각 옵티마이저 설정\n",
    "optimizers_config = {\n",
    "    'SGD (lr=0.01)': tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    'Adam (lr=0.001)': tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    'RMSprop (lr=0.001)': tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "}\n",
    "\n",
    "histories = {}\n",
    "\n",
    "for name, optimizer in optimizers_config.items():\n",
    "    print(f\"\\n학습 중: {name}\")\n",
    "    \n",
    "    # 동일한 가중치 초기화를 위해 시드 고정 후 모델 재생성\n",
    "    tf.random.set_seed(42)\n",
    "    model = build_model()\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_small, y_small,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    histories[name] = history.history\n",
    "    final_val_acc = history.history['val_accuracy'][-1]\n",
    "    print(f\"  완료 - 최종 검증 정확도: {final_val_acc:.4f}, 소요 시간: {elapsed:.1f}초\")\n",
    "\n",
    "# 비교 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for (name, history), color in zip(histories.items(), colors):\n",
    "    epochs_range = range(1, EPOCHS + 1)\n",
    "    \n",
    "    axes[0].plot(epochs_range, history['loss'], label=name, color=color, linewidth=2)\n",
    "    axes[1].plot(epochs_range, history['val_accuracy'], label=name, color=color, linewidth=2)\n",
    "\n",
    "axes[0].set_xlabel('에포크')\n",
    "axes[0].set_ylabel('훈련 손실')\n",
    "axes[0].set_title('옵티마이저별 훈련 손실 비교')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('에포크')\n",
    "axes[1].set_ylabel('검증 정확도')\n",
    "axes[1].set_title('옵티마이저별 검증 정확도 비교')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 정리\n",
    "\n",
    "### 옵티마이저 선택 가이드\n",
    "\n",
    "| 옵티마이저 | 장점 | 단점 | 권장 사용 상황 |\n",
    "|-----------|------|------|---------------|\n",
    "| SGD + Momentum | 일반화 성능 좋음 | 학습률 튜닝 필요 | 이미지 분류, 최종 성능 중요 시 |\n",
    "| Adam | 빠른 수렴, 학습률 튜닝 덜 필요 | 일부 태스크에서 과적합 가능 | 대부분의 경우 기본 선택 |\n",
    "| RMSprop | 비정상 데이터에 강건 | Adam보다 수렴 느릴 수 있음 | 순환 신경망(RNN) |\n",
    "| AdamW | Adam + 더 나은 정규화 | 추가 하이퍼파라미터 | Transformer 기반 모델 |\n",
    "\n",
    "### Learning Rate Scheduler 선택\n",
    "\n",
    "| 스케줄러 | 특징 | 권장 사용 상황 |\n",
    "|---------|------|---------------|\n",
    "| ExponentialDecay | 단순하고 예측 가능 | 일반적인 경우 |\n",
    "| CosineDecay | 부드러운 감소 | 대부분의 딥러닝 태스크 |\n",
    "| CosineDecayRestarts | 주기적 리셋으로 탈출 효과 | 로컬 미니멈 탈출 필요 시 |\n",
    "| ReduceLROnPlateau | 자동 적응형 | 검증 손실 정체 시 자동 조정 필요 |\n",
    "\n",
    "### 핵심 정리\n",
    "- 학습률은 가장 중요한 하이퍼파라미터이다. Adam의 기본값 `0.001`이 좋은 출발점이다\n",
    "- Adam은 대부분의 경우 좋은 성능을 보이지만, SGD+Momentum이 최종 성능에서 유리할 수 있다\n",
    "- Learning Rate Scheduler를 사용하면 추가 비용 없이 성능을 향상시킬 수 있다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
