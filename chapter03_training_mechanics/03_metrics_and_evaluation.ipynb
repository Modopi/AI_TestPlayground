{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 03-03: ë©”íŠ¸ë¦­ê³¼ í‰ê°€ (Metrics and Evaluation)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- Accuracy, Precision, Recall, F1 ë“± ì£¼ìš” ë¶„ë¥˜ ë©”íŠ¸ë¦­ì„ ì´í•´í•˜ê³  ê³„ì‚°í•  ìˆ˜ ìˆë‹¤\n",
    "- Confusion Matrixë¥¼ ì‹œê°í™”í•˜ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤\n",
    "- ROC Curveì™€ AUCë¥¼ ì´í•´í•˜ê³  ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆë‹¤\n",
    "- `tf.keras.metrics.Metric`ì„ ìƒì†í•˜ì—¬ ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ì„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [ê¸°ë³¸ ë¶„ë¥˜ ë©”íŠ¸ë¦­](#2.-ê¸°ë³¸-ë¶„ë¥˜-ë©”íŠ¸ë¦­)\n",
    "3. [Precision, Recall, F1](#3.-Precision,-Recall,-F1)\n",
    "4. [Confusion Matrix ì‹œê°í™”](#4.-Confusion-Matrix-ì‹œê°í™”)\n",
    "5. [ROC Curveì™€ AUC](#5.-ROC-Curveì™€-AUC)\n",
    "6. [ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­](#6.-ì»¤ìŠ¤í…€-ë©”íŠ¸ë¦­)\n",
    "7. [ì •ë¦¬](#7.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "print(\"TensorFlow ë²„ì „:\", tf.__version__)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ\n",
    "\n",
    "### í˜¼ë™ í–‰ë ¬ (Confusion Matrix)\n",
    "\n",
    "|  | ì˜ˆì¸¡ ì–‘ì„± | ì˜ˆì¸¡ ìŒì„± |\n",
    "|--|-----------|----------|\n",
    "| **ì‹¤ì œ ì–‘ì„±** | TP (True Positive) | FN (False Negative) |\n",
    "| **ì‹¤ì œ ìŒì„±** | FP (False Positive) | TN (True Negative) |\n",
    "\n",
    "### ì£¼ìš” ë©”íŠ¸ë¦­ ê³µì‹\n",
    "\n",
    "**ì •í™•ë„ (Accuracy):**\n",
    "$$A = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "**ì •ë°€ë„ (Precision):** ì–‘ì„±ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ ì–‘ì„± ë¹„ìœ¨\n",
    "$$P = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**ì¬í˜„ìœ¨ (Recall):** ì‹¤ì œ ì–‘ì„± ì¤‘ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡í•œ ë¹„ìœ¨\n",
    "$$R = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**F1 ì ìˆ˜:** Precisionê³¼ Recallì˜ ì¡°í™” í‰ê· \n",
    "$$F_1 = \\frac{2PR}{P + R} = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$$\n",
    "\n",
    "> **ì£¼ì˜**: Precisionê³¼ Recallì€ íŠ¸ë ˆì´ë“œì˜¤í”„ ê´€ê³„ì´ë‹¤. í•˜ë‚˜ë¥¼ ì˜¬ë¦¬ë©´ ë‹¤ë¥¸ í•˜ë‚˜ê°€ ë‚´ë ¤ê°€ëŠ” ê²½í–¥ì´ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ í‰ê°€ ì§€í‘œ ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ¯ ì™œ ì •í™•ë„(Accuracy)ë§Œìœ¼ë¡œ ë¶€ì¡±í•´ìš”?\n",
    "\n",
    "> ğŸ’¡ **ì˜ˆì‹œ**: 100ëª… ì¤‘ 99ëª…ì´ ê±´ê°•í•˜ê³  1ëª…ì´ ì•„í”ˆ ìƒí™©ì—ì„œ,\n",
    "> AIê°€ \"ëª¨ë‘ ê±´ê°•í•´ìš”!\"ë¼ê³ ë§Œ í•´ë„ ì •í™•ë„ **99%**!\n",
    "> í•˜ì§€ë§Œ ì•„í”ˆ 1ëª…ì„ ë†“ì³¤ìœ¼ë‹ˆ **ì™„ì „íˆ ì‹¤íŒ¨í•œ AI**ì˜ˆìš”! ğŸ˜±\n",
    "\n",
    "ì´ëŸ° ìƒí™©ì—ì„œëŠ” **ë” ì„¸ë°€í•œ ì§€í‘œ**ê°€ í•„ìš”í•´ìš”.\n",
    "\n",
    "#### ğŸ“Š í˜¼ë™ í–‰ë ¬(Confusion Matrix) â€” ì˜¤ë‹µ ìœ í˜• ë¶„ì„í‘œ\n",
    "\n",
    "```\n",
    "                ì˜ˆì¸¡: ë³‘ ìˆìŒ  ì˜ˆì¸¡: ê±´ê°•\n",
    "ì‹¤ì œ: ë³‘ ìˆìŒ    TP (ì •ë‹µ! âœ…)   FN (ë†“ì¹¨ ğŸ˜±)\n",
    "ì‹¤ì œ: ê±´ê°•       FP (ì˜¤ê²½ë³´ ğŸ˜…)  TN (ì •ë‹µ! âœ…)\n",
    "```\n",
    "\n",
    "| ìš©ì–´ | ëœ» | ë¹„ìœ  |\n",
    "|------|-----|------|\n",
    "| **TP** (True Positive) | ë§ê²Œ ì–‘ì„± íŒì • | ì‹¤ì œ í™˜ìë¥¼ í™˜ìë¡œ ë§í˜ âœ… |\n",
    "| **TN** (True Negative) | ë§ê²Œ ìŒì„± íŒì • | ê±´ê°•í•œ ì‚¬ëŒì„ ê±´ê°•í•˜ë‹¤ê³  ë§í˜ âœ… |\n",
    "| **FP** (False Positive) | í‹€ë¦¬ê²Œ ì–‘ì„± íŒì • | ê±´ê°•í•œ ì‚¬ëŒì„ í™˜ìë¡œ ì˜¤ì§„ ğŸ˜… |\n",
    "| **FN** (False Negative) | í‹€ë¦¬ê²Œ ìŒì„± íŒì • | ì‹¤ì œ í™˜ìë¥¼ ê±´ê°•í•˜ë‹¤ê³  ë†“ì¹¨ ğŸ˜± |\n",
    "\n",
    "#### âš–ï¸ Precision vs Recall íŠ¸ë ˆì´ë“œì˜¤í”„\n",
    "\n",
    "| ì§€í‘œ | ê³„ì‚°ì‹ | ì˜ë¯¸ | ì¤‘ìš”í•œ ìƒí™© |\n",
    "|------|--------|------|----------|\n",
    "| **Precision** | TP/(TP+FP) | ì–‘ì„± íŒì • ì¤‘ ì‹¤ì œ ì–‘ì„± ë¹„ìœ¨ | ìŠ¤íŒ¸ í•„í„° (ì˜¤ê²½ë³´ê°€ ë” ë‚˜ì¨) |\n",
    "| **Recall** | TP/(TP+FN) | ì‹¤ì œ ì–‘ì„± ì¤‘ ë§ê²Œ ì°¾ì€ ë¹„ìœ¨ | ì•” ì§„ë‹¨ (ë†“ì¹˜ëŠ” ê²Œ ë” ë‚˜ì¨) |\n",
    "| **F1** | 2PR/(P+R) | Pì™€ Rì˜ ê· í˜• | ë‘˜ ë‹¤ ì¤‘ìš”í•  ë•Œ |\n",
    "\n",
    "> ğŸ’¡ **í•µì‹¬**: Precisionì„ ì˜¬ë¦¬ë©´ Recallì´ ë‚´ë ¤ê°€ìš”! (ë°˜ëŒ€ë„ ë§ˆì°¬ê°€ì§€)\n",
    "> ëª©ì ì— ë”°ë¼ ì–´ëŠ ìª½ì„ ìš°ì„ í• ì§€ ê²°ì •í•´ì•¼ í•´ìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ê¸°ë³¸ ë¶„ë¥˜ ë©”íŠ¸ë¦­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Accuracy, BinaryAccuracy, CategoricalAccuracy\n",
    "# ---------------------------------------------------\n",
    "\n",
    "print(\"=== Accuracy ë©”íŠ¸ë¦­ ì¢…ë¥˜ ===\")\n",
    "\n",
    "# ì´ì§„ ë¶„ë¥˜ ì˜ˆì‹œ\n",
    "y_true_bin = tf.constant([1, 0, 1, 1, 0, 1, 0, 0, 1, 1])\n",
    "y_pred_bin = tf.constant([0.8, 0.3, 0.7, 0.6, 0.4, 0.9, 0.2, 0.7, 0.8, 0.5])\n",
    "\n",
    "# BinaryAccuracy: ì„ê³„ê°’(threshold)ì„ ê¸°ì¤€ìœ¼ë¡œ 0/1 ë³€í™˜ í›„ ì •í™•ë„ ê³„ì‚°\n",
    "binary_acc = tf.keras.metrics.BinaryAccuracy(threshold=0.5)\n",
    "binary_acc.update_state(y_true_bin, y_pred_bin)\n",
    "print(f\"BinaryAccuracy (threshold=0.5): {binary_acc.result().numpy():.4f}\")\n",
    "\n",
    "# ë‹¤ì¤‘ ë¶„ë¥˜ ì˜ˆì‹œ\n",
    "y_true_cat = tf.constant([0, 1, 2, 1, 0])\n",
    "y_pred_cat = tf.constant([\n",
    "    [0.8, 0.1, 0.1],  # í´ë˜ìŠ¤ 0 ì˜ˆì¸¡ (ì •ë‹µ)\n",
    "    [0.2, 0.7, 0.1],  # í´ë˜ìŠ¤ 1 ì˜ˆì¸¡ (ì •ë‹µ)\n",
    "    [0.3, 0.2, 0.5],  # í´ë˜ìŠ¤ 2 ì˜ˆì¸¡ (ì •ë‹µ)\n",
    "    [0.6, 0.3, 0.1],  # í´ë˜ìŠ¤ 0 ì˜ˆì¸¡ (ì˜¤ë‹µ: ì‹¤ì œ 1)\n",
    "    [0.7, 0.2, 0.1],  # í´ë˜ìŠ¤ 0 ì˜ˆì¸¡ (ì •ë‹µ)\n",
    "])\n",
    "\n",
    "# SparseCategoricalAccuracy: ì •ìˆ˜ ë ˆì´ë¸” + softmax í™•ë¥ \n",
    "sparse_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "sparse_acc.update_state(y_true_cat, y_pred_cat)\n",
    "print(f\"SparseCategoricalAccuracy: {sparse_acc.result().numpy():.4f}  (4/5 = 0.8)\")\n",
    "\n",
    "# One-hot ë ˆì´ë¸” + softmax í™•ë¥ \n",
    "y_true_onehot = tf.one_hot(y_true_cat, depth=3)\n",
    "cat_acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "cat_acc.update_state(y_true_onehot, y_pred_cat)\n",
    "print(f\"CategoricalAccuracy (one-hot): {cat_acc.result().numpy():.4f}\")\n",
    "\n",
    "# ìƒíƒœ ì´ˆê¸°í™” ë°©ë²•\n",
    "print(\"\\n=== ë©”íŠ¸ë¦­ ìƒíƒœ ê´€ë¦¬ ===\")\n",
    "print(\"\"\"\n",
    "# ì—í¬í¬ê°€ ëë‚œ í›„ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”\n",
    "metric.reset_state()  # ë˜ëŠ” metric.reset_states()\n",
    "\n",
    "# ì—¬ëŸ¬ ë°°ì¹˜ ê²°ê³¼ ëˆ„ì \n",
    "for batch in dataset:\n",
    "    metric.update_state(y_true, y_pred)\n",
    "\n",
    "# ì—í¬í¬ ìµœì¢… ê°’ ì¶œë ¥\n",
    "epoch_result = metric.result()\n",
    "metric.reset_state()  # ë‹¤ìŒ ì—í¬í¬ë¥¼ ìœ„í•´ ì´ˆê¸°í™”\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Precision, Recall, F1Score\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤: ì˜ë£Œ ì§„ë‹¨ (ì–‘ì„±=1: ì§ˆë³‘ ìˆìŒ)\n",
    "# ë†’ì€ Recall ì¤‘ìš”: ì‹¤ì œ í™˜ìë¥¼ ë†“ì¹˜ë©´ ì•ˆ ë¨\n",
    "\n",
    "y_true_medical = tf.constant([1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1])\n",
    "y_pred_medical = tf.constant([1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1])\n",
    "\n",
    "# tf.keras.metrics ì‚¬ìš©\n",
    "precision_metric = tf.keras.metrics.Precision()\n",
    "recall_metric = tf.keras.metrics.Recall()\n",
    "\n",
    "precision_metric.update_state(y_true_medical, y_pred_medical)\n",
    "recall_metric.update_state(y_true_medical, y_pred_medical)\n",
    "\n",
    "precision_val = precision_metric.result().numpy()\n",
    "recall_val = recall_metric.result().numpy()\n",
    "\n",
    "# F1 = 2 * P * R / (P + R) (ìˆ˜ë™ ê³„ì‚°)\n",
    "f1_val = 2 * precision_val * recall_val / (precision_val + recall_val + 1e-7)\n",
    "\n",
    "print(\"=== ì˜ë£Œ ì§„ë‹¨ ì‹œë‚˜ë¦¬ì˜¤ ===\")\n",
    "print(f\"ì‹¤ì œ ì–‘ì„± ìˆ˜: {sum(y_true_medical.numpy())}\")\n",
    "print(f\"ì˜ˆì¸¡ ì–‘ì„± ìˆ˜: {sum(y_pred_medical.numpy())}\")\n",
    "print()\n",
    "print(f\"Precision (ì •ë°€ë„): {precision_val:.4f}\")\n",
    "print(f\"  -> ì–‘ì„±ìœ¼ë¡œ ì˜ˆì¸¡í•œ {sum(y_pred_medical.numpy())}ê±´ ì¤‘ ì‹¤ì œ ì–‘ì„± ë¹„ìœ¨\")\n",
    "print(f\"Recall    (ì¬í˜„ìœ¨): {recall_val:.4f}\")\n",
    "print(f\"  -> ì‹¤ì œ ì–‘ì„± {sum(y_true_medical.numpy())}ê±´ ì¤‘ ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¹„ìœ¨\")\n",
    "print(f\"F1 Score          : {f1_val:.4f}\")\n",
    "print()\n",
    "print(\"ì˜ë£Œ ì§„ë‹¨ì—ì„œëŠ” Recallì´ ì¤‘ìš”: ì‹¤ì œ í™˜ìë¥¼ ë†“ì¹˜ëŠ” ê²ƒ(FN)ì´ ìœ„í—˜\")\n",
    "print(\"ìŠ¤íŒ¸ í•„í„°ì—ì„œëŠ” Precisionì´ ì¤‘ìš”: ì •ìƒ ë©”ì¼ì„ ìŠ¤íŒ¸ìœ¼ë¡œ ë¶„ë¥˜(FP)í•˜ë©´ ë¶ˆí¸\")\n",
    "\n",
    "# ì„ê³„ê°’ ë³€ê²½ì— ë”°ë¥¸ Precision-Recall íŠ¸ë ˆì´ë“œì˜¤í”„\n",
    "print(\"\\n=== ì„ê³„ê°’ì— ë”°ë¥¸ P-R íŠ¸ë ˆì´ë“œì˜¤í”„ ===\")\n",
    "y_pred_probs = tf.constant([0.9, 0.85, 0.3, 0.4, 0.1, 0.7, 0.8, 0.75, 0.2, 0.95,\n",
    "                             0.6, 0.35, 0.88, 0.15, 0.92])\n",
    "\n",
    "thresholds = [0.3, 0.5, 0.7, 0.9]\n",
    "print(f\"{'ì„ê³„ê°’':<8} {'Precision':<12} {'Recall':<12} {'F1':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    p_metric = tf.keras.metrics.Precision(thresholds=thresh)\n",
    "    r_metric = tf.keras.metrics.Recall(thresholds=thresh)\n",
    "    p_metric.update_state(y_true_medical, y_pred_probs)\n",
    "    r_metric.update_state(y_true_medical, y_pred_probs)\n",
    "    p = p_metric.result().numpy()\n",
    "    r = r_metric.result().numpy()\n",
    "    f1 = 2 * p * r / (p + r + 1e-7)\n",
    "    print(f\"{thresh:<8.1f} {p:<12.4f} {r:<12.4f} {f1:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Confusion Matrix ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# MNIST ëª¨ë¸ë¡œ Confusion Matrix ì‹œê°í™”\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# MNIST ë°ì´í„° ë¡œë“œ ë° ê°„ë‹¨í•œ ëª¨ë¸ í•™ìŠµ\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 784).astype('float32') / 255.0\n",
    "X_test  = X_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "# ë¹ ë¥¸ ì‹¤í—˜ìš© ì¶•ì†Œ ë°ì´í„°\n",
    "X_tr = X_train[:8000]\n",
    "y_tr = y_train[:8000]\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model_cm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model_cm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_cm.fit(X_tr, y_tr, epochs=5, batch_size=64, verbose=0)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì…‹ìœ¼ë¡œ ì˜ˆì¸¡\n",
    "y_pred_probs = model_cm.predict(X_test[:2000], verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = y_test[:2000]\n",
    "\n",
    "# Confusion Matrix ê³„ì‚° (sklearn ì‚¬ìš©)\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ì™¼ìª½: ì ˆëŒ€ ë¹ˆë„\n",
    "im1 = axes[0].imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "axes[0].set_title('Confusion Matrix (ì ˆëŒ€ ë¹ˆë„)')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "tick_marks = np.arange(10)\n",
    "axes[0].set_xticks(tick_marks)\n",
    "axes[0].set_yticks(tick_marks)\n",
    "axes[0].set_xticklabels([str(i) for i in range(10)])\n",
    "axes[0].set_yticklabels([str(i) for i in range(10)])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        axes[0].text(j, i, str(cm[i, j]),\n",
    "                    ha='center', va='center',\n",
    "                    color='white' if cm[i, j] > cm.max() / 2 else 'black',\n",
    "                    fontsize=8)\n",
    "axes[0].set_ylabel('ì‹¤ì œ ë ˆì´ë¸”')\n",
    "axes[0].set_xlabel('ì˜ˆì¸¡ ë ˆì´ë¸”')\n",
    "\n",
    "# ì˜¤ë¥¸ìª½: ì •ê·œí™” (í–‰ ê¸°ì¤€ = Recall ê¸°ì¤€)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "im2 = axes[1].imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Greens,\n",
    "                      vmin=0, vmax=1)\n",
    "axes[1].set_title('Confusion Matrix (ì •ê·œí™”, í–‰=ì‹¤ì œ í´ë˜ìŠ¤ë³„ ë¹„ìœ¨)')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "axes[1].set_xticks(tick_marks)\n",
    "axes[1].set_yticks(tick_marks)\n",
    "axes[1].set_xticklabels([str(i) for i in range(10)])\n",
    "axes[1].set_yticklabels([str(i) for i in range(10)])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        axes[1].text(j, i, f'{cm_normalized[i, j]:.2f}',\n",
    "                    ha='center', va='center',\n",
    "                    color='white' if cm_normalized[i, j] > 0.5 else 'black',\n",
    "                    fontsize=8)\n",
    "axes[1].set_ylabel('ì‹¤ì œ ë ˆì´ë¸”')\n",
    "axes[1].set_xlabel('ì˜ˆì¸¡ ë ˆì´ë¸”')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ëŒ€ê°ì„  = ì˜¬ë°”ë¥¸ ì˜ˆì¸¡, ì˜¤í”„ ëŒ€ê°ì„  = ì˜¤ë¶„ë¥˜\n",
    "total_acc = np.trace(cm) / cm.sum()\n",
    "print(f\"ì „ì²´ ì •í™•ë„: {total_acc:.4f}\")\n",
    "print(\"\\nê°€ì¥ í˜¼ë™ì´ ë§ì€ í´ë˜ìŠ¤ ìŒ (ì˜¤ë¶„ë¥˜ ìˆœ):\")\n",
    "off_diagonal = [(cm[i, j], i, j) for i in range(10) for j in range(10) if i != j]\n",
    "off_diagonal.sort(reverse=True)\n",
    "for count, true_cls, pred_cls in off_diagonal[:5]:\n",
    "    print(f\"  ì‹¤ì œ {true_cls} -> ì˜ˆì¸¡ {pred_cls}: {count}ê±´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ROC Curveì™€ AUC\n",
    "\n",
    "**ROC Curve (Receiver Operating Characteristic)**ëŠ” ë‹¤ì–‘í•œ ì„ê³„ê°’ì—ì„œì˜ TPRê³¼ FPRì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.\n",
    "\n",
    "$$TPR = Recall = \\frac{TP}{TP + FN}, \\quad FPR = \\frac{FP}{FP + TN}$$\n",
    "\n",
    "**AUC (Area Under the Curve)**: ROC ê³¡ì„  ì•„ë˜ ë©´ì \n",
    "- AUC = 1.0: ì™„ë²½í•œ ë¶„ë¥˜ê¸°\n",
    "- AUC = 0.5: ëœë¤ ë¶„ë¥˜ê¸° (ëŒ€ê°ì„ )\n",
    "- AUC = 0.0: ì™„ì „íˆ ë°˜ëŒ€ë¡œ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# ROC Curveì™€ AUC ì‹œê°í™” (ì´ì§„ ë¶„ë¥˜)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ë°ì´í„° ìƒì„±\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_bin, y_bin = make_classification(\n",
    "    n_samples=2000, n_features=20, n_informative=15,\n",
    "    random_state=42\n",
    ")\n",
    "X_bin = X_bin.astype('float32')\n",
    "\n",
    "# ë¶„í• \n",
    "split = 1500\n",
    "X_bin_train, X_bin_test = X_bin[:split], X_bin[split:]\n",
    "y_bin_train, y_bin_test = y_bin[:split], y_bin[split:]\n",
    "\n",
    "# ì´ì§„ ë¶„ë¥˜ ëª¨ë¸\n",
    "tf.random.set_seed(42)\n",
    "model_roc = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(20,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_roc.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "model_roc.fit(X_bin_train, y_bin_train, epochs=10, batch_size=32,\n",
    "               validation_split=0.2, verbose=0)\n",
    "\n",
    "# ì˜ˆì¸¡ í™•ë¥ \n",
    "y_pred_prob = model_roc.predict(X_bin_test, verbose=0).flatten()\n",
    "\n",
    "# sklearnìœ¼ë¡œ ROC Curve ê³„ì‚°\n",
    "fpr, tpr, thresholds = roc_curve(y_bin_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# TF AUC ë©”íŠ¸ë¦­\n",
    "tf_auc = tf.keras.metrics.AUC()\n",
    "tf_auc.update_state(y_bin_test, y_pred_prob)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC Curve\n",
    "axes[0].plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
    "             label='ëœë¤ ë¶„ë¥˜ê¸° (AUC = 0.5)')\n",
    "axes[0].fill_between(fpr, tpr, alpha=0.1, color='darkorange')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('FPR (False Positive Rate)')\n",
    "axes[0].set_ylabel('TPR (True Positive Rate = Recall)')\n",
    "axes[0].set_title('ROC Curve')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_bin_test, y_pred_prob)\n",
    "avg_precision = average_precision_score(y_bin_test, y_pred_prob)\n",
    "\n",
    "axes[1].plot(recall_vals, precision_vals, color='purple', lw=2,\n",
    "             label=f'PR Curve (AP = {avg_precision:.4f})')\n",
    "axes[1].axhline(y=sum(y_bin_test)/len(y_bin_test), color='navy', linestyle='--',\n",
    "                label=f'ëœë¤ ë¶„ë¥˜ê¸° (baseline = {sum(y_bin_test)/len(y_bin_test):.2f})')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve')\n",
    "axes[1].legend(loc='lower left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"sklearn AUC: {roc_auc:.4f}\")\n",
    "print(f\"TF     AUC: {tf_auc.result().numpy():.4f}\")\n",
    "print(\"\\në¶ˆê· í˜• ë°ì´í„°ì…‹ì—ì„œëŠ” AUCë³´ë‹¤ Average Precision(PR-AUC)ì´ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§€í‘œì´ë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­\n",
    "\n",
    "`tf.keras.metrics.Metric`ì„ ìƒì†í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "í•„ìˆ˜ ë©”ì„œë“œ:\n",
    "- `__init__`: ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™” (`add_weight` ì‚¬ìš©)\n",
    "- `update_state`: ë°°ì¹˜ë§ˆë‹¤ ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "- `result`: í˜„ì¬ê¹Œì§€ ëˆ„ì ëœ ë©”íŠ¸ë¦­ ê°’ ë°˜í™˜\n",
    "- `reset_state`: ì—í¬í¬ í›„ ìƒíƒœ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­: MAPE (Mean Absolute Percentage Error)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "class MeanAbsolutePercentageError(tf.keras.metrics.Metric):\n",
    "    \"\"\"í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨ (MAPE)\n",
    "    \n",
    "    ìˆ˜ì‹: MAPE = (1/N) * sum(|y_true - y_pred| / |y_true|) * 100\n",
    "    - í¼ì„¼íŠ¸ ë‹¨ìœ„ë¡œ í‘œí˜„ë˜ì–´ ì§ê´€ì \n",
    "    - y_trueê°€ 0ì— ê°€ê¹Œìš¸ ë•Œ ë¶ˆì•ˆì •\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name='mape', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        # ëˆ„ì  í•©ì„ ì €ì¥í•  ìƒíƒœ ë³€ìˆ˜\n",
    "        self.total = self.add_weight(\n",
    "            name='total',\n",
    "            initializer='zeros'\n",
    "        )\n",
    "        self.count = self.add_weight(\n",
    "            name='count',\n",
    "            initializer='zeros'\n",
    "        )\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"ë°°ì¹˜ë§ˆë‹¤ MAPE ëˆ„ì \"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "        # ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨ ê³„ì‚°\n",
    "        # y_true = 0ì¸ ê²½ìš° ë¶„ëª¨ì— ì‘ì€ ê°’ ì¶”ê°€ (epsilon)\n",
    "        abs_pct_error = tf.abs((y_true - y_pred) / (tf.abs(y_true) + 1e-7)) * 100.0\n",
    "        \n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, tf.float32)\n",
    "            abs_pct_error = abs_pct_error * sample_weight\n",
    "        \n",
    "        # ë°°ì¹˜ í•©ì‚° ë° ê°œìˆ˜ ì—…ë°ì´íŠ¸\n",
    "        self.total.assign_add(tf.reduce_sum(abs_pct_error))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    \n",
    "    def result(self):\n",
    "        \"\"\"í˜„ì¬ê¹Œì§€ ëˆ„ì ëœ MAPE ë°˜í™˜\"\"\"\n",
    "        return self.total / (self.count + 1e-7)\n",
    "    \n",
    "    def reset_state(self):\n",
    "        \"\"\"ì—í¬í¬ í›„ ìƒíƒœ ì´ˆê¸°í™”\"\"\"\n",
    "        self.total.assign(0.0)\n",
    "        self.count.assign(0.0)\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "mape = MeanAbsolutePercentageError()\n",
    "\n",
    "# ë°°ì¹˜ 1\n",
    "y_true_b1 = tf.constant([100.0, 200.0, 50.0])\n",
    "y_pred_b1 = tf.constant([110.0, 190.0, 55.0])  # ì˜¤ì°¨: 10%, 5%, 10%\n",
    "mape.update_state(y_true_b1, y_pred_b1)\n",
    "print(f\"ë°°ì¹˜ 1 í›„ MAPE: {mape.result().numpy():.2f}%\")\n",
    "\n",
    "# ë°°ì¹˜ 2 (ëˆ„ì )\n",
    "y_true_b2 = tf.constant([80.0, 120.0])\n",
    "y_pred_b2 = tf.constant([88.0, 108.0])   # ì˜¤ì°¨: 10%, 10%\n",
    "mape.update_state(y_true_b2, y_pred_b2)\n",
    "print(f\"ë°°ì¹˜ 2 í›„ MAPE (ëˆ„ì ): {mape.result().numpy():.2f}%\")\n",
    "\n",
    "# ì´ˆê¸°í™” í›„ ì¬ì‚¬ìš©\n",
    "mape.reset_state()\n",
    "print(f\"ì´ˆê¸°í™” í›„ MAPE: {mape.result().numpy():.2f}%\")\n",
    "\n",
    "# ëª¨ë¸ì— ì ìš©\n",
    "print(\"\\n=== ëª¨ë¸ì— ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì ìš© ===\")\n",
    "print(\"\"\"\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=[\n",
    "        'mae',\n",
    "        MeanAbsolutePercentageError()  # ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­\n",
    "    ]\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì •ë¦¬\n",
    "\n",
    "### ë©”íŠ¸ë¦­ ì„ íƒ ê°€ì´ë“œ\n",
    "\n",
    "| ë¬¸ì œ ìœ í˜• | ê¶Œì¥ ë©”íŠ¸ë¦­ | ë¹„ê³  |\n",
    "|-----------|------------|------|\n",
    "| ì´ì§„ ë¶„ë¥˜ (ê· í˜•) | Accuracy, AUC | |\n",
    "| ì´ì§„ ë¶„ë¥˜ (ë¶ˆê· í˜•) | Precision, Recall, F1, PR-AUC | AccuracyëŠ” ì˜¤í•´ ìœ ë°œ ê°€ëŠ¥ |\n",
    "| ë‹¤ì¤‘ ë¶„ë¥˜ | Accuracy, Macro/Micro F1 | í´ë˜ìŠ¤ë³„ ë¶ˆê· í˜• ì£¼ì˜ |\n",
    "| íšŒê·€ | MAE, MSE, MAPE, RÂ² | ë„ë©”ì¸ì— ë”°ë¼ ì„ íƒ |\n",
    "\n",
    "### ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì‘ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "1. `tf.keras.metrics.Metric` ìƒì†\n",
    "2. `__init__`ì—ì„œ `add_weight`ë¡œ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "3. `update_state`ì—ì„œ ë°°ì¹˜ ê²°ê³¼ë¥¼ ìƒíƒœì— ëˆ„ì \n",
    "4. `result`ì—ì„œ ìµœì¢… ë©”íŠ¸ë¦­ ê°’ ê³„ì‚°í•˜ì—¬ ë°˜í™˜\n",
    "5. `reset_state`ì—ì„œ ìƒíƒœ ë³€ìˆ˜ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”\n",
    "\n",
    "### í•µì‹¬ ì •ë¦¬\n",
    "- **Confusion Matrix**: í´ë˜ìŠ¤ë³„ ì˜¤ë¶„ë¥˜ íŒ¨í„´ì„ í•œëˆˆì— íŒŒì•…\n",
    "- **ROC-AUC**: ì„ê³„ê°’ì— ë…ë¦½ì ì¸ ì „ë°˜ì ì¸ ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€\n",
    "- **PR-AUC**: ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§€í‘œ\n",
    "- ë©”íŠ¸ë¦­ì€ ë°°ì¹˜ë§ˆë‹¤ `update_state`ë¡œ ëˆ„ì í•˜ê³ , ì—í¬í¬ í›„ `reset_state`ë¡œ ì´ˆê¸°í™”í•œë‹¤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}