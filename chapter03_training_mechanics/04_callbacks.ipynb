{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 03-04: ì½œë°± (Callbacks)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- ì½œë°±ì˜ ê°œë…ê³¼ ë™ì‘ ì‹œì ì„ ì´í•´í•œë‹¤\n",
    "- ModelCheckpoint, EarlyStopping, ReduceLROnPlateau ë“± ì£¼ìš” ë‚´ì¥ ì½œë°±ì„ í™œìš©í•  ìˆ˜ ìˆë‹¤\n",
    "- TensorBoard ì½œë°±ìœ¼ë¡œ í•™ìŠµ ê³¼ì •ì„ ì‹œê°í™”í•  ìˆ˜ ìˆë‹¤\n",
    "- `tf.keras.callbacks.Callback`ì„ ìƒì†í•˜ì—¬ ì»¤ìŠ¤í…€ ì½œë°±ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ì½œë°±ì´ë€?](#1.-ì½œë°±ì´ë€?)\n",
    "2. [ModelCheckpoint](#2.-ModelCheckpoint)\n",
    "3. [EarlyStopping](#3.-EarlyStopping)\n",
    "4. [ReduceLROnPlateau](#4.-ReduceLROnPlateau)\n",
    "5. [TensorBoard](#5.-TensorBoard)\n",
    "6. [ì»¤ìŠ¤í…€ ì½œë°±](#6.-ì»¤ìŠ¤í…€-ì½œë°±)\n",
    "7. [ì •ë¦¬](#7.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ì½œë°± ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### â° ì½œë°±(Callback)ì´ ë­ì˜ˆìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: ìš”ë¦¬ íƒ€ì´ë¨¸ì²˜ëŸ¼!\n",
    "> íƒ€ì´ë¨¸ë¥¼ ë§ì¶°ë†“ìœ¼ë©´ íŠ¹ì • ì‹œê°„ì— **ìë™ìœ¼ë¡œ ì•ŒëŒ**ì´ ìš¸ë ¤ìš”.\n",
    "> ì½œë°±ë„ í•™ìŠµ ì¤‘ íŠ¹ì • ìˆœê°„ì— **ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ì½”ë“œ**ì˜ˆìš”!\n",
    "\n",
    "#### ğŸ“‹ ì£¼ìš” ì½œë°± ì—­í•  í•œëˆˆì— ë³´ê¸°\n",
    "\n",
    "| ì½œë°± | ì—­í•  | ë¹„ìœ  |\n",
    "|------|------|------|\n",
    "| **ModelCheckpoint** | ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì €ì¥ | ì‹œí—˜ë§ˆë‹¤ ìµœê³  ì ìˆ˜ ê¸°ë¡ ğŸ“ |\n",
    "| **EarlyStopping** | ê°œì„  ì—†ìœ¼ë©´ í•™ìŠµ ì¤‘ë‹¨ | ë” ì´ìƒ ì‹¤ë ¥ì´ ì•ˆ ëŠ˜ë©´ íœ´ì‹ ğŸ›‘ |\n",
    "| **ReduceLROnPlateau** | ì •ì²´ ì‹œ í•™ìŠµë¥  ê°ì†Œ | ë§‰íˆë©´ ì†ë„ ì¤„ì´ê³  ì‹ ì¤‘í•˜ê²Œ ğŸŒ |\n",
    "| **TensorBoard** | í•™ìŠµ ê³¼ì • ì‹¤ì‹œê°„ ì‹œê°í™” | ì„±ì í‘œë¥¼ ê·¸ë˜í”„ë¡œ ë³´ê¸° ğŸ“Š |\n",
    "\n",
    "#### ğŸ”„ ì½œë°±ì´ í˜¸ì¶œë˜ëŠ” ìˆœê°„\n",
    "\n",
    "```\n",
    "í•™ìŠµ ì‹œì‘ â”€â”€â†’ [on_train_begin]\n",
    "  ì—í¬í¬ ì‹œì‘ â”€â”€â†’ [on_epoch_begin]\n",
    "    ë°°ì¹˜ ì‹œì‘ â”€â”€â†’ [on_train_batch_begin]\n",
    "    ë°°ì¹˜ ì¢…ë£Œ â”€â”€â†’ [on_train_batch_end]\n",
    "  ì—í¬í¬ ì¢…ë£Œ â”€â”€â†’ [on_epoch_end]  â† ì—¬ê¸°ì„œ ì²´í¬í¬ì¸íŠ¸/ì¡°ê¸°ì¢…ë£Œ ì²´í¬!\n",
    "í•™ìŠµ ì¢…ë£Œ â”€â”€â†’ [on_train_end]\n",
    "```\n",
    "\n",
    "> ğŸ’¡ **ì™œ í•„ìš”í•´ìš”?**\n",
    "> ìˆ˜ë°± ì—í¬í¬ í•™ìŠµ ì¤‘ì— ì¼ì¼ì´ ëª¨ë‹ˆí„°ë§ í•  ìˆ˜ ì—†ìœ¼ë‹ˆê¹Œìš”!\n",
    "> ì½œë°±ì´ ìë™ìœ¼ë¡œ 'ì¢‹ì€ ëª¨ë¸ ì €ì¥', 'ê³¼ì í•© ê°ì§€', 'í•™ìŠµë¥  ì¡°ì ˆ'ì„ í•´ì¤˜ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "print(\"TensorFlow ë²„ì „:\", tf.__version__)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ì½œë°±ì´ë€?\n",
    "\n",
    "ì½œë°±(Callback)ì€ **í•™ìŠµ ì¤‘ íŠ¹ì • ì‹œì ì— ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜(ë˜ëŠ” ê°ì²´)**ì´ë‹¤.\n",
    "\n",
    "### ì½œë°±ì´ í˜¸ì¶œë˜ëŠ” ì‹œì \n",
    "\n",
    "| ë©”ì„œë“œ | í˜¸ì¶œ ì‹œì  |\n",
    "|--------|----------|\n",
    "| `on_train_begin` | ì „ì²´ í•™ìŠµ ì‹œì‘ ì „ |\n",
    "| `on_train_end` | ì „ì²´ í•™ìŠµ ì¢…ë£Œ í›„ |\n",
    "| `on_epoch_begin` | ê° ì—í¬í¬ ì‹œì‘ ì „ |\n",
    "| `on_epoch_end` | ê° ì—í¬í¬ ì¢…ë£Œ í›„ |\n",
    "| `on_train_batch_begin` | ê° í›ˆë ¨ ë°°ì¹˜ ì‹œì‘ ì „ |\n",
    "| `on_train_batch_end` | ê° í›ˆë ¨ ë°°ì¹˜ ì¢…ë£Œ í›„ |\n",
    "| `on_test_begin` | í‰ê°€(evaluate) ì‹œì‘ ì „ |\n",
    "| `on_predict_begin` | ì˜ˆì¸¡(predict) ì‹œì‘ ì „ |\n",
    "\n",
    "```python\n",
    "# ì½œë°± ì‚¬ìš© ë°©ë²•: model.fitì˜ callbacks ì¸ìˆ˜ì— ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    callbacks=[callback1, callback2, callback3]  # ë³µìˆ˜ì˜ ì½œë°±ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# ê³µí†µ ë°ì´í„° ë° ëª¨ë¸ ì¤€ë¹„\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# MNIST ë°ì´í„° ë¡œë“œ\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 784).astype('float32') / 255.0\n",
    "X_test  = X_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "# ë¹ ë¥¸ ì‹¤í—˜ìš© ì„œë¸Œì…‹\n",
    "X_tr = X_train[:6000]\n",
    "y_tr = y_train[:6000]\n",
    "X_val = X_train[6000:8000]\n",
    "y_val = y_train[6000:8000]\n",
    "\n",
    "def build_model(lr=0.001):\n",
    "    \"\"\"ì‹¤í—˜ìš© ê°„ë‹¨í•œ MLP ëª¨ë¸ ìƒì„±\"\"\"\n",
    "    tf.random.set_seed(42)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"  í›ˆë ¨: {X_tr.shape}, ê²€ì¦: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ModelCheckpoint\n",
    "\n",
    "í•™ìŠµ ì¤‘ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ë˜ëŠ” ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ìë™ ì €ì¥í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# ModelCheckpoint: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìë™ ì €ì¥\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
    "checkpoint_dir = './checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# ModelCheckpoint ì½œë°± ì„¤ì •\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, 'best_model.keras'),  # ì €ì¥ ê²½ë¡œ\n",
    "    monitor='val_accuracy',   # ëª¨ë‹ˆí„°í•  ì§€í‘œ\n",
    "    save_best_only=True,      # True: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë§Œ ì €ì¥ (ê¸°ë³¸: ë§¤ ì—í¬í¬)\n",
    "    save_weights_only=False,  # False: ì „ì²´ ëª¨ë¸ ì €ì¥ (True: ê°€ì¤‘ì¹˜ë§Œ)\n",
    "    mode='max',               # 'max': í´ìˆ˜ë¡ ì¢‹ìŒ (accuracy), 'min': ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ (loss)\n",
    "    verbose=1                 # ì €ì¥ ì‹œ ì¶œë ¥\n",
    ")\n",
    "\n",
    "# ì—í¬í¬ë³„ ì €ì¥ (íŒŒì¼ëª…ì— ì—í¬í¬ ë²ˆí˜¸ì™€ ì§€í‘œ í¬í•¨)\n",
    "checkpoint_all = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, 'epoch_{epoch:02d}_val_acc_{val_accuracy:.4f}.keras'),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=False,     # ëª¨ë“  ì—í¬í¬ ì €ì¥\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "model = build_model()\n",
    "history = model.fit(\n",
    "    X_tr, y_tr,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ ===\")\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    for f in os.listdir(checkpoint_dir):\n",
    "        print(f\"  {f}\")\n",
    "\n",
    "# ì €ì¥ëœ ìµœê³  ëª¨ë¸ ë¡œë“œ\n",
    "print(\"\\n=== ì €ì¥ëœ ìµœê³  ëª¨ë¸ ë¡œë“œ ===\")\n",
    "best_model_path = os.path.join(checkpoint_dir, 'best_model.keras')\n",
    "if os.path.exists(best_model_path):\n",
    "    loaded_model = tf.keras.models.load_model(best_model_path)\n",
    "    test_loss, test_acc = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"ë¡œë“œëœ ìµœê³  ëª¨ë¸ - í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EarlyStopping\n",
    "\n",
    "ê²€ì¦ ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ í•™ìŠµì„ ì¡°ê¸° ì¢…ë£Œí•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# EarlyStopping: ì¡°ê¸° ì¢…ë£Œ\n",
    "# ---------------------------------------------------\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',           # ëª¨ë‹ˆí„°í•  ì§€í‘œ\n",
    "    patience=5,                   # ê°œì„  ì—†ì´ ê¸°ë‹¤ë¦´ ì—í¬í¬ ìˆ˜\n",
    "    min_delta=0.001,              # ê°œì„ ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ ë³€í™”ëŸ‰\n",
    "    restore_best_weights=True,    # ê°€ì¥ ì¢‹ì€ ê°€ì¤‘ì¹˜ë¡œ ë³µì› (ì¤‘ìš”!)\n",
    "    mode='min',                   # 'min': ì†ì‹¤ì´ ê°ì†Œí•´ì•¼ ê°œì„ \n",
    "    baseline=None,                # ê¸°ì¤€ê°’ (None: ì—†ìŒ)\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ModelCheckpointì™€ í•¨ê»˜ ì‚¬ìš© (ê¶Œì¥ íŒ¨í„´)\n",
    "checkpoint_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, 'early_stop_best.keras'),\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "model_es = build_model(lr=0.001)\n",
    "print(\"EarlyStopping patience=5ë¡œ ìµœëŒ€ 30 ì—í¬í¬ í•™ìŠµ ì‹œë„\")\n",
    "history_es = model_es.fit(\n",
    "    X_tr, y_tr,\n",
    "    epochs=30,                          # ìµœëŒ€ ì—í¬í¬ (ì¡°ê¸° ì¢…ë£Œ ê°€ëŠ¥)\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, checkpoint_best],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "actual_epochs = len(history_es.history['loss'])\n",
    "print(f\"\\nì‹¤ì œ í•™ìŠµ ì—í¬í¬ ìˆ˜: {actual_epochs} / 30\")\n",
    "print(f\"ìµœê³  ê²€ì¦ ì†ì‹¤: {min(history_es.history['val_loss']):.4f}\")\n",
    "print(f\"ìµœì¢… ê²€ì¦ ì •í™•ë„: {history_es.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"restore_best_weights=Trueì´ë¯€ë¡œ ì¡°ê¸° ì¢…ë£Œ ì‹œì ì´ ì•„ë‹Œ ìµœê³  ì„±ëŠ¥ ì‹œì ì˜ ê°€ì¤‘ì¹˜ ì‚¬ìš©\")\n",
    "\n",
    "# í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "epochs_range = range(1, actual_epochs + 1)\n",
    "\n",
    "axes[0].plot(epochs_range, history_es.history['loss'], label='í›ˆë ¨ ì†ì‹¤')\n",
    "axes[0].plot(epochs_range, history_es.history['val_loss'], label='ê²€ì¦ ì†ì‹¤')\n",
    "axes[0].axvline(x=actual_epochs, color='red', linestyle='--', label='ì¡°ê¸° ì¢…ë£Œ ì‹œì ')\n",
    "axes[0].set_xlabel('ì—í¬í¬')\n",
    "axes[0].set_ylabel('ì†ì‹¤')\n",
    "axes[0].set_title('EarlyStopping - ì†ì‹¤ ê³¡ì„ ')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(epochs_range, history_es.history['accuracy'], label='í›ˆë ¨ ì •í™•ë„')\n",
    "axes[1].plot(epochs_range, history_es.history['val_accuracy'], label='ê²€ì¦ ì •í™•ë„')\n",
    "axes[1].set_xlabel('ì—í¬í¬')\n",
    "axes[1].set_ylabel('ì •í™•ë„')\n",
    "axes[1].set_title('EarlyStopping - ì •í™•ë„ ê³¡ì„ ')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# ReduceLROnPlateau: í•™ìŠµë¥  ìë™ ê°ì†Œ\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# í•™ìŠµë¥ ì„ ê¸°ë¡í•˜ëŠ” ë„ìš°ë¯¸ ì½œë°±\n",
    "class LRRecorder(tf.keras.callbacks.Callback):\n",
    "    \"\"\"ì—í¬í¬ë³„ í•™ìŠµë¥ ì„ ê¸°ë¡í•˜ëŠ” ë³´ì¡° ì½œë°±\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr_history = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(self.model.optimizer.learning_rate)\n",
    "        self.lr_history.append(lr)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',   # ëª¨ë‹ˆí„° ì§€í‘œ\n",
    "    factor=0.5,           # í•™ìŠµë¥  ê°ì†Œ ë°°ìœ¨: new_lr = lr * factor\n",
    "    patience=3,           # ê°œì„  ì—†ì´ ê¸°ë‹¤ë¦´ ì—í¬í¬\n",
    "    min_lr=1e-6,          # í•™ìŠµë¥  í•˜í•œì„ \n",
    "    min_delta=0.001,      # ìµœì†Œ ê°œì„ ëŸ‰\n",
    "    cooldown=0,           # í•™ìŠµë¥  ê°ì†Œ í›„ ì‰¬ì–´ê°€ëŠ” ì—í¬í¬ ìˆ˜\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_recorder = LRRecorder()\n",
    "\n",
    "# ì˜ë„ì ìœ¼ë¡œ í° í•™ìŠµë¥ ë¡œ ì‹œì‘í•˜ì—¬ ê°ì†Œ ê³¼ì • ê´€ì°°\n",
    "model_rlr = build_model(lr=0.01)\n",
    "history_rlr = model_rlr.fit(\n",
    "    X_tr, y_tr,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[reduce_lr, lr_recorder],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# í•™ìŠµë¥  ë³€í™” ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "epochs_range = range(1, len(history_rlr.history['loss']) + 1)\n",
    "\n",
    "axes[0].semilogy(epochs_range, lr_recorder.lr_history, 'bo-', linewidth=2)\n",
    "axes[0].set_xlabel('ì—í¬í¬')\n",
    "axes[0].set_ylabel('í•™ìŠµë¥  (ë¡œê·¸ ìŠ¤ì¼€ì¼)')\n",
    "axes[0].set_title('ReduceLROnPlateau - í•™ìŠµë¥  ë³€í™”')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(epochs_range, history_rlr.history['val_loss'], 'r-', linewidth=2)\n",
    "axes[1].set_xlabel('ì—í¬í¬')\n",
    "axes[1].set_ylabel('ê²€ì¦ ì†ì‹¤')\n",
    "axes[1].set_title('ê²€ì¦ ì†ì‹¤ ë³€í™”')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ì´ˆê¸° í•™ìŠµë¥ : {lr_recorder.lr_history[0]:.6f}\")\n",
    "print(f\"ìµœì¢… í•™ìŠµë¥ : {lr_recorder.lr_history[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TensorBoard\n",
    "\n",
    "TensorBoardëŠ” í•™ìŠµ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‹œê°í™”í•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# TensorBoard ì½œë°± ì„¤ì •\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± (ì‹¤í—˜ë³„ êµ¬ë¶„)\n",
    "log_dir = os.path.join(\n",
    "    './logs',\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    ")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,              # ë¡œê·¸ ì €ì¥ ê²½ë¡œ\n",
    "    histogram_freq=1,             # N ì—í¬í¬ë§ˆë‹¤ ê°€ì¤‘ì¹˜/í¸í–¥ íˆìŠ¤í† ê·¸ë¨ ê¸°ë¡ (0=ë¹„í™œì„±)\n",
    "    write_graph=True,             # ëª¨ë¸ ê·¸ë˜í”„ ê¸°ë¡\n",
    "    write_images=False,           # ê°€ì¤‘ì¹˜ë¥¼ ì´ë¯¸ì§€ë¡œ ê¸°ë¡ ì—¬ë¶€\n",
    "    update_freq='epoch',          # 'epoch' ë˜ëŠ” 'batch' ë˜ëŠ” ì •ìˆ˜\n",
    "    profile_batch=0               # ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë°°ì¹˜ (0=ë¹„í™œì„±)\n",
    ")\n",
    "\n",
    "model_tb = build_model()\n",
    "print(f\"TensorBoard ë¡œê·¸ ê²½ë¡œ: {log_dir}\")\n",
    "print()\n",
    "\n",
    "model_tb.fit(\n",
    "    X_tr, y_tr,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== TensorBoard ì‹¤í–‰ ë°©ë²• ===\")\n",
    "print(f\"í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰:\")\n",
    "print(f\"  tensorboard --logdir=./logs\")\n",
    "print(f\"ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:6006 ì ‘ì†\")\n",
    "print()\n",
    "print(\"Jupyter Notebookì—ì„œ ì§ì ‘ ì‹¤í–‰:\")\n",
    "print(\"  %load_ext tensorboard\")\n",
    "print(\"  %tensorboard --logdir ./logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì»¤ìŠ¤í…€ ì½œë°±\n",
    "\n",
    "`tf.keras.callbacks.Callback`ì„ ìƒì†í•˜ì—¬ ì›í•˜ëŠ” ë™ì‘ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# ì»¤ìŠ¤í…€ ì½œë°±: ì—í¬í¬ë³„ í•™ìŠµë¥  ë° ë©”íŠ¸ë¦­ ì¶œë ¥\n",
    "# ---------------------------------------------------\n",
    "\n",
    "class DetailedLoggingCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"ì—í¬í¬ ì¢…ë£Œ ì‹œ í•™ìŠµë¥ ê³¼ ì£¼ìš” ë©”íŠ¸ë¦­ì„ ìƒì„¸í•˜ê²Œ ì¶œë ¥í•˜ëŠ” ì½œë°±\"\"\"\n",
    "    \n",
    "    def __init__(self, print_every=1):\n",
    "        super().__init__()\n",
    "        self.print_every = print_every  # N ì—í¬í¬ë§ˆë‹¤ ì¶œë ¥\n",
    "        self.lr_history = []           # í•™ìŠµë¥  ê¸°ë¡\n",
    "        self.metrics_history = {}      # ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"í•™ìŠµ ì‹œì‘ ì‹œ í—¤ë” ì¶œë ¥\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"í•™ìŠµ ì‹œì‘\")\n",
    "        print(f\"ì˜µí‹°ë§ˆì´ì €: {self.model.optimizer.__class__.__name__}\")\n",
    "        print(f\"ì´ˆê¸° í•™ìŠµë¥ : {float(self.model.optimizer.learning_rate):.6f}\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"ì—í¬í¬ ì‹œì‘ ì „ í˜„ì¬ í•™ìŠµë¥  ì¶œë ¥\"\"\"\n",
    "        current_lr = float(self.model.optimizer.learning_rate)\n",
    "        self.lr_history.append(current_lr)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"ì—í¬í¬ ì¢…ë£Œ í›„ ìƒì„¸ ë¡œê·¸ ì¶œë ¥\"\"\"\n",
    "        logs = logs or {}\n",
    "        \n",
    "        # ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "        for key, value in logs.items():\n",
    "            if key not in self.metrics_history:\n",
    "                self.metrics_history[key] = []\n",
    "            self.metrics_history[key].append(value)\n",
    "        \n",
    "        # N ì—í¬í¬ë§ˆë‹¤ ì¶œë ¥\n",
    "        if (epoch + 1) % self.print_every == 0:\n",
    "            current_lr = float(self.model.optimizer.learning_rate)\n",
    "            loss = logs.get('loss', 0)\n",
    "            val_loss = logs.get('val_loss', 0)\n",
    "            acc = logs.get('accuracy', 0)\n",
    "            val_acc = logs.get('val_accuracy', 0)\n",
    "            \n",
    "            print(f\"[ì—í¬í¬ {epoch+1:3d}] \"\n",
    "                  f\"lr={current_lr:.6f} | \"\n",
    "                  f\"loss={loss:.4f} | \"\n",
    "                  f\"val_loss={val_loss:.4f} | \"\n",
    "                  f\"acc={acc:.4f} | \"\n",
    "                  f\"val_acc={val_acc:.4f}\")\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        \"\"\"í•™ìŠµ ì™„ë£Œ í›„ ìš”ì•½ ì¶œë ¥\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"í•™ìŠµ ì™„ë£Œ\")\n",
    "        if 'val_accuracy' in self.metrics_history:\n",
    "            best_epoch = np.argmax(self.metrics_history['val_accuracy']) + 1\n",
    "            best_val_acc = max(self.metrics_history['val_accuracy'])\n",
    "            print(f\"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.4f} (ì—í¬í¬ {best_epoch})\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# ì»¤ìŠ¤í…€ ì½œë°± ì‚¬ìš©\n",
    "detailed_logger = DetailedLoggingCallback(print_every=2)\n",
    "reduce_lr2 = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=3, verbose=0\n",
    ")\n",
    "\n",
    "model_custom = build_model(lr=0.005)\n",
    "model_custom.fit(\n",
    "    X_tr, y_tr,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[detailed_logger, reduce_lr2],\n",
    "    verbose=0  # ê¸°ë³¸ ì¶œë ¥ ë¹„í™œì„±í™”\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì •ë¦¬\n",
    "\n",
    "### ì½œë°± ì‚¬ìš© íŒ¨í„´ ê°€ì´ë“œ\n",
    "\n",
    "#### ê¸°ë³¸ ê¶Œì¥ ì¡°í•©\n",
    "```python\n",
    "callbacks = [\n",
    "    # ìµœê³  ëª¨ë¸ ì €ì¥\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    # ê³¼ì í•© ë°©ì§€ ì¡°ê¸° ì¢…ë£Œ\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    # í•™ìŠµë¥  ìë™ ê°ì†Œ\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5\n",
    "    ),\n",
    "    # ì‹œê°í™”\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "```\n",
    "\n",
    "### ì½œë°±ë³„ í•µì‹¬ íŒŒë¼ë¯¸í„° ìš”ì•½\n",
    "\n",
    "| ì½œë°± | í•µì‹¬ íŒŒë¼ë¯¸í„° | ì„¤ëª… |\n",
    "|------|--------------|------|\n",
    "| ModelCheckpoint | `save_best_only`, `monitor` | ìµœê³  ëª¨ë¸ë§Œ ì €ì¥ vs ëª¨ë“  ì—í¬í¬ ì €ì¥ |\n",
    "| EarlyStopping | `patience`, `restore_best_weights` | ì¡°ê¸° ì¢…ë£Œ í›„ ìµœê³  ê°€ì¤‘ì¹˜ ë³µì› |\n",
    "| ReduceLROnPlateau | `factor`, `patience`, `min_lr` | í•™ìŠµë¥  ê°ì†Œ ë°°ìœ¨ê³¼ ìµœì†Œ í•˜í•œì„  |\n",
    "| TensorBoard | `histogram_freq`, `log_dir` | íˆìŠ¤í† ê·¸ë¨ ê¸°ë¡ ì£¼ê¸° |\n",
    "\n",
    "### ì»¤ìŠ¤í…€ ì½œë°± êµ¬í˜„ í¬ì¸íŠ¸\n",
    "- ì ì ˆí•œ ë©”ì„œë“œ(`on_epoch_end`, `on_batch_end` ë“±)ë¥¼ ì˜¤ë²„ë¼ì´ë“œ\n",
    "- `self.model`ë¡œ í˜„ì¬ ëª¨ë¸ì— ì ‘ê·¼ ê°€ëŠ¥\n",
    "- `logs` ë”•ì…”ë„ˆë¦¬ì—ì„œ í˜„ì¬ ë©”íŠ¸ë¦­ ê°’ ì°¸ì¡° ê°€ëŠ¥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}