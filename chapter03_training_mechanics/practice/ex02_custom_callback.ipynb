{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 03 실습 2: 커스텀 콜백 구현\n",
    "\n",
    "## 목표\n",
    "에포크마다 현재 학습률을 기록하고 시각화하는 콜백을 구현한다.\n",
    "\n",
    "## 실습 내용\n",
    "- `tf.keras.callbacks.Callback`을 상속하여 `LearningRateLogger` 구현\n",
    "- `ReduceLROnPlateau`와 함께 사용하여 학습률 변화 과정 관찰\n",
    "- 학습률 변화 곡선과 손실 곡선을 함께 시각화\n",
    "- 커스텀 콜백의 활용 패턴 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow 버전:\", tf.__version__)\n",
    "\n",
    "# 재현성을 위한 시드 고정\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# LearningRateLogger 커스텀 콜백 구현\n",
    "# ---------------------------------------------------\n",
    "\n",
    "class LearningRateLogger(tf.keras.callbacks.Callback):\n",
    "    \"\"\"에포크별 학습률을 기록하는 커스텀 콜백.\n",
    "    \n",
    "    ReduceLROnPlateau 등 학습률을 변경하는 콜백과 함께 사용하면\n",
    "    학습률이 언제, 얼마나 변경되었는지 추적할 수 있다.\n",
    "    \n",
    "    Attributes:\n",
    "        lr_history: 에포크별 학습률 기록 리스트\n",
    "        epoch_history: 에포크 번호 리스트\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__()\n",
    "        self.verbose = verbose\n",
    "        self.lr_history = []        # 에포크별 학습률\n",
    "        self.epoch_history = []     # 에포크 번호\n",
    "        self.lr_change_epochs = []  # 학습률이 변경된 에포크\n",
    "        self._prev_lr = None        # 이전 학습률 (변화 감지용)\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"학습 시작 시 초기화\"\"\"\n",
    "        self.lr_history = []\n",
    "        self.epoch_history = []\n",
    "        self.lr_change_epochs = []\n",
    "        self._prev_lr = None\n",
    "        \n",
    "        initial_lr = float(self.model.optimizer.learning_rate)\n",
    "        if self.verbose:\n",
    "            print(f\"LearningRateLogger 시작 - 초기 학습률: {initial_lr:.6f}\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"에포크 종료 후 현재 학습률을 기록\n",
    "        \n",
    "        Args:\n",
    "            epoch: 현재 에포크 번호 (0부터 시작)\n",
    "            logs: 현재 에포크의 메트릭 딕셔너리\n",
    "        \"\"\"\n",
    "        # 현재 학습률 가져오기\n",
    "        current_lr = float(self.model.optimizer.learning_rate)\n",
    "        \n",
    "        # 기록\n",
    "        self.lr_history.append(current_lr)\n",
    "        self.epoch_history.append(epoch + 1)  # 1부터 시작\n",
    "        \n",
    "        # 학습률 변화 감지\n",
    "        if self._prev_lr is not None and abs(current_lr - self._prev_lr) > 1e-10:\n",
    "            self.lr_change_epochs.append(epoch + 1)\n",
    "            if self.verbose:\n",
    "                print(f\"  [LR 변경] 에포크 {epoch+1}: \"\n",
    "                      f\"{self._prev_lr:.6f} -> {current_lr:.6f}\")\n",
    "        \n",
    "        self._prev_lr = current_lr\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        \"\"\"학습 완료 후 요약 출력\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"\\n학습률 변경 횟수: {len(self.lr_change_epochs)}\")\n",
    "            if self.lr_change_epochs:\n",
    "                print(f\"변경 에포크: {self.lr_change_epochs}\")\n",
    "            print(f\"초기 학습률: {self.lr_history[0]:.6f}\")\n",
    "            print(f\"최종 학습률: {self.lr_history[-1]:.6f}\")\n",
    "    \n",
    "    def get_lr_stats(self):\n",
    "        \"\"\"학습률 통계 반환\"\"\"\n",
    "        return {\n",
    "            'initial_lr': self.lr_history[0] if self.lr_history else None,\n",
    "            'final_lr': self.lr_history[-1] if self.lr_history else None,\n",
    "            'num_changes': len(self.lr_change_epochs),\n",
    "            'change_epochs': self.lr_change_epochs,\n",
    "            'min_lr': min(self.lr_history) if self.lr_history else None,\n",
    "            'max_lr': max(self.lr_history) if self.lr_history else None,\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"LearningRateLogger 콜백 정의 완료\")\n",
    "print(\"주요 메서드:\")\n",
    "print(\"  on_train_begin: 학습 시작 시 초기화\")\n",
    "print(\"  on_epoch_end: 매 에포크 후 학습률 기록 및 변화 감지\")\n",
    "print(\"  on_train_end: 학습 완료 후 요약\")\n",
    "print(\"  get_lr_stats: 학습률 통계 반환\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 모델 학습: ReduceLROnPlateau + LearningRateLogger\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# 데이터 준비: MNIST\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full.reshape(-1, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "X_train = X_train_full[:10000]\n",
    "y_train = y_train_full[:10000]\n",
    "X_val = X_train_full[10000:12000]\n",
    "y_val = y_train_full[10000:12000]\n",
    "\n",
    "# 모델 생성\n",
    "tf.random.set_seed(SEED)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 의도적으로 큰 학습률로 시작하여 ReduceLROnPlateau 동작 관찰\n",
    "INITIAL_LR = 0.01\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LR),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 콜백 설정\n",
    "lr_logger = LearningRateLogger(verbose=1)  # 학습률 변화 출력 활성화\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.3,       # 학습률을 30%로 감소\n",
    "    patience=4,       # 4 에포크 동안 개선 없으면 감소\n",
    "    min_lr=1e-6,\n",
    "    min_delta=0.005,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "print(f\"\\n초기 학습률: {INITIAL_LR}\")\n",
    "print(f\"학습 시작...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[\n",
    "        lr_logger,          # 커스텀 콜백 (ReduceLROnPlateau보다 먼저 등록)\n",
    "        reduce_lr,          # 학습률 자동 감소\n",
    "        early_stopping      # 조기 종료\n",
    "    ],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 결과 요약\n",
    "lr_stats = lr_logger.get_lr_stats()\n",
    "print(f\"\\n=== 학습 완료 요약 ===\")\n",
    "print(f\"실제 학습 에포크 수: {len(history.history['loss'])}\")\n",
    "print(f\"초기 학습률: {lr_stats['initial_lr']:.6f}\")\n",
    "print(f\"최종 학습률: {lr_stats['final_lr']:.6f}\")\n",
    "print(f\"학습률 변경 횟수: {lr_stats['num_changes']}\")\n",
    "print(f\"학습률 변경 에포크: {lr_stats['change_epochs']}\")\n",
    "print(f\"최고 검증 정확도: {max(history.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 학습률 변화 곡선 시각화\n",
    "# ---------------------------------------------------\n",
    "\n",
    "n_epochs = len(history.history['loss'])\n",
    "epochs_range = range(1, n_epochs + 1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. 학습률 변화 (로그 스케일)\n",
    "ax1 = axes[0, 0]\n",
    "ax1.semilogy(lr_logger.epoch_history, lr_logger.lr_history,\n",
    "             'b-o', linewidth=2, markersize=4, label='학습률')\n",
    "\n",
    "# 학습률 변경 시점 표시\n",
    "for change_epoch in lr_logger.lr_change_epochs:\n",
    "    ax1.axvline(x=change_epoch, color='red', linestyle='--',\n",
    "                alpha=0.7, linewidth=1.5)\n",
    "\n",
    "if lr_logger.lr_change_epochs:\n",
    "    ax1.axvline(x=lr_logger.lr_change_epochs[0], color='red',\n",
    "                linestyle='--', alpha=0.7, linewidth=1.5, label='학습률 감소 시점')\n",
    "\n",
    "ax1.set_xlabel('에포크')\n",
    "ax1.set_ylabel('학습률 (로그 스케일)')\n",
    "ax1.set_title('학습률 변화 (LearningRateLogger)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "# 2. 훈련/검증 손실\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(epochs_range, history.history['loss'],\n",
    "         'b-', linewidth=2, label='훈련 손실')\n",
    "ax2.plot(epochs_range, history.history['val_loss'],\n",
    "         'r-', linewidth=2, label='검증 손실')\n",
    "\n",
    "# 학습률 변경 시점 표시\n",
    "for change_epoch in lr_logger.lr_change_epochs:\n",
    "    ax2.axvline(x=change_epoch, color='orange', linestyle='--',\n",
    "                alpha=0.8, linewidth=1.5)\n",
    "\n",
    "ax2.set_xlabel('에포크')\n",
    "ax2.set_ylabel('손실')\n",
    "ax2.set_title('훈련/검증 손실 (주황 점선: LR 감소 시점)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 훈련/검증 정확도\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(epochs_range, history.history['accuracy'],\n",
    "         'b-', linewidth=2, label='훈련 정확도')\n",
    "ax3.plot(epochs_range, history.history['val_accuracy'],\n",
    "         'r-', linewidth=2, label='검증 정확도')\n",
    "\n",
    "for change_epoch in lr_logger.lr_change_epochs:\n",
    "    ax3.axvline(x=change_epoch, color='orange', linestyle='--',\n",
    "                alpha=0.8, linewidth=1.5)\n",
    "\n",
    "ax3.set_xlabel('에포크')\n",
    "ax3.set_ylabel('정확도')\n",
    "ax3.set_title('훈련/검증 정확도 (주황 점선: LR 감소 시점)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 학습률 변화 (선형 스케일, 세부 시각화)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(lr_logger.epoch_history, lr_logger.lr_history,\n",
    "         'b-o', linewidth=2, markersize=5)\n",
    "ax4.fill_between(lr_logger.epoch_history, lr_logger.lr_history,\n",
    "                  alpha=0.2, color='blue')\n",
    "\n",
    "# 각 변경 시점에 주석 추가\n",
    "for i, change_epoch in enumerate(lr_logger.lr_change_epochs):\n",
    "    idx = change_epoch - 1  # 0-based 인덱스\n",
    "    if idx < len(lr_logger.lr_history):\n",
    "        lr_val = lr_logger.lr_history[idx]\n",
    "        ax4.annotate(\n",
    "            f'에포크 {change_epoch}\\n-> {lr_val:.5f}',\n",
    "            xy=(change_epoch, lr_val),\n",
    "            xytext=(change_epoch + 0.5, lr_val * 1.5),\n",
    "            fontsize=8,\n",
    "            arrowprops=dict(arrowstyle='->', color='red'),\n",
    "            color='red'\n",
    "        )\n",
    "\n",
    "ax4.set_xlabel('에포크')\n",
    "ax4.set_ylabel('학습률 (선형 스케일)')\n",
    "ax4.set_title('학습률 변화 상세 (변경 시점 주석 포함)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('커스텀 LearningRateLogger + ReduceLROnPlateau 결과',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== 학습률 변화 기록 ===\")\n",
    "print(f\"{'에포크':^8} {'학습률':^15} {'변화':^10}\")\n",
    "print(\"-\" * 35)\n",
    "prev_lr = None\n",
    "for epoch, lr in zip(lr_logger.epoch_history, lr_logger.lr_history):\n",
    "    changed = \"\"\n",
    "    if prev_lr is not None and abs(lr - prev_lr) > 1e-10:\n",
    "        changed = f\"  <- {prev_lr:.6f} * 0.3\"\n",
    "    print(f\"{epoch:^8d} {lr:^15.6f}{changed}\")\n",
    "    prev_lr = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도전 과제\n",
    "\n",
    "### 도전 1: 조기 종료 커스텀 콜백 구현\n",
    "\n",
    "아래 조건을 만족하는 `SmartEarlyStopping` 콜백을 구현해보세요:\n",
    "\n",
    "- `patience` 에포크 동안 `val_accuracy`가 개선되지 않으면 학습 종료\n",
    "- 학습 종료 시 \"최고 성능 에포크\"와 \"최고 정확도\"를 출력\n",
    "- `min_delta` 파라미터로 개선의 최소 기준을 설정\n",
    "- 학습 종료 시 `self.model.stop_training = True`로 학습을 중단\n",
    "\n",
    "```python\n",
    "class SmartEarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        super().__init__()\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        # 여기에 초기화 코드 작성\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 여기에 조기 종료 로직 구현\n",
    "        pass\n",
    "```\n",
    "\n",
    "### 도전 2: 그래디언트 노름 모니터링 콜백\n",
    "\n",
    "매 배치마다 그래디언트 노름(norm)을 기록하는 `GradientNormLogger` 콜백을 구현해보세요.\n",
    "- `on_train_batch_end`를 사용하여 배치별 그래디언트 평균 노름을 기록\n",
    "- 그래디언트 폭발(exploding gradients) 감지 기능 추가\n",
    "\n",
    "### 도전 3: WarmupScheduler 구현\n",
    "\n",
    "처음 `warmup_epochs` 동안 학습률을 선형으로 증가시킨 후 지정된 학습률로 유지하는 `WarmupScheduler` 콜백을 구현해보세요.\n",
    "\n",
    "$$lr_{warmup}(e) = \\frac{e}{warmup\\_epochs} \\cdot lr_{target}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
