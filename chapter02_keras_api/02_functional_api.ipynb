{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 02-02: Functional API\n",
    "\n",
    "## 학습 목표\n",
    "- Functional API로 비선형 구조의 모델을 만든다\n",
    "- 잔차 연결(Residual Connection)을 구현한다\n",
    "- 다중 출력 모델을 설계한다\n",
    "\n",
    "## 목차\n",
    "1. Functional API가 필요한 상황\n",
    "2. 기본 사용법\n",
    "3. Sequential과 동일한 MNIST 모델을 Functional로 재구현\n",
    "4. 잔차 블록 구현\n",
    "5. 다중 출력 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"TensorFlow 버전:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API가 필요한 상황\n",
    "\n",
    "- 다중 입력(Multiple Inputs): 텍스트 + 이미지 동시 입력\n",
    "- 다중 출력(Multiple Outputs): 분류 + 회귀 동시 출력\n",
    "- 잔차 연결(Residual Connection): Skip connection\n",
    "- 가지치기(Branch) 구조\n",
    "\n",
    "**수학적 기초 — Skip Connection**:\n",
    "$$h_l = F(x_l, W_l) + x_l$$\n",
    "레이어 입력을 출력에 직접 더함 → 기울기가 직접 흐르는 경로 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 기본 Functional API 사용법\n",
    "\n",
    "Functional API는 `tf.keras.Input`으로 입력 텐서를 정의하고,\n",
    "레이어를 **함수처럼 호출**하여 텐서를 연결한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 기본 Functional API 예시 ─────────────────────────────────────────────\n",
    "\n",
    "# 1단계: 입력 텐서 정의 (배치 차원 제외)\n",
    "inputs = tf.keras.Input(shape=(784,), name='input_layer')\n",
    "\n",
    "# 2단계: 레이어를 함수처럼 호출하여 텐서 변환\n",
    "x = tf.keras.layers.Dense(64, activation='relu', name='hidden_1')(inputs)  # inputs → x\n",
    "x = tf.keras.layers.Dense(32, activation='relu', name='hidden_2')(x)       # x → x\n",
    "\n",
    "# 3단계: 출력 텐서 정의\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "# 4단계: 입력과 출력 텐서를 묶어 Model 생성\n",
    "func_model = tf.keras.Model(inputs=inputs, outputs=outputs, name='basic_functional')\n",
    "\n",
    "func_model.summary()\n",
    "print(\"\\n입력 shape:\", func_model.input_shape)\n",
    "print(\"출력 shape:\", func_model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sequential과 동일한 MNIST 모델을 Functional API로 재구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── MNIST 분류 모델 — Functional 버전 ─────────────────────────────────────\n",
    "\n",
    "# 28×28 이미지를 직접 입력으로 받음\n",
    "img_inputs = tf.keras.Input(shape=(28, 28), name='image_input')\n",
    "\n",
    "# Flatten: 2D 이미지 → 1D 벡터\n",
    "x = tf.keras.layers.Flatten(name='flatten')(img_inputs)\n",
    "\n",
    "# 은닉층\n",
    "x = tf.keras.layers.Dense(128, activation='relu', name='hidden')(x)\n",
    "\n",
    "# Dropout으로 과적합 방지\n",
    "x = tf.keras.layers.Dropout(0.2, name='dropout')(x)\n",
    "\n",
    "# 출력층\n",
    "img_outputs = tf.keras.layers.Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "mnist_functional = tf.keras.Model(\n",
    "    inputs=img_inputs,\n",
    "    outputs=img_outputs,\n",
    "    name='mnist_functional'\n",
    ")\n",
    "\n",
    "mnist_functional.summary()\n",
    "\n",
    "# Sequential 모델과 파라미터 수 동일 여부 확인\n",
    "print(f\"\\nFunctional 파라미터 수: {mnist_functional.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 잔차 블록 구현\n",
    "\n",
    "잔차 연결은 $h_l = F(x_l) + x_l$ 구조로,\n",
    "입력을 변환 결과에 직접 더하여 **기울기 소실 문제**를 완화한다.\n",
    "\n",
    "단, 더하기 위해서는 입출력 차원이 같아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 잔차 블록을 포함한 모델 ───────────────────────────────────────────────\n",
    "\n",
    "def residual_block(x, units, name_prefix):\n",
    "    \"\"\"잔차 블록: F(x) + x\n",
    "    \n",
    "    입력과 출력의 차원이 동일해야 덧셈이 가능하다.\n",
    "    \"\"\"\n",
    "    # 변환 경로: Dense → Dense\n",
    "    h = tf.keras.layers.Dense(units, activation='relu',\n",
    "                               name=f'{name_prefix}_dense1')(x)\n",
    "    h = tf.keras.layers.Dense(units, activation=None,       # 활성화 함수 적용 전에 더함\n",
    "                               name=f'{name_prefix}_dense2')(h)\n",
    "\n",
    "    # 스킵 연결: 입력을 그대로 더함\n",
    "    out = tf.keras.layers.Add(name=f'{name_prefix}_add')([h, x])\n",
    "\n",
    "    # 더한 뒤 활성화 함수 적용\n",
    "    out = tf.keras.layers.Activation('relu', name=f'{name_prefix}_relu')(out)\n",
    "    return out\n",
    "\n",
    "# 입력 정의\n",
    "res_inputs = tf.keras.Input(shape=(784,), name='res_input')\n",
    "\n",
    "# 차원을 64로 맞추는 투영 레이어\n",
    "x = tf.keras.layers.Dense(64, activation='relu', name='projection')(res_inputs)\n",
    "\n",
    "# 잔차 블록 2개 적층\n",
    "x = residual_block(x, units=64, name_prefix='res1')\n",
    "x = residual_block(x, units=64, name_prefix='res2')\n",
    "\n",
    "# 출력층\n",
    "res_outputs = tf.keras.layers.Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "# 잔차 모델 생성\n",
    "residual_model = tf.keras.Model(inputs=res_inputs, outputs=res_outputs,\n",
    "                                 name='residual_model')\n",
    "residual_model.summary()\n",
    "print(f\"\\n잔차 모델 파라미터 수: {residual_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 다중 출력 모델\n",
    "\n",
    "하나의 모델에서 여러 개의 출력을 동시에 생성할 수 있다.\n",
    "예: 주 분류기 + 보조 분류기(보조 손실로 훈련 안정화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 다중 출력 모델 예시: 주 출력 + 보조 출력 ─────────────────────────────\n",
    "\n",
    "multi_inputs = tf.keras.Input(shape=(28, 28), name='image_input')\n",
    "\n",
    "# 공유 특징 추출 경로\n",
    "x = tf.keras.layers.Flatten(name='flatten')(multi_inputs)\n",
    "x = tf.keras.layers.Dense(128, activation='relu', name='shared_1')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu',  name='shared_2')(x)\n",
    "\n",
    "# ─ 주 출력: 10개 클래스 분류 ─\n",
    "main_output = tf.keras.layers.Dense(10, activation='softmax',\n",
    "                                     name='main_output')(x)\n",
    "\n",
    "# ─ 보조 출력: 홀수/짝수 이진 분류 (보조 손실) ─\n",
    "aux_branch  = tf.keras.layers.Dense(32, activation='relu', name='aux_dense')(x)\n",
    "aux_output  = tf.keras.layers.Dense(1,  activation='sigmoid',\n",
    "                                     name='aux_output')(aux_branch)  # 짝수=0, 홀수=1\n",
    "\n",
    "# 다중 출력 모델 생성 (outputs를 리스트로 전달)\n",
    "multi_output_model = tf.keras.Model(\n",
    "    inputs=multi_inputs,\n",
    "    outputs=[main_output, aux_output],\n",
    "    name='multi_output_model'\n",
    ")\n",
    "\n",
    "multi_output_model.summary()\n",
    "\n",
    "# 다중 출력 모델 컴파일: 출력별로 손실함수 지정\n",
    "multi_output_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'main_output': 'sparse_categorical_crossentropy',  # 주 출력 손실\n",
    "        'aux_output':  'binary_crossentropy'               # 보조 출력 손실\n",
    "    },\n",
    "    loss_weights={\n",
    "        'main_output': 1.0,   # 주 손실 가중치\n",
    "        'aux_output':  0.3    # 보조 손실 가중치 (작게 설정)\n",
    "    },\n",
    "    metrics={'main_output': 'accuracy'}\n",
    ")\n",
    "print(\"\\n다중 출력 모델 컴파일 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "| 항목 | Sequential | Functional |\n",
    "|------|-----------|------------|\n",
    "| 구조 | 선형 (레이어 순차 연결) | 비선형 (임의 연결 가능) |\n",
    "| 다중 입출력 | 불가 | 가능 |\n",
    "| 잔차 연결 | 불가 | 가능 |\n",
    "| 모델 시각화 | 가능 | 가능 |\n",
    "| 사용 난이도 | 쉬움 | 중간 |\n",
    "| 권장 상황 | 간단한 선형 모델 | 복잡한 아키텍처 |\n",
    "\n",
    "**다음**: 03_subclassing_api.ipynb — 완전 커스텀 모델 구현"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
