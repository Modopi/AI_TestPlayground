{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 02-01: Sequential API\n",
    "\n",
    "## 학습 목표\n",
    "- Sequential 모델로 레이어를 쌓는 법을 이해한다\n",
    "- model.summary()로 파라미터 수를 해석한다\n",
    "- MNIST 손글씨 분류 전체 파이프라인을 구현한다\n",
    "\n",
    "## 목차\n",
    "1. Sequential 모델 생성\n",
    "2. model.summary() 해석\n",
    "3. MNIST 분류 실습\n",
    "4. 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"TensorFlow 버전:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수학적 기초\n",
    "\n",
    "완전 연결 레이어의 연산:\n",
    "$$\\mathbf{y} = f(\\mathbf{W}\\mathbf{x} + \\mathbf{b})$$\n",
    "\n",
    "- $\\mathbf{W}$: 가중치 행렬, shape $(n_{out}, n_{in})$\n",
    "- $\\mathbf{b}$: 편향 벡터, shape $(n_{out},)$\n",
    "- $f$: 활성화 함수\n",
    "\n",
    "**파라미터 수** (Dense 레이어):\n",
    "$$\\text{params} = n_{in} \\times n_{out} + n_{out}$$\n",
    "\n",
    "예시: Dense(784 → 128) = $784 \\times 128 + 128 = 100,480$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sequential 모델 생성\n",
    "\n",
    "Sequential API는 레이어를 **순서대로 쌓을 때** 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 방법 1: 생성자에 리스트로 레이어를 전달 ──────────────────────────────\n",
    "model_v1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)),  # 입력층 + 첫 번째 은닉층\n",
    "    tf.keras.layers.Dense(32, activation='relu'),                       # 두 번째 은닉층\n",
    "    tf.keras.layers.Dense(10, activation='softmax')                     # 출력층 (10개 클래스)\n",
    "])\n",
    "print(\"방법 1 — 생성자 리스트로 생성:\")\n",
    "print(\"레이어 수:\", len(model_v1.layers))\n",
    "\n",
    "# ── 방법 2: 빈 모델을 만든 뒤 .add()로 레이어를 하나씩 추가 ──────────────\n",
    "model_v2 = tf.keras.Sequential()                                        # 빈 Sequential 모델 생성\n",
    "model_v2.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)))  # 첫 번째 레이어 추가\n",
    "model_v2.add(tf.keras.layers.Dense(32, activation='relu'))              # 두 번째 레이어 추가\n",
    "model_v2.add(tf.keras.layers.Dense(10, activation='softmax'))           # 출력 레이어 추가\n",
    "print(\"\\n방법 2 — .add()로 순차 추가:\")\n",
    "print(\"레이어 수:\", len(model_v2.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. model.summary() 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary 출력을 위한 예시 모델 생성\n",
    "summary_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,),\n",
    "                          name='hidden_1'),   # 파라미터: 784*128 + 128 = 100,480\n",
    "    tf.keras.layers.Dense(64, activation='relu',\n",
    "                          name='hidden_2'),   # 파라미터: 128*64 + 64  = 8,256\n",
    "    tf.keras.layers.Dense(10, activation='softmax',\n",
    "                          name='output')      # 파라미터: 64*10 + 10   = 650\n",
    "])\n",
    "\n",
    "summary_model.summary()\n",
    "# ── 파라미터 수 직접 확인 ────────────────────────────────────────────────\n",
    "total_params = summary_model.count_params()\n",
    "print(f\"\\n전체 파라미터 수: {total_params:,}\")\n",
    "print(f\"예상 파라미터 수: {784*128+128 + 128*64+64 + 64*10+10:,}\")\n",
    "\n",
    "# 레이어별 파라미터 수 출력\n",
    "print(\"\\n── 레이어별 파라미터 수 ──\")\n",
    "for layer in summary_model.layers:\n",
    "    w_count = sum([tf.size(w).numpy() for w in layer.weights])  # 가중치 텐서 크기 합산\n",
    "    print(f\"{layer.name:15s}: {w_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MNIST 손글씨 분류\n",
    "\n",
    "### 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터셋 로드 (60,000 훈련 / 10,000 테스트)\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 픽셀 값을 [0, 255] → [0.0, 1.0] 범위로 정규화\n",
    "x_train = x_train / 255.0\n",
    "x_test  = x_test  / 255.0\n",
    "\n",
    "print(\"훈련 데이터 shape:\", x_train.shape)   # (60000, 28, 28)\n",
    "print(\"테스트 데이터 shape:\", x_test.shape)   # (10000, 28, 28)\n",
    "print(\"레이블 예시:\", y_train[:10])\n",
    "\n",
    "# 샘플 이미지 시각화\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_train[i], cmap='gray')        # 흑백 이미지 표시\n",
    "    ax.set_title(f\"레이블: {y_train[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"MNIST 샘플 이미지\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 분류 모델 구성\n",
    "mnist_model = tf.keras.Sequential([\n",
    "    # 28×28 2D 이미지를 784차원 1D 벡터로 펼침\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28), name='flatten'),\n",
    "\n",
    "    # 은닉층: 128개 뉴런, ReLU 활성화\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='hidden'),\n",
    "\n",
    "    # Dropout: 훈련 시 20% 뉴런 무작위 비활성화 → 과적합 방지\n",
    "    tf.keras.layers.Dropout(0.2, name='dropout'),\n",
    "\n",
    "    # 출력층: 10개 클래스 (0~9), Softmax로 확률 분포 출력\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "], name='mnist_classifier')\n",
    "\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일: 옵티마이저, 손실함수, 평가지표 설정\n",
    "mnist_model.compile(\n",
    "    optimizer='adam',                          # Adam 옵티마이저 (적응형 학습률)\n",
    "    loss='sparse_categorical_crossentropy',    # 정수 레이블용 교차 엔트로피 손실\n",
    "    metrics=['accuracy']                       # 정확도 모니터링\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "history = mnist_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,                  # 전체 데이터를 10번 반복 학습\n",
    "    batch_size=128,             # 미니배치 크기\n",
    "    validation_split=0.1,       # 훈련 데이터의 10%를 검증 데이터로 사용\n",
    "    verbose=1                   # 학습 진행 상황 출력\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트 최종 평가\n",
    "test_loss, test_acc = mnist_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"테스트 손실: {test_loss:.4f}\")\n",
    "print(f\"테스트 정확도: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "# ── 학습 곡선 시각화 ─────────────────────────────────────────────────────\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 손실 곡선\n",
    "ax1.plot(history.history['loss'],     label='훈련 손실',   linewidth=2)\n",
    "ax1.plot(history.history['val_loss'], label='검증 손실',   linewidth=2, linestyle='--')\n",
    "ax1.set_title('손실 곡선')\n",
    "ax1.set_xlabel('에포크')\n",
    "ax1.set_ylabel('손실')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 정확도 곡선\n",
    "ax2.plot(history.history['accuracy'],     label='훈련 정확도', linewidth=2)\n",
    "ax2.plot(history.history['val_accuracy'], label='검증 정확도', linewidth=2, linestyle='--')\n",
    "ax2.set_title('정확도 곡선')\n",
    "ax2.set_xlabel('에포크')\n",
    "ax2.set_ylabel('정확도')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('MNIST Sequential 모델 학습 결과', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "| 메서드 | 역할 |\n",
    "|--------|------|\n",
    "| `model.compile()` | 손실함수, 옵티마이저, 메트릭 설정 |\n",
    "| `model.fit()` | 모델 학습 |\n",
    "| `model.evaluate()` | 테스트 세트 평가 |\n",
    "| `model.predict()` | 새 데이터 예측 |\n",
    "\n",
    "**다음**: 02_functional_api.ipynb — 다중 입출력, 잔차 연결"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
