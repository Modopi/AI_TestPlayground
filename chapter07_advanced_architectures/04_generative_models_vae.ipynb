{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0001-4001-8001-000000000001",
   "metadata": {},
   "source": [
    "# Chapter 07-04: 생성 모델 — VAE (Variational Autoencoder)\n",
    "\n",
    "## 학습 목표\n",
    "- Autoencoder와 VAE의 차이를 이해한다\n",
    "- VAE의 ELBO 손실 함수와 재파라미터화 트릭을 이해한다\n",
    "- MNIST 데이터로 VAE를 구현하고 학습한다\n",
    "- 잠재 공간(Latent Space)을 시각화하고 보간(Interpolation)으로 새 이미지를 생성한다\n",
    "\n",
    "## 목차\n",
    "1. 수식 이해\n",
    "2. 기본 Autoencoder 구현\n",
    "3. VAE 확장 (재파라미터화 트릭)\n",
    "4. 커스텀 VAE 손실 함수\n",
    "5. 잠재 공간 시각화\n",
    "6. 잠재 공간 보간으로 이미지 생성\n",
    "7. 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0002-4002-8002-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 한글 폰트 설정 (macOS)\n",
    "matplotlib.rcParams['font.family'] = 'AppleGothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f'TensorFlow 버전: {tf.__version__}')\n",
    "\n",
    "# 재현성을 위한 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0003-4003-8003-000000000003",
   "metadata": {},
   "source": [
    "## 1. 수식 이해\n",
    "\n",
    "### VAE ELBO (Evidence Lower BOund)\n",
    "\n",
    "VAE는 데이터의 로그 우도(log-likelihood) $\\log p(x)$를 직접 최적화하기 어려우므로,  \n",
    "**하한(Lower Bound)**인 ELBO를 최대화하여 간접적으로 학습한다:\n",
    "\n",
    "$$\\mathcal{L} = \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - D_{KL}(q(z|x) \\| p(z))$$\n",
    "\n",
    "| 항 | 이름 | 역할 |\n",
    "|----|------|------|\n",
    "| $\\mathbb{E}_{q(z|x)}[\\log p(x|z)]$ | 재구성 손실 | 디코더가 원본 $x$를 얼마나 잘 복원하는가 |\n",
    "| $D_{KL}(q(z|x) \\| p(z))$ | KL 발산 | 인코더의 잠재 분포를 표준 정규분포에 가깝게 |\n",
    "\n",
    "### KL 발산 (가우시안 가정)\n",
    "\n",
    "$q(z|x) = \\mathcal{N}(\\mu, \\sigma^2)$, $p(z) = \\mathcal{N}(0, I)$ 가정 시 닫힌 형태:\n",
    "\n",
    "$$D_{KL} = -\\frac{1}{2}\\sum\\left(1 + \\log\\sigma^2 - \\mu^2 - \\sigma^2\\right)$$\n",
    "\n",
    "### 재파라미터화 트릭 (Reparameterization Trick)\n",
    "\n",
    "샘플링 연산은 역전파가 불가능하므로, 샘플링을 결정론적 연산으로 분리한다:\n",
    "\n",
    "$$z = \\mu + \\sigma \\odot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0,I)$$\n",
    "\n",
    "- $\\epsilon$을 **표준 정규분포**에서 샘플링 (기울기 불필요)\n",
    "- $\\mu$와 $\\sigma$는 인코더의 학습 가능한 출력 → 역전파 가능\n",
    "- $\\odot$: 원소별 곱셈(element-wise multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0004-4004-8004-000000000004",
   "metadata": {},
   "source": [
    "## 2. 기본 Autoencoder 구현 (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0005-4005-8005-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 로드 및 전처리\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# 정규화 [0, 255] → [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32')  / 255.0\n",
    "\n",
    "# 평탄화: (28, 28) → (784,)\n",
    "x_train_flat = x_train.reshape(-1, 784)\n",
    "x_test_flat  = x_test.reshape(-1, 784)\n",
    "\n",
    "print(f'훈련 데이터: {x_train_flat.shape}')\n",
    "print(f'테스트 데이터: {x_test_flat.shape}')\n",
    "\n",
    "# ---- 기본 Autoencoder ----\n",
    "LATENT_DIM_AE = 32  # 잠재 벡터 차원\n",
    "\n",
    "# Encoder: 784 → 256 → 128 → latent_dim\n",
    "ae_encoder_input = keras.Input(shape=(784,), name='ae_encoder_input')\n",
    "ae_x = keras.layers.Dense(256, activation='relu')(ae_encoder_input)\n",
    "ae_x = keras.layers.Dense(128, activation='relu')(ae_x)\n",
    "ae_latent = keras.layers.Dense(LATENT_DIM_AE, activation='relu', name='latent')(ae_x)\n",
    "ae_encoder = keras.Model(ae_encoder_input, ae_latent, name='AE_Encoder')\n",
    "\n",
    "# Decoder: latent_dim → 128 → 256 → 784\n",
    "ae_decoder_input = keras.Input(shape=(LATENT_DIM_AE,), name='ae_decoder_input')\n",
    "ae_d = keras.layers.Dense(128, activation='relu')(ae_decoder_input)\n",
    "ae_d = keras.layers.Dense(256, activation='relu')(ae_d)\n",
    "ae_output = keras.layers.Dense(784, activation='sigmoid', name='ae_output')(ae_d)  # sigmoid → [0,1]\n",
    "ae_decoder = keras.Model(ae_decoder_input, ae_output, name='AE_Decoder')\n",
    "\n",
    "# Autoencoder 조합\n",
    "ae_input = keras.Input(shape=(784,))\n",
    "ae_encoded = ae_encoder(ae_input)\n",
    "ae_reconstructed = ae_decoder(ae_encoded)\n",
    "autoencoder = keras.Model(ae_input, ae_reconstructed, name='Autoencoder')\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy'  # 픽셀별 이진 교차 엔트로피\n",
    ")\n",
    "\n",
    "print('\\n기본 Autoencoder 구조:')\n",
    "ae_encoder.summary()\n",
    "\n",
    "# 학습\n",
    "print('\\nAutoencoder 학습 시작...')\n",
    "ae_history = autoencoder.fit(\n",
    "    x_train_flat, x_train_flat,  # 입력과 타겟이 동일\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 재구성 결과 시각화\n",
    "n_samples = 8\n",
    "test_samples = x_test_flat[:n_samples]\n",
    "reconstructed = autoencoder.predict(test_samples, verbose=0)\n",
    "\n",
    "fig, axes = plt.subplots(2, n_samples, figsize=(16, 4))\n",
    "for i in range(n_samples):\n",
    "    axes[0, i].imshow(test_samples[i].reshape(28, 28), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('원본', fontsize=10, pad=3)\n",
    "    axes[1, i].imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('재구성', fontsize=10, pad=3)\n",
    "\n",
    "plt.suptitle('Autoencoder 재구성 결과', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0006-4006-8006-000000000006",
   "metadata": {},
   "source": [
    "## 3. VAE 확장 — Sampling 레이어(재파라미터화 트릭)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0007-4007-8007-000000000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 2  # 2D 시각화를 위해 잠재 차원 = 2\n",
    "\n",
    "# ---- Sampling 레이어 (재파라미터화 트릭 구현) ----\n",
    "class SamplingLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    재파라미터화 트릭: z = mu + sigma * epsilon\n",
    "    epsilon ~ N(0, I)\n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        mu, log_var = inputs  # 인코더로부터 평균과 로그 분산 수신\n",
    "        \n",
    "        # 배치 크기와 잠재 차원 추출\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim   = tf.shape(mu)[1]\n",
    "        \n",
    "        # 표준 정규 노이즈 샘플링 (역전파 불필요)\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        \n",
    "        # z = mu + exp(0.5 * log_var) * epsilon\n",
    "        # sigma = exp(0.5 * log_var) = sqrt(exp(log_var)) = sqrt(var)\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "\n",
    "# ---- VAE Encoder ----\n",
    "encoder_input = keras.Input(shape=(784,), name='encoder_input')\n",
    "enc_h1 = keras.layers.Dense(256, activation='relu')(encoder_input)\n",
    "enc_h2 = keras.layers.Dense(128, activation='relu')(enc_h1)\n",
    "\n",
    "# 평균(mu)과 로그 분산(log_var) 동시 출력\n",
    "z_mu      = keras.layers.Dense(LATENT_DIM, name='z_mu')(enc_h2)       # 평균\n",
    "z_log_var = keras.layers.Dense(LATENT_DIM, name='z_log_var')(enc_h2)  # 로그 분산\n",
    "\n",
    "# 재파라미터화 샘플링\n",
    "z = SamplingLayer(name='z_sampling')([z_mu, z_log_var])\n",
    "\n",
    "# 인코더 모델 (mu, log_var, z 모두 출력)\n",
    "vae_encoder = keras.Model(encoder_input, [z_mu, z_log_var, z], name='VAE_Encoder')\n",
    "\n",
    "# ---- VAE Decoder ----\n",
    "decoder_input = keras.Input(shape=(LATENT_DIM,), name='decoder_input')\n",
    "dec_h1 = keras.layers.Dense(128, activation='relu')(decoder_input)\n",
    "dec_h2 = keras.layers.Dense(256, activation='relu')(dec_h1)\n",
    "decoder_output = keras.layers.Dense(784, activation='sigmoid', name='decoder_output')(dec_h2)\n",
    "\n",
    "vae_decoder = keras.Model(decoder_input, decoder_output, name='VAE_Decoder')\n",
    "\n",
    "print('VAE Encoder 구조:')\n",
    "vae_encoder.summary()\n",
    "print('\\nVAE Decoder 구조:')\n",
    "vae_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0008-4008-8008-000000000008",
   "metadata": {},
   "source": [
    "## 4. 커스텀 VAE 손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0009-4009-8009-000000000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder\n",
    "    커스텀 train_step으로 ELBO 손실(재구성 + KL) 계산\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        # 손실 추적기\n",
    "        self.total_loss_tracker    = keras.metrics.Mean(name='total_loss')\n",
    "        self.recon_loss_tracker    = keras.metrics.Mean(name='recon_loss')\n",
    "        self.kl_loss_tracker       = keras.metrics.Mean(name='kl_loss')\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss_tracker, self.recon_loss_tracker, self.kl_loss_tracker]\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x = data  # VAE는 입력 = 타겟\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # 인코더 실행: mu, log_var, z 추출\n",
    "            z_mu, z_log_var, z = self.encoder(x, training=True)\n",
    "            \n",
    "            # 디코더 실행: z에서 이미지 재구성\n",
    "            x_reconstructed = self.decoder(z, training=True)\n",
    "            \n",
    "            # 재구성 손실: 픽셀별 이진 교차 엔트로피의 합\n",
    "            recon_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(x, x_reconstructed),\n",
    "                    axis=-1  # 784개 픽셀에 대해 합산\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # KL 발산 손실: -0.5 * sum(1 + log_var - mu^2 - exp(log_var))\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    1 + z_log_var - tf.square(z_mu) - tf.exp(z_log_var),\n",
    "                    axis=-1  # 잠재 차원에 대해 합산\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # 전체 손실 = 재구성 손실 + KL 손실\n",
    "            total_loss = recon_loss + kl_loss\n",
    "        \n",
    "        # 역전파\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        # 손실 업데이트\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.recon_loss_tracker.update_state(recon_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            'total_loss': self.total_loss_tracker.result(),\n",
    "            'recon_loss': self.recon_loss_tracker.result(),\n",
    "            'kl_loss':    self.kl_loss_tracker.result()\n",
    "        }\n",
    "\n",
    "\n",
    "# VAE 인스턴스 생성 및 학습\n",
    "vae = VAE(vae_encoder, vae_decoder, name='VAE')\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3))\n",
    "\n",
    "print('VAE 학습 시작...')\n",
    "vae_history = vae.fit(\n",
    "    x_train_flat,\n",
    "    batch_size=256,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 손실 곡선 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(vae_history.history['total_loss'], label='전체 손실', linewidth=2)\n",
    "ax.plot(vae_history.history['recon_loss'], label='재구성 손실', linewidth=2, linestyle='--')\n",
    "ax.plot(vae_history.history['kl_loss'],   label='KL 발산 손실', linewidth=2, linestyle=':')\n",
    "ax.set_xlabel('에포크', fontsize=11)\n",
    "ax.set_ylabel('손실', fontsize=11)\n",
    "ax.set_title('VAE 학습 손실 (재구성 + KL 발산)', fontsize=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0010-4010-8010-000000000010",
   "metadata": {},
   "source": [
    "## 5. 잠재 공간 시각화 (2D 잠재 공간)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0011-4011-8011-000000000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터를 잠재 공간으로 인코딩\n",
    "z_mu_test, z_log_var_test, z_test = vae_encoder.predict(x_test_flat, verbose=0)\n",
    "\n",
    "print(f'테스트 잠재 벡터 shape: {z_test.shape}')  # (10000, 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# --- 잠재 공간 산점도 (클래스별 색상) ---\n",
    "ax = axes[0]\n",
    "scatter = ax.scatter(\n",
    "    z_test[:, 0], z_test[:, 1],\n",
    "    c=y_test, cmap='tab10',\n",
    "    alpha=0.5, s=5\n",
    ")\n",
    "plt.colorbar(scatter, ax=ax, label='숫자 클래스')\n",
    "ax.set_xlabel('잠재 차원 1 ($z_1$)', fontsize=11)\n",
    "ax.set_ylabel('잠재 차원 2 ($z_2$)', fontsize=11)\n",
    "ax.set_title('VAE 2D 잠재 공간 (테스트 데이터)', fontsize=12)\n",
    "\n",
    "# 각 클래스 중심점에 레이블 표시\n",
    "for digit in range(10):\n",
    "    mask = y_test == digit\n",
    "    center_x = z_test[mask, 0].mean()\n",
    "    center_y = z_test[mask, 1].mean()\n",
    "    ax.annotate(str(digit), (center_x, center_y),\n",
    "                fontsize=14, fontweight='bold', ha='center', va='center',\n",
    "                color='white',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.6))\n",
    "\n",
    "# --- 잠재 공간 격자 → 디코딩된 이미지 ---\n",
    "ax2 = axes[1]\n",
    "\n",
    "# 잠재 공간의 범위 설정 ([-3, 3] × [-3, 3])\n",
    "n_grid = 12\n",
    "grid_range = np.linspace(-3, 3, n_grid)\n",
    "\n",
    "# 격자 포인트 생성 → 디코딩 → 이미지 배치\n",
    "canvas = np.zeros((28 * n_grid, 28 * n_grid))\n",
    "\n",
    "for i, z2 in enumerate(grid_range[::-1]):\n",
    "    for j, z1 in enumerate(grid_range):\n",
    "        z_point = np.array([[z1, z2]])  # (1, 2)\n",
    "        decoded = vae_decoder.predict(z_point, verbose=0)  # (1, 784)\n",
    "        img = decoded[0].reshape(28, 28)\n",
    "        canvas[i*28:(i+1)*28, j*28:(j+1)*28] = img\n",
    "\n",
    "ax2.imshow(canvas, cmap='gray')\n",
    "ax2.set_title(f'잠재 공간 격자 디코딩 ({n_grid}×{n_grid})', fontsize=12)\n",
    "ax2.set_xlabel('$z_1$', fontsize=11)\n",
    "ax2.set_ylabel('$z_2$', fontsize=11)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.suptitle('VAE 잠재 공간 분석', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0012-4012-8012-000000000012",
   "metadata": {},
   "source": [
    "## 6. 잠재 공간 보간(Interpolation)으로 이미지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0013-4013-8013-000000000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_latent(z_start, z_end, n_steps=10):\n",
    "    \"\"\"\n",
    "    두 잠재 벡터 사이를 선형 보간\n",
    "    z = (1 - alpha) * z_start + alpha * z_end, alpha in [0, 1]\n",
    "    \"\"\"\n",
    "    alphas = np.linspace(0, 1, n_steps)\n",
    "    interpolated = np.array([\n",
    "        (1 - alpha) * z_start + alpha * z_end\n",
    "        for alpha in alphas\n",
    "    ])  # (n_steps, latent_dim)\n",
    "    return interpolated\n",
    "\n",
    "\n",
    "# 각 숫자 쌍의 잠재 벡터 추출 (클래스 평균값 사용)\n",
    "digit_pairs = [(0, 1), (2, 7), (3, 8), (4, 9)]\n",
    "n_steps = 12\n",
    "\n",
    "fig, axes = plt.subplots(len(digit_pairs), n_steps, figsize=(20, 7))\n",
    "\n",
    "for row, (digit_a, digit_b) in enumerate(digit_pairs):\n",
    "    # 각 클래스의 잠재 벡터 평균 계산\n",
    "    z_a = z_mu_test[y_test == digit_a].mean(axis=0)  # (2,)\n",
    "    z_b = z_mu_test[y_test == digit_b].mean(axis=0)  # (2,)\n",
    "    \n",
    "    # 선형 보간\n",
    "    z_interp = interpolate_latent(z_a, z_b, n_steps)  # (n_steps, 2)\n",
    "    \n",
    "    # 디코딩\n",
    "    decoded_images = vae_decoder.predict(z_interp, verbose=0)  # (n_steps, 784)\n",
    "    \n",
    "    for col in range(n_steps):\n",
    "        ax = axes[row, col]\n",
    "        ax.imshow(decoded_images[col].reshape(28, 28), cmap='gray')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # 시작/끝 레이블\n",
    "        if col == 0:\n",
    "            ax.set_title(f'{digit_a}', fontsize=11, fontweight='bold', color='blue')\n",
    "        elif col == n_steps - 1:\n",
    "            ax.set_title(f'{digit_b}', fontsize=11, fontweight='bold', color='red')\n",
    "\n",
    "plt.suptitle('잠재 공간 선형 보간: 두 숫자 사이의 연속적 변환', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('보간 결과: 잠재 공간이 연속적이고 의미있는 구조를 가짐을 확인')\n",
    "\n",
    "# 순수 생성: 표준 정규 분포에서 샘플링\n",
    "print('\\n랜덤 생성 이미지 (z ~ N(0,I)):')\n",
    "n_generated = 16\n",
    "z_random = np.random.randn(n_generated, LATENT_DIM)  # 표준 정규 샘플링\n",
    "generated = vae_decoder.predict(z_random, verbose=0)\n",
    "\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(generated[i].reshape(28, 28), cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('VAE 랜덤 생성 이미지 ($z \\\\sim \\\\mathcal{N}(0,I)$)', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0014-4014-8014-000000000014",
   "metadata": {},
   "source": [
    "## 7. 정리\n",
    "\n",
    "### Autoencoder vs VAE 비교\n",
    "\n",
    "| 구분 | Autoencoder | VAE |\n",
    "|------|------------|-----|\n",
    "| 잠재 공간 | 비구조적 (점) | 확률 분포 $\\mathcal{N}(\\mu, \\sigma^2)$ |\n",
    "| 손실 함수 | 재구성 손실만 | 재구성 손실 + KL 발산 |\n",
    "| 생성 가능성 | 낮음 (새 점 샘플링 어려움) | 높음 ($z \\sim \\mathcal{N}(0,I)$ 샘플링) |\n",
    "| 잠재 공간 연속성 | 보장 없음 | 연속적, 매끄러운 보간 가능 |\n",
    "| 역전파 가능성 | 가능 | 재파라미터화 트릭으로 가능 |\n",
    "\n",
    "### 핵심 개념 요약\n",
    "\n",
    "- **ELBO**: 직접 최적화 불가능한 로그 우도의 하한 → 최대화\n",
    "- **재파라미터화 트릭**: 샘플링을 결정론적 연산으로 분리하여 역전파 가능\n",
    "- **KL 발산**: 잠재 분포를 표준 정규분포로 정규화 → 잠재 공간의 연속성 보장\n",
    "- **보간**: 잠재 공간이 매끄러우므로 두 점 사이의 선형 보간이 의미있는 전환 생성\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "**Chapter 07-05: GAN (Generative Adversarial Networks)** — 생성자와 판별자의 적대적 학습으로 더욱 사실적인 이미지를 생성한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
