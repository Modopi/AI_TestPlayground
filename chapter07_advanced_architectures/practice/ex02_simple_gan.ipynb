{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0-0001-4001-8001-000000000001",
   "metadata": {},
   "source": [
    "# Chapter 07 실습 2: 간단한 GAN 구현\n",
    "\n",
    "## 실습 목표\n",
    "- Dense 레이어만으로 구성된 기본 GAN을 처음부터 구현한다\n",
    "- Generator와 Discriminator를 각각 별도의 옵티마이저로 교대 학습한다\n",
    "- 30 에포크 동안 학습하며 생성 이미지의 품질 변화를 시각화한다\n",
    "- DCGAN으로 개선하는 방법을 탐구한다 (도전 과제)\n",
    "\n",
    "## 실습 개요\n",
    "\n",
    "```\n",
    "Dense GAN 구조:\n",
    "\n",
    "Generator:\n",
    "  z (100,) → Dense(256, LeakyReLU) → Dense(512, LeakyReLU)\n",
    "           → Dense(1024, LeakyReLU) → Dense(784, tanh) → 이미지 (28×28)\n",
    "\n",
    "Discriminator:\n",
    "  이미지 (784,) → Dense(1024, LeakyReLU) → Dense(512, LeakyReLU)\n",
    "               → Dense(256, LeakyReLU) → Dense(1, sigmoid) → 진위 확률\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0002-4002-8002-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "\n",
    "# 한글 폰트 설정 (macOS)\n",
    "matplotlib.rcParams['font.family'] = 'AppleGothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f'TensorFlow 버전: {tf.__version__}')\n",
    "\n",
    "# 재현성 시드\n",
    "tf.random.set_seed(2024)\n",
    "np.random.seed(2024)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "LATENT_DIM  = 100   # 잠재 벡터 차원 (노이즈 차원)\n",
    "IMAGE_DIM   = 784   # 28×28 = 784 픽셀\n",
    "BATCH_SIZE  = 256   # 배치 크기\n",
    "EPOCHS      = 30    # 학습 에포크 수\n",
    "LR_G        = 2e-4  # Generator 학습률\n",
    "LR_D        = 2e-4  # Discriminator 학습률\n",
    "\n",
    "print(f'잠재 벡터 차원: {LATENT_DIM}')\n",
    "print(f'이미지 차원:   {IMAGE_DIM} (28×28)')\n",
    "print(f'배치 크기:     {BATCH_SIZE}')\n",
    "print(f'학습 에포크:   {EPOCHS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0003-4003-8003-000000000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 로드 + 정규화\n",
    "print('MNIST 데이터 로딩...')\n",
    "(x_train, y_train), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# [0, 255] → [-1, 1] 정규화 (Generator의 tanh 출력과 일치)\n",
    "# tanh: [-1, 1] 출력 → 동일한 범위로 데이터 정규화 필요\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = (x_train - 127.5) / 127.5  # 127.5를 빼고 나누면 [-1, 1]\n",
    "\n",
    "# (60000, 28, 28) → (60000, 784) 평탄화\n",
    "x_train_flat = x_train.reshape(-1, IMAGE_DIM)\n",
    "\n",
    "print(f'훈련 데이터 shape: {x_train_flat.shape}')\n",
    "print(f'픽셀 범위: [{x_train_flat.min():.1f}, {x_train_flat.max():.1f}]')\n",
    "\n",
    "# TF Dataset 파이프라인\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(x_train_flat)\n",
    "    .shuffle(60000)                          # 전체 데이터 셔플\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)  # 마지막 불완전 배치 제거\n",
    "    .prefetch(tf.data.AUTOTUNE)              # 비동기 로딩으로 GPU 대기 시간 감소\n",
    ")\n",
    "\n",
    "print(f'배치 수: {len(list(train_dataset))}')\n",
    "\n",
    "# 원본 이미지 샘플 시각화\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    digit = i % 10\n",
    "    idx = np.where(y_train == digit)[0][i // 10]\n",
    "    # [-1, 1] → [0, 1]로 되돌려 시각화\n",
    "    img = (x_train_flat[idx] + 1) / 2.0\n",
    "    ax.imshow(img.reshape(28, 28), cmap='gray')\n",
    "    ax.set_title(str(digit), fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('MNIST 원본 이미지 샘플 (정규화 후 표시)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0004-4004-8004-000000000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim=LATENT_DIM, output_dim=IMAGE_DIM):\n",
    "    \"\"\"\n",
    "    Dense 기반 Generator\n",
    "    노이즈 z (100,) → 이미지 벡터 (784,)\n",
    "    \n",
    "    단계별 특징 맵 확장:\n",
    "    100 → 256 → 512 → 1024 → 784\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # 입력층\n",
    "        keras.layers.Input(shape=(latent_dim,), name='noise_input'),\n",
    "        \n",
    "        # 첫 번째 Dense: 잠재 벡터 확장\n",
    "        keras.layers.Dense(256),\n",
    "        keras.layers.BatchNormalization(),   # 학습 안정화\n",
    "        keras.layers.LeakyReLU(alpha=0.2),  # 음수 기울기 허용\n",
    "        \n",
    "        # 두 번째 Dense: 특징 확장\n",
    "        keras.layers.Dense(512),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        # 세 번째 Dense: 특징 확장\n",
    "        keras.layers.Dense(1024),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        # 출력층: 784 픽셀, tanh 활성화 → [-1, 1] 출력\n",
    "        keras.layers.Dense(output_dim, activation='tanh', name='image_output')\n",
    "    ], name='Generator')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Generator 생성 및 확인\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "\n",
    "# 동작 테스트\n",
    "test_noise = tf.random.normal([4, LATENT_DIM])\n",
    "test_gen_out = generator(test_noise, training=False)\n",
    "print(f'\\n입력 노이즈 shape: {test_noise.shape}')\n",
    "print(f'생성 이미지 shape: {test_gen_out.shape}')  # (4, 784)\n",
    "print(f'픽셀 범위: [{test_gen_out.numpy().min():.3f}, {test_gen_out.numpy().max():.3f}]')\n",
    "\n",
    "# 미학습 Generator의 출력 (노이즈)\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    img = ((test_gen_out[i].numpy() + 1) / 2.0).reshape(28, 28)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f'초기 생성 {i+1}', fontsize=9)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('학습 전 Generator 출력 (무작위 노이즈)', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0005-4005-8005-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_dim=IMAGE_DIM):\n",
    "    \"\"\"\n",
    "    Dense 기반 Discriminator\n",
    "    이미지 벡터 (784,) → 진위 확률 스칼라\n",
    "    \n",
    "    단계별 특징 맵 축소:\n",
    "    784 → 1024 → 512 → 256 → 1\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # 입력층\n",
    "        keras.layers.Input(shape=(input_dim,), name='image_input'),\n",
    "        \n",
    "        # 첫 번째 Dense: 특징 추출\n",
    "        keras.layers.Dense(1024),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),  # 음수 입력에도 기울기 유지\n",
    "        keras.layers.Dropout(0.3),           # 과적합 방지 (D에서는 BN 대신 Dropout)\n",
    "        \n",
    "        # 두 번째 Dense: 특징 압축\n",
    "        keras.layers.Dense(512),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # 세 번째 Dense: 추가 압축\n",
    "        keras.layers.Dense(256),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # 출력층: 진위 확률 [0=가짜, 1=실제]\n",
    "        keras.layers.Dense(1, activation='sigmoid', name='real_prob')\n",
    "    ], name='Discriminator')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Discriminator 생성 및 확인\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n",
    "\n",
    "# 동작 테스트\n",
    "test_images = tf.random.normal([4, IMAGE_DIM])\n",
    "test_disc_out = discriminator(test_images, training=False)\n",
    "print(f'\\n입력 이미지 shape: {test_images.shape}')\n",
    "print(f'판별 결과 shape:   {test_disc_out.shape}')  # (4, 1)\n",
    "print(f'판별 확률 (초기 무작위): {test_disc_out.numpy().flatten().round(4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0006-4006-8006-000000000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "bce = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    \"\"\"G 손실: 가짜 이미지를 실제(1)로 속이도록 최소화\"\"\"\n",
    "    return bce(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"D 손실: 실제=1, 가짜=0으로 분류하도록 최소화\"\"\"\n",
    "    real_loss = bce(tf.ones_like(real_output), real_output)   # 실제 이미지 → 1\n",
    "    fake_loss = bce(tf.zeros_like(fake_output), fake_output)  # 가짜 이미지 → 0\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "# 별도 Optimizer\n",
    "gen_optimizer  = keras.optimizers.Adam(LR_G, beta_1=0.5)\n",
    "disc_optimizer = keras.optimizers.Adam(LR_D, beta_1=0.5)\n",
    "\n",
    "@tf.function  # TF 그래프로 컴파일하여 속도 향상\n",
    "def train_step(real_images):\n",
    "    \"\"\"GAN 한 스텝 학습: D 업데이트 → G 업데이트\"\"\"\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "    \n",
    "    # 노이즈 샘플링\n",
    "    noise = tf.random.normal([batch_size, LATENT_DIM])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # G 순전파: 가짜 이미지 생성\n",
    "        fake_images = generator(noise, training=True)\n",
    "        \n",
    "        # D 순전파: 실제와 가짜 판별\n",
    "        real_output = discriminator(real_images, training=True)\n",
    "        fake_output = discriminator(fake_images, training=True)\n",
    "        \n",
    "        # 손실 계산\n",
    "        g_loss = generator_loss(fake_output)\n",
    "        d_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    # D 파라미터 업데이트\n",
    "    d_grads = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    disc_optimizer.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "    \n",
    "    # G 파라미터 업데이트\n",
    "    g_grads = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    gen_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "    \n",
    "    return g_loss, d_loss\n",
    "\n",
    "\n",
    "# 학습 루프 (30 에포크)\n",
    "print(f'GAN 학습 시작 ({EPOCHS} 에포크)...')\n",
    "\n",
    "# 학습 진행 모니터링용 고정 노이즈\n",
    "monitor_noise = tf.random.normal([16, LATENT_DIM])  # 4×4 격자용 16개\n",
    "\n",
    "gen_losses  = []\n",
    "disc_losses = []\n",
    "epoch_images = []   # 에포크별 생성 이미지 저장\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_g_losses = []\n",
    "    epoch_d_losses = []\n",
    "    \n",
    "    for batch in train_dataset:\n",
    "        g_loss, d_loss = train_step(batch)\n",
    "        epoch_g_losses.append(float(g_loss))\n",
    "        epoch_d_losses.append(float(d_loss))\n",
    "    \n",
    "    # 에포크 평균 손실\n",
    "    avg_g = np.mean(epoch_g_losses)\n",
    "    avg_d = np.mean(epoch_d_losses)\n",
    "    gen_losses.append(avg_g)\n",
    "    disc_losses.append(avg_d)\n",
    "    \n",
    "    # 고정 노이즈로 이미지 생성 저장\n",
    "    generated = generator(monitor_noise, training=False).numpy()\n",
    "    epoch_images.append(generated)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f'에포크 {epoch+1:2d}/{EPOCHS} | '\n",
    "          f'G: {avg_g:.4f} | D: {avg_d:.4f} | '\n",
    "          f'{elapsed:.1f}초')\n",
    "\n",
    "print('\\n학습 완료!')\n",
    "print(f'총 소요 시간: {(time.time()-start):.1f}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0007-4007-8007-000000000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(images_flat, title, n_rows=4, n_cols=4):\n",
    "    \"\"\"\n",
    "    생성 이미지를 4×4 격자로 시각화\n",
    "    images_flat: shape = (16, 784), 픽셀 범위 [-1, 1]\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(8, 8))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img = ((images_flat[i] + 1) / 2.0).reshape(28, 28)  # [-1,1] → [0,1]\n",
    "        ax.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "        ax.axis('off')\n",
    "    plt.suptitle(title, fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 에포크 1, 10, 20, 30 비교\n",
    "milestones = [1, 10, 20, 30]\n",
    "for ep in milestones:\n",
    "    idx = min(ep - 1, len(epoch_images) - 1)\n",
    "    plot_grid(epoch_images[idx], title=f'에포크 {ep} 생성 이미지 (4×4 격자)')\n",
    "\n",
    "# 손실 곡선\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 손실 그래프\n",
    "ax1 = axes[0]\n",
    "ax1.plot(range(1, EPOCHS+1), gen_losses,  'b-o', label='Generator 손실',     linewidth=2, markersize=4)\n",
    "ax1.plot(range(1, EPOCHS+1), disc_losses, 'r-s', label='Discriminator 손실', linewidth=2, markersize=4)\n",
    "ax1.axhline(y=np.log(2), color='gray', linestyle='--', alpha=0.8, label=f'균형점 (ln2≈{np.log(2):.3f})')\n",
    "ax1.set_xlabel('에포크', fontsize=11)\n",
    "ax1.set_ylabel('손실', fontsize=11)\n",
    "ax1.set_title('GAN 학습 손실 곡선', fontsize=12)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 손실 비율 (G/D 균형 확인)\n",
    "ax2 = axes[1]\n",
    "loss_ratio = [g/d if d > 0 else 0 for g, d in zip(gen_losses, disc_losses)]\n",
    "ax2.plot(range(1, EPOCHS+1), loss_ratio, 'g-^', linewidth=2, markersize=4)\n",
    "ax2.axhline(y=1.0, color='gray', linestyle='--', alpha=0.8, label='G/D = 1.0 (이상적 균형)')\n",
    "ax2.set_xlabel('에포크', fontsize=11)\n",
    "ax2.set_ylabel('G 손실 / D 손실', fontsize=11)\n",
    "ax2.set_title('G/D 손실 비율 (균형 모니터링)', fontsize=12)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Simple GAN 학습 분석', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'최종 Generator 손실:     {gen_losses[-1]:.4f}')\n",
    "print(f'최종 Discriminator 손실: {disc_losses[-1]:.4f}')\n",
    "print(f'이론적 균형점:            {np.log(2):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0-0008-4008-8008-000000000008",
   "metadata": {},
   "source": [
    "## 도전 과제: DCGAN으로 개선\n",
    "\n",
    "Dense 기반 GAN을 DCGAN(Deep Convolutional GAN)으로 개선하여 이미지 품질을 향상시켜 보자.\n",
    "\n",
    "### DCGAN Generator (참고 코드)\n",
    "\n",
    "```python\n",
    "def build_dcgan_generator(latent_dim=100):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(latent_dim,)),\n",
    "        \n",
    "        # Dense → Reshape\n",
    "        keras.layers.Dense(7 * 7 * 256, use_bias=False),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(0.2),\n",
    "        keras.layers.Reshape((7, 7, 256)),\n",
    "        \n",
    "        # Conv2DTranspose 스택\n",
    "        keras.layers.Conv2DTranspose(128, 5, strides=1, padding='same', use_bias=False),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(0.2),\n",
    "        \n",
    "        keras.layers.Conv2DTranspose(64, 5, strides=2, padding='same', use_bias=False),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(0.2),\n",
    "        \n",
    "        # 출력층: (28, 28, 1), tanh\n",
    "        keras.layers.Conv2DTranspose(1, 5, strides=2, padding='same', activation='tanh')\n",
    "    ], name='DCGAN_Generator')\n",
    "    return model\n",
    "```\n",
    "\n",
    "### DCGAN Discriminator (참고 코드)\n",
    "\n",
    "```python\n",
    "def build_dcgan_discriminator():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(28, 28, 1)),\n",
    "        \n",
    "        # Conv2D 스택\n",
    "        keras.layers.Conv2D(64, 5, strides=2, padding='same'),\n",
    "        keras.layers.LeakyReLU(0.2),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        keras.layers.Conv2D(128, 5, strides=2, padding='same'),\n",
    "        keras.layers.LeakyReLU(0.2),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # 분류 헤드\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ], name='DCGAN_Discriminator')\n",
    "    return model\n",
    "```\n",
    "\n",
    "### Dense GAN vs DCGAN 비교 실험\n",
    "\n",
    "| 항목 | Dense GAN | DCGAN |\n",
    "|------|-----------|-------|\n",
    "| 생성 이미지 품질 | ? | ? |\n",
    "| 파라미터 수 | ? | ? |\n",
    "| 학습 시간/에포크 | ? | ? |\n",
    "| Mode Collapse 빈도 | ? | ? |\n",
    "\n",
    "### 추가 개선 아이디어\n",
    "\n",
    "1. **Label Smoothing**: 실제 이미지 레이블 0.9로 설정 (D가 과자신감 방지)\n",
    "2. **One-sided Label Smoothing**: 실제만 0.9, 가짜는 0 유지\n",
    "3. **Spectral Normalization**: D의 가중치를 spectral norm으로 제약\n",
    "4. **WGAN**: BCE 손실 → Wasserstein Distance로 교체\n",
    "5. **Conditional GAN**: 생성할 숫자 클래스를 조건으로 입력 (c-GAN)\n",
    "\n",
    "### 참고: Conditional GAN 아이디어\n",
    "\n",
    "```python\n",
    "# G 입력: [noise (100,), class_label (10,)] → concatenate\n",
    "noise_input = keras.layers.Input(shape=(100,))\n",
    "label_input = keras.layers.Input(shape=(10,))  # one-hot\n",
    "x = keras.layers.Concatenate()([noise_input, label_input])  # (110,)\n",
    "# ... Dense 레이어 ...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
