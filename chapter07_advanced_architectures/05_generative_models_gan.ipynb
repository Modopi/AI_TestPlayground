{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0001-4001-8001-000000000001",
   "metadata": {},
   "source": [
    "# Chapter 07-05: 생성 모델 — GAN (Generative Adversarial Network)\n",
    "\n",
    "## 학습 목표\n",
    "- GAN의 목적 함수와 생성자/판별자의 역할을 이해한다\n",
    "- DCGAN(Deep Convolutional GAN)의 Generator와 Discriminator를 구현한다\n",
    "- 커스텀 학습 루프로 생성자와 판별자를 교대 업데이트한다\n",
    "- 에포크별 생성 이미지를 시각화하여 학습 진행을 모니터링한다\n",
    "- GAN 학습 불안정성의 원인과 해결책을 이해한다\n",
    "\n",
    "## 목차\n",
    "1. GAN 목적 함수\n",
    "2. DCGAN Generator 구현\n",
    "3. DCGAN Discriminator 구현\n",
    "4. 커스텀 GAN 학습 루프\n",
    "5. 에포크별 생성 이미지 시각화\n",
    "6. 학습 불안정성과 해결책\n",
    "7. 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0002-4002-8002-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "\n",
    "# 한글 폰트 설정 (macOS)\n",
    "matplotlib.rcParams['font.family'] = 'AppleGothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f'TensorFlow 버전: {tf.__version__}')\n",
    "\n",
    "# 재현성 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0003-4003-8003-000000000003",
   "metadata": {},
   "source": [
    "## 1. GAN 목적 함수\n",
    "\n",
    "GAN은 **생성자(Generator, G)**와 **판별자(Discriminator, D)**가 서로 경쟁하는 미니맥스 게임:\n",
    "\n",
    "$$\\min_G \\max_D\\; \\mathbb{E}[\\log D(x)] + \\mathbb{E}[\\log(1-D(G(z)))]$$\n",
    "\n",
    "| 항 | 해석 | 최적화 방향 |\n",
    "|----|------|------------|\n",
    "| $\\mathbb{E}[\\log D(x)]$ | 실제 이미지 $x$를 실제로 판별할 확률 | D는 **최대화** (1에 가깝게) |\n",
    "| $\\mathbb{E}[\\log(1-D(G(z)))]$ | 가짜 이미지 $G(z)$를 가짜로 판별할 확률 | D는 **최대화**, G는 **최소화** |\n",
    "\n",
    "### 직관적 이해\n",
    "\n",
    "```\n",
    "Generator G: 노이즈 z → 가짜 이미지 G(z) → D를 속이려 한다\n",
    "Discriminator D: 실제/가짜 이미지 → 진위 확률 D(x) → G를 검출하려 한다\n",
    "```\n",
    "\n",
    "- **균형점(Nash Equilibrium)**: D(x) = 0.5 → 판별자가 더 이상 구분 불가\n",
    "- **실제 학습**: G 손실 = $-\\log(D(G(z)))$ (Non-saturating 변형으로 기울기 안정화)\n",
    "\n",
    "### 손실 함수 (이진 교차 엔트로피 기반)\n",
    "\n",
    "- **D 손실**: $-\\mathbb{E}[\\log D(x)] - \\mathbb{E}[\\log(1-D(G(z)))]$\n",
    "  - 실제 이미지 레이블 = 1, 가짜 이미지 레이블 = 0\n",
    "- **G 손실**: $-\\mathbb{E}[\\log D(G(z))]$\n",
    "  - 가짜 이미지를 실제(레이블=1)로 속이려 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0004-4004-8004-000000000004",
   "metadata": {},
   "source": [
    "## 2. DCGAN Generator 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0005-4005-8005-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 100  # 잠재 벡터(노이즈) 차원\n",
    "\n",
    "def build_generator(latent_dim=LATENT_DIM):\n",
    "    \"\"\"\n",
    "    DCGAN Generator\n",
    "    노이즈 z (latent_dim,) → 이미지 (28, 28, 1)\n",
    "    \n",
    "    구조: Dense → Reshape → Conv2DTranspose 스택 → tanh 출력\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name='Generator')\n",
    "    \n",
    "    # --- Dense + Reshape ---\n",
    "    # 잠재 벡터를 작은 공간 맵으로 변환 (7×7×256 특징 맵)\n",
    "    model.add(keras.layers.Dense(7 * 7 * 256, use_bias=False,\n",
    "                                  input_shape=(latent_dim,)))\n",
    "    model.add(keras.layers.BatchNormalization())   # 배치 정규화로 학습 안정화\n",
    "    model.add(keras.layers.LeakyReLU(0.2))        # LeakyReLU (음수 기울기 허용)\n",
    "    \n",
    "    model.add(keras.layers.Reshape((7, 7, 256)))   # (7, 7, 256)\n",
    "    \n",
    "    # --- Conv2DTranspose (전치 합성곱) 스택 ---\n",
    "    # 공간 해상도를 점진적으로 2배씩 업샘플링\n",
    "    \n",
    "    # (7, 7, 256) → (7, 7, 128)\n",
    "    model.add(keras.layers.Conv2DTranspose(\n",
    "        128, kernel_size=5, strides=1, padding='same', use_bias=False\n",
    "    ))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    \n",
    "    # (7, 7, 128) → (14, 14, 64)  ← strides=2로 해상도 2배\n",
    "    model.add(keras.layers.Conv2DTranspose(\n",
    "        64, kernel_size=5, strides=2, padding='same', use_bias=False\n",
    "    ))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    \n",
    "    # (14, 14, 64) → (28, 28, 1)  ← 최종 출력층\n",
    "    model.add(keras.layers.Conv2DTranspose(\n",
    "        1, kernel_size=5, strides=2, padding='same',\n",
    "        use_bias=False, activation='tanh'  # tanh: 출력 범위 [-1, 1]\n",
    "    ))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "\n",
    "# 동작 확인\n",
    "test_noise = tf.random.normal([1, LATENT_DIM])\n",
    "test_gen_output = generator(test_noise, training=False)\n",
    "print(f'\\n노이즈 shape: {test_noise.shape}')\n",
    "print(f'생성 이미지 shape: {test_gen_output.shape}')  # (1, 28, 28, 1)\n",
    "print(f'픽셀 범위: [{test_gen_output.numpy().min():.3f}, {test_gen_output.numpy().max():.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0006-4006-8006-000000000006",
   "metadata": {},
   "source": [
    "## 3. DCGAN Discriminator 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0007-4007-8007-000000000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    DCGAN Discriminator\n",
    "    이미지 (28, 28, 1) → 확률 스칼라 (0~1)\n",
    "    \n",
    "    구조: Conv2D 스택 → Flatten → Dense → Sigmoid 출력\n",
    "    배치 정규화 대신 Dropout 사용 (GAN 판별자 권장)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name='Discriminator')\n",
    "    \n",
    "    # --- Conv2D 스택 (해상도 점진적 축소) ---\n",
    "    \n",
    "    # (28, 28, 1) → (14, 14, 64)\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        64, kernel_size=5, strides=2, padding='same',\n",
    "        input_shape=(28, 28, 1)\n",
    "    ))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))  # 음수 기울기 허용 (0.2 slope)\n",
    "    model.add(keras.layers.Dropout(0.3))    # 과적합 방지 (BN 대신 Dropout 사용)\n",
    "    \n",
    "    # (14, 14, 64) → (7, 7, 128)\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        128, kernel_size=5, strides=2, padding='same'\n",
    "    ))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    # --- 분류 헤드 ---\n",
    "    model.add(keras.layers.Flatten())       # (7*7*128,) = (6272,)\n",
    "    model.add(keras.layers.Dense(\n",
    "        1, activation='sigmoid'             # 0(가짜) ~ 1(실제) 확률\n",
    "    ))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n",
    "\n",
    "# 동작 확인\n",
    "test_image = tf.random.normal([1, 28, 28, 1])\n",
    "test_d_output = discriminator(test_image, training=False)\n",
    "print(f'\\n입력 이미지 shape: {test_image.shape}')\n",
    "print(f'판별 결과 shape: {test_d_output.shape}')      # (1, 1)\n",
    "print(f'판별 확률 (초기): {test_d_output.numpy()[0][0]:.4f}')  # 초기에는 무작위"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0008-4008-8008-000000000008",
   "metadata": {},
   "source": [
    "## 4. 커스텀 GAN 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0009-4009-8009-000000000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 준비\n",
    "(x_train, _), (_, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# 정규화: [0, 255] → [-1, 1] (tanh 출력과 일치)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = (x_train - 127.5) / 127.5        # [-1, 1] 범위로 정규화\n",
    "x_train = x_train[..., np.newaxis]          # (60000, 28, 28) → (60000, 28, 28, 1)\n",
    "\n",
    "print(f'훈련 데이터 shape: {x_train.shape}')\n",
    "print(f'픽셀 범위: [{x_train.min():.1f}, {x_train.max():.1f}]')\n",
    "\n",
    "# TF Dataset 파이프라인\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE  = 256\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(x_train)\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.AUTOTUNE)  # 비동기 데이터 로딩\n",
    ")\n",
    "\n",
    "# 손실 함수: 이진 교차 엔트로피 (from_logits=False, 이미 sigmoid 적용됨)\n",
    "bce_loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"\n",
    "    판별자 손실:\n",
    "    - 실제 이미지 → 1로 분류 (real_loss)\n",
    "    - 가짜 이미지 → 0으로 분류 (fake_loss)\n",
    "    \"\"\"\n",
    "    real_loss = bce_loss(tf.ones_like(real_output), real_output)   # 실제=1\n",
    "    fake_loss = bce_loss(tf.zeros_like(fake_output), fake_output)  # 가짜=0\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    \"\"\"\n",
    "    생성자 손실 (Non-saturating):\n",
    "    가짜 이미지를 실제(1)로 속이도록 학습\n",
    "    \"\"\"\n",
    "    return bce_loss(tf.ones_like(fake_output), fake_output)        # 가짜를 1로\n",
    "\n",
    "# 별도 Optimizer (D와 G가 독립적으로 학습)\n",
    "gen_optimizer  = keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)  # GAN 권장\n",
    "disc_optimizer = keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n",
    "\n",
    "print('손실 함수 및 옵티마이저 설정 완료')\n",
    "\n",
    "@tf.function  # 그래프 모드로 컴파일 → 속도 향상\n",
    "def train_step(real_images):\n",
    "    \"\"\"\n",
    "    한 배치의 GAN 학습 스텝:\n",
    "    1. G: 노이즈 → 가짜 이미지 생성\n",
    "    2. D: 실제/가짜 이미지 판별 후 손실 계산 → D 업데이트\n",
    "    3. G: 판별 결과로 손실 계산 → G 업데이트\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "    \n",
    "    # 노이즈 샘플링 (z ~ N(0, I))\n",
    "    noise = tf.random.normal([batch_size, LATENT_DIM])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # G 순전파: 가짜 이미지 생성\n",
    "        fake_images = generator(noise, training=True)\n",
    "        \n",
    "        # D 순전파: 실제/가짜 이미지 판별\n",
    "        real_output = discriminator(real_images, training=True)\n",
    "        fake_output = discriminator(fake_images, training=True)\n",
    "        \n",
    "        # 손실 계산\n",
    "        gen_loss  = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    # D 역전파 (D의 파라미터만 업데이트)\n",
    "    disc_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    disc_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n",
    "    \n",
    "    # G 역전파 (G의 파라미터만 업데이트)\n",
    "    gen_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gen_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "\n",
    "# 학습 루프\n",
    "EPOCHS = 20\n",
    "\n",
    "# 시각화용 고정 노이즈 (학습 진행 모니터링)\n",
    "seed_noise = tf.random.normal([16, LATENT_DIM])\n",
    "\n",
    "gen_losses  = []\n",
    "disc_losses = []\n",
    "saved_images = []  # 에포크별 생성 이미지 저장\n",
    "\n",
    "print(f'GAN 학습 시작 (총 {EPOCHS} 에포크)...')\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_gen_loss  = []\n",
    "    epoch_disc_loss = []\n",
    "    \n",
    "    for batch in train_dataset:\n",
    "        g_loss, d_loss = train_step(batch)\n",
    "        epoch_gen_loss.append(g_loss.numpy())\n",
    "        epoch_disc_loss.append(d_loss.numpy())\n",
    "    \n",
    "    avg_g_loss = np.mean(epoch_gen_loss)\n",
    "    avg_d_loss = np.mean(epoch_disc_loss)\n",
    "    gen_losses.append(avg_g_loss)\n",
    "    disc_losses.append(avg_d_loss)\n",
    "    \n",
    "    # 에포크별 생성 이미지 저장\n",
    "    generated = generator(seed_noise, training=False).numpy()\n",
    "    saved_images.append(generated)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f'에포크 {epoch+1:3d}/{EPOCHS} | '\n",
    "          f'G 손실: {avg_g_loss:.4f} | '\n",
    "          f'D 손실: {avg_d_loss:.4f} | '\n",
    "          f'경과: {elapsed:.1f}초')\n",
    "\n",
    "print('\\n학습 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0010-4010-8010-000000000010",
   "metadata": {},
   "source": [
    "## 5. 에포크별 생성 이미지 격자 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0011-4011-8011-000000000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(images, epoch, n_rows=4, n_cols=4):\n",
    "    \"\"\"\n",
    "    생성 이미지를 n_rows × n_cols 격자로 시각화\n",
    "    images: shape = (n, 28, 28, 1), 픽셀 범위 [-1, 1]\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 10))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(images):\n",
    "            # [-1, 1] → [0, 1]로 변환\n",
    "            img = (images[i, :, :, 0] + 1) / 2.0\n",
    "            ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'에포크 {epoch}: GAN 생성 이미지', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 초기/중간/최종 에포크 이미지 비교\n",
    "milestone_epochs = [1, EPOCHS//4, EPOCHS//2, EPOCHS]\n",
    "\n",
    "for ep in milestone_epochs:\n",
    "    idx = min(ep - 1, len(saved_images) - 1)\n",
    "    plot_generated_images(saved_images[idx], epoch=ep)\n",
    "\n",
    "# 손실 곡선\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(range(1, EPOCHS+1), gen_losses,  label='Generator 손실',     linewidth=2, color='blue')\n",
    "ax.plot(range(1, EPOCHS+1), disc_losses, label='Discriminator 손실', linewidth=2, color='red')\n",
    "ax.axhline(y=np.log(2), color='gray', linestyle='--', alpha=0.7, label='이론적 균형점 (ln2 ≈ 0.693)')\n",
    "ax.set_xlabel('에포크', fontsize=11)\n",
    "ax.set_ylabel('손실', fontsize=11)\n",
    "ax.set_title('GAN 학습 손실 곡선', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'최종 Generator 손실:     {gen_losses[-1]:.4f}')\n",
    "print(f'최종 Discriminator 손실: {disc_losses[-1]:.4f}')\n",
    "print(f'이론적 균형점:            {np.log(2):.4f} (ln 2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0012-4012-8012-000000000012",
   "metadata": {},
   "source": [
    "## 6. 학습 불안정성 원인과 해결책\n",
    "\n",
    "### 주요 문제 1: Mode Collapse (모드 붕괴)\n",
    "\n",
    "**현상**: Generator가 항상 동일하거나 매우 유사한 이미지만 생성  \n",
    "**원인**: D를 쉽게 속이는 특정 모드에만 집중하는 지름길 학습\n",
    "\n",
    "```\n",
    "예: MNIST에서 항상 숫자 '1'만 생성하여 D를 속이는 경우\n",
    "```\n",
    "\n",
    "**해결책**:\n",
    "- **Minibatch Discrimination**: 배치 내 다양성을 D 입력에 추가\n",
    "- **Feature Matching**: G가 D의 중간 레이어 특징 분포를 매칭\n",
    "- **Wasserstein GAN (WGAN)**: Earth Mover Distance로 손실 대체\n",
    "- **Mode Seeking Regularization**: 다양한 z → 다양한 이미지 장려\n",
    "\n",
    "### 주요 문제 2: Vanishing Gradient (기울기 소실)\n",
    "\n",
    "**현상**: D가 너무 잘 학습되면 G의 기울기가 0에 가까워져 G 학습 불가  \n",
    "**원인**: 완벽한 D → $D(G(z)) \\approx 0$ → $\\log(1-D(G(z))) \\approx 0$의 기울기가 소실\n",
    "\n",
    "**해결책**:\n",
    "- **Non-Saturating Loss**: $\\log(D(G(z)))$ 최대화로 변경 (기울기 포화 방지)\n",
    "- **Label Smoothing**: 실제 이미지 레이블을 1 대신 0.9로 설정\n",
    "- **WGAN-GP**: Gradient Penalty로 D의 Lipschitz 제약 강화\n",
    "\n",
    "### 주요 문제 3: 학습 불안정 (Oscillation)\n",
    "\n",
    "**현상**: G와 D 손실이 수렴하지 않고 진동  \n",
    "**해결책**:\n",
    "- **Two Time-Scale Update Rule (TTUR)**: G와 D에 다른 학습률 적용\n",
    "- **Spectral Normalization**: D의 가중치 정규화로 안정화\n",
    "- **D 업데이트 빈도 조절**: G 1회 업데이트 당 D를 n회 업데이트\n",
    "\n",
    "### GAN 변형 모델 비교\n",
    "\n",
    "| 모델 | 핵심 아이디어 | 장점 |\n",
    "|------|-------------|------|\n",
    "| **DCGAN** | Conv2DTranspose 기반 | 이미지 생성 기준 모델 |\n",
    "| **WGAN** | Wasserstein Distance | Mode Collapse 감소 |\n",
    "| **WGAN-GP** | Gradient Penalty | 학습 안정화 |\n",
    "| **StyleGAN** | 스타일 제어 | 고화질 얼굴 생성 |\n",
    "| **CycleGAN** | 비쌍 이미지 변환 | 도메인 변환 |\n",
    "| **Pix2Pix** | 쌍 이미지 변환 | 조건부 이미지 생성 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0013-4013-8013-000000000013",
   "metadata": {},
   "source": [
    "## 7. 정리\n",
    "\n",
    "### DCGAN 구현 핵심 요약\n",
    "\n",
    "| 요소 | Generator | Discriminator |\n",
    "|------|-----------|---------------|\n",
    "| 입력 | 노이즈 $z \\sim \\mathcal{N}(0,I)$ | 이미지 (28×28×1) |\n",
    "| 출력 | 이미지 (28×28×1) | 확률 스칼라 [0,1] |\n",
    "| 핵심 레이어 | Conv2DTranspose | Conv2D |\n",
    "| 정규화 | BatchNormalization | Dropout |\n",
    "| 활성화 | LeakyReLU + tanh(출력) | LeakyReLU + sigmoid(출력) |\n",
    "| 손실 목표 | D(G(z)) → 1 | D(x) → 1, D(G(z)) → 0 |\n",
    "\n",
    "### 학습 팁\n",
    "\n",
    "- **학습률**: G와 D 모두 `2e-4`, `beta_1=0.5` (Adam)\n",
    "- **픽셀 정규화**: 입력 이미지를 `[-1, 1]`로 (tanh 출력과 일치)\n",
    "- **배치 크기**: 64 ~ 256 (크면 학습 안정적)\n",
    "- **D 먼저 업데이트**: 일반적으로 D → G 순서로 업데이트\n",
    "- **균형 모니터링**: G 손실 ≈ D 손실 ≈ `ln(2) ≈ 0.693` 이 이상적"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
