{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 01: TensorFlow 소개 및 생태계\n",
    "\n",
    "## 학습 목표\n",
    "- TensorFlow 2.x의 핵심 철학과 Eager Execution 이해\n",
    "- TF 1.x의 정적 그래프 방식과의 차이점 파악\n",
    "- 현재 환경(버전, 장치, GPU/Metal 백엔드) 확인 방법 습득\n",
    "- TensorFlow 생태계 전체 조망\n",
    "\n",
    "## 목차\n",
    "1. [환경 확인](#환경-확인)\n",
    "2. [TF 1.x vs TF 2.x: 철학의 변화](#tf-1x-vs-tf-2x)\n",
    "3. [Eager Execution 이해](#eager-execution)\n",
    "4. [Apple Silicon & Metal 백엔드](#apple-silicon)\n",
    "5. [TensorFlow 생태계](#생태계)\n",
    "6. [요약](#요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 환경 확인 ──────────────────────────────────────────────────\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Python 버전     : {sys.version.split()[0]}\")\n",
    "print(f\"TensorFlow 버전 : {tf.__version__}\")\n",
    "print(f\"NumPy 버전      : {np.__version__}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 사용 가능한 물리적 장치 목록 출력\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"\\n사용 가능한 장치:\")\n",
    "for device in physical_devices:\n",
    "    print(f\"  - {device.device_type}: {device.name}\")\n",
    "\n",
    "# GPU 전용 목록\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"\\nGPU 개수: {len(gpus)}\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(f\"  GPU 장치: {gpu.name}\")\n",
    "else:\n",
    "    print(\"  GPU를 찾을 수 없습니다. CPU 모드로 실행됩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apple Silicon & Metal 백엔드 확인 <a name='apple-silicon'></a>\n",
    "\n",
    "Apple M-시리즈 칩(M1/M2/M3/M4)을 사용하는 경우, `tensorflow-metal` 플러그인을 통해  \n",
    "GPU 가속을 활용할 수 있습니다.\n",
    "\n",
    "**설치 방법:**\n",
    "```bash\n",
    "pip install tensorflow-metal\n",
    "```\n",
    "\n",
    "설치 후 장치 목록에 `GPU` 항목이 나타나면 Metal 백엔드가 정상 동작하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운영체제  : Darwin\n",
      "아키텍처  : arm64\n",
      "프로세서  : arm\n",
      "\n",
      " Apple Silicon 감지 (Metal 미설치 또는 CPU 전용 빌드)\n",
      "  'pip install tensorflow-metal' 로 GPU 가속을 활성화하세요.\n"
     ]
    }
   ],
   "source": [
    "# Apple Silicon Metal 백엔드 확인\n",
    "import platform\n",
    "\n",
    "print(f\"운영체제  : {platform.system()}\")\n",
    "print(f\"아키텍처  : {platform.machine()}\")\n",
    "print(f\"프로세서  : {platform.processor()}\")\n",
    "\n",
    "# Metal GPU 감지\n",
    "metal_gpus = tf.config.list_physical_devices('GPU')\n",
    "if metal_gpus and platform.machine() == 'arm64':\n",
    "    print(\"\\n Apple Silicon + Metal 백엔드 감지됨!\")\n",
    "    print(f\"  Metal GPU 장치: {metal_gpus[0].name}\")\n",
    "elif platform.machine() == 'arm64':\n",
    "    print(\"\\n Apple Silicon 감지 (Metal 미설치 또는 CPU 전용 빌드)\")\n",
    "    print(\"  'pip install tensorflow-metal' 로 GPU 가속을 활성화하세요.\")\n",
    "else:\n",
    "    print(\"\\n Intel/AMD 시스템\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF 1.x vs TF 2.x: 철학의 변화 <a name='tf-1x-vs-tf-2x'></a>\n",
    "\n",
    "### TensorFlow 1.x: 정적 계산 그래프 (Define-and-Run)\n",
    "\n",
    "TF 1.x에서는 코드를 실행하기 전에 **계산 그래프(Computational Graph)**를 먼저 선언하고,  \n",
    "이후 `Session`을 통해 그래프를 실행하는 방식이었습니다.\n",
    "\n",
    "```python\n",
    "# TF 1.x 방식 (현재는 사용하지 않음)\n",
    "import tensorflow as tf\n",
    "a = tf.placeholder(tf.float32)      # 자리 표시자 선언\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = tf.add(a, b)                    # 그래프 노드 연결\n",
    "with tf.Session() as sess:          # 세션에서만 실제 계산\n",
    "    result = sess.run(c, feed_dict={a: 3.0, b: 4.0})\n",
    "    print(result)  # 7.0\n",
    "```\n",
    "\n",
    "**단점:** 직관적이지 않음, 디버깅 어려움, Python 코드와의 자연스러운 통합 어려움\n",
    "\n",
    "---\n",
    "\n",
    "### TensorFlow 2.x: Eager Execution (Define-by-Run)\n",
    "\n",
    "TF 2.x는 **즉시 실행(Eager Execution)**을 기본으로 채택했습니다.  \n",
    "Python 코드가 실행되는 즉시 연산이 수행되어, NumPy처럼 직관적으로 사용할 수 있습니다.\n",
    "\n",
    "| 구분 | TF 1.x | TF 2.x |\n",
    "|------|--------|--------|\n",
    "| 실행 방식 | 정적 그래프 + Session | Eager Execution (즉시 실행) |\n",
    "| 디버깅 | 어려움 (그래프 전체 실행 필요) | 쉬움 (Python 디버거 사용 가능) |\n",
    "| API | 저수준 API 중심 | Keras 고수준 API 통합 |\n",
    "| 직관성 | 낮음 | 높음 (NumPy 스타일) |\n",
    "| 성능 최적화 | 그래프 최적화 자동 | `@tf.function` 데코레이터로 선택적 최적화 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Execution 이해 <a name='eager-execution'></a>\n",
    "\n",
    "Eager Execution이란 Python 코드 한 줄 한 줄이 즉시 실행되는 방식입니다.  \n",
    "마치 Python의 `int`, `float`처럼 Tensor도 즉시 값을 가집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eager Execution 기본 동작 확인\n",
    "print(\"Eager Execution 활성화 여부:\", tf.executing_eagerly())\n",
    "\n",
    "# 즉시 실행: Session 없이 바로 값이 계산됨\n",
    "a = tf.constant(3.0)\n",
    "b = tf.constant(4.0)\n",
    "c = a + b\n",
    "\n",
    "# TF 1.x였다면 c는 Tensor 노드였고, 값을 보려면 sess.run(c)가 필요했음\n",
    "# TF 2.x에서는 즉시 값을 출력 가능\n",
    "print(f\"a = {a.numpy()}\")\n",
    "print(f\"b = {b.numpy()}\")\n",
    "print(f\"c = a + b = {c.numpy()}\")\n",
    "print(f\"c 의 타입: {type(c)}\")\n",
    "print(f\"c 의 dtype: {c.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 제어 흐름과 자연스럽게 통합 (TF 1.x에서는 tf.cond, tf.while_loop 필요)\n",
    "def fizzbuzz_tf(n):\n",
    "    \"\"\"TF 텐서로 FizzBuzz - 일반 Python if/for 사용 가능\"\"\"\n",
    "    result = []\n",
    "    for i in tf.range(1, n + 1):\n",
    "        # 일반 Python 조건문 사용 가능 (Eager Execution 덕분)\n",
    "        val = i.numpy()\n",
    "        if val % 15 == 0:\n",
    "            result.append(\"FizzBuzz\")\n",
    "        elif val % 3 == 0:\n",
    "            result.append(\"Fizz\")\n",
    "        elif val % 5 == 0:\n",
    "            result.append(\"Buzz\")\n",
    "        else:\n",
    "            result.append(str(val))\n",
    "    return result\n",
    "\n",
    "print(\"FizzBuzz (1~20):\", fizzbuzz_tf(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function: 성능이 중요할 때 그래프 모드로 컴파일\n",
    "# Eager Execution의 편의성 + 그래프 최적화 성능을 모두 얻는 방법\n",
    "\n",
    "@tf.function  # 이 데코레이터로 함수를 계산 그래프로 컴파일\n",
    "def compute_graph(x, y):\n",
    "    return tf.matmul(x, y) + tf.reduce_sum(x)\n",
    "\n",
    "x = tf.random.normal([100, 100])\n",
    "y = tf.random.normal([100, 100])\n",
    "\n",
    "# 첫 호출: 트레이싱(tracing)으로 그래프 생성\n",
    "result = compute_graph(x, y)\n",
    "print(f\"계산 결과 shape: {result.shape}\")\n",
    "print(\"@tf.function으로 그래프 최적화 적용됨\")\n",
    "\n",
    "# 간단한 속도 비교\n",
    "import time\n",
    "\n",
    "def eager_fn(x, y):\n",
    "    return tf.matmul(x, y) + tf.reduce_sum(x)\n",
    "\n",
    "@tf.function\n",
    "def graph_fn(x, y):\n",
    "    return tf.matmul(x, y) + tf.reduce_sum(x)\n",
    "\n",
    "# 워밍업\n",
    "_ = eager_fn(x, y)\n",
    "_ = graph_fn(x, y)\n",
    "\n",
    "N = 100\n",
    "start = time.time()\n",
    "for _ in range(N):\n",
    "    eager_fn(x, y)\n",
    "eager_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(N):\n",
    "    graph_fn(x, y)\n",
    "graph_time = time.time() - start\n",
    "\n",
    "print(f\"\\nEager 실행 시간 ({N}회): {eager_time:.4f}초\")\n",
    "print(f\"Graph 실행 시간 ({N}회): {graph_time:.4f}초\")\n",
    "if graph_time < eager_time:\n",
    "    print(f\"@tf.function이 {eager_time/graph_time:.2f}배 빠름\")\n",
    "else:\n",
    "    print(\"이 경우 Eager가 더 빠르거나 비슷함 (단순 연산의 경우)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 생태계 <a name='생태계'></a>\n",
    "\n",
    "TensorFlow는 단순한 딥러닝 프레임워크가 아니라 **엔드-투-엔드 ML 플랫폼**입니다.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────┐\n",
    "│              TensorFlow 생태계                   │\n",
    "├──────────────┬──────────────┬────────────────────┤\n",
    "│   데이터     │    모델링    │     배포           │\n",
    "│  tf.data     │  tf.keras    │  TFLite (모바일)   │\n",
    "│  tf.io       │  tf.nn       │  TF Serving (서버) │\n",
    "│  TF Datasets │  tf.layers   │  TF.js (웹브라우저)│\n",
    "├──────────────┴──────────────┴────────────────────┤\n",
    "│               모니터링 & 도구                    │\n",
    "│  TensorBoard │ TF Profiler  │ TF Hub (모델 허브) │\n",
    "└─────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 주요 구성 요소\n",
    "\n",
    "| 구성 요소 | 역할 | 주요 사용 시나리오 |\n",
    "|-----------|------|-------------------|\n",
    "| **tf.keras** | 고수준 모델 API | 모델 정의, 학습, 평가 |\n",
    "| **tf.data** | 데이터 파이프라인 | 대용량 데이터 로딩/전처리 |\n",
    "| **TensorBoard** | 시각화 도구 | 학습 곡선, 모델 구조 시각화 |\n",
    "| **TFLite** | 경량화/배포 | 모바일, 임베디드 기기 |\n",
    "| **TF Hub** | 사전학습 모델 허브 | 전이학습(Transfer Learning) |\n",
    "| **TF Serving** | 모델 서빙 | 프로덕션 API 서버 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 하위 모듈 탐색\n",
    "print(\"tf.keras 구성요소 (일부):\")\n",
    "keras_modules = ['layers', 'models', 'optimizers', 'losses', 'metrics', 'callbacks']\n",
    "for mod in keras_modules:\n",
    "    print(f\"  tf.keras.{mod}\")\n",
    "\n",
    "print(\"\\ntf 핵심 모듈 (일부):\")\n",
    "tf_modules = ['data', 'io', 'math', 'nn', 'linalg', 'image', 'signal']\n",
    "for mod in tf_modules:\n",
    "    print(f\"  tf.{mod}\")\n",
    "\n",
    "print(\"\\n전체 서브모듈 수:\", len([m for m in dir(tf) if not m.startswith('_')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data 파이프라인 간단 예시\n",
    "# 실제 학습에서는 대용량 데이터를 효율적으로 처리하는 핵심 도구\n",
    "\n",
    "# 간단한 데이터셋 생성\n",
    "dataset = tf.data.Dataset.range(10)  # 0~9 숫자 데이터셋\n",
    "\n",
    "# 파이프라인 구성: 셔플 → 배치 → 반복\n",
    "pipeline = (\n",
    "    dataset\n",
    "    .shuffle(buffer_size=10, seed=42)   # 무작위 섞기\n",
    "    .batch(3)                            # 3개씩 묶기\n",
    "    .prefetch(tf.data.AUTOTUNE)          # 백그라운드 데이터 준비\n",
    ")\n",
    "\n",
    "print(\"tf.data 파이프라인 출력 (배치 크기=3):\")\n",
    "for batch in pipeline:\n",
    "    print(f\"  배치: {batch.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras 모델 구조 미리보기 (다음 챕터에서 자세히)\n",
    "# Sequential API로 간단한 신경망 구조 정의\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "], name='mnist_demo_model')\n",
    "\n",
    "print(\"Keras 모델 요약:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약 <a name='요약'></a>\n",
    "\n",
    "### 핵심 개념 정리\n",
    "\n",
    "| 개념 | 설명 |\n",
    "|------|------|\n",
    "| **Eager Execution** | 코드 실행 즉시 연산 수행. Python처럼 직관적 |\n",
    "| **@tf.function** | 함수를 계산 그래프로 컴파일해 성능 최적화 |\n",
    "| **tf.config** | 장치(GPU/CPU) 확인 및 설정 |\n",
    "| **Metal 백엔드** | Apple Silicon에서 GPU 가속 (tensorflow-metal) |\n",
    "| **tf.keras** | 고수준 모델링 API (TF 2.x에 완전 통합) |\n",
    "| **tf.data** | 효율적인 데이터 입력 파이프라인 |\n",
    "\n",
    "### 다음 챕터 예고: 02. 텐서와 연산\n",
    "\n",
    "다음 챕터에서는 TensorFlow의 핵심 데이터 구조인 **Tensor**를 심층적으로 학습합니다:\n",
    "- Tensor의 rank, shape, dtype\n",
    "- `tf.constant` vs `tf.Variable`\n",
    "- 행렬 곱 $C_{ij} = \\sum_k A_{ik}B_{kj}$\n",
    "- 브로드캐스팅 메커니즘\n",
    "- NumPy와의 상호 변환"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
