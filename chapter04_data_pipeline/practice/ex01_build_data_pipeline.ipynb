{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 04 실습: 데이터 파이프라인 구축\n",
    "\n",
    "## 목표\n",
    "CIFAR-10 데이터셋으로 완전한 학습용 파이프라인을 구축하고 시각화한다.\n",
    "\n",
    "### 실습 구성\n",
    "| 실습 | 내용 |\n",
    "|------|------|\n",
    "| 실습 1 | CIFAR-10 데이터 로드 및 탐색 |\n",
    "| 실습 2 | 전처리 파이프라인 (정규화 + cache/shuffle/batch/prefetch) |\n",
    "| 실습 3 | 데이터 증강 레이어 추가 |\n",
    "| 실습 4 | 시각화 (4×4 그리드, 클래스 레이블) |\n",
    "\n",
    "### 도전 과제 (선택)\n",
    "1. 증강 강도를 높여 (rotation=0.3) 시각화해보기\n",
    "2. Z-score 정규화 방법으로 바꿔보기\n",
    "3. `prefetch` 없을 때와 있을 때 배치 로드 시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 상위 디렉토리(chapter04_data_pipeline)를 모듈 경로에 추가\n",
    "# 공통 유틸리티가 있을 경우 import 가능\n",
    "sys.path.append('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# 한글 폰트 설정 (macOS)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 재현성을 위한 시드 고정\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "print('TensorFlow 버전:', tf.__version__)\n",
    "print('Python 버전:', sys.version)\n",
    "print('GPU 사용 가능:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 1: 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# CIFAR-10 데이터셋 로드\n",
    "# - 60,000장의 32×32 컬러 이미지 (훈련 50,000 + 테스트 10,000)\n",
    "# - 10개 클래스: airplane, automobile, bird, cat, deer,\n",
    "#                dog, frog, horse, ship, truck\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# y는 (N, 1) shape → (N,)으로 squeeze\n",
    "y_train = y_train.squeeze()\n",
    "y_test  = y_test.squeeze()\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "print('=== 데이터셋 정보 ===')\n",
    "print(f'훈련 이미지: {x_train.shape}  dtype: {x_train.dtype}')\n",
    "print(f'훈련 레이블: {y_train.shape}  dtype: {y_train.dtype}')\n",
    "print(f'테스트 이미지: {x_test.shape}')\n",
    "print(f'클래스 수: {len(CLASS_NAMES)}')\n",
    "print(f'픽셀값 범위: [{x_train.min()}, {x_train.max()}]')\n",
    "\n",
    "# 클래스별 샘플 수 확인\n",
    "print('\\n=== 클래스별 훈련 샘플 수 ===')\n",
    "for cls_id, cls_name in enumerate(CLASS_NAMES):\n",
    "    count = np.sum(y_train == cls_id)\n",
    "    print(f'  [{cls_id}] {cls_name:12s}: {count}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 원본 데이터 시각화: 각 클래스 대표 이미지\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "fig.suptitle('CIFAR-10 클래스별 대표 이미지 (원본 uint8)', fontsize=14)\n",
    "\n",
    "for cls_id, ax in enumerate(axes.flat):\n",
    "    # 해당 클래스의 첫 번째 샘플\n",
    "    idx = np.where(y_train == cls_id)[0][0]\n",
    "    ax.imshow(x_train[idx])\n",
    "    ax.set_title(f'[{cls_id}] {CLASS_NAMES[cls_id]}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 2: 전처리 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Min-Max 정규화 함수\n",
    "#\n",
    "# 수식: x' = (x - x_min) / (x_max - x_min)\n",
    "# CIFAR-10의 경우 x_min=0, x_max=255이므로 단순히 / 255.0\n",
    "#\n",
    "# 결과: 픽셀값 범위 [0, 255] → [0.0, 1.0]\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def normalize_minmax(image, label):\n",
    "    \"\"\"Min-Max 정규화: uint8 [0,255] → float32 [0.0, 1.0]\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0  # x_min=0, x_max=255 고정\n",
    "    return image, label\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 파이프라인 구성: cache → shuffle → batch → prefetch\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "BATCH_SIZE  = 32\n",
    "BUFFER_SIZE = 10_000  # shuffle 버퍼 크기\n",
    "\n",
    "def build_base_pipeline(x, y, batch_size=BATCH_SIZE, training=True):\n",
    "    \"\"\"\n",
    "    기본 전처리 파이프라인 (증강 없음).\n",
    "    x: numpy uint8 이미지 배열\n",
    "    y: numpy 레이블 배열\n",
    "    training: True이면 셔플 포함\n",
    "    \"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "    # 1단계: 개별 샘플 정규화 (병렬)\n",
    "    ds = ds.map(normalize_minmax, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # 2단계: 캐시 — 첫 에포크 전처리 결과를 메모리에 저장\n",
    "    #         두 번째 에포크부터는 캐시에서 읽어 속도 향상\n",
    "    ds = ds.cache()\n",
    "\n",
    "    # 3단계: 셔플 (훈련 시에만)\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "\n",
    "    # 4단계: 배치 생성\n",
    "    ds = ds.batch(batch_size, drop_remainder=training)\n",
    "\n",
    "    # 5단계: 프리패치 — GPU 연산 중 CPU가 다음 배치 준비\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "train_ds_base = build_base_pipeline(x_train, y_train, training=True)\n",
    "test_ds_base  = build_base_pipeline(x_test,  y_test,  training=False)\n",
    "\n",
    "print('=== 기본 파이프라인 구성 완료 ===')\n",
    "print('훈련 Dataset spec:', train_ds_base.element_spec)\n",
    "\n",
    "# 정규화 결과 확인\n",
    "for imgs, lbls in train_ds_base.take(1):\n",
    "    print(f'\\n배치 shape: {imgs.shape}')\n",
    "    print(f'픽셀값 범위: [{imgs.numpy().min():.4f}, {imgs.numpy().max():.4f}]')\n",
    "    print(f'평균: {imgs.numpy().mean():.4f}, 표준편차: {imgs.numpy().std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 3: 데이터 증강 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Keras Sequential 증강 레이어\n",
    "# 파이프라인의 .map() 단계에 삽입하여 CPU에서 처리한다\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    # 수평 뒤집기: 50% 확률 (자동차, 배 등에 적합)\n",
    "    tf.keras.layers.RandomFlip('horizontal', seed=SEED),\n",
    "\n",
    "    # ±15% 회전 (0.15 ≈ 8.6°)\n",
    "    # 너무 크면 숫자/텍스트 분류에서 오히려 해로울 수 있다\n",
    "    tf.keras.layers.RandomRotation(factor=0.15, seed=SEED),\n",
    "\n",
    "    # ±10% 크기 조정\n",
    "    tf.keras.layers.RandomZoom(height_factor=0.1, width_factor=0.1, seed=SEED),\n",
    "], name='augmentation')\n",
    "\n",
    "def augment_fn(image, label):\n",
    "    \"\"\"파이프라인용 증강 래퍼 함수.\"\"\"\n",
    "    # training=True: 훈련 시에만 랜덤 증강 활성화\n",
    "    image = augmentation(image, training=True)\n",
    "    return image, label\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 증강 포함 파이프라인 구성\n",
    "# 증강은 배치 이후에 적용: 배치 단위로 한 번에 처리\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def build_augmented_pipeline(x, y, batch_size=BATCH_SIZE, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    ds = ds.map(normalize_minmax, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.cache()\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "    ds = ds.batch(batch_size, drop_remainder=training)\n",
    "    if training:\n",
    "        # 배치 단위 증강: num_parallel_calls로 CPU 병렬 처리\n",
    "        ds = ds.map(augment_fn, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds_aug = build_augmented_pipeline(x_train, y_train, training=True)\n",
    "test_ds      = build_augmented_pipeline(x_test,  y_test,  training=False)\n",
    "\n",
    "print('=== 증강 파이프라인 구성 완료 ===')\n",
    "print('훈련 Dataset spec:', train_ds_aug.element_spec)\n",
    "print('증강 레이어 구성:')\n",
    "augmentation.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 4: 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 증강된 샘플 16개를 4×4 그리드로 시각화\n",
    "# 각 셀에 클래스 레이블(한글) 표시\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "CLASS_NAMES_KO = [\n",
    "    '비행기', '자동차', '새', '고양이', '사슴',\n",
    "    '개', '개구리', '말', '선박', '트럭'\n",
    "]\n",
    "\n",
    "# 첫 번째 배치에서 16개 추출\n",
    "for imgs, lbls in train_ds_aug.take(1):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "    fig.suptitle('증강된 CIFAR-10 샘플 (4×4 그리드)', fontsize=14, y=1.02)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # 픽셀값을 [0,1] 범위로 클리핑 후 시각화\n",
    "        img = tf.clip_by_value(imgs[i], 0.0, 1.0).numpy()\n",
    "        lbl = lbls[i].numpy()\n",
    "\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(\n",
    "            f'{CLASS_NAMES_KO[lbl]}\\n({CLASS_NAMES[lbl]})',\n",
    "            fontsize=9,\n",
    "            pad=3\n",
    "        )\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 원본 vs 증강 비교: 동일 이미지 1장을 여러 번 증강\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# 원본 이미지 한 장 선택 (float32 정규화)\n",
    "sample_img = tf.cast(x_train[0], tf.float32) / 255.0  # (32, 32, 3)\n",
    "sample_lbl = y_train[0]\n",
    "sample_batch = tf.expand_dims(sample_img, 0)           # (1, 32, 32, 3)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "fig.suptitle(\n",
    "    f'원본: {CLASS_NAMES_KO[sample_lbl]} ({CLASS_NAMES[sample_lbl]}) '\n",
    "    f'→ 동일 이미지 9번 증강',\n",
    "    fontsize=13\n",
    ")\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i == 0:\n",
    "        ax.imshow(sample_img.numpy())\n",
    "        ax.set_title('원본', fontsize=10, color='red')\n",
    "    else:\n",
    "        # training=True: 랜덤 증강 적용\n",
    "        aug_img = augmentation(sample_batch, training=True)[0]\n",
    "        ax.imshow(tf.clip_by_value(aug_img, 0.0, 1.0).numpy())\n",
    "        ax.set_title(f'증강 #{i}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도전 과제\n",
    "\n",
    "### 도전 1: 증강 강도 높이기 (rotation=0.3)\n",
    "\n",
    "아래 셀에서 `RandomRotation(factor=0.3)`으로 변경하고 시각화를 다시 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도전 1: 더 강한 증강 레이어\n",
    "augmentation_strong = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal', seed=SEED),\n",
    "    tf.keras.layers.RandomRotation(factor=0.3, seed=SEED),   # 0.15 → 0.3으로 강화\n",
    "    tf.keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2, seed=SEED),\n",
    "    tf.keras.layers.RandomContrast(factor=0.3, seed=SEED),   # 대비 조정 추가\n",
    "], name='augmentation_strong')\n",
    "\n",
    "# 강한 증강 시각화\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "fig.suptitle('[도전 1] 강한 증강 (rotation=0.3)', fontsize=13)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i == 0:\n",
    "        ax.imshow(sample_img.numpy())\n",
    "        ax.set_title('원본', fontsize=10, color='red')\n",
    "    else:\n",
    "        aug_img = augmentation_strong(sample_batch, training=True)[0]\n",
    "        ax.imshow(tf.clip_by_value(aug_img, 0.0, 1.0).numpy())\n",
    "        ax.set_title(f'강한 증강 #{i}', fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 도전 2: Z-score 정규화\n",
    "#\n",
    "# 수식: x' = (x - mu) / sigma\n",
    "#\n",
    "# CIFAR-10의 채널별 평균/표준편차 (사전 계산된 통계값)\n",
    "# mean = [0.4914, 0.4822, 0.4465]  (R, G, B)\n",
    "# std  = [0.2470, 0.2435, 0.2616]  (R, G, B)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# 훈련 데이터에서 직접 계산\n",
    "x_train_f = x_train.astype('float32') / 255.0\n",
    "CIFAR_MEAN = x_train_f.mean(axis=(0, 1, 2))  # 채널별 평균\n",
    "CIFAR_STD  = x_train_f.std(axis=(0, 1, 2))   # 채널별 표준편차\n",
    "\n",
    "print('CIFAR-10 채널별 통계값:')\n",
    "print(f'  Mean: R={CIFAR_MEAN[0]:.4f}, G={CIFAR_MEAN[1]:.4f}, B={CIFAR_MEAN[2]:.4f}')\n",
    "print(f'  Std:  R={CIFAR_STD[0]:.4f},  G={CIFAR_STD[1]:.4f},  B={CIFAR_STD[2]:.4f}')\n",
    "\n",
    "# Z-score 정규화 함수\n",
    "MEAN_TENSOR = tf.constant(CIFAR_MEAN, dtype=tf.float32)  # (3,)\n",
    "STD_TENSOR  = tf.constant(CIFAR_STD,  dtype=tf.float32)  # (3,)\n",
    "\n",
    "def normalize_zscore(image, label):\n",
    "    \"\"\"Z-score 표준화: 채널별 평균 0, 표준편차 1로 변환\"\"\"\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # 먼저 [0,1]로\n",
    "    image = (image - MEAN_TENSOR) / STD_TENSOR   # Z-score\n",
    "    return image, label\n",
    "\n",
    "# Z-score 파이프라인 구성\n",
    "train_ds_zscore = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .map(normalize_zscore, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE, seed=SEED)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "for imgs_z, _ in train_ds_zscore.take(1):\n",
    "    print(f'\\n[도전 2] Z-score 정규화 결과:')\n",
    "    print(f'  shape: {imgs_z.shape}')\n",
    "    print(f'  R 채널 — 평균: {imgs_z[...,0].numpy().mean():.4f}, 표준편차: {imgs_z[...,0].numpy().std():.4f}')\n",
    "    print(f'  G 채널 — 평균: {imgs_z[...,1].numpy().mean():.4f}, 표준편차: {imgs_z[...,1].numpy().std():.4f}')\n",
    "    print(f'  B 채널 — 평균: {imgs_z[...,2].numpy().mean():.4f}, 표준편차: {imgs_z[...,2].numpy().std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 도전 3: prefetch 유무에 따른 배치 로드 시간 측정\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "NUM_EPOCHS = 3  # 여러 에포크에 걸쳐 측정 (캐시 효과 포함)\n",
    "\n",
    "def time_pipeline(ds, epochs=NUM_EPOCHS, label=''):\n",
    "    \"\"\"dataset을 epochs 회 순회하는 시간(초)을 반환한다.\"\"\"\n",
    "    times = []\n",
    "    for ep in range(epochs):\n",
    "        t0 = time.perf_counter()\n",
    "        batch_count = 0\n",
    "        for _ in ds:\n",
    "            batch_count += 1\n",
    "        elapsed = time.perf_counter() - t0\n",
    "        times.append(elapsed)\n",
    "        print(f'  [{label}] 에포크 {ep+1}: {elapsed:.3f}초  ({batch_count}배치)')\n",
    "    return times\n",
    "\n",
    "# prefetch 없는 파이프라인\n",
    "ds_no_prefetch = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .map(normalize_minmax, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE, seed=SEED)\n",
    "    .batch(BATCH_SIZE)\n",
    "    # .prefetch() 없음\n",
    ")\n",
    "\n",
    "# prefetch 있는 파이프라인\n",
    "ds_with_prefetch = ds_no_prefetch.prefetch(AUTOTUNE)\n",
    "\n",
    "print('=== prefetch 없음 ===')\n",
    "times_no = time_pipeline(ds_no_prefetch, label='no prefetch')\n",
    "\n",
    "print('\\n=== prefetch 있음 (AUTOTUNE) ===')\n",
    "times_yes = time_pipeline(ds_with_prefetch, label='with prefetch')\n",
    "\n",
    "# 결과 요약\n",
    "print('\\n=== 결과 요약 ===')\n",
    "print(f'prefetch 없음 — 평균: {np.mean(times_no):.3f}초')\n",
    "print(f'prefetch 있음 — 평균: {np.mean(times_yes):.3f}초')\n",
    "ratio = np.mean(times_no) / np.mean(times_yes)\n",
    "print(f'속도 향상: {ratio:.2f}x  ({\"빠름\" if ratio > 1 else \"차이 없음\"})')\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "epochs_x = list(range(1, NUM_EPOCHS + 1))\n",
    "ax.plot(epochs_x, times_no,  'o-', label='prefetch 없음', color='tomato')\n",
    "ax.plot(epochs_x, times_yes, 's-', label='prefetch 있음 (AUTOTUNE)', color='steelblue')\n",
    "ax.set_xlabel('에포크')\n",
    "ax.set_ylabel('소요 시간 (초)')\n",
    "ax.set_title('prefetch 유무에 따른 배치 로드 시간 비교')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "### 이번 실습에서 구축한 파이프라인 전체 구조\n",
    "\n",
    "```\n",
    "CIFAR-10 numpy 배열\n",
    "  │\n",
    "  ├─ from_tensor_slices()\n",
    "  │\n",
    "  ├─ .map(normalize_minmax)   ← Min-Max 정규화: x' = x / 255\n",
    "  │\n",
    "  ├─ .cache()                 ← 메모리 캐시 (2번째 에포크부터 고속)\n",
    "  │\n",
    "  ├─ .shuffle(10000)          ← 랜덤 셔플 (훈련 시만)\n",
    "  │\n",
    "  ├─ .batch(32)               ← 배치 생성\n",
    "  │\n",
    "  ├─ .map(augment_fn)         ← RandomFlip + RandomRotation + RandomZoom\n",
    "  │                              (훈련 시만, 배치 단위 처리)\n",
    "  │\n",
    "  └─ .prefetch(AUTOTUNE)      ← 비동기 프리패치\n",
    "```\n",
    "\n",
    "### 도전 과제 결과 요약\n",
    "\n",
    "| 도전 | 핵심 포인트 |\n",
    "|------|------------|\n",
    "| 1. 강한 증강 (rotation=0.3) | 과도한 회전은 객체 인식을 어렵게 만들 수 있음 |\n",
    "| 2. Z-score 정규화 | 채널별 평균 ≈ 0, 표준편차 ≈ 1; 심층 네트워크 학습 안정화 |\n",
    "| 3. prefetch 성능 측정 | 특히 1번째 에포크(캐시 미스) 이후에 효과가 두드러짐 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
