{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 04-03: TFRecord 포맷\n",
    "\n",
    "## 학습 목표\n",
    "- TFRecord 형식의 구조와 대용량 데이터에서의 이점을 이해한다\n",
    "- `tf.train.Example` / `tf.train.Feature`로 데이터를 직렬화한다\n",
    "- TFRecord 파일을 쓰고 읽는 전체 워크플로우를 구현한다\n",
    "- 파싱 함수와 `tf.data` 파이프라인을 연결한다\n",
    "\n",
    "## 목차\n",
    "1. TFRecord가 필요한 이유\n",
    "2. tf.train.Feature 3가지 타입\n",
    "3. MNIST → TFRecord 변환\n",
    "4. TFRecord 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "# 한글 폰트 설정 (macOS)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print('TensorFlow 버전:', tf.__version__)\n",
    "\n",
    "# MNIST 데이터 로드\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(f'MNIST 훈련: {x_train.shape}, 테스트: {x_test.shape}')\n",
    "\n",
    "# TFRecord 저장 경로 설정\n",
    "TFRECORD_DIR = pathlib.Path('/tmp/mnist_tfrecords')\n",
    "TFRECORD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_TFR = str(TFRECORD_DIR / 'train.tfrecord')\n",
    "TEST_TFR  = str(TFRECORD_DIR / 'test.tfrecord')\n",
    "print(f'TFRecord 저장 경로: {TFRECORD_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord가 필요한 이유\n",
    "\n",
    "**일반 이미지 파일**: 각 파일을 개별로 열어야 → 대용량에서 I/O 병목\n",
    "\n",
    "**TFRecord**: 모든 데이터를 하나의 이진 파일로 → 순차 읽기 최적화\n",
    "\n",
    "### 파일 형식 비교\n",
    "\n",
    "| 방식 | 파일 수 | 읽기 방식 | 대용량 성능 |\n",
    "|------|---------|-----------|------------|\n",
    "| 개별 JPEG/PNG | 데이터 수만큼 | 랜덤 접근 (비효율) | 느림 |\n",
    "| TFRecord | 몇 개의 큰 파일 | 순차 읽기 (최적화) | 빠름 |\n",
    "\n",
    "### TFRecord 파일 구조\n",
    "```\n",
    "TFRecord 파일\n",
    "├── Record 1: tf.train.Example (직렬화된 protobuf)\n",
    "│     └── tf.train.Features\n",
    "│           ├── 'image': bytes_list\n",
    "│           └── 'label': int64_list\n",
    "├── Record 2: tf.train.Example\n",
    "│     └── ...\n",
    "└── Record N: tf.train.Example\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.train.Feature 3가지 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# tf.train.Feature는 세 가지 타입만 지원한다:\n",
    "#   1. bytes_list  — 문자열, 바이트 배열, 직렬화된 이미지\n",
    "#   2. float_list  — 부동소수점 수 (float32)\n",
    "#   3. int64_list  — 정수 (int64)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# 1. bytes_list: 이미지 raw bytes나 문자열 저장에 사용\n",
    "def bytes_feature(value):\n",
    "    \"\"\"bytes 또는 str을 bytes_list Feature로 변환한다.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()  # EagerTensor → bytes 변환\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "# 2. float_list: 정규화된 픽셀값, 임베딩 벡터 등\n",
    "def float_feature(value):\n",
    "    \"\"\"float 또는 float 리스트를 float_list Feature로 변환한다.\"\"\"\n",
    "    if not isinstance(value, (list, np.ndarray)):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "# 3. int64_list: 레이블, 인덱스, 정수형 메타데이터\n",
    "def int64_feature(value):\n",
    "    \"\"\"int 또는 int 리스트를 int64_list Feature로 변환한다.\"\"\"\n",
    "    if not isinstance(value, (list, np.ndarray)):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "# 각 타입 동작 확인\n",
    "ex_bytes = bytes_feature(b'hello tfrecord')\n",
    "ex_float = float_feature([0.1, 0.2, 0.9])\n",
    "ex_int   = int64_feature([3, 7, 42])\n",
    "\n",
    "print('bytes_list Feature:')\n",
    "print(ex_bytes)\n",
    "print('float_list Feature:')\n",
    "print(ex_float)\n",
    "print('int64_list Feature:')\n",
    "print(ex_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST → TFRecord 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# create_tf_example: 이미지 + 레이블 → tf.train.Example\n",
    "#\n",
    "# 이미지는 bytes_list에 저장한다:\n",
    "#   - numpy ndarray.tobytes()로 raw bytes 직렬화\n",
    "#   - shape 정보도 별도 Feature로 저장해야 복원 가능\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def create_tf_example(image, label):\n",
    "    \"\"\"\n",
    "    image: numpy uint8 배열 (28, 28)\n",
    "    label: int\n",
    "    returns: 직렬화된 tf.train.Example bytes\n",
    "    \"\"\"\n",
    "    # 이미지를 raw bytes로 변환\n",
    "    image_bytes = image.tobytes()\n",
    "\n",
    "    feature = {\n",
    "        'image/raw':    bytes_feature(image_bytes),      # 이미지 raw bytes\n",
    "        'image/height': int64_feature(image.shape[0]),   # 높이 (28)\n",
    "        'image/width':  int64_feature(image.shape[1]),   # 너비 (28)\n",
    "        'label':        int64_feature(int(label)),       # 레이블 (0-9)\n",
    "    }\n",
    "\n",
    "    tf_example = tf.train.Example(\n",
    "        features=tf.train.Features(feature=feature)\n",
    "    )\n",
    "    # SerializeToString(): protobuf → bytes (파일에 쓸 수 있는 형태)\n",
    "    return tf_example.SerializeToString()\n",
    "\n",
    "# 단일 샘플 테스트\n",
    "test_example = create_tf_example(x_train[0], y_train[0])\n",
    "print(f'직렬화된 Example 크기: {len(test_example)} bytes')\n",
    "print(f'원본 이미지 크기: {x_train[0].nbytes} bytes')\n",
    "print(f'오버헤드: {len(test_example) - x_train[0].nbytes} bytes (Feature 키 + protobuf 헤더)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# TFRecord 파일 쓰기\n",
    "# tf.io.TFRecordWriter를 컨텍스트 매니저로 사용하면\n",
    "# 파일이 자동으로 닫히고 flush된다\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def write_tfrecord(images, labels, filepath, max_samples=None):\n",
    "    \"\"\"\n",
    "    images, labels 배열을 TFRecord 파일로 저장한다.\n",
    "    max_samples: 저장할 최대 샘플 수 (None이면 전체)\n",
    "    \"\"\"\n",
    "    if max_samples is not None:\n",
    "        images = images[:max_samples]\n",
    "        labels = labels[:max_samples]\n",
    "\n",
    "    start = time.time()\n",
    "    with tf.io.TFRecordWriter(filepath) as writer:\n",
    "        for i, (img, lbl) in enumerate(zip(images, labels)):\n",
    "            serialized = create_tf_example(img, lbl)\n",
    "            writer.write(serialized)\n",
    "            if (i + 1) % 5000 == 0:\n",
    "                print(f'  {i+1}/{len(images)} 기록 완료...')\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    file_size = os.path.getsize(filepath) / 1024 / 1024\n",
    "    print(f'저장 완료: {filepath}')\n",
    "    print(f'  샘플 수: {len(images)}, 파일 크기: {file_size:.2f} MB, 소요 시간: {elapsed:.1f}초')\n",
    "\n",
    "# 훈련 데이터 전체 → TFRecord (처음 실행 시 약 10-20초 소요)\n",
    "print('=== 훈련 TFRecord 생성 ===')\n",
    "write_tfrecord(x_train, y_train, TRAIN_TFR)\n",
    "\n",
    "print('\\n=== 테스트 TFRecord 생성 ===')\n",
    "write_tfrecord(x_test, y_test, TEST_TFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 파싱 함수: 직렬화된 bytes → (이미지 텐서, 레이블 텐서)\n",
    "#\n",
    "# tf.io.parse_single_example():\n",
    "#   - serialized: 단일 직렬화 Example\n",
    "#   - features: Feature 이름 → 예상 타입/형태 명세\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Feature 명세 (쓸 때와 동일한 키/타입 사용)\n",
    "FEATURE_DESCRIPTION = {\n",
    "    'image/raw':    tf.io.FixedLenFeature([], tf.string),   # bytes_list\n",
    "    'image/height': tf.io.FixedLenFeature([], tf.int64),    # int64_list\n",
    "    'image/width':  tf.io.FixedLenFeature([], tf.int64),    # int64_list\n",
    "    'label':        tf.io.FixedLenFeature([], tf.int64),    # int64_list\n",
    "}\n",
    "\n",
    "def parse_fn(serialized_example):\n",
    "    \"\"\"\n",
    "    직렬화된 tf.train.Example을 파싱하여\n",
    "    (이미지 텐서, 레이블 텐서) 쌍을 반환한다.\n",
    "    \"\"\"\n",
    "    # protobuf 파싱\n",
    "    parsed = tf.io.parse_single_example(serialized_example, FEATURE_DESCRIPTION)\n",
    "\n",
    "    # raw bytes → uint8 텐서 복원\n",
    "    image = tf.io.decode_raw(parsed['image/raw'], tf.uint8)\n",
    "\n",
    "    # flat 텐서 → 원래 shape으로 reshape\n",
    "    h = parsed['image/height']\n",
    "    w = parsed['image/width']\n",
    "    image = tf.reshape(image, [h, w])\n",
    "\n",
    "    # 정규화: [0,255] → [0.0, 1.0]\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    # 채널 차원 추가: (28,28) → (28,28,1)\n",
    "    image = tf.expand_dims(image, axis=-1)\n",
    "\n",
    "    label = parsed['label']\n",
    "    return image, label\n",
    "\n",
    "# 파싱 함수 단독 테스트\n",
    "raw_ds = tf.data.TFRecordDataset(TRAIN_TFR)\n",
    "for raw_record in raw_ds.take(1):\n",
    "    img, lbl = parse_fn(raw_record)\n",
    "    print(f'파싱 후 이미지 shape: {img.shape}, dtype: {img.dtype}')\n",
    "    print(f'파싱 후 레이블: {lbl.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# TFRecord → tf.data 파이프라인 구성\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def load_tfrecord_dataset(filepath, training=True, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    TFRecord 파일에서 완전한 학습용 Dataset을 생성한다.\n",
    "    num_parallel_reads: 여러 TFRecord 파일을 병렬로 읽을 때 사용\n",
    "    \"\"\"\n",
    "    ds = tf.data.TFRecordDataset(\n",
    "        filepath,\n",
    "        num_parallel_reads=AUTOTUNE  # 파일이 여러 개일 때 병렬 읽기\n",
    "    )\n",
    "    # 파싱을 병렬로 수행 (CPU 코어 활용)\n",
    "    ds = ds.map(parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.cache()                           # 파싱 결과를 메모리에 캐시\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=10_000)\n",
    "    ds = ds.batch(batch_size, drop_remainder=training)\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = load_tfrecord_dataset(TRAIN_TFR, training=True)\n",
    "test_ds  = load_tfrecord_dataset(TEST_TFR,  training=False)\n",
    "\n",
    "print('훈련 Dataset spec:', train_ds.element_spec)\n",
    "print('테스트 Dataset spec:', test_ds.element_spec)\n",
    "\n",
    "# 배치 수 확인\n",
    "n_train_batches = sum(1 for _ in train_ds)\n",
    "n_test_batches  = sum(1 for _ in test_ds)\n",
    "print(f'\\n훈련 배치 수: {n_train_batches}  (60000 // 64 = {60000 // 64})')\n",
    "print(f'테스트 배치 수: {n_test_batches}  (10000 // 64 ≈ {10000 // 64})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# TFRecord 파이프라인에서 로드된 데이터 시각화\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "for imgs, labels in train_ds.take(1):\n",
    "    fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "    fig.suptitle('TFRecord에서 로드된 MNIST 이미지 (배치 크기=64 중 24개)', fontsize=13)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(imgs[i].numpy().squeeze(), cmap='gray')\n",
    "        ax.set_title(f'레이블: {labels[i].numpy()}', fontsize=8)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f'배치 이미지 shape: {imgs.shape}  — (64, 28, 28, 1)')\n",
    "print(f'픽셀값 범위: [{imgs.numpy().min():.3f}, {imgs.numpy().max():.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# (심화) 다중 TFRecord 파일 분할\n",
    "#\n",
    "# 대규모 데이터셋에서는 하나의 TFRecord 대신\n",
    "# 여러 개의 shard 파일로 분할하면:\n",
    "#   1. 병렬 읽기 가능 (num_parallel_reads=AUTOTUNE)\n",
    "#   2. 파일별로 캐시/스트리밍 관리 용이\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "NUM_SHARDS = 4  # 4개 파일로 분할\n",
    "SHARD_DIR = TFRECORD_DIR / 'shards'\n",
    "SHARD_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 샘플 수 / 샤드 수 = 샤드당 샘플 수\n",
    "shard_size = len(x_train) // NUM_SHARDS\n",
    "\n",
    "for shard_id in range(NUM_SHARDS):\n",
    "    shard_path = str(SHARD_DIR / f'train-{shard_id:05d}-of-{NUM_SHARDS:05d}.tfrecord')\n",
    "    start_idx = shard_id * shard_size\n",
    "    end_idx   = start_idx + shard_size\n",
    "\n",
    "    with tf.io.TFRecordWriter(shard_path) as writer:\n",
    "        for img, lbl in zip(x_train[start_idx:end_idx], y_train[start_idx:end_idx]):\n",
    "            writer.write(create_tf_example(img, lbl))\n",
    "\n",
    "    print(f'  shard {shard_id+1}/{NUM_SHARDS}: {shard_path} ({shard_size}개)')\n",
    "\n",
    "# glob 패턴으로 모든 shard 로드\n",
    "shard_files = sorted(SHARD_DIR.glob('*.tfrecord'))\n",
    "shard_ds = tf.data.TFRecordDataset(\n",
    "    [str(f) for f in shard_files],\n",
    "    num_parallel_reads=AUTOTUNE  # 4개 파일을 병렬로 읽음\n",
    ").map(parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "print(f'\\n{NUM_SHARDS}개 shard에서 로드된 총 샘플 수: {sum(1 for _ in shard_ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "### TFRecord 워크플로우 요약\n",
    "\n",
    "```\n",
    "[쓰기]\n",
    "numpy 배열\n",
    "  └→ bytes_feature / int64_feature / float_feature\n",
    "       └→ tf.train.Features\n",
    "            └→ tf.train.Example\n",
    "                 └→ .SerializeToString()\n",
    "                      └→ TFRecordWriter.write()\n",
    "\n",
    "[읽기]\n",
    "TFRecord 파일\n",
    "  └→ tf.data.TFRecordDataset\n",
    "       └→ .map(parse_fn)\n",
    "            └→ tf.io.parse_single_example()\n",
    "                 └→ tf.io.decode_raw() / decode_jpeg() 등\n",
    "                      └→ reshape → normalize\n",
    "                           └→ .cache().shuffle().batch().prefetch()\n",
    "```\n",
    "\n",
    "| 항목 | 설명 |\n",
    "|------|------|\n",
    "| `bytes_list` | 이미지 raw bytes, 문자열, 직렬화된 텐서 |\n",
    "| `float_list` | 부동소수점 수, 정규화된 픽셀, 임베딩 |\n",
    "| `int64_list` | 레이블, 정수 메타데이터, shape 정보 |\n",
    "| `FixedLenFeature` | 길이가 고정된 Feature 파싱 |\n",
    "| `VarLenFeature` | 길이가 가변적인 Feature 파싱 |\n",
    "\n",
    "**다음**: practice/ex01_build_data_pipeline.ipynb — 종합 실습"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
