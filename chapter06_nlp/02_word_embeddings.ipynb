{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-0002-0001-0001-000000000001",
   "metadata": {},
   "source": [
    "# Chapter 06-02: ë‹¨ì–´ ì„ë² ë”© (Word Embeddings)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- One-Hot ì¸ì½”ë”©ì˜ í•œê³„ë¥¼ ì´í•´í•œë‹¤.\n",
    "- ë‹¨ì–´ ì„ë² ë”©ì˜ ê°œë…ê³¼ ì¥ì ì„ íŒŒì•…í•œë‹¤.\n",
    "- `tf.keras.layers.Embedding` ë ˆì´ì–´ë¥¼ êµ¬ì„±í•˜ê³  í™œìš©í•œë‹¤.\n",
    "- ì‚¬ì „ í•™ìŠµëœ ì„ë² ë”©(GloVe ë“±)ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì„ ìµíŒë‹¤.\n",
    "- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ í†µí•´ ë‹¨ì–´ ê°„ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•œë‹¤.\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ê¸°ë³¸ ì„í¬íŠ¸](#1.-ê¸°ë³¸-ì„í¬íŠ¸)\n",
    "2. [ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìˆ˜ì‹](#2.-ì½”ì‚¬ì¸-ìœ ì‚¬ë„-ìˆ˜ì‹)\n",
    "3. [One-Hot ì¸ì½”ë”©ì˜ í•œê³„](#3.-One-Hot-ì¸ì½”ë”©ì˜-í•œê³„)\n",
    "4. [Embedding ë ˆì´ì–´](#4.-Embedding-ë ˆì´ì–´)\n",
    "5. [ì‚¬ì „ í•™ìŠµ ì„ë² ë”© (GloVe ì‹œë®¬ë ˆì´ì…˜)](#5.-ì‚¬ì „-í•™ìŠµ-ì„ë² ë”©)\n",
    "6. [ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°](#6.-ì½”ì‚¬ì¸-ìœ ì‚¬ë„-ê³„ì‚°)\n",
    "7. [ì •ë¦¬](#7.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ë‹¨ì–´ ì„ë² ë”© ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ¤” ì»´í“¨í„°ëŠ” ë‹¨ì–´ë¥¼ ì–´ë–»ê²Œ ì´í•´í•´ìš”?\n",
    "\n",
    "ì»´í“¨í„°ëŠ” ìˆ«ìë§Œ ì•Œì•„ìš”! ê·¸ë˜ì„œ ë‹¨ì–´ë¥¼ ìˆ«ìë¡œ ë°”ê¿”ì•¼ í•´ìš”.\n",
    "\n",
    "#### 1ï¸âƒ£ ê¸°ì¡´ ë°©ë²•: One-Hot ì¸ì½”ë”©\n",
    "\n",
    "```\n",
    "ì–´íœ˜: [ê³ ì–‘ì´, ê°•ì•„ì§€, ìë™ì°¨, ë¹„í–‰ê¸°]\n",
    "\n",
    "ê³ ì–‘ì´ = [1, 0, 0, 0]\n",
    "ê°•ì•„ì§€ = [0, 1, 0, 0]\n",
    "ìë™ì°¨ = [0, 0, 1, 0]\n",
    "```\n",
    "\n",
    "âŒ **ë¬¸ì œ**: ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ê°€ ìë™ì°¨ë§Œí¼ 'ë‹¤ë¥´ê²Œ' í‘œí˜„ë¼ìš”!\n",
    "ê°™ì€ ë™ë¬¼ì¸ë°ë„ ì»´í“¨í„°ëŠ” êµ¬ë¶„ì„ ëª»í•´ìš”.\n",
    "\n",
    "#### 2ï¸âƒ£ ë” ì¢‹ì€ ë°©ë²•: ë‹¨ì–´ ì„ë² ë”©(Word Embedding)\n",
    "\n",
    "ë‹¨ì–´ë¥¼ **ì˜ë¯¸ê°€ ë‹´ê¸´ ì¢Œí‘œ(ë²¡í„°)**ë¡œ í‘œí˜„í•´ìš”!\n",
    "\n",
    "```\n",
    "              ë™ë¬¼ì„±  í¬ê¸°  ì†ë„  ...  (50~300ê°œ ìˆ«ì!)\n",
    "ê³ ì–‘ì´ =       [0.9,  0.3, 0.4, ...]\n",
    "ê°•ì•„ì§€ =       [0.9,  0.4, 0.5, ...]  â† ê³ ì–‘ì´ì™€ ë¹„ìŠ·!\n",
    "ìë™ì°¨ =       [0.0,  0.7, 0.9, ...]  â† ì™„ì „ ë‹¤ë¦„!\n",
    "```\n",
    "\n",
    "#### ğŸ“ ë‹¨ì–´ë¥¼ ê³µê°„(ì§€ë„)ì— ë°°ì¹˜í•˜ëŠ” ê²ƒê³¼ ê°™ì•„ìš”!\n",
    "\n",
    "```\n",
    "ë†’ì€ ë™ë¬¼ì„± â†‘\n",
    "           ê³ ì–‘ì´ â€¢ ê°•ì•„ì§€     â† ë™ë¬¼ ì˜ì—­\n",
    "           ìƒˆ â€¢\n",
    "           \n",
    "           ìë™ì°¨ â€¢  ë¹„í–‰ê¸° â€¢  â† íƒˆê²ƒ ì˜ì—­\n",
    "ë‚®ì€ ë™ë¬¼ì„± â†“\n",
    "           ë‚®ì€ ì†ë„ â†â€”â€”â†’ ë†’ì€ ì†ë„\n",
    "```\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: ì„¸ê³„ì§€ë„ì—ì„œ\n",
    "> ê°€ê¹Œìš´ ë‚˜ë¼ë“¤ì€ ë¹„ìŠ·í•œ ë¬¸í™”/ì–¸ì–´ë¥¼ ê°€ì§€ë“¯,\n",
    "> ì„ë² ë”© ê³µê°„ì—ì„œ ê°€ê¹Œìš´ ë‹¨ì–´ë“¤ì€ ì˜ë¯¸ê°€ ë¹„ìŠ·í•´ìš”!\n",
    "\n",
    "#### ğŸ”¢ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ 'ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€' ì¸¡ì •\n",
    "\n",
    "$$\\cos(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}$$\n",
    "\n",
    "- 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ = ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ë‹¨ì–´\n",
    "- 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ = ê´€ë ¨ ì—†ëŠ” ë‹¨ì–´\n",
    "- -1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ = ë°˜ëŒ€ ì˜ë¯¸ì˜ ë‹¨ì–´\n",
    "\n",
    "#### âœ¨ ì„ë² ë”©ì˜ ë†€ë¼ìš´ íŠ¹ì„±\n",
    "\n",
    "ì˜ í•™ìŠµëœ ì„ë² ë”©ì€ ì´ëŸ° ì—°ì‚°ë„ ê°€ëŠ¥í•´ìš”!\n",
    "\n",
    "$$\\vec{\\text{ì™•}} - \\vec{\\text{ë‚¨ì}} + \\vec{\\text{ì—¬ì}} \\approx \\vec{\\text{ì—¬ì™•}}$$\n",
    "\n",
    "> ğŸ’¡ ë‹¨ì–´ì˜ **ì˜ë¯¸**ê°€ ë²¡í„° ê³µê°„ì— ìˆ˜í•™ì ìœ¼ë¡œ ì¸ì½”ë”©ëœ ê±°ì˜ˆìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5-0002-0002-0001-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (macOS)\n",
    "matplotlib.rcParams['font.family'] = 'AppleGothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n",
    "print(f\"NumPy ë²„ì „: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-0002-0003-0001-000000000003",
   "metadata": {},
   "source": [
    "## 2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìˆ˜ì‹\n",
    "\n",
    "ë‘ ë²¡í„° $A$ì™€ $B$ ì‚¬ì´ì˜ **ì½”ì‚¬ì¸ ìœ ì‚¬ë„**ëŠ” ë²¡í„° ê°„ì˜ ê°ë„ë¡œ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•œë‹¤.\n",
    "\n",
    "$$\\cos(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}$$\n",
    "\n",
    "- $A \\cdot B$: ë‘ ë²¡í„°ì˜ ë‚´ì  (dot product)\n",
    "- $\\|A\\|$, $\\|B\\|$: ê° ë²¡í„°ì˜ L2 ë…¸ë¦„ (í¬ê¸°)\n",
    "\n",
    "### í•´ì„\n",
    "| ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê°’ | ì˜ë¯¸ |\n",
    "|-----------------|------|\n",
    "| $1.0$ | ì™„ì „íˆ ë™ì¼í•œ ë°©í–¥ (ë§¤ìš° ìœ ì‚¬) |\n",
    "| $0.0$ | ì§êµ (ê´€ë ¨ ì—†ìŒ) |\n",
    "| $-1.0$ | ì™„ì „íˆ ë°˜ëŒ€ ë°©í–¥ (ìƒë°˜ë¨) |\n",
    "\n",
    "ì„ë² ë”© ê³µê°„ì—ì„œ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ì€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ê°€ ë†’ë‹¤.  \n",
    "ì˜ˆ: $\\cos(\\vec{\\text{king}}, \\vec{\\text{queen}}) \\approx 0.8$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-0002-0004-0001-000000000004",
   "metadata": {},
   "source": [
    "## 3. One-Hot ì¸ì½”ë”©ì˜ í•œê³„\n",
    "\n",
    "One-Hot ì¸ì½”ë”©ì€ ê° ë‹¨ì–´ë¥¼ í•˜ë‚˜ì˜ ì°¨ì›ë§Œ 1ì´ê³  ë‚˜ë¨¸ì§€ëŠ” 0ì¸ ë²¡í„°ë¡œ í‘œí˜„í•œë‹¤.\n",
    "\n",
    "### ë¬¸ì œì \n",
    "\n",
    "1. **ê³ ì°¨ì›ì„±**: ì–´íœ˜ ì‚¬ì „ í¬ê¸°ê°€ 10ë§Œ ê°œë©´ ë²¡í„° ì°¨ì›ë„ 10ë§Œ ì°¨ì›\n",
    "2. **í¬ì†Œì„±(Sparsity)**: ëŒ€ë¶€ë¶„ì˜ ê°’ì´ 0 â†’ ê³„ì‚° ë¹„íš¨ìœ¨\n",
    "3. **ì˜ë¯¸ ë¶€ì¬**: ëª¨ë“  ë‹¨ì–´ ìŒì˜ ê±°ë¦¬ê°€ ë™ì¼ â†’ ìœ ì‚¬í•œ ë‹¨ì–´ ê´€ê³„ í‘œí˜„ ë¶ˆê°€\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´, \"cat\"ê³¼ \"dog\"ëŠ” ëª¨ë‘ ë™ë¬¼ì´ì§€ë§Œ One-Hot í‘œí˜„ì—ì„œëŠ”:\n",
    "- cat = [1, 0, 0, 0, 0, ...]\n",
    "- dog = [0, 1, 0, 0, 0, ...]\n",
    "- car = [0, 0, 1, 0, 0, ...]\n",
    "\n",
    "$\\cos(\\vec{\\text{cat}}, \\vec{\\text{dog}}) = 0$, $\\cos(\\vec{\\text{cat}}, \\vec{\\text{car}}) = 0$ â†’ êµ¬ë¶„ ë¶ˆê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5-0002-0005-0001-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot ì¸ì½”ë”©ì˜ í•œê³„ ì‹œê°í™”\n",
    "\n",
    "# ì˜ˆì‹œ ì–´íœ˜ ì‚¬ì „\n",
    "vocab = [\"cat\", \"dog\", \"car\", \"truck\", \"kitten\", \"puppy\"]\n",
    "vocab_size = len(vocab)\n",
    "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
    "\n",
    "# One-Hot ë²¡í„° ìƒì„±\n",
    "def one_hot(word, vocab_size, word_to_idx):\n",
    "    \"\"\"ë‹¨ì–´ë¥¼ One-Hot ë²¡í„°ë¡œ ë³€í™˜\"\"\"\n",
    "    vec = np.zeros(vocab_size)\n",
    "    vec[word_to_idx[word]] = 1.0\n",
    "    return vec\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "# One-Hot ë²¡í„° ê³„ì‚°\n",
    "cat_oh    = one_hot(\"cat\",    vocab_size, word_to_idx)\n",
    "dog_oh    = one_hot(\"dog\",    vocab_size, word_to_idx)\n",
    "kitten_oh = one_hot(\"kitten\", vocab_size, word_to_idx)\n",
    "car_oh    = one_hot(\"car\",    vocab_size, word_to_idx)\n",
    "\n",
    "print(\"=== One-Hot ë²¡í„° ===\")\n",
    "print(f\"  cat   : {cat_oh}\")\n",
    "print(f\"  dog   : {dog_oh}\")\n",
    "print(f\"  kitten: {kitten_oh}\")\n",
    "print(f\"  car   : {car_oh}\")\n",
    "print()\n",
    "\n",
    "print(\"=== One-Hot ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ===\")\n",
    "print(f\"  cat vs dog   : {cosine_similarity(cat_oh, dog_oh):.4f}  (ë™ë¬¼ë¼ë¦¬ â†’ 0ì´ì–´ì•¼ í•˜ì§€ ì•ŠìŒ!)\")\n",
    "print(f\"  cat vs kitten: {cosine_similarity(cat_oh, kitten_oh):.4f}  (cat-kitten ë§¤ìš° ìœ ì‚¬í•œë° 0!)\")\n",
    "print(f\"  cat vs car   : {cosine_similarity(cat_oh, car_oh):.4f}  (ì™„ì „ ë‹¤ë¥¸ë°ë„ 0)\")\n",
    "print()\n",
    "print(\"â†’ One-Hotì€ ëª¨ë“  ë‹¨ì–´ ìŒì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ê°€ 0 â†’ ì˜ë¯¸ êµ¬ë¶„ ë¶ˆê°€\")\n",
    "\n",
    "# One-Hot í–‰ë ¬ ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "oh_matrix = np.array([one_hot(w, vocab_size, word_to_idx) for w in vocab])\n",
    "im = ax.imshow(oh_matrix, cmap='Blues', aspect='auto')\n",
    "ax.set_xticks(range(vocab_size))\n",
    "ax.set_xticklabels(vocab, rotation=45)\n",
    "ax.set_yticks(range(vocab_size))\n",
    "ax.set_yticklabels(vocab)\n",
    "ax.set_title(\"One-Hot ì¸ì½”ë”© í–‰ë ¬\\n(ì–´íœ˜ í¬ê¸°ê°€ ì»¤ì§€ë©´ í–‰ë ¬ë„ ê±°ëŒ€í•´ì§)\")\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-0002-0006-0001-000000000006",
   "metadata": {},
   "source": [
    "## 4. Embedding ë ˆì´ì–´\n",
    "\n",
    "`tf.keras.layers.Embedding`ì€ ì •ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ë°€ì§‘(dense) ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ë ˆì´ì–´ì´ë‹¤.  \n",
    "ë‚´ë¶€ì ìœ¼ë¡œ **ê°€ì¤‘ì¹˜ í–‰ë ¬** $W \\in \\mathbb{R}^{\\text{vocab\\_size} \\times \\text{embed\\_dim}}$ì„ í•™ìŠµí•œë‹¤.\n",
    "\n",
    "### ì£¼ìš” íŒŒë¼ë¯¸í„°\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ì„¤ëª… |\n",
    "|----------|------|\n",
    "| `input_dim` | ì–´íœ˜ ì‚¬ì „ í¬ê¸° (ì •ìˆ˜ ì¸ë±ìŠ¤ ìµœëŒ€ê°’ + 1) |\n",
    "| `output_dim` | ì„ë² ë”© ë²¡í„° ì°¨ì› ìˆ˜ |\n",
    "| `embeddings_initializer` | ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ë°©ë²• (ê¸°ë³¸: ê· ì¼ ë¶„í¬) |\n",
    "| `mask_zero` | íŒ¨ë”© ë§ˆìŠ¤í‚¹ í™œì„±í™” ì—¬ë¶€ |\n",
    "| `trainable` | ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì—¬ë¶€ (ì‚¬ì „ í•™ìŠµ ì„ë² ë”© ê³ ì • ì‹œ False) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5-0002-0007-0001-000000000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding ë ˆì´ì–´ ì‹¤ìŠµ\n",
    "\n",
    "# ì–´íœ˜ ì‚¬ì „ í¬ê¸°ì™€ ì„ë² ë”© ì°¨ì› ì„¤ì •\n",
    "VOCAB_SIZE = 1000   # ì–´íœ˜ ì‚¬ì „ í¬ê¸°\n",
    "EMBED_DIM  = 16     # ì„ë² ë”© ë²¡í„° ì°¨ì›\n",
    "\n",
    "# Embedding ë ˆì´ì–´ ìƒì„±\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=VOCAB_SIZE,              # ì–´íœ˜ ì‚¬ì „ í¬ê¸°\n",
    "    output_dim=EMBED_DIM,              # ì„ë² ë”© ì°¨ì›\n",
    "    embeddings_initializer='uniform',  # ì´ˆê¸°í™”: ê· ì¼ ë¶„í¬\n",
    "    mask_zero=True,                    # íŒ¨ë”© ë§ˆìŠ¤í‚¹ í™œì„±í™”\n",
    "    name='word_embedding'\n",
    ")\n",
    "\n",
    "# ì…ë ¥ í˜•íƒœ: (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´)\n",
    "# ì¶œë ¥ í˜•íƒœ: (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì„ë² ë”© ì°¨ì›)\n",
    "sample_input = tf.constant([[1, 2, 3, 4, 0],   # ë°°ì¹˜ ìƒ˜í”Œ 1 (0ì€ íŒ¨ë”©)\n",
    "                             [5, 6, 7, 0, 0]])  # ë°°ì¹˜ ìƒ˜í”Œ 2\n",
    "output = embedding_layer(sample_input)\n",
    "\n",
    "print(\"ì…ë ¥ í˜•íƒœ:\", sample_input.shape, \"â†’ (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´)\")\n",
    "print(\"ì¶œë ¥ í˜•íƒœ:\", output.shape, \"â†’ (ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì„ë² ë”© ì°¨ì›)\")\n",
    "print()\n",
    "print(\"ì„ë² ë”© ê°€ì¤‘ì¹˜ í–‰ë ¬ í¬ê¸°:\", embedding_layer.embeddings.shape)\n",
    "print(f\"  â†’ {VOCAB_SIZE}ê°œ ë‹¨ì–´ Ã— {EMBED_DIM}ì°¨ì›\")\n",
    "print()\n",
    "print(\"ë‹¨ì–´ ì¸ë±ìŠ¤ 1ì˜ ì„ë² ë”© ë²¡í„°:\", output[0][0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-0002-0008-0001-000000000008",
   "metadata": {},
   "source": [
    "## 5. ì‚¬ì „ í•™ìŠµ ì„ë² ë”© (GloVe ì‹œë®¬ë ˆì´ì…˜)\n",
    "\n",
    "**GloVe(Global Vectors for Word Representation)**ëŠ” ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ì½”í¼ìŠ¤ì—ì„œ  \n",
    "ì‚¬ì „ í•™ìŠµëœ ë‹¨ì–´ ì„ë² ë”©ì´ë‹¤. ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:\n",
    "\n",
    "1. GloVe íŒŒì¼(`.txt`)ì„ ë‹¤ìš´ë¡œë“œí•œë‹¤.\n",
    "2. ê° ë‹¨ì–´ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì½ì–´ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥í•œë‹¤.\n",
    "3. ìì‹ ì˜ ì–´íœ˜ ì‚¬ì „ì— ë§ëŠ” ì„ë² ë”© í–‰ë ¬ì„ êµ¬ì„±í•œë‹¤.\n",
    "4. Embedding ë ˆì´ì–´ ê°€ì¤‘ì¹˜ë¥¼ í•´ë‹¹ í–‰ë ¬ë¡œ ì´ˆê¸°í™”í•˜ê³  `trainable=False`ë¡œ ê³ ì •í•œë‹¤.\n",
    "\n",
    "ì•„ë˜ ì½”ë“œëŠ” GloVe ë¡œë“œ ê³¼ì •ì„ **ì‹œë®¬ë ˆì´ì…˜**í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5-0002-0009-0001-000000000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ì „ í•™ìŠµ ì„ë² ë”© ê°€ì¤‘ì¹˜ ì§ì ‘ ì„¤ì • (GloVe ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜)\n",
    "\n",
    "# ì‹œë®¬ë ˆì´ì…˜ìš© ì–´íœ˜ ì‚¬ì „ê³¼ ì„ë² ë”© ì°¨ì›\n",
    "words = [\"cat\", \"dog\", \"kitten\", \"puppy\", \"car\", \"truck\"]\n",
    "SIM_VOCAB_SIZE = len(words) + 2  # íŒ¨ë”©(0) + OOV(1) + ì‹¤ì œ ë‹¨ì–´ë“¤\n",
    "SIM_EMBED_DIM  = 8\n",
    "\n",
    "word_to_idx_sim = {word: idx + 2 for idx, word in enumerate(words)}  # 0=íŒ¨ë”©, 1=OOV\n",
    "\n",
    "# GloVe ì„ë² ë”© ì‹œë®¬ë ˆì´ì…˜\n",
    "# ì‹¤ì œì—ì„œëŠ” íŒŒì¼ì—ì„œ ì½ì–´ì˜¤ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì˜ë¯¸ ìˆëŠ” ê°’ì„ ìˆ˜ë™ìœ¼ë¡œ ì •ì˜\n",
    "# ì°¨ì› ì˜ë¯¸ (ì„ì˜ ì„¤ì •): [ë™ë¬¼ì„±, ì‘ìŒ, í„¸, ë°˜ë ¤, ê¸°ê³„, ë¬´ê±°ì›€, ì†ë„, ìœ¡ì§€]\n",
    "simulated_glove = {\n",
    "    \"cat\":    np.array([0.9,  0.6,  0.9,  0.8, -0.5, -0.3,  0.2,  0.4]),\n",
    "    \"dog\":    np.array([0.9,  0.5,  0.8,  0.9, -0.4, -0.2,  0.4,  0.5]),\n",
    "    \"kitten\": np.array([0.8,  0.9,  0.9,  0.7, -0.5, -0.4,  0.1,  0.3]),\n",
    "    \"puppy\":  np.array([0.8,  0.8,  0.7,  0.9, -0.4, -0.3,  0.2,  0.4]),\n",
    "    \"car\":    np.array([-0.2, 0.3, -0.3, -0.1,  0.9,  0.5,  0.8,  0.6]),\n",
    "    \"truck\":  np.array([-0.1, 0.1, -0.2, -0.2,  0.9,  0.9,  0.6,  0.8]),\n",
    "}\n",
    "\n",
    "# ì„ë² ë”© í–‰ë ¬ ì´ˆê¸°í™” (íŒ¨ë”©ê³¼ OOV í† í°ì€ 0 ë²¡í„°)\n",
    "embedding_matrix = np.zeros((SIM_VOCAB_SIZE, SIM_EMBED_DIM))\n",
    "for word, idx in word_to_idx_sim.items():\n",
    "    if word in simulated_glove:\n",
    "        embedding_matrix[idx] = simulated_glove[word]\n",
    "\n",
    "print(\"ì„ë² ë”© í–‰ë ¬ í¬ê¸°:\", embedding_matrix.shape)\n",
    "print()\n",
    "\n",
    "# Embedding ë ˆì´ì–´ì— ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "pretrained_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=SIM_VOCAB_SIZE,\n",
    "    output_dim=SIM_EMBED_DIM,\n",
    "    # ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,  # ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ê³ ì • (ë¯¸ì„¸ ì¡°ì • ì‹œ Trueë¡œ ë³€ê²½)\n",
    "    name='pretrained_glove'\n",
    ")\n",
    "\n",
    "# ë‹¨ì–´ ì¸ë±ìŠ¤ë¡œ ì„ë² ë”© ë²¡í„° ì¡°íšŒ\n",
    "cat_idx = word_to_idx_sim[\"cat\"]\n",
    "cat_embed = pretrained_embedding(tf.constant([[cat_idx]]))\n",
    "print(f\"'cat' (ì¸ë±ìŠ¤ {cat_idx}) ì„ë² ë”© ë²¡í„°:\")\n",
    "print(f\"  {cat_embed.numpy()[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-0002-0010-0001-000000000010",
   "metadata": {},
   "source": [
    "## 6. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5-0002-0011-0001-000000000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”© ë²¡í„° ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì˜ˆì‹œ\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"ë‘ ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "# ê° ë‹¨ì–´ì˜ ì„ë² ë”© ë²¡í„° ì¶”ì¶œ\n",
    "word_vectors = {word: simulated_glove[word] for word in words}\n",
    "\n",
    "# ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°\n",
    "n = len(words)\n",
    "sim_matrix = np.zeros((n, n))\n",
    "for i, w1 in enumerate(words):\n",
    "    for j, w2 in enumerate(words):\n",
    "        sim_matrix[i, j] = cosine_similarity(word_vectors[w1], word_vectors[w2])\n",
    "\n",
    "# ìœ ì‚¬ë„ í–‰ë ¬ ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(sim_matrix, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(n))\n",
    "ax.set_xticklabels(words, rotation=45, ha='right')\n",
    "ax.set_yticks(range(n))\n",
    "ax.set_yticklabels(words)\n",
    "ax.set_title(\"ë‹¨ì–´ ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬\\n(ì´ˆë¡=ë†’ì€ ìœ ì‚¬ë„, ë¹¨ê°•=ë‚®ì€ ìœ ì‚¬ë„)\")\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# ìœ ì‚¬ë„ ê°’ í‘œì‹œ\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        ax.text(j, i, f\"{sim_matrix[i,j]:.2f}\",\n",
    "                ha='center', va='center', fontsize=9,\n",
    "                color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nì£¼ëª©í•  ìœ ì‚¬ë„:\")\n",
    "pairs = [\n",
    "    (\"cat\",    \"kitten\", \"ë¹„ìŠ·í•œ ë™ë¬¼\"),\n",
    "    (\"dog\",    \"puppy\",  \"ë¹„ìŠ·í•œ ë™ë¬¼\"),\n",
    "    (\"car\",    \"truck\",  \"ë¹„ìŠ·í•œ íƒˆê²ƒ\"),\n",
    "    (\"cat\",    \"car\",    \"ì™„ì „íˆ ë‹¤ë¥¸ ë²”ì£¼\"),\n",
    "]\n",
    "for w1, w2, desc in pairs:\n",
    "    sim = cosine_similarity(word_vectors[w1], word_vectors[w2])\n",
    "    print(f\"  {w1:8s} vs {w2:8s} ({desc:15s}): {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-0002-0012-0001-000000000012",
   "metadata": {},
   "source": [
    "## 7. ì •ë¦¬\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ë°©ë²• | ì°¨ì› | ì˜ë¯¸ í‘œí˜„ | íŠ¹ì§• |\n",
    "|------|------|-----------|------|\n",
    "| **One-Hot** | ì–´íœ˜ í¬ê¸° | ë¶ˆê°€ | í¬ì†Œ, ê³ ì°¨ì›, ê³„ì‚° ë¹„íš¨ìœ¨ |\n",
    "| **Word Embedding** | ìˆ˜ì‹­~ìˆ˜ë°± | ê°€ëŠ¥ | ë°€ì§‘, ì €ì°¨ì›, ì˜ë¯¸ì  ìœ ì‚¬ë„ í¬ì°© |\n",
    "| **ì‚¬ì „ í•™ìŠµ ì„ë² ë”©** | ìˆ˜ë°± | ë§¤ìš° ìš°ìˆ˜ | ëŒ€ê·œëª¨ í•™ìŠµ, ì „ì´ í•™ìŠµ |\n",
    "\n",
    "### ì„ë² ë”© ê³µê°„ì˜ íŠ¹ì„±\n",
    "ì˜ í•™ìŠµëœ ì„ë² ë”©ì€ ë‹¤ìŒê³¼ ê°™ì€ ë²¡í„° ì—°ì‚°ì´ ê°€ëŠ¥í•˜ë‹¤:\n",
    "\n",
    "$$\\vec{\\text{king}} - \\vec{\\text{man}} + \\vec{\\text{woman}} \\approx \\vec{\\text{queen}}$$\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "- **Chapter 06-03**: RNN, LSTM, GRU  \n",
    "  ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ìˆœí™˜ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ í•™ìŠµí•œë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}