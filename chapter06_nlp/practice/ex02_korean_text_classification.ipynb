{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0-0007-0001-0001-000000000001",
   "metadata": {},
   "source": [
    "# Chapter 06 실습 2: 한국어 텍스트 분류\n",
    "\n",
    "## 목표\n",
    "네이버 영화 리뷰(NSMC) 데이터로 한국어 감성 분석을 구현한다.\n",
    "\n",
    "## 학습 내용\n",
    "- 한국어 감성 분석의 특수성(교착어, 형태소)을 이해한다.\n",
    "- KoNLPy 미설치 환경에서도 실행 가능한 폴백(fallback) 로직을 구현한다.\n",
    "- 공백 분리와 형태소 분리의 성능 차이를 비교한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0007-0002-0001-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import re\n",
    "\n",
    "# 한글 폰트 설정 (macOS)\n",
    "matplotlib.rcParams['font.family'] = 'AppleGothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0-0007-0003-0001-000000000003",
   "metadata": {},
   "source": [
    "## NSMC(Naver Sentiment Movie Corpus) 데이터셋\n",
    "\n",
    "### 데이터셋 소개\n",
    "- 네이버 영화 리뷰 200,000개 (훈련 150,000 / 테스트 50,000)\n",
    "- 레이블: 0 (부정), 1 (긍정)\n",
    "- 출처: [https://github.com/e9t/nsmc](https://github.com/e9t/nsmc)\n",
    "\n",
    "### 데이터 로드 방법 (실제 파일이 있는 경우)\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# GitHub에서 다운로드 후 로컬 경로 지정\n",
    "train_df = pd.read_csv('ratings_train.txt', sep='\\t')\n",
    "test_df  = pd.read_csv('ratings_test.txt',  sep='\\t')\n",
    "\n",
    "# 결측값 제거\n",
    "train_df = train_df.dropna()\n",
    "test_df  = test_df.dropna()\n",
    "\n",
    "train_texts  = train_df['document'].tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "test_texts   = test_df['document'].tolist()\n",
    "test_labels  = test_df['label'].tolist()\n",
    "```\n",
    "\n",
    "이 실습에서는 실제 NSMC 없이도 실행 가능하도록 샘플 데이터를 하드코딩한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0007-0004-0001-000000000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 한국어 영화 리뷰 데이터 (NSMC 없이 실행 가능)\n",
    "# 실제 NSMC와 유사한 구조로 설계된 샘플 데이터\n",
    "\n",
    "SAMPLE_REVIEWS = [\n",
    "    # 긍정 리뷰 (label=1)\n",
    "    (\"정말 재미있었어요 배우들의 연기가 너무 좋았습니다\",           1),\n",
    "    (\"감동적인 영화 눈물이 절로 났어요\",                          1),\n",
    "    (\"스토리가 탄탄하고 연출이 훌륭합니다\",                        1),\n",
    "    (\"올해 본 영화 중 최고 강력 추천합니다\",                       1),\n",
    "    (\"배우들의 연기력이 정말 뛰어나네요\",                          1),\n",
    "    (\"긴장감 넘치는 전개 끝까지 눈을 뗄 수 없었어요\",               1),\n",
    "    (\"가족과 함께 보기 좋은 따뜻한 영화\",                         1),\n",
    "    (\"명작입니다 두 번 세 번 봐도 좋을 것 같아요\",                  1),\n",
    "    (\"OST도 너무 좋고 영상미도 훌륭했습니다\",                      1),\n",
    "    (\"반전이 있어서 더욱 재미있었습니다 추천\",                      1),\n",
    "    (\"배우들이 모두 열연을 펼쳐서 몰입이 잘 됐어요\",                1),\n",
    "    (\"예상보다 훨씬 좋았습니다 감독의 연출력이 대단해요\",            1),\n",
    "    (\"이런 영화를 기다렸습니다 정말 완성도가 높아요\",               1),\n",
    "    (\"웃음과 감동을 동시에 주는 영화 강추합니다\",                   1),\n",
    "    (\"특수효과도 훌륭하고 스토리도 탄탄하네요\",                     1),\n",
    "    (\"주인공의 캐릭터가 너무 매력적이었어요\",                       1),\n",
    "    (\"시나리오가 정말 잘 짜여져 있어요 감동입니다\",                  1),\n",
    "    (\"한국 영화의 저력을 보여주는 걸작\",                           1),\n",
    "    (\"처음부터 끝까지 흥미진진하게 봤습니다\",                       1),\n",
    "    (\"연출 연기 스토리 모든 면에서 완벽했어요\",                     1),\n",
    "    # 부정 리뷰 (label=0)\n",
    "    (\"완전 실망이에요 돈 아까워\",                                  0),\n",
    "    (\"스토리가 엉망이에요 시간 낭비했습니다\",                       0),\n",
    "    (\"배우 연기가 너무 어색하고 대사도 유치하네요\",                  0),\n",
    "    (\"지루해서 중간에 나올 뻔 했어요\",                             0),\n",
    "    (\"억지 전개가 너무 심해요 공감이 안 됩니다\",                    0),\n",
    "    (\"기대했는데 너무 실망이에요 비추천\",                           0),\n",
    "    (\"이런 영화를 만들어도 되는 건지 최악이에요\",                    0),\n",
    "    (\"복잡하기만 하고 아무 감동도 없어요\",                          0),\n",
    "    (\"주인공이 너무 답답해서 화가 났어요\",                          0),\n",
    "    (\"돈 버리는 영화 절대 비추\",                                  0),\n",
    "    (\"개연성이 전혀 없고 결말도 황당해요\",                          0),\n",
    "    (\"연출이 조잡하고 특수효과도 형편없어요\",                        0),\n",
    "    (\"시간이 아까웠습니다 정말 별로였어요\",                         0),\n",
    "    (\"억지 감동 코드가 너무 노골적이에요\",                          0),\n",
    "    (\"스토리 구멍이 너무 많아요 논리가 없어요\",                     0),\n",
    "    (\"처음에는 기대했는데 점점 실망스러웠어요\",                      0),\n",
    "    (\"2시간이 넘는데 볼 게 하나도 없어요\",                         0),\n",
    "    (\"캐릭터들이 너무 평면적이고 매력이 없어요\",                     0),\n",
    "    (\"감독이 하고 싶은 말이 뭔지 모르겠어요\",                       0),\n",
    "    (\"뻔한 내용에 재미도 감동도 없는 영화\",                         0),\n",
    "]\n",
    "\n",
    "# 데이터를 훈련/검증/테스트로 분할\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# 데이터 확장 (샘플을 반복하여 충분한 양 확보)\n",
    "expanded_data = []\n",
    "for _ in range(50):  # 50회 반복으로 2000개 생성\n",
    "    shuffled = SAMPLE_REVIEWS.copy()\n",
    "    random.shuffle(shuffled)\n",
    "    expanded_data.extend(shuffled)\n",
    "\n",
    "random.shuffle(expanded_data)\n",
    "\n",
    "texts  = [item[0] for item in expanded_data]\n",
    "labels = [item[1] for item in expanded_data]\n",
    "\n",
    "# 훈련(70%) / 검증(15%) / 테스트(15%) 분할\n",
    "total    = len(texts)\n",
    "train_end = int(total * 0.7)\n",
    "val_end   = int(total * 0.85)\n",
    "\n",
    "train_texts  = texts[:train_end]\n",
    "train_labels = np.array(labels[:train_end])\n",
    "val_texts    = texts[train_end:val_end]\n",
    "val_labels   = np.array(labels[train_end:val_end])\n",
    "test_texts   = texts[val_end:]\n",
    "test_labels  = np.array(labels[val_end:])\n",
    "\n",
    "print(f\"전체 데이터: {total:,d}개\")\n",
    "print(f\"  훈련: {len(train_texts):,d}개  |  검증: {len(val_texts):,d}개  |  테스트: {len(test_texts):,d}개\")\n",
    "print(f\"  긍정 비율 (훈련): {train_labels.mean():.1%}\")\n",
    "print()\n",
    "print(\"샘플 데이터:\")\n",
    "for text, label in zip(texts[:4], labels[:4]):\n",
    "    print(f\"  [{'긍정' if label == 1 else '부정'}] {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0007-0005-0001-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoNLPy 형태소 분석 또는 공백 기준 분리 폴백\n",
    "\n",
    "# 한국어 특수문자 제거 함수\n",
    "def clean_korean(text):\n",
    "    \"\"\"한국어 텍스트 정제: 숫자, 영문, 한글, 공백만 유지\"\"\"\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# KoNLPy 설치 여부 확인\n",
    "USE_KONLPY = False\n",
    "okt = None\n",
    "\n",
    "try:\n",
    "    from konlpy.tag import Okt\n",
    "    okt = Okt()\n",
    "    USE_KONLPY = True\n",
    "    print(\"KoNLPy(Okt) 로드 성공 → 형태소 분석 사용\")\n",
    "except ImportError:\n",
    "    print(\"KoNLPy 미설치 → 공백 기준 분리 사용 (폴백)\")\n",
    "    print(\"설치 방법: pip install konlpy\")\n",
    "\n",
    "def tokenize(text, use_konlpy=USE_KONLPY):\n",
    "    \"\"\"\n",
    "    텍스트를 토큰으로 분리\n",
    "    KoNLPy 설치 시 형태소 분석, 미설치 시 공백 분리\n",
    "    \n",
    "    Args:\n",
    "        text: 입력 텍스트\n",
    "        use_konlpy: KoNLPy 사용 여부\n",
    "    \n",
    "    Returns:\n",
    "        토큰 리스트\n",
    "    \"\"\"\n",
    "    cleaned = clean_korean(text)\n",
    "    if use_konlpy and okt is not None:\n",
    "        # Okt 형태소 분석기 사용\n",
    "        # norm=True: 어휘 정규화 (예: 함ㅎㅎ → 함)\n",
    "        # stem=True: 어간 추출 (예: 가는 → 가다)\n",
    "        return okt.morphs(cleaned, norm=True, stem=True)\n",
    "    else:\n",
    "        # 공백 기준 단순 분리\n",
    "        return cleaned.split()\n",
    "\n",
    "# 토큰화 예시\n",
    "example_texts = [\n",
    "    \"정말 재미있었어요 배우들의 연기가 너무 좋았습니다\",\n",
    "    \"완전 실망이에요 돈 아까워\",\n",
    "]\n",
    "print(\"\\n=== 토큰화 결과 ===\")\n",
    "for text in example_texts:\n",
    "    tokens = tokenize(text)\n",
    "    method = \"형태소 분석\" if USE_KONLPY else \"공백 분리\"\n",
    "    print(f\"  원문: '{text}'\")\n",
    "    print(f\"  토큰 ({method}): {tokens}\")\n",
    "    print()\n",
    "\n",
    "# 전체 데이터 토큰화\n",
    "print(\"전체 데이터 토큰화 중...\")\n",
    "train_tokenized = [' '.join(tokenize(t)) for t in train_texts]\n",
    "val_tokenized   = [' '.join(tokenize(t)) for t in val_texts]\n",
    "test_tokenized  = [' '.join(tokenize(t)) for t in test_texts]\n",
    "print(f\"  토큰화 완료: 훈련 {len(train_tokenized)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0007-0006-0001-000000000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextVectorization + Embedding + BiLSTM 모델 구성\n",
    "\n",
    "# 하이퍼파라미터\n",
    "MAX_TOKENS  = 5000   # 한국어는 어휘 크기가 작을 수 있어 5000으로 설정\n",
    "MAX_SEQ_LEN = 50     # 한국어 리뷰는 비교적 짧음\n",
    "EMBED_DIM   = 64     # 임베딩 차원\n",
    "LSTM_UNITS  = 32     # LSTM 은닉 유닛\n",
    "BATCH_SIZE  = 32     # 배치 크기\n",
    "EPOCHS      = 15     # 학습 에포크\n",
    "\n",
    "# TextVectorization 레이어 생성 및 어휘 사전 구축\n",
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    output_sequence_length=MAX_SEQ_LEN,\n",
    "    output_mode='int',\n",
    "    name='text_vectorizer'\n",
    ")\n",
    "\n",
    "# 훈련 데이터로 어휘 사전 구축\n",
    "vectorizer.adapt(train_tokenized)\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "print(f\"어휘 사전 크기: {len(vocab)}\")\n",
    "print(f\"주요 단어 (상위 20개): {vocab[2:22]}\")\n",
    "\n",
    "# 텍스트 → 정수 시퀀스 변환\n",
    "x_train = vectorizer(train_tokenized)\n",
    "x_val   = vectorizer(val_tokenized)\n",
    "x_test  = vectorizer(test_tokenized)\n",
    "y_train = train_labels.astype('float32')\n",
    "y_val   = val_labels.astype('float32')\n",
    "y_test  = test_labels.astype('float32')\n",
    "\n",
    "print(f\"\\n훈련 데이터 형태: {x_train.shape}\")\n",
    "\n",
    "# BiLSTM 모델 구성\n",
    "model = tf.keras.Sequential([\n",
    "    # 임베딩 레이어\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(vocab) + 1,\n",
    "        output_dim=EMBED_DIM,\n",
    "        mask_zero=True,\n",
    "        name='embedding'\n",
    "    ),\n",
    "    \n",
    "    # 양방향 LSTM: 한국어의 문장 앞뒤 문맥 모두 활용\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(LSTM_UNITS, dropout=0.3),\n",
    "        name='bilstm'\n",
    "    ),\n",
    "    \n",
    "    # 완전 연결층\n",
    "    tf.keras.layers.Dense(32, activation='relu', name='dense'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    # 출력층: 이진 분류\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='output')\n",
    "], name='Korean_BiLSTM_Sentiment')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-0007-0007-0001-000000000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 평가\n",
    "\n",
    "# 콜백 설정\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"한국어 BiLSTM 모델 학습 시작...\")\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 테스트 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\n테스트 정확도: {test_acc:.4f}\")\n",
    "print(f\"테스트 손실:   {test_loss:.4f}\")\n",
    "\n",
    "# 학습 곡선 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "axes[0].plot(epochs_range, history.history['accuracy'],\n",
    "             'b-o', label='훈련 정확도', linewidth=2)\n",
    "axes[0].plot(epochs_range, history.history['val_accuracy'],\n",
    "             'r-s', label='검증 정확도', linewidth=2)\n",
    "axes[0].axhline(y=test_acc, color='green', linestyle='--',\n",
    "                label=f'테스트: {test_acc:.4f}')\n",
    "axes[0].set_xlabel('에포크')\n",
    "axes[0].set_ylabel('정확도')\n",
    "axes[0].set_title('정확도 학습 곡선')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(epochs_range, history.history['loss'],\n",
    "             'b-o', label='훈련 손실', linewidth=2)\n",
    "axes[1].plot(epochs_range, history.history['val_loss'],\n",
    "             'r-s', label='검증 손실', linewidth=2)\n",
    "axes[1].set_xlabel('에포크')\n",
    "axes[1].set_ylabel('손실')\n",
    "axes[1].set_title('손실 학습 곡선')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'한국어 BiLSTM 감성 분석 학습 곡선\\n'\n",
    "             f'(토큰화: {\"형태소 분석(Okt)\" if USE_KONLPY else \"공백 분리\"})',\n",
    "             fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 새 리뷰 예측 테스트\n",
    "def predict_korean_sentiment(text):\n",
    "    \"\"\"한국어 리뷰 문자열 → 긍정/부정 예측\"\"\"\n",
    "    tokenized = ' '.join(tokenize(text))\n",
    "    vec = vectorizer([tokenized])\n",
    "    prob = model.predict(vec, verbose=0)[0][0]\n",
    "    label = \"긍정\" if prob >= 0.5 else \"부정\"\n",
    "    return label, float(prob)\n",
    "\n",
    "print(\"\\n=== 새 리뷰 예측 ===\")\n",
    "new_reviews = [\n",
    "    \"진짜 너무 재미있어요 두 번 보고 싶어요\",\n",
    "    \"별로였어요 시간 낭비\",\n",
    "    \"배우들이 연기를 정말 잘 하네요\",\n",
    "    \"이해가 안 되는 스토리였어요\",\n",
    "]\n",
    "for review in new_reviews:\n",
    "    label, prob = predict_korean_sentiment(review)\n",
    "    print(f\"  [{label}({prob:.4f})] {review}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0-0007-0008-0001-000000000008",
   "metadata": {},
   "source": [
    "## 도전 과제\n",
    "\n",
    "### 1. 형태소 분리 vs 공백 분리 성능 비교\n",
    "\n",
    "KoNLPy가 설치된 환경에서 두 가지 방법을 비교해 보세요.\n",
    "\n",
    "```python\n",
    "# 공백 분리 모델 학습\n",
    "train_ws  = [' '.join(t.split()) for t in train_texts]  # 공백 분리\n",
    "# 형태소 분리 모델 학습  \n",
    "train_ma  = [' '.join(okt.morphs(t, norm=True, stem=True)) for t in train_texts]  # 형태소\n",
    "\n",
    "# 두 모델의 테스트 정확도 비교\n",
    "```\n",
    "\n",
    "예상 결과:\n",
    "| 토큰화 방법 | 예상 정확도 | 장단점 |\n",
    "|-------------|-------------|--------|\n",
    "| 공백 분리 | ~75~80% | 빠르지만 같은 단어의 다른 형태 미인식 |\n",
    "| 형태소 분석 | ~80~85% | 느리지만 어간 통합으로 성능 향상 |\n",
    "\n",
    "### 2. 어휘 사전 크기 실험\n",
    "- `MAX_TOKENS`를 1000, 3000, 5000, 10000으로 변경하며 성능 변화를 분석해 보세요.\n",
    "\n",
    "### 3. 모델 구조 실험\n",
    "- 단방향 LSTM vs 양방향 LSTM의 성능 차이를 비교해 보세요.\n",
    "- LSTM 대신 GRU를 사용해 보세요.\n",
    "\n",
    "### 4. 실제 NSMC 데이터 적용\n",
    "아래 명령어로 실제 데이터를 다운로드하여 실행해 보세요:\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
    "wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
