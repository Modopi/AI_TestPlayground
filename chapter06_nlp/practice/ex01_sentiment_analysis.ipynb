{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9-0006-0001-0001-000000000001",
   "metadata": {},
   "source": [
    "# Chapter 06 실습 1: 감성 분석\n",
    "\n",
    "## 목표\n",
    "IMDB 영화 리뷰 데이터로 긍정/부정 이진 분류기를 구현한다.\n",
    "\n",
    "## 요구사항\n",
    "- `tf.keras.datasets.imdb`에서 데이터를 로드한다.\n",
    "- Embedding + Bidirectional LSTM 구조를 사용한다.\n",
    "- 학습 곡선을 시각화한다.\n",
    "- 새로운 리뷰 텍스트를 입력하면 긍정/부정을 출력하는 함수를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9-0006-0002-0001-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 한글 폰트 설정 (macOS)\n",
    "matplotlib.rcParams['font.family'] = 'AppleGothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9-0006-0003-0001-000000000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB 데이터 로드 및 TextVectorization 준비\n",
    "\n",
    "# 하이퍼파라미터\n",
    "MAX_TOKENS  = 10000  # 어휘 사전 크기\n",
    "MAX_SEQ_LEN = 256    # 최대 시퀀스 길이\n",
    "EMBED_DIM   = 128    # 임베딩 차원\n",
    "BATCH_SIZE  = 32     # 배치 크기\n",
    "EPOCHS      = 10     # 학습 에포크 수\n",
    "\n",
    "# IMDB 데이터 로드 (정수 인코딩)\n",
    "print(\"IMDB 데이터셋 로드 중...\")\n",
    "(x_train_raw, y_train), (x_test_raw, y_test) = tf.keras.datasets.imdb.load_data(\n",
    "    num_words=MAX_TOKENS\n",
    ")\n",
    "\n",
    "print(f\"  훈련 샘플: {len(x_train_raw):,d}개  |  테스트 샘플: {len(x_test_raw):,d}개\")\n",
    "print(f\"  긍정 비율 (훈련): {y_train.mean():.1%}\")\n",
    "print(f\"  시퀀스 길이 분포: 최소={min(len(x) for x in x_train_raw)}, \"\n",
    "      f\"최대={max(len(x) for x in x_train_raw)}, \"\n",
    "      f\"평균={np.mean([len(x) for x in x_train_raw]):.0f}\")\n",
    "\n",
    "# 패딩 적용\n",
    "x_train = tf.keras.utils.pad_sequences(\n",
    "    x_train_raw, maxlen=MAX_SEQ_LEN, padding='post', truncating='post'\n",
    ")\n",
    "x_test = tf.keras.utils.pad_sequences(\n",
    "    x_test_raw, maxlen=MAX_SEQ_LEN, padding='post', truncating='post'\n",
    ")\n",
    "\n",
    "print(f\"\\n패딩 후 훈련 데이터 형태: {x_train.shape}\")\n",
    "print(f\"패딩 후 테스트 데이터 형태: {x_test.shape}\")\n",
    "\n",
    "# 단어 인덱스 저장 (예측 시 사용)\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "# 인덱스 3부터 시작 (0=패딩, 1=시작, 2=OOV)\n",
    "word_to_idx = {w: i + 3 for w, i in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9-0006-0004-0001-000000000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding + Bidirectional LSTM 모델 구성, 컴파일, 학습\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # 임베딩 레이어: 정수 인덱스 → 밀집 벡터\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=MAX_TOKENS + 1,\n",
    "        output_dim=EMBED_DIM,\n",
    "        mask_zero=True,  # 패딩 마스킹 활성화\n",
    "        name='embedding'\n",
    "    ),\n",
    "    \n",
    "    # 양방향 LSTM: 순방향과 역방향 문맥 모두 학습\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64, dropout=0.3, recurrent_dropout=0.3),\n",
    "        name='bilstm'\n",
    "    ),\n",
    "    \n",
    "    # 완전 연결층\n",
    "    tf.keras.layers.Dense(64, activation='relu', name='dense_1'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    # 출력층: 긍정/부정 이진 분류\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='output')\n",
    "], name='BiLSTM_Sentiment')\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 콜백 설정\n",
    "callbacks = [\n",
    "    # 검증 손실이 개선되지 않으면 학습률 감소\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1\n",
    "    ),\n",
    "    # 과적합 방지: 검증 손실이 5 에포크 동안 개선되지 않으면 조기 종료\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=5, restore_best_weights=True, verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 모델 학습\n",
    "print(\"\\n모델 학습 시작...\")\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 최종 테스트 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\n최종 테스트 정확도: {test_acc:.4f}\")\n",
    "print(f\"최종 테스트 손실:   {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9-0006-0005-0001-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 시각화\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 에포크 수\n",
    "epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "# (1) 정확도 곡선\n",
    "axes[0].plot(epochs_range, history.history['accuracy'],\n",
    "             'b-o', label='훈련 정확도', linewidth=2, markersize=5)\n",
    "axes[0].plot(epochs_range, history.history['val_accuracy'],\n",
    "             'r-s', label='검증 정확도', linewidth=2, markersize=5)\n",
    "axes[0].set_xlabel('에포크')\n",
    "axes[0].set_ylabel('정확도')\n",
    "axes[0].set_title('훈련 / 검증 정확도')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "# 테스트 정확도 수평선\n",
    "axes[0].axhline(y=test_acc, color='green', linestyle='--',\n",
    "                label=f'테스트 정확도: {test_acc:.4f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# (2) 손실 곡선\n",
    "axes[1].plot(epochs_range, history.history['loss'],\n",
    "             'b-o', label='훈련 손실', linewidth=2, markersize=5)\n",
    "axes[1].plot(epochs_range, history.history['val_loss'],\n",
    "             'r-s', label='검증 손실', linewidth=2, markersize=5)\n",
    "axes[1].set_xlabel('에포크')\n",
    "axes[1].set_ylabel('손실')\n",
    "axes[1].set_title('훈련 / 검증 손실')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('BiLSTM 감성 분석 모델 학습 곡선', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9-0006-0006-0001-000000000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 리뷰 예측 함수 구현\n",
    "\n",
    "def preprocess_review(text, word_to_idx, max_len=MAX_SEQ_LEN):\n",
    "    \"\"\"\n",
    "    리뷰 텍스트를 모델 입력 형태로 변환\n",
    "    \n",
    "    Args:\n",
    "        text: 예측할 영어 리뷰 문자열\n",
    "        word_to_idx: 단어 → 인덱스 딕셔너리\n",
    "        max_len: 패딩 후 시퀀스 최대 길이\n",
    "    \n",
    "    Returns:\n",
    "        패딩된 정수 시퀀스 (1, max_len)\n",
    "    \"\"\"\n",
    "    # 소문자 변환 및 단어 분리\n",
    "    words = text.lower().split()\n",
    "    # 단어를 인덱스로 변환 (미등록 단어는 인덱스 2: OOV)\n",
    "    encoded = [word_to_idx.get(w, 2) for w in words]\n",
    "    # MAX_TOKENS를 초과하는 인덱스는 OOV로 처리\n",
    "    encoded = [idx if idx <= MAX_TOKENS else 2 for idx in encoded]\n",
    "    # 패딩\n",
    "    padded = tf.keras.utils.pad_sequences(\n",
    "        [encoded], maxlen=max_len, padding='post', truncating='post'\n",
    "    )\n",
    "    return padded\n",
    "\n",
    "def predict_sentiment(text, threshold=0.5):\n",
    "    \"\"\"\n",
    "    리뷰 문자열 입력 → 긍정/부정 판별\n",
    "    \n",
    "    Args:\n",
    "        text: 예측할 영어 리뷰 텍스트\n",
    "        threshold: 긍정 판별 임계값 (기본 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        감성 판별 결과와 확률\n",
    "    \"\"\"\n",
    "    processed = preprocess_review(text, word_to_idx)\n",
    "    prob = model.predict(processed, verbose=0)[0][0]\n",
    "    \n",
    "    label = \"긍정 (Positive)\" if prob >= threshold else \"부정 (Negative)\"\n",
    "    confidence = prob if prob >= threshold else 1 - prob\n",
    "    \n",
    "    return {\n",
    "        'label': label,\n",
    "        'probability': float(prob),\n",
    "        'confidence': float(confidence)\n",
    "    }\n",
    "\n",
    "# 새 리뷰로 예측 테스트\n",
    "test_reviews = [\n",
    "    \"This movie was absolutely fantastic! The acting was superb and the story was gripping.\",\n",
    "    \"Terrible film. Complete waste of time. The plot made no sense whatsoever.\",\n",
    "    \"An average movie. Some good parts but also quite boring at times.\",\n",
    "    \"One of the best films I have ever seen. A masterpiece of cinema!\",\n",
    "    \"I couldn't even finish watching it. So boring and predictable.\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"새 리뷰 감성 분석 결과\")\n",
    "print(\"=\" * 65)\n",
    "for review in test_reviews:\n",
    "    result = predict_sentiment(review)\n",
    "    print(f\"\\n리뷰: {review[:60]}...\" if len(review) > 60 else f\"\\n리뷰: {review}\")\n",
    "    print(f"결과: {result['label']}  (확률: {result['probability']:.4f}, 확신도: {result['confidence']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9-0006-0007-0001-000000000007",
   "metadata": {},
   "source": [
    "## 도전 과제\n",
    "\n",
    "아래 과제를 스스로 수행해 보세요.\n",
    "\n",
    "### 1. 모델 개선\n",
    "- Stacked Bidirectional LSTM(2층)을 구현하고 성능을 비교해 보세요.\n",
    "- 임베딩 차원(`EMBED_DIM`)을 64, 128, 256으로 변경하며 성능 변화를 측정해 보세요.\n",
    "\n",
    "### 2. 정규화 기법 실험\n",
    "- Dropout 비율(0.2, 0.3, 0.5)을 변경하며 과적합 정도를 비교해 보세요.\n",
    "- `recurrent_dropout`이 성능에 어떤 영향을 미치는지 확인해 보세요.\n",
    "\n",
    "### 3. 분석 심화\n",
    "- 모델이 잘못 분류한 예시(오분류 샘플)를 찾아 분석해 보세요.\n",
    "- 혼동 행렬(Confusion Matrix)을 시각화해 보세요.\n",
    "\n",
    "### 4. 임계값 조정\n",
    "- `predict_sentiment()` 함수의 `threshold`를 0.3, 0.5, 0.7로 변경하며  \n",
    "  정밀도(Precision)와 재현율(Recall)의 변화를 분석해 보세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
