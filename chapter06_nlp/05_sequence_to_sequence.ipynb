{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0005-0001-0001-000000000001",
   "metadata": {},
   "source": [
    "# Chapter 06-05: Sequence-to-Sequence (Seq2Seq)\n",
    "\n",
    "## 학습 목표\n",
    "- Seq2Seq 아키텍처(인코더-디코더)의 구조와 작동 원리를 이해한다.\n",
    "- Context Vector의 개념과 한계를 파악한다.\n",
    "- 날짜 형식 변환 예제로 Seq2Seq 모델을 직접 구현한다.\n",
    "- Attention 메커니즘의 필요성을 이해한다.\n",
    "\n",
    "## 목차\n",
    "1. [기본 임포트](#1.-기본-임포트)\n",
    "2. [Seq2Seq 아키텍처](#2.-Seq2Seq-아키텍처)\n",
    "3. [날짜 변환 데이터 생성](#3.-날짜-변환-데이터-생성)\n",
    "4. [Encoder-Decoder LSTM 구현](#4.-Encoder-Decoder-LSTM-구현)\n",
    "5. [학습 및 예측](#5.-학습-및-예측)\n",
    "6. [Attention의 필요성](#6.-Attention의-필요성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0005-0002-0001-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 한글 폰트 설정 (macOS)\n",
    "matplotlib.rcParams['font.family'] = 'AppleGothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
    "\n",
    "# 재현성을 위한 시드 설정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0005-0003-0001-000000000003",
   "metadata": {},
   "source": [
    "## 2. Seq2Seq 아키텍처\n",
    "\n",
    "### 인코더-디코더 구조\n",
    "\n",
    "Seq2Seq 모델은 가변 길이의 입력 시퀀스를 가변 길이의 출력 시퀀스로 변환한다.\n",
    "\n",
    "```\n",
    "[입력 시퀀스]          [출력 시퀀스]\n",
    "\"2024년 1월 15일\"  →  \"2024-01-15\"\n",
    "\"I love you\"       →  \"나는 너를 사랑해\"\n",
    "```\n",
    "\n",
    "**구성 요소:**\n",
    "\n",
    "1. **인코더(Encoder)**\n",
    "   - 입력 시퀀스 전체를 읽어 고정 크기의 **Context Vector**($h_T$)로 압축\n",
    "   - 마지막 타임스텝의 은닉 상태가 Context Vector가 됨\n",
    "\n",
    "2. **Context Vector**\n",
    "   - 입력 시퀀스의 의미를 담은 고정 크기 벡터\n",
    "   - 인코더의 출력을 디코더의 초기 상태로 전달\n",
    "\n",
    "3. **디코더(Decoder)**\n",
    "   - Context Vector에서 시작하여 출력 시퀀스를 한 토큰씩 생성\n",
    "   - 이전 타임스텝의 출력을 다음 타임스텝의 입력으로 사용 (자기회귀)\n",
    "\n",
    "### Context Vector의 한계\n",
    "\n",
    "고정 크기 벡터에 모든 입력 정보를 압축하므로:\n",
    "- 긴 시퀀스에서 **정보 손실** 발생\n",
    "- 입력 초반부 단어의 정보가 **희석**됨\n",
    "- 이를 해결하기 위해 **Attention 메커니즘** 도입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0005-0004-0001-000000000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 형식 변환 예제 데이터 생성\n",
    "# 과제: \"2024년 1월 15일\" → \"2024-01-15\"\n",
    "\n",
    "# 한국어 날짜 → ISO 형식 날짜 변환\n",
    "def generate_date_pairs(n_samples=5000):\n",
    "    \"\"\"랜덤 날짜 쌍 생성 (한국어 형식 → ISO 형식)\"\"\"\n",
    "    months_kr = [\n",
    "        '1월', '2월', '3월', '4월', '5월', '6월',\n",
    "        '7월', '8월', '9월', '10월', '11월', '12월'\n",
    "    ]\n",
    "    days_per_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    \n",
    "    pairs = []\n",
    "    years = list(range(2000, 2026))  # 2000~2025년\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        year  = random.choice(years)\n",
    "        month = random.randint(1, 12)\n",
    "        day   = random.randint(1, days_per_month[month - 1])\n",
    "        \n",
    "        # 입력: 한국어 날짜 형식\n",
    "        source = f\"{year}년 {months_kr[month-1]} {day}일\"\n",
    "        # 출력: ISO 날짜 형식\n",
    "        target = f\"{year}-{month:02d}-{day:02d}\"\n",
    "        \n",
    "        pairs.append((source, target))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# 데이터 생성\n",
    "date_pairs = generate_date_pairs(5000)\n",
    "\n",
    "print(\"생성된 날짜 변환 예시:\")\n",
    "for src, tgt in date_pairs[:8]:\n",
    "    print(f\"  입력: {src:20s}  →  출력: {tgt}\")\n",
    "print(f\"\\n총 데이터 수: {len(date_pairs):,d}\")\n",
    "\n",
    "# 입력/출력 분리\n",
    "sources = [p[0] for p in date_pairs]\n",
    "targets = [p[1] for p in date_pairs]\n",
    "\n",
    "# 출력 시퀀스에 시작/종료 토큰 추가\n",
    "# 디코더 학습: <start> 토큰으로 시작\n",
    "# 디코더 타겟: <end> 토큰으로 끝\n",
    "targets_in  = ['<start> ' + t for t in targets]  # 디코더 입력\n",
    "targets_out = [t + ' <end>'    for t in targets]  # 디코더 타겟\n",
    "\n",
    "print(\"\\n디코더 입력/타겟 예시:\")\n",
    "print(f\"  디코더 입력: '{targets_in[0]}'\")\n",
    "print(f\"  디코더 타겟: '{targets_out[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0005-0005-0001-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-Decoder LSTM 구현\n",
    "\n",
    "# 문자 수준 처리 (날짜 변환은 문자 수준이 적합)\n",
    "LATENT_DIM = 256  # LSTM 은닉 유닛 수\n",
    "\n",
    "# 문자 집합 구성 (입력/출력 각각)\n",
    "all_source_chars = sorted(set(''.join(sources)))\n",
    "all_target_chars = sorted(set(''.join(targets_in + targets_out)))\n",
    "\n",
    "print(f\"입력 문자 집합 크기: {len(all_source_chars)}\")\n",
    "print(f\"  문자들: {all_source_chars}\")\n",
    "print(f\"\\n출력 문자 집합 크기: {len(all_target_chars)}\")\n",
    "print(f\"  문자들: {all_target_chars}\")\n",
    "\n",
    "# 문자 ↔ 인덱스 매핑\n",
    "src_char2idx = {c: i for i, c in enumerate(all_source_chars)}\n",
    "tgt_char2idx = {c: i for i, c in enumerate(all_target_chars)}\n",
    "tgt_idx2char = {i: c for c, i in tgt_char2idx.items()}\n",
    "\n",
    "NUM_SRC_CHARS = len(all_source_chars)\n",
    "NUM_TGT_CHARS = len(all_target_chars)\n",
    "\n",
    "# 최대 시퀀스 길이\n",
    "max_src_len = max(len(s) for s in sources)\n",
    "max_tgt_len = max(len(t) for t in targets_in)\n",
    "print(f\"\\n최대 입력 길이: {max_src_len}\")\n",
    "print(f\"최대 출력 길이: {max_tgt_len}\")\n",
    "\n",
    "# One-Hot 인코딩 데이터 생성\n",
    "print(\"\\nOne-Hot 인코딩 데이터 생성 중...\")\n",
    "N = len(date_pairs)\n",
    "\n",
    "encoder_input_data  = np.zeros((N, max_src_len, NUM_SRC_CHARS), dtype='float32')\n",
    "decoder_input_data  = np.zeros((N, max_tgt_len, NUM_TGT_CHARS), dtype='float32')\n",
    "decoder_target_data = np.zeros((N, max_tgt_len, NUM_TGT_CHARS), dtype='float32')\n",
    "\n",
    "for i, (src, tgt_in, tgt_out) in enumerate(zip(sources, targets_in, targets_out)):\n",
    "    for t, ch in enumerate(src):\n",
    "        encoder_input_data[i, t, src_char2idx[ch]] = 1.0\n",
    "    for t, ch in enumerate(tgt_in):\n",
    "        decoder_input_data[i, t, tgt_char2idx[ch]] = 1.0\n",
    "    for t, ch in enumerate(tgt_out):\n",
    "        decoder_target_data[i, t, tgt_char2idx[ch]] = 1.0\n",
    "\n",
    "print(f\"인코더 입력 형태: {encoder_input_data.shape}\")\n",
    "print(f\"디코더 입력 형태: {decoder_input_data.shape}\")\n",
    "print(f\"디코더 타겟 형태: {decoder_target_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0005-0006-0001-000000000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq 모델 구성 및 학습\n",
    "\n",
    "# ── 인코더 ──────────────────────────────────────────────\n",
    "encoder_inputs = tf.keras.Input(shape=(None, NUM_SRC_CHARS), name='encoder_input')\n",
    "# return_state=True: 은닉 상태와 셀 상태를 반환 (Context Vector로 사용)\n",
    "encoder_lstm = tf.keras.layers.LSTM(\n",
    "    LATENT_DIM,\n",
    "    return_state=True,  # (output, hidden_state, cell_state) 반환\n",
    "    name='encoder_lstm'\n",
    ")\n",
    "# encoder_outputs: 전체 시퀀스 출력 (사용하지 않음)\n",
    "# state_h, state_c: 마지막 타임스텝의 은닉/셀 상태 → Context Vector\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]  # 디코더 초기 상태로 전달\n",
    "\n",
    "# ── 디코더 ──────────────────────────────────────────────\n",
    "decoder_inputs = tf.keras.Input(shape=(None, NUM_TGT_CHARS), name='decoder_input')\n",
    "decoder_lstm = tf.keras.layers.LSTM(\n",
    "    LATENT_DIM,\n",
    "    return_sequences=True,  # 모든 타임스텝 출력\n",
    "    return_state=True,\n",
    "    name='decoder_lstm'\n",
    ")\n",
    "# initial_state=encoder_states: 인코더의 마지막 상태로 초기화\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# 출력층: 각 타임스텝마다 문자 확률 분포 출력\n",
    "decoder_dense = tf.keras.layers.Dense(NUM_TGT_CHARS, activation='softmax', name='output')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Seq2Seq 모델 생성\n",
    "seq2seq_model = tf.keras.Model(\n",
    "    [encoder_inputs, decoder_inputs],\n",
    "    decoder_outputs,\n",
    "    name='Seq2Seq'\n",
    ")\n",
    "\n",
    "seq2seq_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "seq2seq_model.summary()\n",
    "\n",
    "# 학습 실행\n",
    "print(\"\\nSeq2Seq 모델 학습 시작...\")\n",
    "history = seq2seq_model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-0005-0007-0001-000000000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 함수 구현 (추론 시에는 학습과 다른 방식으로 디코딩)\n",
    "\n",
    "# ── 추론용 인코더 모델 ───────────────────────────────────\n",
    "# 입력을 받아 Context Vector(인코더 상태)를 반환\n",
    "encoder_model = tf.keras.Model(\n",
    "    encoder_inputs,\n",
    "    encoder_states,\n",
    "    name='Encoder_Inference'\n",
    ")\n",
    "\n",
    "# ── 추론용 디코더 모델 ───────────────────────────────────\n",
    "# 이전 상태를 입력으로 받아 다음 토큰과 새로운 상태를 반환\n",
    "decoder_state_input_h = tf.keras.Input(shape=(LATENT_DIM,), name='dec_state_h')\n",
    "decoder_state_input_c = tf.keras.Input(shape=(LATENT_DIM,), name='dec_state_c')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(\n",
    "    decoder_inputs,\n",
    "    initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states_inf = [state_h_inf, state_c_inf]\n",
    "decoder_outputs_inf = decoder_dense(decoder_outputs_inf)\n",
    "\n",
    "decoder_model = tf.keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs_inf] + decoder_states_inf,\n",
    "    name='Decoder_Inference'\n",
    ")\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    \"\"\"그리디 디코딩으로 출력 시퀀스 생성\"\"\"\n",
    "    # 1. 인코더로 Context Vector 생성\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    \n",
    "    # 2. <start> 토큰으로 디코더 시작\n",
    "    target_seq = np.zeros((1, 1, NUM_TGT_CHARS))\n",
    "    target_seq[0, 0, tgt_char2idx['<']] = 1.0  # '<start>' 시작\n",
    "    \n",
    "    # 실제로는 '<' 대신 '<start>' 전체를 처리해야 하지만,\n",
    "    # 이 예제에서는 단순화를 위해 첫 문자만 사용\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    max_decode_len = 20\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # 3. 디코더로 다음 토큰 예측\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value, verbose=0\n",
    "        )\n",
    "        \n",
    "        # 4. 가장 높은 확률의 토큰 선택 (그리디)\n",
    "        sampled_token_idx = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tgt_idx2char[sampled_token_idx]\n",
    "        \n",
    "        # 5. 종료 조건 확인\n",
    "        if sampled_char == '>' or len(decoded_sentence) > max_decode_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += sampled_char\n",
    "        \n",
    "        # 6. 다음 타임스텝 준비\n",
    "        target_seq = np.zeros((1, 1, NUM_TGT_CHARS))\n",
    "        target_seq[0, 0, sampled_token_idx] = 1.0\n",
    "        states_value = [h, c]  # 상태 업데이트\n",
    "    \n",
    "    return decoded_sentence\n",
    "\n",
    "# 테스트 예측\n",
    "print(\"=== 날짜 변환 예측 테스트 ===\")\n",
    "test_indices = random.sample(range(N), 5)\n",
    "for idx in test_indices:\n",
    "    input_seq  = encoder_input_data[idx:idx+1]\n",
    "    predicted  = decode_sequence(input_seq)\n",
    "    actual     = targets[idx]\n",
    "    source_txt = sources[idx]\n",
    "    print(f\"  입력:  {source_txt:20s}\")\n",
    "    print(f\"  예측:  {predicted}\")\n",
    "    print(f\"  실제:  {actual}\")\n",
    "    print(f\"  결과:  {'정답' if predicted.strip() == actual else '오답'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0005-0008-0001-000000000008",
   "metadata": {},
   "source": [
    "## 6. Attention 메커니즘의 필요성\n",
    "\n",
    "### Context Vector의 병목 문제\n",
    "\n",
    "Seq2Seq 모델에서 인코더는 입력 시퀀스 전체를 **고정 크기**의 Context Vector로 압축한다.  \n",
    "이 접근법은 짧은 시퀀스에서는 잘 동작하지만, 긴 시퀀스에서는 한계가 있다.\n",
    "\n",
    "$$\\text{긴 문장} \\xrightarrow{\\text{인코더}} \\underbrace{\\vec{c}}_{\\text{고정 크기 벡터}} \\xrightarrow{\\text{디코더}} \\text{출력}$$\n",
    "\n",
    "### Attention의 아이디어\n",
    "\n",
    "디코더가 출력을 생성할 때 **입력 시퀀스의 모든 타임스텝**을 직접 참조한다.  \n",
    "각 출력 토큰을 생성할 때마다 **어느 입력에 집중할지(Attention)**를 학습한다.\n",
    "\n",
    "$$\\text{Attention Score}: e_{t,s} = \\text{score}(h_t, \\bar{h}_s)$$\n",
    "\n",
    "$$\\text{Attention Weight}: \\alpha_{t,s} = \\frac{\\exp(e_{t,s})}{\\sum_{s'} \\exp(e_{t,s'})}$$\n",
    "\n",
    "$$\\text{Context Vector}: c_t = \\sum_s \\alpha_{t,s} \\bar{h}_s$$\n",
    "\n",
    "### Transformer로의 발전\n",
    "\n",
    "Attention 메커니즘은 이후 **Self-Attention**과 **Transformer** 아키텍처로 발전했다.  \n",
    "BERT, GPT 등 현재의 대규모 언어 모델은 모두 Transformer 기반이다.\n",
    "\n",
    "---\n",
    "\n",
    "### 다음 챕터 예고\n",
    "- **Chapter 06 실습 1**: 감성 분석 (ex01_sentiment_analysis.ipynb)  \n",
    "- **Chapter 06 실습 2**: 한국어 텍스트 분류 (ex02_korean_text_classification.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
