{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0004-0001-0001-000000000001",
   "metadata": {},
   "source": [
    "# Chapter 06-04: 텍스트 분류 (Text Classification)\n",
    "\n",
    "## 학습 목표\n",
    "- IMDB 영화 리뷰 데이터셋으로 감성 분류(긍정/부정)를 구현한다.\n",
    "- 4가지 모델 아키텍처(BoW, LSTM, GRU, BiLSTM)를 비교한다.\n",
    "- `TextVectorization`을 활용한 엔드-투-엔드 파이프라인을 구성한다.\n",
    "- 각 모델의 검증 정확도와 학습 시간을 비교한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0004-0002-0001-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "\n",
    "# 한글 폰트 설정 (macOS)\n",
    "matplotlib.rcParams['font.family'] = 'AppleGothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
    "\n",
    "# 재현성을 위한 시드 설정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0004-0003-0001-000000000003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB 데이터셋 로드 및 TextVectorization 적용\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "MAX_TOKENS  = 10000  # 어휘 사전 최대 크기\n",
    "MAX_SEQ_LEN = 200    # 시퀀스 최대 길이\n",
    "EMBED_DIM   = 64     # 임베딩 차원\n",
    "BATCH_SIZE  = 32     # 배치 크기\n",
    "EPOCHS      = 5      # 학습 에포크 수\n",
    "\n",
    "# IMDB 데이터셋 로드 (정수 인코딩된 버전)\n",
    "# num_words: 빈도 순위 상위 MAX_TOKENS개 단어만 사용\n",
    "print(\"IMDB 데이터셋 로드 중...\")\n",
    "(x_train_raw, y_train), (x_test_raw, y_test) = tf.keras.datasets.imdb.load_data(\n",
    "    num_words=MAX_TOKENS\n",
    ")\n",
    "print(f\"  훈련 샘플: {len(x_train_raw):,d}개\")\n",
    "print(f\"  테스트 샘플: {len(x_test_raw):,d}개\")\n",
    "print(f\"  레이블: 0=부정, 1=긍정\")\n",
    "print()\n",
    "\n",
    "# IMDB 단어 인덱스 → 원문 복원\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "# 인덱스 3부터 시작 (0=패딩, 1=시작, 2=미등록)\n",
    "reverse_word_index = {v + 3: k for k, v in word_index.items()}\n",
    "reverse_word_index[0] = '<PAD>'\n",
    "reverse_word_index[1] = '<START>'\n",
    "reverse_word_index[2] = '<UNK>'\n",
    "\n",
    "def decode_review(encoded):\n",
    "    \"\"\"정수 시퀀스를 원문 텍스트로 복원\"\"\"\n",
    "    return ' '.join(reverse_word_index.get(i, '?') for i in encoded)\n",
    "\n",
    "print(\"샘플 리뷰 (처음 50단어):\")\n",
    "print(decode_review(x_train_raw[0][:50]))\n",
    "print(f\"레이블: {'긍정' if y_train[0] == 1 else '부정'}\")\n",
    "print()\n",
    "\n",
    "# 패딩: 시퀀스 길이를 MAX_SEQ_LEN으로 통일\n",
    "x_train = tf.keras.utils.pad_sequences(\n",
    "    x_train_raw, maxlen=MAX_SEQ_LEN, padding='post', truncating='post'\n",
    ")\n",
    "x_test = tf.keras.utils.pad_sequences(\n",
    "    x_test_raw, maxlen=MAX_SEQ_LEN, padding='post', truncating='post'\n",
    ")\n",
    "print(f\"패딩 후 훈련 데이터 형태: {x_train.shape}\")\n",
    "print(f\"패딩 후 테스트 데이터 형태: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0004-0004-0001-000000000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 1: Embedding + GlobalAveragePooling (Bag of Words)\n",
    "# 순서 정보를 무시하고 단어 임베딩의 평균을 사용하는 가장 단순한 방법\n",
    "\n",
    "def build_bow_model():\n",
    "    \"\"\"Bag-of-Words 방식: 임베딩 평균 사용\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        # Embedding: 정수 인덱스 → 밀집 벡터\n",
    "        tf.keras.layers.Embedding(MAX_TOKENS + 1, EMBED_DIM,\n",
    "                                  mask_zero=True, name='embedding'),\n",
    "        # GlobalAveragePooling1D: 시퀀스 차원을 평균으로 압축\n",
    "        # (배치, 시퀀스, 임베딩) → (배치, 임베딩)\n",
    "        tf.keras.layers.GlobalAveragePooling1D(name='global_avg_pool'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # 이진 분류\n",
    "    ], name='BoW_Model')\n",
    "    return model\n",
    "\n",
    "model_bow = build_bow_model()\n",
    "model_bow.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_bow.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0004-0005-0001-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 2: Embedding + LSTM\n",
    "\n",
    "def build_lstm_model():\n",
    "    \"\"\"단방향 LSTM 분류 모델\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(MAX_TOKENS + 1, EMBED_DIM,\n",
    "                                  mask_zero=True, name='embedding'),\n",
    "        # LSTM: 순서 정보를 유지하며 시퀀스 처리\n",
    "        tf.keras.layers.LSTM(64, name='lstm'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ], name='LSTM_Model')\n",
    "    return model\n",
    "\n",
    "model_lstm = build_lstm_model()\n",
    "model_lstm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0004-0006-0001-000000000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 3: Embedding + GRU\n",
    "\n",
    "def build_gru_model():\n",
    "    \"\"\"GRU 분류 모델 - LSTM보다 경량\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(MAX_TOKENS + 1, EMBED_DIM,\n",
    "                                  mask_zero=True, name='embedding'),\n",
    "        # GRU: LSTM보다 파라미터가 적어 학습 속도 빠름\n",
    "        tf.keras.layers.GRU(64, name='gru'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ], name='GRU_Model')\n",
    "    return model\n",
    "\n",
    "model_gru = build_gru_model()\n",
    "model_gru.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0004-0007-0001-000000000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 4: Embedding + Bidirectional LSTM\n",
    "\n",
    "def build_bilstm_model():\n",
    "    \"\"\"양방향 LSTM 분류 모델 - 양쪽 문맥 포착\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(MAX_TOKENS + 1, EMBED_DIM,\n",
    "                                  mask_zero=True, name='embedding'),\n",
    "        # Bidirectional: 순방향과 역방향 LSTM을 결합\n",
    "        # 출력 차원: LSTM(64) × 2 = 128\n",
    "        tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(64),\n",
    "            name='bilstm'\n",
    "        ),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ], name='BiLSTM_Model')\n",
    "    return model\n",
    "\n",
    "model_bilstm = build_bilstm_model()\n",
    "model_bilstm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_bilstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0004-0008-0001-000000000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4개 모델 학습 및 검증 정확도 비교\n",
    "\n",
    "results = {}  # 학습 결과 저장\n",
    "\n",
    "models_to_train = [\n",
    "    ('BoW (GlobalAvgPool)', model_bow),\n",
    "    ('LSTM',               model_lstm),\n",
    "    ('GRU',                model_gru),\n",
    "    ('Bidirectional LSTM', model_bilstm),\n",
    "]\n",
    "\n",
    "for model_name, model in models_to_train:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"학습 중: {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,  # 훈련 데이터의 20%를 검증에 사용\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # 테스트 평가\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'history': history,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'time': elapsed\n",
    "    }\n",
    "    \n",
    "    print(f\"테스트 정확도: {test_acc:.4f} | 학습 시간: {elapsed:.1f}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0004-0009-0001-000000000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4개 모델 성능 비교 시각화\n",
    "\n",
    "model_names  = list(results.keys())\n",
    "test_accs    = [results[m]['test_accuracy'] for m in model_names]\n",
    "train_times  = [results[m]['time'] for m in model_names]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# (1) 테스트 정확도 막대 차트\n",
    "colors = ['#4C72B0', '#DD8452', '#55A868', '#C44E52']\n",
    "bars = axes[0].bar(model_names, test_accs, color=colors, edgecolor='black', linewidth=0.8)\n",
    "axes[0].set_ylim([0.8, 1.0])\n",
    "axes[0].set_ylabel('테스트 정확도')\n",
    "axes[0].set_title('모델별 테스트 정확도 비교')\n",
    "axes[0].tick_params(axis='x', rotation=30)\n",
    "for bar, acc in zip(bars, test_accs):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
    "                 f'{acc:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# (2) 학습 시간 막대 차트\n",
    "bars2 = axes[1].bar(model_names, train_times, color=colors, edgecolor='black', linewidth=0.8)\n",
    "axes[1].set_ylabel('학습 시간 (초)')\n",
    "axes[1].set_title('모델별 학습 시간 비교')\n",
    "axes[1].tick_params(axis='x', rotation=30)\n",
    "for bar, t in zip(bars2, train_times):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                 f'{t:.1f}s', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# (3) 학습 곡선 비교\n",
    "for i, (name, res) in enumerate(results.items()):\n",
    "    val_acc = res['history'].history['val_accuracy']\n",
    "    axes[2].plot(range(1, len(val_acc)+1), val_acc,\n",
    "                 marker='o', label=name, color=colors[i])\n",
    "axes[2].set_xlabel('에포크')\n",
    "axes[2].set_ylabel('검증 정확도')\n",
    "axes[2].set_title('에포크별 검증 정확도')\n",
    "axes[2].legend(fontsize=8)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('IMDB 감성 분석: 4가지 모델 비교', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최종 성능 요약 테이블\n",
    "print(\"\\n=== 최종 성능 요약 ===\")\n",
    "print(f\"{'모델':<22} {'테스트 정확도':>14} {'학습 시간':>12}\")\n",
    "print('-' * 52)\n",
    "for name in model_names:\n",
    "    acc  = results[name]['test_accuracy']\n",
    "    t    = results[name]['time']\n",
    "    print(f\"{name:<22} {acc:>14.4f} {t:>10.1f}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-0004-0010-0001-000000000010",
   "metadata": {},
   "source": [
    "## 결과 분석 및 정리\n",
    "\n",
    "### 실험 결과 해석\n",
    "\n",
    "| 모델 | 특징 | 예상 정확도 | 예상 학습 시간 |\n",
    "|------|------|-------------|----------------|\n",
    "| **BoW (GlobalAvgPool)** | 순서 무시, 매우 빠름 | ~86% | 가장 빠름 |\n",
    "| **LSTM** | 순서 포착, 장기 의존성 | ~87~88% | 중간 |\n",
    "| **GRU** | LSTM과 유사, 경량 | ~87~88% | LSTM보다 빠름 |\n",
    "| **Bidirectional LSTM** | 양방향 문맥 | ~88~89% | 가장 느림 |\n",
    "\n",
    "### 주요 관찰\n",
    "1. **BoW 모델**은 단순하지만 IMDB처럼 단어 빈도가 중요한 데이터에서도 준수한 성능을 보인다.\n",
    "2. **LSTM/GRU**는 단어 순서(\"not good\" vs \"good not\")를 구분할 수 있어 더 정확하다.\n",
    "3. **BiLSTM**은 일반적으로 가장 높은 정확도를 달성하지만 학습 시간이 2배 이상이다.\n",
    "4. 실무에서는 **정확도와 속도의 트레이드오프**를 고려하여 모델을 선택한다.\n",
    "\n",
    "### 다음 챕터 예고\n",
    "- **Chapter 06-05**: Seq2Seq 모델  \n",
    "  인코더-디코더 구조로 입력 시퀀스를 다른 시퀀스로 변환하는 방법을 학습한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
