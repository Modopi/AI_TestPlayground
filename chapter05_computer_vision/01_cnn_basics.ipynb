{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05-01: CNN 기초 — 합성곱 신경망\n",
    "\n",
    "## 학습 목표\n",
    "- 합성곱(Convolution) 연산의 수학적 원리를 이해한다\n",
    "- Padding과 Stride가 출력 크기에 미치는 영향을 계산할 수 있다\n",
    "- Pooling 레이어의 종류와 역할을 설명할 수 있다\n",
    "- 기본 CNN 구조를 TensorFlow/Keras로 구현하고 MNIST를 학습시킬 수 있다\n",
    "- 중간 레이어의 특징 맵(Feature Map)을 시각화할 수 있다\n",
    "\n",
    "## 목차\n",
    "1. [합성곱 연산 수학 공식](#1)\n",
    "2. [Numpy로 수동 2D 합성곱 구현](#2)\n",
    "3. [Padding과 Stride](#3)\n",
    "4. [Pooling 레이어 비교](#4)\n",
    "5. [기본 CNN 구성 및 MNIST 학습](#5)\n",
    "6. [특징 맵 시각화](#6)\n",
    "7. [정리](#7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# 한글 폰트 설정 (macOS 기준)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 재현성을 위한 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f'TensorFlow 버전: {tf.__version__}')\n",
    "print(f'NumPy 버전: {np.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 합성곱 연산 수학 공식 <a id='1'></a>\n",
    "\n",
    "### 2D 합성곱 (2D Convolution)\n",
    "\n",
    "입력 이미지 $I$와 커널 $K$의 합성곱은 다음과 같이 정의된다:\n",
    "\n",
    "$(I * K)[i,j] = \\sum_m \\sum_n I[i+m,\\, j+n] \\cdot K[m,n]$\n",
    "\n",
    "여기서 $i, j$는 출력의 위치, $m, n$은 커널 내 상대적 위치이다.\n",
    "\n",
    "### 출력 크기 계산\n",
    "\n",
    "입력 크기 $I$, 커널 크기 $K$, 패딩 $P$, 스트라이드 $S$가 주어질 때 출력 크기 $O$는:\n",
    "\n",
    "$O = \\lfloor\\frac{I - K + 2P}{S}\\rfloor + 1$\n",
    "\n",
    "예시: 입력 $28 \\times 28$, 커널 $3 \\times 3$, 패딩 0, 스트라이드 1이면\n",
    "$O = \\lfloor\\frac{28 - 3 + 0}{1}\\rfloor + 1 = 26$\n",
    "\n",
    "### Conv2D 파라미터 수\n",
    "\n",
    "커널 높이 $K_h$, 커널 너비 $K_w$, 입력 채널 $C_{in}$, 출력 채널 $C_{out}$일 때:\n",
    "\n",
    "$\\text{파라미터 수} = K_h \\times K_w \\times C_{in} \\times C_{out} + C_{out}$\n",
    "\n",
    "마지막 $+ C_{out}$은 편향(bias) 항이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numpy로 수동 2D 합성곱 구현 <a id='2'></a>\n",
    "\n",
    "합성곱 연산의 직관을 얻기 위해 NumPy만으로 2D 합성곱을 직접 구현해 본다.\n",
    "엣지 검출(Edge Detection) 커널로 실제 이미지에 적용한다.\n",
    "\n",
    "대표적인 엣지 검출 커널:\n",
    "- **Sobel X**: 수직 방향 엣지 검출\n",
    "- **Sobel Y**: 수평 방향 엣지 검출\n",
    "- **Laplacian**: 전방향 엣지 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_manual(image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    NumPy로 구현한 수동 2D 합성곱 함수\n",
    "    \n",
    "    Args:\n",
    "        image: 2D 입력 이미지 배열 (H, W)\n",
    "        kernel: 2D 커널 배열 (Kh, Kw)\n",
    "        stride: 스트라이드 (기본값 1)\n",
    "        padding: 제로 패딩 크기 (기본값 0)\n",
    "    \n",
    "    Returns:\n",
    "        출력 특징 맵 (output feature map)\n",
    "    \"\"\"\n",
    "    # 패딩 적용\n",
    "    if padding > 0:\n",
    "        image = np.pad(image, padding, mode='constant', constant_values=0)\n",
    "    \n",
    "    I_h, I_w = image.shape          # 입력 높이, 너비\n",
    "    K_h, K_w = kernel.shape         # 커널 높이, 너비\n",
    "    \n",
    "    # 출력 크기 계산: O = floor((I - K) / S) + 1\n",
    "    O_h = (I_h - K_h) // stride + 1\n",
    "    O_w = (I_w - K_w) // stride + 1\n",
    "    \n",
    "    # 출력 배열 초기화\n",
    "    output = np.zeros((O_h, O_w))\n",
    "    \n",
    "    # 합성곱 연산: 슬라이딩 윈도우 방식\n",
    "    for i in range(O_h):\n",
    "        for j in range(O_w):\n",
    "            # 현재 윈도우 위치에서 요소별 곱셈 후 합산\n",
    "            output[i, j] = np.sum(\n",
    "                image[i*stride:i*stride+K_h, j*stride:j*stride+K_w] * kernel\n",
    "            )\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# 테스트용 간단한 이미지 생성 (6x6)\n",
    "test_image = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 2, 2, 1, 0],\n",
    "    [0, 1, 2, 2, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0]\n",
    "], dtype=float)\n",
    "\n",
    "# 엣지 검출 커널 정의\n",
    "sobel_x = np.array([[-1, 0, 1],\n",
    "                     [-2, 0, 2],\n",
    "                     [-1, 0, 1]], dtype=float)  # 수직 엣지 검출\n",
    "\n",
    "sobel_y = np.array([[-1, -2, -1],\n",
    "                     [ 0,  0,  0],\n",
    "                     [ 1,  2,  1]], dtype=float)  # 수평 엣지 검출\n",
    "\n",
    "laplacian = np.array([[ 0, -1,  0],\n",
    "                       [-1,  4, -1],\n",
    "                       [ 0, -1,  0]], dtype=float)  # 전방향 엣지 검출\n",
    "\n",
    "# 각 커널 적용\n",
    "out_sobel_x = conv2d_manual(test_image, sobel_x)\n",
    "out_sobel_y = conv2d_manual(test_image, sobel_y)\n",
    "out_laplacian = conv2d_manual(test_image, laplacian)\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "\n",
    "axes[0].imshow(test_image, cmap='gray')\n",
    "axes[0].set_title('원본 이미지')\n",
    "\n",
    "axes[1].imshow(out_sobel_x, cmap='RdBu')\n",
    "axes[1].set_title('Sobel X (수직 엣지)')\n",
    "\n",
    "axes[2].imshow(out_sobel_y, cmap='RdBu')\n",
    "axes[2].set_title('Sobel Y (수평 엣지)')\n",
    "\n",
    "axes[3].imshow(out_laplacian, cmap='RdBu')\n",
    "axes[3].set_title('Laplacian (전방향 엣지)')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('엣지 검출 커널 적용 결과', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'입력 크기: {test_image.shape}')\n",
    "print(f'출력 크기 (3x3 커널, stride=1, padding=0): {out_sobel_x.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Padding과 Stride <a id='3'></a>\n",
    "\n",
    "### Padding\n",
    "- **valid**: 패딩 없음. 입력 경계 외부는 무시 → 출력 크기 감소\n",
    "- **same**: 출력 크기 = 입력 크기가 되도록 자동으로 제로 패딩 추가\n",
    "\n",
    "### Stride\n",
    "- 커널이 이동하는 간격\n",
    "- stride=2이면 출력 크기가 약 절반으로 줄어든다\n",
    "- MaxPooling 없이 Stride로 다운샘플링하는 경우도 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding과 Stride 효과 비교\n",
    "\n",
    "# 28x28 더미 입력 (MNIST 크기)\n",
    "dummy_input = tf.random.normal([1, 28, 28, 1])\n",
    "\n",
    "# 다양한 설정으로 Conv2D 적용\n",
    "configs = [\n",
    "    {'filters': 32, 'kernel_size': 3, 'strides': 1, 'padding': 'valid', 'label': 'valid, stride=1'},\n",
    "    {'filters': 32, 'kernel_size': 3, 'strides': 1, 'padding': 'same',  'label': 'same,  stride=1'},\n",
    "    {'filters': 32, 'kernel_size': 3, 'strides': 2, 'padding': 'valid', 'label': 'valid, stride=2'},\n",
    "    {'filters': 32, 'kernel_size': 3, 'strides': 2, 'padding': 'same',  'label': 'same,  stride=2'},\n",
    "]\n",
    "\n",
    "print(f'{'설정':<25} {'입력 크기':<15} {'출력 크기':<15} {'이론값'}')\n",
    "print('-' * 70)\n",
    "\n",
    "for cfg in configs:\n",
    "    layer = tf.keras.layers.Conv2D(\n",
    "        filters=cfg['filters'],\n",
    "        kernel_size=cfg['kernel_size'],\n",
    "        strides=cfg['strides'],\n",
    "        padding=cfg['padding']\n",
    "    )\n",
    "    output = layer(dummy_input)\n",
    "    \n",
    "    # 이론적 출력 크기 계산 (valid 패딩 기준)\n",
    "    if cfg['padding'] == 'valid':\n",
    "        theory = (28 - cfg['kernel_size']) // cfg['strides'] + 1\n",
    "    else:  # same\n",
    "        theory = int(np.ceil(28 / cfg['strides']))\n",
    "    \n",
    "    print(f\"{cfg['label']:<25} {str(dummy_input.shape[1:3]):<15} \"\n",
    "          f\"{str(output.shape[1:3]):<15} H={theory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pooling 레이어 비교 <a id='4'></a>\n",
    "\n",
    "Pooling은 공간 차원을 줄여 계산량을 감소시키고 과적합을 방지하는 역할을 한다.\n",
    "\n",
    "| 종류 | 설명 | 특징 |\n",
    "|------|------|------|\n",
    "| MaxPooling2D | 윈도우 내 최댓값 선택 | 가장 강한 특징 보존 |\n",
    "| AveragePooling2D | 윈도우 내 평균값 | 부드러운 특징 추출 |\n",
    "| GlobalAveragePooling2D | 채널별 전체 평균 | Flatten 대체, 파라미터 절약 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling 레이어 비교 예시\n",
    "\n",
    "# 4x4 특징 맵 예시\n",
    "feature_map = np.array([[[[1, 2, 3, 4],\n",
    "                           [5, 6, 7, 8],\n",
    "                           [9, 10, 11, 12],\n",
    "                           [13, 14, 15, 16]]]], dtype=float)\n",
    "# 형태 변환: (1, 4, 4, 1)\n",
    "feature_map = feature_map.transpose(0, 2, 3, 1)\n",
    "print(f'입력 특징 맵 형태: {feature_map.shape}')\n",
    "print(f'입력:\\n{feature_map[0,:,:,0]}')\n",
    "print()\n",
    "\n",
    "# MaxPooling2D (2x2, stride=2)\n",
    "max_pool = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)\n",
    "out_max = max_pool(feature_map)\n",
    "print(f'MaxPooling2D 출력 (2x2, stride=2):\\n{out_max[0,:,:,0].numpy()}')\n",
    "print()\n",
    "\n",
    "# AveragePooling2D (2x2, stride=2)\n",
    "avg_pool = tf.keras.layers.AveragePooling2D(pool_size=2, strides=2)\n",
    "out_avg = avg_pool(feature_map)\n",
    "print(f'AveragePooling2D 출력 (2x2, stride=2):\\n{out_avg[0,:,:,0].numpy()}')\n",
    "print()\n",
    "\n",
    "# GlobalAveragePooling2D (채널별 전체 평균 → 1D 벡터)\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()\n",
    "out_gap = gap(feature_map)\n",
    "print(f'GlobalAveragePooling2D 출력 (채널별 평균): {out_gap.numpy()}')\n",
    "print(f'  → 전체 평균: {feature_map.mean():.1f} (확인)')\n",
    "print()\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "axes[0].imshow(out_max[0,:,:,0], cmap='Blues', vmin=1, vmax=16)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[0].text(j, i, f'{out_max[0,i,j,0].numpy():.0f}',\n",
    "                     ha='center', va='center', fontsize=16, fontweight='bold')\n",
    "axes[0].set_title('MaxPooling2D\\n(최댓값 선택)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(out_avg[0,:,:,0], cmap='Greens', vmin=1, vmax=16)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[1].text(j, i, f'{out_avg[0,i,j,0].numpy():.1f}',\n",
    "                     ha='center', va='center', fontsize=16, fontweight='bold')\n",
    "axes[1].set_title('AveragePooling2D\\n(평균값)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow([[out_gap[0,0].numpy()]], cmap='Oranges', vmin=1, vmax=16)\n",
    "axes[2].text(0, 0, f'{out_gap[0,0].numpy():.1f}',\n",
    "             ha='center', va='center', fontsize=20, fontweight='bold')\n",
    "axes[2].set_title('GlobalAveragePooling2D\\n(전체 평균 → 스칼라)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle('Pooling 레이어 비교', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 기본 CNN 구성 및 MNIST 학습 <a id='5'></a>\n",
    "\n",
    "전형적인 CNN 구조:\n",
    "```\n",
    "Conv2D → MaxPool → Conv2D → MaxPool → Flatten → Dense → Dense(출력)\n",
    "```\n",
    "\n",
    "각 단계의 역할:\n",
    "- **Conv2D + ReLU**: 지역적 패턴 (엣지, 텍스처, 형태) 추출\n",
    "- **MaxPooling**: 공간 해상도 축소, 평행이동 불변성 부여\n",
    "- **Flatten**: 2D 특징 맵을 1D 벡터로 변환\n",
    "- **Dense**: 전역적 특징 조합 및 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 로드 및 전처리\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# CNN 입력을 위해 채널 차원 추가 및 정규화 [0, 255] → [0, 1]\n",
    "x_train = x_train[..., np.newaxis] / 255.0  # (60000, 28, 28, 1)\n",
    "x_test  = x_test[..., np.newaxis]  / 255.0  # (10000, 28, 28, 1)\n",
    "\n",
    "print(f'학습 데이터: {x_train.shape}, 레이블: {y_train.shape}')\n",
    "print(f'테스트 데이터: {x_test.shape}, 레이블: {y_test.shape}')\n",
    "\n",
    "# 기본 CNN 모델 구성\n",
    "model = tf.keras.Sequential([\n",
    "    # 첫 번째 합성곱 블록\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                           input_shape=(28, 28, 1), name='conv1'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), name='pool1'),\n",
    "    \n",
    "    # 두 번째 합성곱 블록\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', name='conv2'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), name='pool2'),\n",
    "    \n",
    "    # 분류 헤드\n",
    "    tf.keras.layers.Flatten(name='flatten'),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='dense1'),\n",
    "    tf.keras.layers.Dropout(0.3, name='dropout'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "], name='basic_cnn')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 테스트 세트 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'\\n테스트 정확도: {test_acc:.4f}')\n",
    "\n",
    "# 학습 곡선 시각화\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='학습 손실')\n",
    "ax1.plot(history.history['val_loss'], label='검증 손실')\n",
    "ax1.set_xlabel('에폭')\n",
    "ax1.set_ylabel('손실')\n",
    "ax1.set_title('학습/검증 손실 곡선')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(history.history['accuracy'], label='학습 정확도')\n",
    "ax2.plot(history.history['val_accuracy'], label='검증 정확도')\n",
    "ax2.set_xlabel('에폭')\n",
    "ax2.set_ylabel('정확도')\n",
    "ax2.set_title('학습/검증 정확도 곡선')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.suptitle(f'Basic CNN on MNIST (테스트 정확도: {test_acc:.4f})', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 특징 맵 시각화 <a id='6'></a>\n",
    "\n",
    "학습된 CNN의 중간 레이어 출력을 추출하여 각 필터가 어떤 특징을 감지하는지 확인한다.\n",
    "\n",
    "**방법**: `tf.keras.Model`을 이용해 중간 레이어의 출력을 추출하는 서브모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중간 레이어 출력을 추출하는 시각화 모델 생성\n",
    "layer_names = ['conv1', 'pool1', 'conv2', 'pool2']\n",
    "\n",
    "# 각 레이어의 출력을 반환하는 서브모델\n",
    "visualization_model = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=[model.get_layer(name).output for name in layer_names]\n",
    ")\n",
    "\n",
    "# 샘플 이미지 선택 (숫자 '7')\n",
    "sample_idx = np.where(y_test == 7)[0][0]\n",
    "sample_image = x_test[sample_idx:sample_idx+1]  # (1, 28, 28, 1)\n",
    "\n",
    "# 중간 레이어 출력 계산\n",
    "feature_maps = visualization_model.predict(sample_image, verbose=0)\n",
    "\n",
    "# 각 레이어의 특징 맵 시각화\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 원본 이미지\n",
    "ax = fig.add_subplot(5, 1, 1)\n",
    "ax.imshow(sample_image[0, :, :, 0], cmap='gray')\n",
    "ax.set_title(f'원본 이미지 (레이블: {y_test[sample_idx]})', fontsize=12)\n",
    "ax.axis('off')\n",
    "\n",
    "# 각 레이어의 특징 맵 (최대 16개 필터)\n",
    "n_display = 16  # 표시할 필터 수\n",
    "\n",
    "for layer_idx, (layer_name, fmap) in enumerate(zip(layer_names, feature_maps)):\n",
    "    n_filters = min(fmap.shape[-1], n_display)\n",
    "    \n",
    "    # 서브플롯 그리드 (4열)\n",
    "    for f_idx in range(n_filters):\n",
    "        ax = fig.add_subplot(5, n_display, (layer_idx + 1) * n_display + f_idx + 1)\n",
    "        ax.imshow(fmap[0, :, :, f_idx], cmap='viridis')\n",
    "        ax.axis('off')\n",
    "        if f_idx == 0:\n",
    "            ax.set_ylabel(f'{layer_name}\\n{fmap.shape[1:3]}', fontsize=9)\n",
    "\n",
    "plt.suptitle('CNN 중간 레이어 특징 맵 시각화', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 각 레이어별 정보 출력\n",
    "print('\\n레이어별 특징 맵 정보:')\n",
    "print(f'{'레이어':<15} {'출력 형태':<20} {'파라미터 수'}')\n",
    "print('-' * 50)\n",
    "for layer_name, fmap in zip(layer_names, feature_maps):\n",
    "    layer = model.get_layer(layer_name)\n",
    "    params = layer.count_params()\n",
    "    print(f'{layer_name:<15} {str(fmap.shape[1:]):<20} {params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 정리 <a id='7'></a>\n",
    "\n",
    "### 핵심 수식 요약\n",
    "\n",
    "| 항목 | 수식 |\n",
    "|------|------|\n",
    "| 2D 합성곱 | $(I * K)[i,j] = \\sum_m \\sum_n I[i+m, j+n] \\cdot K[m,n]$ |\n",
    "| 출력 크기 | $O = \\lfloor\\frac{I - K + 2P}{S}\\rfloor + 1$ |\n",
    "| Conv2D 파라미터 | $K_h \\times K_w \\times C_{in} \\times C_{out} + C_{out}$ |\n",
    "\n",
    "### 핵심 개념\n",
    "- **합성곱**: 슬라이딩 윈도우로 지역 패턴을 추출하는 연산\n",
    "- **패딩(same)**: 출력 크기를 입력과 동일하게 유지\n",
    "- **스트라이드**: 클수록 출력 크기 감소 (다운샘플링)\n",
    "- **MaxPooling**: 공간 크기 축소 + 평행이동 불변성\n",
    "- **특징 맵**: 각 필터가 감지하는 특정 패턴의 활성화 강도\n",
    "\n",
    "### 다음 챕터 예고\n",
    "**Chapter 05-02**: VGG, ResNet, EfficientNet 등 실제 서비스에 사용되는 고급 CNN 아키텍처를 학습한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
