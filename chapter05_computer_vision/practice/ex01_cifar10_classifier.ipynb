{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05 실습 1: CIFAR-10 분류기\n",
    "\n",
    "## 목표\n",
    "CIFAR-10 데이터셋으로 CNN 분류기를 구현하고 성능을 분석한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 재현성 시드 고정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f'TensorFlow 버전: {tf.__version__}')\n",
    "print(f'NumPy 버전: {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 데이터 로드 및 전처리\n",
    "\n",
    "# CIFAR-10 로드\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# 레이블 배열 압축: (50000, 1) → (50000,)\n",
    "y_train = y_train.squeeze()\n",
    "y_test  = y_test.squeeze()\n",
    "\n",
    "# 픽셀값 정규화: [0, 255] → [0.0, 1.0]\n",
    "x_train = x_train / 255.0\n",
    "x_test  = x_test  / 255.0\n",
    "\n",
    "# 클래스 이름 정의\n",
    "CLASS_NAMES = ['비행기', '자동차', '새', '고양이', '사슴',\n",
    "               '개', '개구리', '말', '배', '트럭']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "print(f'학습 데이터: {x_train.shape}, dtype: {x_train.dtype}')\n",
    "print(f'테스트 데이터: {x_test.shape}, dtype: {x_test.dtype}')\n",
    "print(f'학습 레이블: {y_train.shape}, 범위: [{y_train.min()}, {y_train.max()}]')\n",
    "print(f'클래스 수: {NUM_CLASSES}')\n",
    "print()\n",
    "\n",
    "# 클래스별 샘플 수 확인\n",
    "print('클래스별 학습 샘플 수:')\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    count = np.sum(y_train == i)\n",
    "    print(f'  {i}: {name:<8} → {count:,}개')\n",
    "\n",
    "# 샘플 이미지 시각화\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    # 각 클래스에서 대표 이미지 선택\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    ax.imshow(x_train[idx])\n",
    "    ax.set_title(f'{i}: {CLASS_NAMES[i]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('CIFAR-10 클래스별 샘플 이미지', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 구성\n",
    "# 구조: Conv→BN→MaxPool → Conv→BN→MaxPool → Flatten → Dense → Dropout → Dense(출력)\n",
    "\n",
    "def build_cnn_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    \"\"\"\n",
    "    CIFAR-10용 CNN 모델 구성\n",
    "    \n",
    "    아키텍처:\n",
    "      - 합성곱 블록 1: Conv2D(32) → BatchNorm → ReLU → MaxPool\n",
    "      - 합성곱 블록 2: Conv2D(64) → BatchNorm → ReLU → MaxPool\n",
    "      - 합성곱 블록 3: Conv2D(128) → BatchNorm → ReLU → MaxPool\n",
    "      - 분류 헤드:    Flatten → Dense(128) → Dropout(0.5) → Dense(10, softmax)\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        # ====== 합성곱 블록 1 ======\n",
    "        # padding='same': 출력 크기 유지 (32x32 → 32x32)\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), padding='same', use_bias=False,\n",
    "            input_shape=input_shape, name='conv1'\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(name='bn1'),   # 배치 정규화: 학습 안정화\n",
    "        tf.keras.layers.Activation('relu', name='relu1'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name='pool1'),  # 32x32 → 16x16\n",
    "        \n",
    "        # ====== 합성곱 블록 2 ======\n",
    "        tf.keras.layers.Conv2D(\n",
    "            64, (3, 3), padding='same', use_bias=False, name='conv2'\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(name='bn2'),\n",
    "        tf.keras.layers.Activation('relu', name='relu2'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name='pool2'),  # 16x16 → 8x8\n",
    "        \n",
    "        # ====== 합성곱 블록 3 ======\n",
    "        tf.keras.layers.Conv2D(\n",
    "            128, (3, 3), padding='same', use_bias=False, name='conv3'\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(name='bn3'),\n",
    "        tf.keras.layers.Activation('relu', name='relu3'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), name='pool3'),  # 8x8 → 4x4\n",
    "        \n",
    "        # ====== 분류 헤드 ======\n",
    "        tf.keras.layers.Flatten(name='flatten'),              # (4, 4, 128) → (2048,)\n",
    "        tf.keras.layers.Dense(128, activation='relu', name='dense1'),\n",
    "        tf.keras.layers.Dropout(0.5, name='dropout'),         # 과적합 방지\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', name='output')\n",
    "    ], name='CIFAR10_CNN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# 모델 생성 및 구조 출력\n",
    "model = build_cnn_model(input_shape=(32, 32, 3), num_classes=NUM_CLASSES)\n",
    "model.summary()\n",
    "\n",
    "print(f'\\n총 파라미터: {model.count_params():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 및 학습\n",
    "\n",
    "# 모델 저장 디렉토리 생성\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 콜백 정의\n",
    "callbacks = [\n",
    "    # EarlyStopping: 검증 손실이 개선되지 않으면 조기 종료\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,               # 5 에폭 연속 개선 없으면 종료\n",
    "        restore_best_weights=True, # 최적 가중치로 복원\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # ModelCheckpoint: 최고 성능 모델 자동 저장\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='checkpoints/cifar10_best.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,       # 최고 성능일 때만 저장\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # ReduceLROnPlateau: 성능 정체 시 학습률 감소\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,                # 학습률 절반으로 감소\n",
    "        patience=3,                # 3 에폭 개선 없으면 적용\n",
    "        min_lr=1e-6,               # 최소 학습률\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print('모델 컴파일 완료')\n",
    "print(f'학습률: {model.optimizer.learning_rate.numpy():.0e}')\n",
    "print(f'콜백: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau')\n",
    "print()\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,   # 학습 데이터의 10%를 검증용으로 사용\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f'\\n학습 완료 (총 {len(history.history[\"loss\"])} 에폭)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 시각화\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "epochs_ran = len(history.history['loss'])\n",
    "epoch_range = range(1, epochs_ran + 1)\n",
    "\n",
    "# 1. 손실 곡선\n",
    "axes[0].plot(epoch_range, history.history['loss'],\n",
    "             'b-o', markersize=4, label='학습 손실')\n",
    "axes[0].plot(epoch_range, history.history['val_loss'],\n",
    "             'r-o', markersize=4, label='검증 손실')\n",
    "axes[0].set_xlabel('에폭')\n",
    "axes[0].set_ylabel('손실 (Cross-Entropy)')\n",
    "axes[0].set_title('학습/검증 손실 곡선')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 정확도 곡선\n",
    "axes[1].plot(epoch_range, history.history['accuracy'],\n",
    "             'b-o', markersize=4, label='학습 정확도')\n",
    "axes[1].plot(epoch_range, history.history['val_accuracy'],\n",
    "             'r-o', markersize=4, label='검증 정확도')\n",
    "axes[1].set_xlabel('에폭')\n",
    "axes[1].set_ylabel('정확도')\n",
    "axes[1].set_title('학습/검증 정확도 곡선')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. 학습률 변화 (ReduceLROnPlateau 효과 확인)\n",
    "if 'lr' in history.history:\n",
    "    axes[2].semilogy(epoch_range, history.history['lr'],\n",
    "                     'g-o', markersize=4)\n",
    "    axes[2].set_xlabel('에폭')\n",
    "    axes[2].set_ylabel('학습률 (로그 스케일)')\n",
    "    axes[2].set_title('학습률 변화 (ReduceLROnPlateau)')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[2].text(0.5, 0.5, '학습률 기록 없음\\n(콜백 미사용)',\n",
    "                  ha='center', va='center', transform=axes[2].transAxes)\n",
    "\n",
    "# 최종 성능 주석\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc   = history.history['val_accuracy'][-1]\n",
    "best_val_acc    = max(history.history['val_accuracy'])\n",
    "\n",
    "plt.suptitle(\n",
    "    f'CIFAR-10 CNN 학습 곡선\\n'\n",
    "    f'최종 학습 정확도: {final_train_acc:.4f} | '\n",
    "    f'최종 검증 정확도: {final_val_acc:.4f} | '\n",
    "    f'최고 검증 정확도: {best_val_acc:.4f}',\n",
    "    fontsize=12\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트 평가 및 혼동 행렬 시각화\n",
    "\n",
    "# 테스트 세트 최종 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'테스트 손실: {test_loss:.4f}')\n",
    "print(f'테스트 정확도: {test_acc:.4f} ({test_acc*100:.2f}%)')\n",
    "print()\n",
    "\n",
    "# 예측값 계산\n",
    "y_pred_proba = model.predict(x_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# 분류 리포트\n",
    "print('분류 보고서:')\n",
    "print(classification_report(\n",
    "    y_test, y_pred,\n",
    "    target_names=CLASS_NAMES,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 절대값 혼동 행렬\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=CLASS_NAMES,\n",
    "    yticklabels=CLASS_NAMES,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_xlabel('예측 레이블')\n",
    "axes[0].set_ylabel('실제 레이블')\n",
    "axes[0].set_title('혼동 행렬 (절대값)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 정규화 혼동 행렬 (재현율 관점)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "sns.heatmap(\n",
    "    cm_normalized, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "    xticklabels=CLASS_NAMES,\n",
    "    yticklabels=CLASS_NAMES,\n",
    "    vmin=0, vmax=1,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_xlabel('예측 레이블')\n",
    "axes[1].set_ylabel('실제 레이블')\n",
    "axes[1].set_title('혼동 행렬 (행별 정규화 = 재현율)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle(f'CIFAR-10 분류 결과 (테스트 정확도: {test_acc:.4f})', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 클래스별 정확도 분석\n",
    "print('\\n클래스별 정확도:')\n",
    "class_acc = cm_normalized.diagonal()\n",
    "for name, acc in sorted(zip(CLASS_NAMES, class_acc), key=lambda x: x[1], reverse=True):\n",
    "    bar = '█' * int(acc * 20) + '░' * (20 - int(acc * 20))\n",
    "    print(f'  {name:<8} {bar} {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오분류 샘플 분석: 어떤 이미지를 잘못 분류했는지 확인\n",
    "\n",
    "# 오분류된 인덱스 찾기\n",
    "wrong_idx = np.where(y_pred != y_test)[0]\n",
    "print(f'오분류된 샘플 수: {len(wrong_idx)} / {len(y_test)} '\n",
    "      f'({len(wrong_idx)/len(y_test)*100:.1f}%)')\n",
    "\n",
    "# 오분류 샘플 시각화 (15개)\n",
    "n_show = min(15, len(wrong_idx))\n",
    "selected = np.random.choice(wrong_idx, n_show, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(16, 10))\n",
    "for ax, idx in zip(axes.flatten(), selected):\n",
    "    ax.imshow(x_test[idx])\n",
    "    true_label = CLASS_NAMES[y_test[idx]]\n",
    "    pred_label = CLASS_NAMES[y_pred[idx]]\n",
    "    confidence = y_pred_proba[idx, y_pred[idx]]\n",
    "    \n",
    "    ax.set_title(\n",
    "        f'실제: {true_label}\\n예측: {pred_label} ({confidence:.2f})',\n",
    "        fontsize=9,\n",
    "        color='red'\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('오분류 샘플 분석 (빨간 글씨: 오분류)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도전 과제\n",
    "\n",
    "### 과제 1: 배치 정규화 제거 후 성능 비교\n",
    "```python\n",
    "# BatchNormalization 레이어를 제거한 모델 구현\n",
    "def build_cnn_no_bn(input_shape=(32, 32, 3), num_classes=10):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "                               input_shape=input_shape),\n",
    "        # BatchNormalization 없이 MaxPooling으로 바로 이동\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        # ... 동일한 구조로 계속\n",
    "    ])\n",
    "    return model\n",
    "```\n",
    "- BN 유/무의 학습 속도, 최종 정확도, 수렴 안정성을 비교하라\n",
    "\n",
    "### 과제 2: Dropout 비율 변경\n",
    "- `Dropout(0.0)`, `Dropout(0.3)`, `Dropout(0.5)`, `Dropout(0.7)` 비교\n",
    "- 학습/검증 정확도 차이를 통해 과적합 정도를 분석하라\n",
    "\n",
    "### 과제 3: 데이터 증강 추가\n",
    "```python\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "```\n",
    "- 데이터 증강 유/무의 성능 차이를 비교하라\n",
    "\n",
    "### 과제 4: Conv2D 채널 수 실험\n",
    "- `[32, 64, 128]` vs `[64, 128, 256]` vs `[16, 32, 64]`\n",
    "- 파라미터 수와 성능의 트레이드오프를 분석하라"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
