{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05 실습 2: 전이학습 — Flowers 분류\n",
    "\n",
    "## 목표\n",
    "EfficientNetV2B0 전이학습으로 꽃 이미지 5종을 분류한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 재현성 시드\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f'TensorFlow 버전: {tf.__version__}')\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "IMG_SIZE   = 224         # EfficientNetV2B0 입력 크기 (기본 224, 하지만 V2는 260도 권장)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 5          # 꽃 5종 (daisy, dandelion, roses, sunflowers, tulips)\n",
    "AUTOTUNE   = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flowers 데이터셋 다운로드 및 로드\n",
    "\n",
    "# tf.keras.utils.get_file로 TensorFlow 공식 flowers 데이터셋 다운로드\n",
    "dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
    "\n",
    "data_dir = tf.keras.utils.get_file(\n",
    "    fname='flower_photos',           # 저장될 파일/폴더명\n",
    "    origin=dataset_url,\n",
    "    untar=True,                      # tgz 파일 자동 압축 해제\n",
    "    cache_subdir='datasets/flowers'  # ~/.keras/datasets/flowers/ 에 저장\n",
    ")\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# 데이터셋 구조 확인\n",
    "print(f'데이터 디렉토리: {data_dir}')\n",
    "print(f'\\n폴더 구조:')\n",
    "total_images = 0\n",
    "class_names = sorted([item.name for item in data_dir.glob('*') if item.is_dir()])\n",
    "print(f'클래스 목록: {class_names}')\n",
    "print()\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = data_dir / class_name\n",
    "    n_images = len(list(class_dir.glob('*.jpg')))\n",
    "    total_images += n_images\n",
    "    print(f'  {class_name:<15}: {n_images:>5}개 이미지')\n",
    "\n",
    "print(f'\\n전체 이미지 수: {total_images:,}개')\n",
    "\n",
    "# 클래스 이름 한국어 매핑\n",
    "CLASS_KO = {\n",
    "    'daisy':      '데이지',\n",
    "    'dandelion':  '민들레',\n",
    "    'roses':      '장미',\n",
    "    'sunflowers': '해바라기',\n",
    "    'tulips':     '튤립'\n",
    "}\n",
    "\n",
    "# image_dataset_from_directory로 데이터셋 생성\n",
    "# 80% 학습, 20% 검증으로 분할\n",
    "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=42,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),  # 자동 리사이즈\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int'                  # 정수 레이블\n",
    ")\n",
    "\n",
    "val_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=42,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "# 클래스 이름 확인\n",
    "class_names = train_ds_raw.class_names\n",
    "print(f'\\n데이터셋 클래스 순서: {class_names}')\n",
    "print(f'학습 배치 수: {len(train_ds_raw)}')\n",
    "print(f'검증 배치 수: {len(val_ds_raw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 파이프라인 구성: 정규화 + 데이터 증강 + prefetch\n",
    "\n",
    "# ===== 데이터 증강 레이어 정의 =====\n",
    "# 학습 시에만 적용, 검증 시에는 사용 안 함\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    # 좌우 뒤집기 (꽃은 좌우 대칭)\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    \n",
    "    # 최대 10% 회전\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    \n",
    "    # 최대 10% 줌\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    \n",
    "    # 밝기 변화 (±20%)\n",
    "    tf.keras.layers.RandomBrightness(0.2),\n",
    "], name='data_augmentation')\n",
    "\n",
    "\n",
    "def preprocess_train(images, labels):\n",
    "    \"\"\"\n",
    "    학습용 전처리: 증강 + 정규화\n",
    "    EfficientNetV2B0은 [0,255] 입력을 내부적으로 전처리하므로 (rescaling preprocessing 내장)\n",
    "    별도 정규화 없이 그대로 전달 (내장 전처리 사용)\n",
    "    \"\"\"\n",
    "    # 데이터 증강 적용 (학습 시에만)\n",
    "    images = data_augmentation(images, training=True)\n",
    "    # float32로 변환 (uint8 → float32)\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def preprocess_val(images, labels):\n",
    "    \"\"\"\n",
    "    검증용 전처리: 정규화만 (증강 없음)\n",
    "    \"\"\"\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# 최종 학습/검증 데이터셋 파이프라인\n",
    "train_ds = (\n",
    "    train_ds_raw\n",
    "    .map(preprocess_train, num_parallel_calls=AUTOTUNE)  # 병렬 전처리\n",
    "    .shuffle(buffer_size=1000)                            # 무작위 셔플\n",
    "    .prefetch(AUTOTUNE)                                   # 미리 불러오기 (GPU 병목 방지)\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    val_ds_raw\n",
    "    .map(preprocess_val, num_parallel_calls=AUTOTUNE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "print('데이터 파이프라인 구성 완료')\n",
    "print(f'학습 파이프라인: map(증강+변환) → shuffle → prefetch')\n",
    "print(f'검증 파이프라인: map(변환) → prefetch')\n",
    "print()\n",
    "\n",
    "# 증강된 이미지 샘플 시각화\n",
    "sample_batch_images, sample_batch_labels = next(iter(train_ds_raw))\n",
    "sample_image = sample_batch_images[0:1]  # 첫 번째 이미지만\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "# 원본 이미지 5개\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(sample_batch_images[i].numpy().astype(np.uint8))\n",
    "    class_name = class_names[sample_batch_labels[i].numpy()]\n",
    "    axes[0, i].set_title(f'원본: {CLASS_KO.get(class_name, class_name)}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# 동일 이미지에 증강 5번 적용\n",
    "first_image = sample_batch_images[0:1]\n",
    "first_label = sample_batch_labels[0]\n",
    "for i in range(5):\n",
    "    aug_img = data_augmentation(first_image, training=True)\n",
    "    axes[1, i].imshow(aug_img[0].numpy().astype(np.uint8))\n",
    "    axes[1, i].set_title(f'증강 #{i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('데이터 증강 효과 (아래 행: 동일 이미지에 증강 반복 적용)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction 단계: EfficientNetV2B0 + 새 분류 헤드\n",
    "\n",
    "# EfficientNetV2B0 기본 모델 로드 (ImageNet 사전 학습)\n",
    "base_model = tf.keras.applications.EfficientNetV2B0(\n",
    "    include_top=False,                          # 분류 헤드 제거\n",
    "    weights='imagenet',                          # ImageNet 가중치\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")\n",
    "\n",
    "# 기본 모델 완전 동결 (Feature Extraction 단계)\n",
    "base_model.trainable = False\n",
    "\n",
    "# ===== 모델 구성 =====\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input_image')\n",
    "\n",
    "# 기본 모델 통과 (BN은 추론 모드로 실행)\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# GlobalAveragePooling: (7, 7, 1280) → (1280,)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "\n",
    "# 중간 Dense 레이어 (새로 학습할 레이어)\n",
    "x = tf.keras.layers.Dense(256, activation='relu', name='dense_head')(x)\n",
    "\n",
    "# Dropout으로 과적합 방지\n",
    "x = tf.keras.layers.Dropout(0.4, name='dropout')(x)\n",
    "\n",
    "# 최종 분류: 5개 꽃 클래스\n",
    "outputs = tf.keras.layers.Dense(\n",
    "    NUM_CLASSES, activation='softmax', name='flower_classifier'\n",
    ")(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = tf.keras.Model(inputs, outputs, name='Flowers_EfficientNetV2B0')\n",
    "\n",
    "# 파라미터 통계\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "print(f'전체 파라미터:    {total_params:>10,}')\n",
    "print(f'학습 가능 파라미터: {trainable_params:>10,}  (새 헤드만)')\n",
    "print(f'동결된 파라미터:   {total_params-trainable_params:>10,}  (EfficientNetV2B0 본체)')\n",
    "print(f'학습 효율:         {trainable_params/total_params*100:.2f}%')\n",
    "print()\n",
    "\n",
    "# Feature Extraction 컴파일\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Feature Extraction 학습\n",
    "print('===== Feature Extraction 단계 학습 시작 =====')\n",
    "history_fe = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy', patience=3,\n",
    "            restore_best_weights=True, verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "fe_val_acc = max(history_fe.history['val_accuracy'])\n",
    "print(f'\\nFeature Extraction 최고 검증 정확도: {fe_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tuning 단계: 상위 20개 레이어 해동\n",
    "\n",
    "print(f'EfficientNetV2B0 전체 레이어 수: {len(base_model.layers)}')\n",
    "print()\n",
    "\n",
    "# 기본 모델 해동\n",
    "base_model.trainable = True\n",
    "\n",
    "# 상위 20개 레이어만 학습 가능하게 설정\n",
    "FINE_TUNE_FROM = len(base_model.layers) - 20\n",
    "\n",
    "for layer in base_model.layers[:FINE_TUNE_FROM]:\n",
    "    layer.trainable = False  # 하위 레이어 동결 유지\n",
    "\n",
    "# 해동된 레이어 목록 출력\n",
    "unfrozen_layers = [l.name for l in base_model.layers[FINE_TUNE_FROM:]]\n",
    "print(f'해동된 레이어 ({len(unfrozen_layers)}개):')\n",
    "for name in unfrozen_layers[-5:]:  # 마지막 5개만 표시\n",
    "    print(f'  ... {name}')\n",
    "print(f'  (이하 {len(unfrozen_layers)-5}개 레이어 포함)')\n",
    "print()\n",
    "\n",
    "# 파라미터 변화 확인\n",
    "trainable_params_ft = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
    "print(f'Fine-Tuning 학습 가능 파라미터: {trainable_params_ft:,}')\n",
    "print(f'  (Feature Extraction 대비 {trainable_params_ft/trainable_params:.1f}배)')\n",
    "print()\n",
    "\n",
    "# Fine-Tuning 컴파일 (중요: 학습률 10배 낮춤)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # 1e-3 → 1e-4\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-Tuning 학습 (Feature Extraction 이후 계속 학습)\n",
    "fe_epochs = len(history_fe.history['loss'])\n",
    "\n",
    "print('===== Fine-Tuning 단계 학습 시작 =====')\n",
    "history_ft = model.fit(\n",
    "    train_ds,\n",
    "    epochs=fe_epochs + 10,\n",
    "    initial_epoch=fe_epochs,       # Feature Extraction 에폭 이후부터\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy', patience=4,\n",
    "            restore_best_weights=True, verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', factor=0.5,\n",
    "            patience=2, min_lr=1e-7, verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ft_val_acc = max(history_ft.history['val_accuracy'])\n",
    "print(f'\\nFine-Tuning 최고 검증 정확도: {ft_val_acc:.4f}')\n",
    "print(f'정확도 향상: {fe_val_acc:.4f} → {ft_val_acc:.4f} '\n",
    "      f'(+{(ft_val_acc - fe_val_acc)*100:.2f}%p)')\n",
    "\n",
    "# 전체 학습 곡선 시각화\n",
    "acc_all     = history_fe.history['accuracy']     + history_ft.history['accuracy']\n",
    "val_acc_all = history_fe.history['val_accuracy'] + history_ft.history['val_accuracy']\n",
    "loss_all    = history_fe.history['loss']         + history_ft.history['loss']\n",
    "val_loss_all= history_fe.history['val_loss']     + history_ft.history['val_loss']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, train_vals, val_vals, ylabel, title in [\n",
    "    (ax1, acc_all, val_acc_all, '정확도', '학습/검증 정확도'),\n",
    "    (ax2, loss_all, val_loss_all, '손실', '학습/검증 손실')\n",
    "]:\n",
    "    ax.plot(train_vals, 'b-o', markersize=3, label='학습')\n",
    "    ax.plot(val_vals,   'r-o', markersize=3, label='검증')\n",
    "    ax.axvline(x=fe_epochs - 0.5, color='green', linestyle='--',\n",
    "               label=f'Fine-Tuning 시작 (에폭 {fe_epochs})')\n",
    "    ax.fill_betweenx([min(min(train_vals), min(val_vals)),\n",
    "                       max(max(train_vals), max(val_vals))],\n",
    "                      0, fe_epochs - 0.5, alpha=0.08, color='blue',\n",
    "                      label='Feature Extraction')\n",
    "    ax.fill_betweenx([min(min(train_vals), min(val_vals)),\n",
    "                       max(max(train_vals), max(val_vals))],\n",
    "                      fe_epochs - 0.5, len(acc_all), alpha=0.08, color='green',\n",
    "                      label='Fine-Tuning')\n",
    "    ax.set_xlabel('에폭')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Flowers 분류 전이학습 학습 곡선', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 시각화: 샘플 이미지 + 예측 레이블 + 신뢰도 막대 그래프\n",
    "\n",
    "# 검증 데이터에서 샘플 배치 가져오기\n",
    "val_images_batch, val_labels_batch = next(iter(val_ds_raw))\n",
    "\n",
    "# 예측 수행\n",
    "val_images_float = tf.cast(val_images_batch, tf.float32)\n",
    "predictions = model.predict(val_images_float, verbose=0)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "true_labels = val_labels_batch.numpy()\n",
    "\n",
    "# 시각화 (10개 샘플)\n",
    "n_show = min(10, BATCH_SIZE)\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "for idx in range(n_show):\n",
    "    # 이미지 서브플롯\n",
    "    ax_img = fig.add_subplot(2, n_show, idx + 1)\n",
    "    ax_img.imshow(val_images_batch[idx].numpy().astype(np.uint8))\n",
    "    \n",
    "    true_cls  = class_names[true_labels[idx]]\n",
    "    pred_cls  = class_names[pred_labels[idx]]\n",
    "    true_ko   = CLASS_KO.get(true_cls, true_cls)\n",
    "    pred_ko   = CLASS_KO.get(pred_cls, pred_cls)\n",
    "    confidence = predictions[idx, pred_labels[idx]]\n",
    "    \n",
    "    # 정답이면 파란색, 오답이면 빨간색\n",
    "    color = 'blue' if true_labels[idx] == pred_labels[idx] else 'red'\n",
    "    ax_img.set_title(\n",
    "        f'실제: {true_ko}\\n예측: {pred_ko}\\n신뢰도: {confidence:.2f}',\n",
    "        fontsize=8, color=color\n",
    "    )\n",
    "    ax_img.axis('off')\n",
    "    \n",
    "    # 확률 분포 막대 그래프\n",
    "    ax_bar = fig.add_subplot(2, n_show, n_show + idx + 1)\n",
    "    bars = ax_bar.bar(\n",
    "        range(NUM_CLASSES), predictions[idx],\n",
    "        color=['#FF6B6B' if i == pred_labels[idx] else\n",
    "               '#45B7D1' if i == true_labels[idx] else '#D3D3D3'\n",
    "               for i in range(NUM_CLASSES)]\n",
    "    )\n",
    "    ax_bar.set_xticks(range(NUM_CLASSES))\n",
    "    ax_bar.set_xticklabels(\n",
    "        [CLASS_KO.get(cn, cn)[:3] for cn in class_names],\n",
    "        fontsize=7, rotation=45\n",
    "    )\n",
    "    ax_bar.set_ylim([0, 1])\n",
    "    ax_bar.set_ylabel('확률', fontsize=7)\n",
    "    ax_bar.tick_params(axis='y', labelsize=7)\n",
    "\n",
    "plt.suptitle(\n",
    "    '예측 시각화 (파란 제목=정답, 빨간 제목=오답 / 막대: 빨강=예측, 하늘=정답)',\n",
    "    fontsize=11\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 전체 검증 세트 정확도 계산\n",
    "all_true, all_pred = [], []\n",
    "for batch_images, batch_labels in val_ds_raw:\n",
    "    batch_float = tf.cast(batch_images, tf.float32)\n",
    "    batch_preds = model.predict(batch_float, verbose=0)\n",
    "    all_true.extend(batch_labels.numpy())\n",
    "    all_pred.extend(np.argmax(batch_preds, axis=1))\n",
    "\n",
    "all_true = np.array(all_true)\n",
    "all_pred = np.array(all_pred)\n",
    "final_acc = np.mean(all_true == all_pred)\n",
    "\n",
    "print(f'\\n전체 검증 세트 정확도: {final_acc:.4f} ({final_acc*100:.2f}%)')\n",
    "\n",
    "# 클래스별 정확도\n",
    "print('\\n클래스별 정확도:')\n",
    "for i, cname in enumerate(class_names):\n",
    "    mask = all_true == i\n",
    "    cls_acc = np.mean(all_pred[mask] == all_true[mask])\n",
    "    bar = '█' * int(cls_acc * 20) + '░' * (20 - int(cls_acc * 20))\n",
    "    ko_name = CLASS_KO.get(cname, cname)\n",
    "    print(f'  {ko_name:<6} {bar} {cls_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 분석 및 도전 과제\n",
    "\n",
    "### 결과 분석\n",
    "\n",
    "EfficientNetV2B0 전이학습을 통해 상대적으로 적은 데이터(약 3,670장)로도 높은 정확도를 달성할 수 있다.\n",
    "\n",
    "| 단계 | 검증 정확도 | 학습 가능 파라미터 |\n",
    "|------|-----------|------------------|\n",
    "| Feature Extraction | ~85-88% | ~330K (헤드만) |\n",
    "| Fine-Tuning (상위 20층) | ~90-93% | ~1.2M |\n",
    "\n",
    "Fine-Tuning을 통해 Feature Extraction 대비 약 3~5%p 성능이 향상된다.\n",
    "\n",
    "### 혼동 패턴 분석\n",
    "- **민들레 ↔ 해바라기**: 노란색 꽃이라는 공통점으로 혼동 발생 가능\n",
    "- **장미 ↔ 튤립**: 붉은색 계열로 혼동 가능\n",
    "\n",
    "### 도전 과제\n",
    "\n",
    "**과제 1: 다른 기본 모델과 비교**\n",
    "```python\n",
    "# EfficientNetB3, MobileNetV2, ResNet50 비교\n",
    "models_to_try = [\n",
    "    tf.keras.applications.EfficientNetB3,\n",
    "    tf.keras.applications.MobileNetV2,\n",
    "    tf.keras.applications.ResNet50\n",
    "]\n",
    "```\n",
    "\n",
    "**과제 2: 데이터 증강 강도 실험**\n",
    "- 증강 없음 vs 현재 vs 강한 증강 (`RandomContrast`, `RandomTranslation` 추가)\n",
    "- 각 설정의 학습/검증 정확도 차이 분석\n",
    "\n",
    "**과제 3: Fine-Tuning 해동 레이어 수 최적화**\n",
    "```python\n",
    "# 10개, 20개, 30개, 50개 레이어 해동 비교\n",
    "for n_unfreeze in [10, 20, 30, 50]:\n",
    "    # 각 설정으로 Fine-Tuning 후 성능 측정\n",
    "    pass\n",
    "```\n",
    "\n",
    "**과제 4: 학습률 탐색 (LR Range Test)**\n",
    "- 1e-6부터 1e-1까지 로그 스케일로 학습률을 변화시키며 손실 변화 관찰\n",
    "- 손실이 가장 빠르게 감소하는 학습률 구간 찾기\n",
    "\n",
    "**과제 5: 앙상블 (Ensemble)**\n",
    "- Feature Extraction 모델과 Fine-Tuning 모델의 예측 평균\n",
    "- 단일 모델 대비 성능 향상 여부 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}