{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 05-02: CNN 아키텍처 — LeNet부터 EfficientNet까지\n",
    "\n",
    "## 학습 목표\n",
    "- 주요 CNN 아키텍처의 역사적 발전 흐름을 이해한다\n",
    "- LeNet-5, VGG 블록 패턴을 직접 구현할 수 있다\n",
    "- ResNet의 잔차 연결(Skip Connection) 원리를 이해하고 구현한다\n",
    "- `tf.keras.applications`로 사전 학습 모델을 불러와 활용할 수 있다\n",
    "\n",
    "## 목차\n",
    "1. [주요 CNN 아키텍처 역사](#1)\n",
    "2. [LeNet-5 구현](#2)\n",
    "3. [VGG 블록 패턴](#3)\n",
    "4. [ResNet 잔차 블록](#4)\n",
    "5. [사전 학습 모델 (tf.keras.applications)](#5)\n",
    "6. [정리](#6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 재현성 시드 설정\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f'TensorFlow 버전: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 주요 CNN 아키텍처 역사 <a id='1'></a>\n",
    "\n",
    "CNN 아키텍처는 지난 30여 년간 급격한 발전을 이루었다.\n",
    "\n",
    "| 연도 | 모델 | 주요 특징 | ImageNet Top-5 오류율 |\n",
    "|------|------|-----------|----------------------|\n",
    "| 1998 | **LeNet-5** | 최초의 실용적 CNN, 손글씨 인식 | - |\n",
    "| 2012 | **AlexNet** | GPU 학습, ReLU, Dropout 적용 | 15.3% |\n",
    "| 2014 | **VGGNet** | 3×3 Conv 반복, 깊이 강조 | 7.3% |\n",
    "| 2015 | **ResNet** | 잔차 연결(Skip Connection), 152층 | 3.6% |\n",
    "| 2017 | **MobileNet** | Depthwise Separable Conv, 경량화 | - |\n",
    "| 2019 | **EfficientNet** | 복합 스케일링(Compound Scaling) | 2.9% |\n",
    "\n",
    "### 핵심 발전 방향\n",
    "- **더 깊게**: LeNet(5층) → ResNet(152층)\n",
    "- **더 효율적으로**: VGG → MobileNet → EfficientNet\n",
    "- **경사 소실 해결**: ResNet의 Skip Connection이 핵심 돌파구\n",
    "\n",
    "### 아키텍처 발전 타임라인\n",
    "```\n",
    "1998       2012        2014      2015      2017        2019\n",
    "LeNet-5 → AlexNet → VGGNet → ResNet → MobileNet → EfficientNet\n",
    "  5층      8층        19층      152층      28층          ---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LeNet-5 구현 <a id='2'></a>\n",
    "\n",
    "LeNet-5 (LeCun et al., 1998)는 우편번호 인식을 위해 설계된 최초의 실용적 CNN이다.\n",
    "\n",
    "구조:\n",
    "```\n",
    "입력(32×32) → Conv(6) → AvgPool → Conv(16) → AvgPool → Flatten → FC(120) → FC(84) → FC(10)\n",
    "```\n",
    "\n",
    "원본은 Tanh 활성화를 사용했으나, 현대적 버전에서는 ReLU를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 구현 (현대적 버전: ReLU 활성화)\n",
    "def build_lenet5(input_shape=(32, 32, 1), num_classes=10):\n",
    "    \"\"\"\n",
    "    LeNet-5 아키텍처 구현\n",
    "    \n",
    "    Args:\n",
    "        input_shape: 입력 이미지 형태 (H, W, C)\n",
    "        num_classes: 분류 클래스 수\n",
    "    \n",
    "    Returns:\n",
    "        tf.keras.Sequential 모델\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        # C1: 첫 번째 합성곱 레이어 (5x5 커널, 6 필터)\n",
    "        tf.keras.layers.Conv2D(6, kernel_size=5, activation='relu',\n",
    "                               input_shape=input_shape, name='C1_conv'),\n",
    "        \n",
    "        # S2: 평균 풀링 (원본 LeNet은 AvgPooling 사용)\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=2, strides=2, name='S2_pool'),\n",
    "        \n",
    "        # C3: 두 번째 합성곱 레이어 (5x5 커널, 16 필터)\n",
    "        tf.keras.layers.Conv2D(16, kernel_size=5, activation='relu', name='C3_conv'),\n",
    "        \n",
    "        # S4: 평균 풀링\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=2, strides=2, name='S4_pool'),\n",
    "        \n",
    "        # C5: 세 번째 합성곱 (1x1 출력 → Fully Connected와 동일)\n",
    "        tf.keras.layers.Conv2D(120, kernel_size=5, activation='relu', name='C5_conv'),\n",
    "        \n",
    "        # 평탄화\n",
    "        tf.keras.layers.Flatten(name='flatten'),\n",
    "        \n",
    "        # F6: 완전 연결층\n",
    "        tf.keras.layers.Dense(84, activation='relu', name='F6_dense'),\n",
    "        \n",
    "        # 출력층\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', name='output')\n",
    "    ], name='LeNet-5')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# LeNet-5 모델 생성 및 구조 출력\n",
    "lenet = build_lenet5(input_shape=(32, 32, 1), num_classes=10)\n",
    "lenet.summary()\n",
    "\n",
    "# MNIST 데이터로 빠른 테스트\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 28x28 → 32x32 리사이즈 (LeNet-5 입력 크기)\n",
    "x_train_resized = tf.image.resize(x_train[..., np.newaxis], [32, 32]) / 255.0\n",
    "x_test_resized  = tf.image.resize(x_test[..., np.newaxis],  [32, 32]) / 255.0\n",
    "\n",
    "lenet.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 빠른 학습 (3 에폭만)\n",
    "history_lenet = lenet.fit(\n",
    "    x_train_resized, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=256,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss, test_acc = lenet.evaluate(x_test_resized, y_test, verbose=0)\n",
    "print(f'\\nLeNet-5 테스트 정확도: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. VGG 블록 패턴 <a id='3'></a>\n",
    "\n",
    "VGGNet (Simonyan & Zisserman, 2014)의 핵심 아이디어:\n",
    "- **3×3 Conv만 사용**: 작은 커널을 여러 번 쌓으면 큰 수용 영역(Receptive Field)을 얻을 수 있다\n",
    "  - 3×3 Conv 2개 = 5×5 Conv 1개와 동일한 수용 영역, 하지만 파라미터 수는 더 적다\n",
    "  - $2 \\times (3^2 \\times C^2) = 18C^2$ vs $5^2 \\times C^2 = 25C^2$\n",
    "- **일정한 VGG 블록**: Conv → Conv → MaxPool 패턴 반복\n",
    "- **채널 수 점진적 증가**: 64 → 128 → 256 → 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, num_filters):\n",
    "    \"\"\"\n",
    "    VGG 블록 생성 함수\n",
    "    \n",
    "    Args:\n",
    "        num_convs: 블록 내 합성곱 레이어 수\n",
    "        num_filters: 필터 수 (출력 채널 수)\n",
    "    \n",
    "    Returns:\n",
    "        tf.keras.Sequential 블록\n",
    "    \"\"\"\n",
    "    block = tf.keras.Sequential(name=f'vgg_block_{num_filters}ch')\n",
    "    \n",
    "    # num_convs개의 3x3 Conv 레이어 반복\n",
    "    for _ in range(num_convs):\n",
    "        block.add(tf.keras.layers.Conv2D(\n",
    "            num_filters, kernel_size=3, padding='same', activation='relu'\n",
    "        ))\n",
    "    \n",
    "    # 블록 끝에 MaxPooling으로 공간 크기 절반 축소\n",
    "    block.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "    \n",
    "    return block\n",
    "\n",
    "\n",
    "def build_mini_vgg(input_shape=(32, 32, 3), num_classes=10):\n",
    "    \"\"\"\n",
    "    CIFAR-10용 미니 VGG 모델\n",
    "    (원본 VGG-16은 224x224 입력 → 32x32에 맞게 축소)\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # VGG 블록 스택 (필터 수 점진적 증가)\n",
    "    x = vgg_block(num_convs=2, num_filters=64)(inputs)   # 32→16\n",
    "    x = vgg_block(num_convs=2, num_filters=128)(x)        # 16→8\n",
    "    x = vgg_block(num_convs=2, num_filters=256)(x)        # 8→4\n",
    "    \n",
    "    # 분류 헤드\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs, name='Mini-VGG')\n",
    "\n",
    "\n",
    "# Mini-VGG 모델 생성 및 구조 확인\n",
    "mini_vgg = build_mini_vgg(input_shape=(32, 32, 3), num_classes=10)\n",
    "mini_vgg.summary()\n",
    "\n",
    "# 파라미터 수 비교\n",
    "print(f'\\nMini-VGG 총 파라미터: {mini_vgg.count_params():,}')\n",
    "print(f'LeNet-5 총 파라미터:  {lenet.count_params():,}')\n",
    "print(f'파라미터 차이: {mini_vgg.count_params() / lenet.count_params():.1f}배')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ResNet 잔차 블록 <a id='4'></a>\n",
    "\n",
    "### 경사 소실 문제 (Vanishing Gradient Problem)\n",
    "\n",
    "네트워크가 깊어질수록 역전파 시 경사가 점점 작아져 초기 레이어가 학습되지 않는 문제가 발생한다.\n",
    "\n",
    "### ResNet의 핵심 아이디어: Skip Connection\n",
    "\n",
    "He et al. (2015)는 **잔차 연결(Residual Connection)**로 이 문제를 해결했다:\n",
    "\n",
    "$h_l = F(x_l, W_l) + x_l$\n",
    "\n",
    "여기서:\n",
    "- $x_l$: 레이어 $l$의 입력\n",
    "- $F(x_l, W_l)$: Conv → BN → ReLU → Conv → BN 블록의 출력 (잔차, Residual)\n",
    "- $h_l$: 최종 출력 (잔차 + 항등 입력)\n",
    "\n",
    "이 구조는 경사를 최소 $1$로 유지하여 매우 깊은 네트워크(100층 이상)도 학습 가능하게 한다:\n",
    "\n",
    "$\\frac{\\partial h_l}{\\partial x_l} = \\frac{\\partial F}{\\partial x_l} + 1$\n",
    "\n",
    "즉, 항등(identity) 경로가 항상 경사를 보존한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1, use_projection=False):\n",
    "    \"\"\"\n",
    "    ResNet 잔차 블록 구현 (Functional API)\n",
    "    \n",
    "    구조: Conv → BN → ReLU → Conv → BN → (+ shortcut) → ReLU\n",
    "    \n",
    "    Args:\n",
    "        x: 입력 텐서\n",
    "        filters: 출력 채널 수\n",
    "        kernel_size: 합성곱 커널 크기\n",
    "        stride: 첫 번째 Conv의 스트라이드 (2이면 다운샘플링)\n",
    "        use_projection: 입출력 채널이 다를 때 shortcut에 1x1 Conv 적용 여부\n",
    "    \n",
    "    Returns:\n",
    "        잔차 블록 출력 텐서\n",
    "    \"\"\"\n",
    "    shortcut = x  # 항등 경로 저장\n",
    "    \n",
    "    # 주 경로: F(x, W)\n",
    "    # --- 첫 번째 Conv ---\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size, strides=stride, padding='same', use_bias=False\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # --- 두 번째 Conv ---\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size, strides=1, padding='same', use_bias=False\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # 차원이 맞지 않을 때 1x1 Conv로 프로젝션 (Projection Shortcut)\n",
    "    if use_projection or stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = tf.keras.layers.Conv2D(\n",
    "            filters, kernel_size=1, strides=stride, padding='same', use_bias=False\n",
    "        )(shortcut)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "    \n",
    "    # Skip Connection: F(x) + x\n",
    "    x = tf.keras.layers.Add()([x, shortcut])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def build_mini_resnet(input_shape=(32, 32, 3), num_classes=10):\n",
    "    \"\"\"CIFAR-10용 미니 ResNet 구현\"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # 초기 합성곱\n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding='same', use_bias=False)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # 잔차 블록 스택\n",
    "    x = residual_block(x, filters=64)                            # 32x32\n",
    "    x = residual_block(x, filters=64)\n",
    "    \n",
    "    x = residual_block(x, filters=128, stride=2)                 # 16x16 (다운샘플링)\n",
    "    x = residual_block(x, filters=128)\n",
    "    \n",
    "    x = residual_block(x, filters=256, stride=2)                 # 8x8 (다운샘플링)\n",
    "    x = residual_block(x, filters=256)\n",
    "    \n",
    "    # 분류 헤드\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)              # Flatten 대신 GAP 사용\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs, name='Mini-ResNet')\n",
    "\n",
    "\n",
    "# Mini-ResNet 생성 및 구조 확인\n",
    "mini_resnet = build_mini_resnet(input_shape=(32, 32, 3), num_classes=10)\n",
    "mini_resnet.summary()\n",
    "\n",
    "print(f'\\nMini-ResNet 총 파라미터: {mini_resnet.count_params():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 사전 학습 모델 (tf.keras.applications) <a id='5'></a>\n",
    "\n",
    "`tf.keras.applications`는 ImageNet으로 사전 학습된 다양한 모델을 제공한다.\n",
    "\n",
    "### 주요 모델 비교\n",
    "\n",
    "| 모델 | 파라미터 수 | Top-1 정확도 | 특징 |\n",
    "|------|------------|-------------|------|\n",
    "| ResNet50 | 25.6M | 74.9% | 잔차 연결, 균형적 성능 |\n",
    "| MobileNetV2 | 3.5M | 71.3% | 경량화, 모바일 친화적 |\n",
    "| EfficientNetB0 | 5.3M | 77.1% | 복합 스케일링 (레거시 — V2로 대체 권장) |",
    "| EfficientNetV2B0 | 7.1M | 78.7% | 개선된 정규화·훈련 효율, 권장 최신 버전 (2026-02-25 기준) |\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.applications에서 사전 학습 모델 로드\n",
    "# include_top=False: ImageNet 분류 헤드 제거 (전이학습용)\n",
    "# weights='imagenet': ImageNet 사전 학습 가중치 사용\n",
    "\n",
    "models_to_compare = [\n",
    "    {\n",
    "        'name': 'ResNet50',\n",
    "        'loader': tf.keras.applications.ResNet50,\n",
    "        'input_size': 224\n",
    "    },\n",
    "    {\n",
    "        'name': 'MobileNetV2',\n",
    "        'loader': tf.keras.applications.MobileNetV2,\n",
    "        'input_size': 224\n",
    "    },\n",
    "    {\n",
    "        'name': 'EfficientNetV2B0',\n",
    "        'loader': tf.keras.applications.EfficientNetV2B0,\n",
    "        'input_size': 224\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f'{'모델명':<20} {'총 파라미터':>15} {'학습 가능 파라미터':>20} {'입력 크기':>10}')\n",
    "print('=' * 70)\n",
    "\n",
    "loaded_models = {}\n",
    "for cfg in models_to_compare:\n",
    "    # 모델 로드 (include_top=False: 분류 헤드 제외)\n",
    "    base_model = cfg['loader'](\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(cfg['input_size'], cfg['input_size'], 3)\n",
    "    )\n",
    "    \n",
    "    total_params     = base_model.count_params()\n",
    "    trainable_params = sum([tf.size(w).numpy() for w in base_model.trainable_weights])\n",
    "    \n",
    "    print(f\"{cfg['name']:<20} {total_params:>15,} {trainable_params:>20,} \"\n",
    "          f\"{cfg['input_size']}x{cfg['input_size']:>3}\")\n",
    "    \n",
    "    loaded_models[cfg['name']] = base_model\n",
    "\n",
    "print('\\n출력 형태 확인:')\n",
    "for name, model in loaded_models.items():\n",
    "    dummy = tf.random.normal([1, 224, 224, 3])\n",
    "    out = model(dummy, training=False)\n",
    "    print(f'  {name}: 출력 형태 = {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 아키텍처 시각화: 레이어 수와 파라미터 수 비교\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "model_names = ['LeNet-5', 'Mini-VGG', 'Mini-ResNet', 'ResNet50', 'MobileNetV2', 'EfficientNetV2B0']\n",
    "param_counts = [\n",
    "    lenet.count_params(),\n",
    "    mini_vgg.count_params(),\n",
    "    mini_resnet.count_params(),\n",
    "    loaded_models['ResNet50'].count_params(),\n",
    "    loaded_models['MobileNetV2'].count_params(),\n",
    "    loaded_models['EfficientNetV2B0'].count_params()\n",
    "]\n",
    "layer_counts = [\n",
    "    len(lenet.layers),\n",
    "    len(mini_vgg.layers),\n",
    "    len(mini_resnet.layers),\n",
    "    len(loaded_models['ResNet50'].layers),\n",
    "    len(loaded_models['MobileNetV2'].layers),\n",
    "    len(loaded_models['EfficientNetV2B0'].layers)\n",
    "]\n",
    "\n",
    "colors = ['#FF6B6B', '#FFA500', '#4ECDC4', '#45B7D1', '#96CEB4', '#88D8B0']\n",
    "\n",
    "# 파라미터 수 막대 그래프\n",
    "bars1 = axes[0].bar(model_names, [p/1e6 for p in param_counts], color=colors)\n",
    "axes[0].set_xlabel('모델')\n",
    "axes[0].set_ylabel('파라미터 수 (백만)')\n",
    "axes[0].set_title('모델별 파라미터 수 비교')\n",
    "axes[0].tick_params(axis='x', rotation=30)\n",
    "for bar, count in zip(bars1, param_counts):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                 f'{count/1e6:.1f}M', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 레이어 수 막대 그래프\n",
    "bars2 = axes[1].bar(model_names, layer_counts, color=colors)\n",
    "axes[1].set_xlabel('모델')\n",
    "axes[1].set_ylabel('레이어 수')\n",
    "axes[1].set_title('모델별 레이어 수 비교')\n",
    "axes[1].tick_params(axis='x', rotation=30)\n",
    "for bar, count in zip(bars2, layer_counts):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                 str(count), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.suptitle('CNN 아키텍처 비교', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 정리 <a id='6'></a>\n",
    "\n",
    "### 아키텍처별 특징 비교 표\n",
    "\n",
    "| 항목 | LeNet-5 | VGGNet | ResNet | MobileNet | EfficientNet |\n",
    "|------|---------|--------|--------|-----------|-------------|\n",
    "| 연도 | 1998 | 2014 | 2015 | 2017 | 2019 |\n",
    "| 커널 크기 | 5×5 | 3×3 | 3×3 | Depthwise | 3×3 |\n",
    "| 핵심 아이디어 | 최초 CNN | 깊이 증가 | Skip Connection | 경량화 | 복합 스케일링 |\n",
    "| 활성화 함수 | Tanh | ReLU | ReLU | ReLU6 | Swish |\n",
    "| 정규화 | 없음 | Dropout | BatchNorm | BatchNorm | BatchNorm |\n",
    "| 모바일 적합성 | 낮음 | 낮음 | 중간 | 높음 | 높음 |\n",
    "\n",
    "### 핵심 교훈\n",
    "1. **깊이의 한계**: 단순히 층을 쌓으면 경사 소실 문제 발생 → ResNet의 Skip Connection으로 해결\n",
    "2. **효율성 추구**: 정확도뿐 아니라 파라미터 효율도 중요 → MobileNet, EfficientNet\n",
    "3. **전이학습 활용**: 처음부터 학습보다 사전 학습 모델을 활용하는 것이 현실적\n",
    "\n",
    "### 다음 챕터 예고\n",
    "**Chapter 05-03**: 사전 학습 모델을 이용한 전이학습 (Transfer Learning)을 실습한다.\n",
    "Feature Extraction과 Fine-Tuning 전략을 단계별로 구현한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}