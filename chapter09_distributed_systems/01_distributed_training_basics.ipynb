{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 09-01: ë¶„ì‚° í•™ìŠµ ê¸°ì´ˆ (Distributed Training Basics)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- ë‹¨ì¼ GPUì˜ **ë©”ëª¨ë¦¬ í•œê³„**ë¥¼ ìˆ˜ì¹˜ë¡œ ì´í•´í•˜ê³ , ë¶„ì‚° í•™ìŠµì´ í•„ìš”í•œ ì´ìœ ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤\n",
    "- **Data Parallelism(DP)**ì™€ **Distributed Data Parallel(DDP)**ì˜ êµ¬ì¡°ì™€ ì„±ëŠ¥ ì°¨ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ë¹„êµí•œë‹¤\n",
    "- **Ring All-Reduce** ì•Œê³ ë¦¬ì¦˜ì˜ í†µì‹  ë¹„ìš© ìˆ˜ì‹ $T = 2(N-1)\\frac{K}{N}$ì„ ìŠ¤ìŠ¤ë¡œ ë„ì¶œí•˜ê³ , ìˆœìˆ˜ íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•œë‹¤\n",
    "- TensorFlow `MirroredStrategy`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ ë…¸ë“œ ë¶„ì‚° í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì™„ì„±í•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: í†µì‹  ë¹„ìš©ê³¼ í™•ì¥ì„±](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [ì™œ ë¶„ì‚° í•™ìŠµì´ í•„ìš”í•œê°€? (ë©”ëª¨ë¦¬ ê³„ì‚°)](#2.-ë©”ëª¨ë¦¬-ê³„ì‚°)\n",
    "3. [DP vs DDP êµ¬ì¡° ë¹„êµ](#3.-DP-vs-DDP)\n",
    "4. [Ring All-Reduce ì•Œê³ ë¦¬ì¦˜ ì‹¬í™”](#4.-Ring-All-Reduce-ì‹¬í™”)\n",
    "5. [TF MirroredStrategy ì‹¤ì „ ì‹¤ìŠµ](#5.-MirroredStrategy-ì‹¤ìŠµ)\n",
    "6. [í†µì‹  ë¹„ìš© ì‹œê°í™” ë¹„êµ](#6.-í†µì‹ -ë¹„ìš©-ì‹œê°í™”)\n",
    "7. [ì •ë¦¬ ë° ì—°ìŠµ ë¬¸ì œ](#7.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ\n",
    "\n",
    "### í†µì‹  ë¹„ìš© (All-Reduce)\n",
    "\n",
    "Ring All-Reduceë¥¼ ì´í•´í•˜ê¸° ìœ„í•œ í•µì‹¬ ìˆ˜ì‹:\n",
    "\n",
    "$$\\boxed{T_{comm} = 2(N-1)\\frac{K}{N} \\cdot t_{byte}}$$\n",
    "\n",
    "- $N$: GPU(ë…¸ë“œ) ìˆ˜\n",
    "- $K$: ì „ì²´ ê·¸ë˜ë””ì–¸íŠ¸ í…ì„œì˜ ë°”ì´íŠ¸ í¬ê¸°\n",
    "- $t_{byte}$: ë°”ì´íŠ¸ë‹¹ ì „ì†¡ ì‹œê°„ (ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ì˜ ì—­ìˆ˜)\n",
    "\n",
    "**í•µì‹¬**: $N \\to \\infty$ì¼ ë•Œ $T_{comm} \\to 2K \\cdot t_{byte}$, ì¦‰ GPUê°€ ëŠ˜ì–´ë„ í†µì‹  ë¹„ìš©ì´ **ìƒìˆ˜**ë¡œ ìˆ˜ë ´!\n",
    "\n",
    "### í•™ìŠµ ë©”ëª¨ë¦¬ ê³µì‹ (Mixed Precision + Adam)\n",
    "\n",
    "| í•­ëª© | ë°ì´í„°íƒ€ì… | ë°”ì´íŠ¸ |\n",
    "|------|-----------|--------|\n",
    "| ëª¨ë¸ íŒŒë¼ë¯¸í„° | FP16 | $2P$ |\n",
    "| ê·¸ë˜ë””ì–¸íŠ¸ | FP16 | $2P$ |\n",
    "| ë§ˆìŠ¤í„° ê°€ì¤‘ì¹˜ | FP32 | $4P$ |\n",
    "| Adam 1ì°¨ ëª¨ë©˜íŠ¸ $m$ | FP32 | $4P$ |\n",
    "| Adam 2ì°¨ ëª¨ë©˜íŠ¸ $v$ | FP32 | $4P$ |\n",
    "| **í•©ê³„** | | $\\mathbf{16P}$ bytes |\n",
    "\n",
    "> ì˜ˆ: Llama-2 7B â†’ $16 \\times 7 \\times 10^9 \\approx 112$ GB\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ­ ë¶„ì‚° í•™ìŠµì´ ì™œ í•„ìš”í•œê°€ìš”?\n",
    "\n",
    "AI ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒì€ ë§ˆì¹˜ **ì—„ì²­ë‚˜ê²Œ í° í¼ì¦ì„ ë§ì¶”ëŠ” ê²ƒ**ê³¼ ê°™ì•„ìš”.\n",
    "\n",
    "```\n",
    "ğŸ§© í¼ì¦ ì¡°ê° ìˆ˜: 70,000,000,000ê°œ (Llama-2 70Bì˜ íŒŒë¼ë¯¸í„° ìˆ˜!)\n",
    "ğŸ—‚ï¸ ë°© í¬ê¸° (GPU): 80GB (ì•„ë¬´ë¦¬ í° ë°©ë„ ê²°êµ­ ê½‰ ì°¬ë‹¤!)\n",
    "```\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: ë°© í•˜ë‚˜ì— í¼ì¦ì´ ì•ˆ ë“¤ì–´ê°€ë©´? ì—¬ëŸ¬ ë°©ìœ¼ë¡œ ë‚˜ëˆ ì„œ ê°ì ë‹´ë‹¹ êµ¬ì—­ì„ ë§ì¶”ë©´ ë©ë‹ˆë‹¤!  \n",
    "> í•˜ì§€ë§Œ ë§ˆì§€ë§‰ì— í•©ì³ì•¼ í•˜ë¯€ë¡œ, ìš”ë¦¬ì‚¬ë“¤ë¼ë¦¬ **ë ˆì‹œí”¼(ê·¸ë˜ë””ì–¸íŠ¸)**ë¥¼ ê³µìœ í•´ì•¼ í•´ìš”.\n",
    "\n",
    "#### ğŸ”„ All-Reduceê°€ ë­”ê°€ìš”?\n",
    "\n",
    "> 4íŒ€ì´ ê°ì ë¶€ë¶„ ì ìˆ˜ë¥¼ ê³„ì‚°í•œ í›„, ëª¨ë“  íŒ€ì´ ì´ì ì„ ì•Œì•„ì•¼ í•  ë•Œ:\n",
    "> - **ë‚˜ìœ ë°©ë²•**: ë°˜ì¥(ë§ˆìŠ¤í„° GPU)ì—ê²Œ ë‹¤ ì „ë‹¬ â†’ ë°˜ì¥ì´ ë”í•¨ â†’ ë‹¤ì‹œ ë°°í¬  \n",
    ">   (ë°˜ì¥ì´ ë„ˆë¬´ ë°”ë¹ ì§!)\n",
    "> - **ì¢‹ì€ ë°©ë²•**: 1íŒ€â†’2íŒ€â†’3íŒ€â†’4íŒ€â†’1íŒ€ ìˆœì„œë¡œ ëŒì•„ê°€ë©° í•©ì‚°  \n",
    ">   (ëª¨ë“  íŒ€ì´ ì¼ì„ ë‚˜ëˆ”! = **Ring All-Reduce**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: í•„ìš” GPU ìˆ˜ ê³„ì‚°\n",
    "\n",
    "GPT-3 175B ëª¨ë¸ì„ H100 80GB GPUë¡œ í•™ìŠµí•œë‹¤. Mixed Precision + Adam ê¸°ì¤€,  \n",
    "í•„ìš”í•œ ìµœì†Œ GPU ìˆ˜ëŠ”? (ê° GPUë¥¼ 80% íš¨ìœ¨ë¡œ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •)\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "ì´ í•™ìŠµ ë©”ëª¨ë¦¬ = $16 \\times 175 \\times 10^9$ bytes $= 2800$ GB  \n",
    "GPUë‹¹ í™œìš© ë©”ëª¨ë¦¬ = $80 \\times 0.8 = 64$ GB  \n",
    "í•„ìš” GPU = $\\lceil 2800 / 64 \\rceil = \\mathbf{44}$ëŒ€\n",
    "\n",
    "(ì‹¤ì œë¡œëŠ” Activation, Temp ë©”ëª¨ë¦¬ ë“±ìœ¼ë¡œ ë” í•„ìš” â†’ ì‹¤ì œ í•™ìŠµì—” 1,024~4,096ëŒ€ ì‚¬ìš©)\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: Ring All-Reduce í†µì‹ ëŸ‰ ê³„ì‚°\n",
    "\n",
    "128ëŒ€ GPUê°€ FP32 ê·¸ë˜ë””ì–¸íŠ¸($4K$ bytes, $K = 175 \\times 10^9$)ë¥¼ All-Reduce í•  ë•Œ,  \n",
    "GPUë‹¹ ì´ í†µì‹ ëŸ‰ì„ ê³„ì‚°í•˜ë¼. (ë‹¨ìˆœ ë§ˆìŠ¤í„° ì¤‘ì‹¬ ë°©ì‹ê³¼ ë¹„êµí•  ê²ƒ)\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸° $K_{bytes} = 175 \\times 10^9 \\times 4 = 700$ GB  \n",
    "\n",
    "**Ring All-Reduce**: $2(128-1) \\times \\frac{700}{128} \\approx 2 \\times 700 = 1400$ GB (ìˆ˜ë ´ê°’)\n",
    "\n",
    "**ë§ˆìŠ¤í„° ì¤‘ì‹¬ Gather**: ë§ˆìŠ¤í„°ê°€ $127 \\times 700 = 88900$ GB ìˆ˜ì‹  â†’ **63.5ë°°** ë” ë§ìŒ!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow ë²„ì „:\", tf.__version__)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë©”ëª¨ë¦¬ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# ëª¨ë¸ í¬ê¸°ë³„ í•™ìŠµ ë©”ëª¨ë¦¬ ë° í•„ìš” GPU ìˆ˜ ê³„ì‚°\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def compute_training_memory(params_B, optimizer='adam', mixed_precision=True):\n",
    "    \"\"\"Mixed Precision + ì˜µí‹°ë§ˆì´ì € ê¸°ì¤€ í•™ìŠµ ë©”ëª¨ë¦¬ ê³„ì‚° (GB)\"\"\"\n",
    "    P = params_B * 1e9\n",
    "    if mixed_precision:\n",
    "        model_gb  = P * 2 / 1e9  # FP16 ëª¨ë¸\n",
    "        grad_gb   = P * 2 / 1e9  # FP16 ê·¸ë˜ë””ì–¸íŠ¸\n",
    "        master_gb = P * 4 / 1e9  # FP32 ë§ˆìŠ¤í„° ê°€ì¤‘ì¹˜\n",
    "    else:\n",
    "        model_gb  = P * 4 / 1e9\n",
    "        grad_gb   = P * 4 / 1e9\n",
    "        master_gb = 0.0\n",
    "\n",
    "    optim_gb = {'sgd': 0, 'momentum': P*4/1e9, 'adam': P*8/1e9}[optimizer]\n",
    "    total_gb = model_gb + grad_gb + master_gb + optim_gb\n",
    "    return {'model': model_gb, 'grad': grad_gb, 'master': master_gb,\n",
    "            'optim': optim_gb, 'total': total_gb}\n",
    "\n",
    "models = [\n",
    "    ('BERT-L\\n0.34B', 0.34), ('GPT-2\\n1.5B', 1.5),\n",
    "    ('Llama-2\\n7B', 7),   ('Llama-2\\n70B', 70),\n",
    "    ('GPT-3\\n175B', 175)\n",
    "]\n",
    "gpu_vram = 80  # H100 80GB\n",
    "\n",
    "print(f\"{'ëª¨ë¸':<15} {'ì´ ë©”ëª¨ë¦¬(GB)':>14} {'H100 80GB í•„ìš” ìˆ˜':>18}\")\n",
    "print(\"-\" * 50)\n",
    "for label, p in models:\n",
    "    m = compute_training_memory(p)\n",
    "    n_gpu = max(1, int(np.ceil(m['total'] / (gpu_vram * 0.8))))\n",
    "    print(f\"{label.replace(chr(10), ' '):<15} {m['total']:>14.1f} GB {n_gpu:>16} ëŒ€\")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "labels = [m[0].replace('\\n', ' ') for m in models]\n",
    "totals = [compute_training_memory(m[1])['total'] for m in models]\n",
    "results = [compute_training_memory(m[1]) for m in models]\n",
    "colors = ['#42A5F5', '#66BB6A', '#FFA726', '#EF5350', '#AB47BC']\n",
    "\n",
    "# ìŠ¤íƒ ë°”\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(labels))\n",
    "w = 0.55\n",
    "b0 = [r['model'] for r in results]\n",
    "b1 = [r['grad'] for r in results]\n",
    "b2 = [r['master'] for r in results]\n",
    "b3 = [r['optim'] for r in results]\n",
    "\n",
    "ax1.bar(x, b0, w, label='ëª¨ë¸ FP16', color='#2196F3')\n",
    "ax1.bar(x, b1, w, bottom=b0, label='ê·¸ë˜ë””ì–¸íŠ¸ FP16', color='#4CAF50')\n",
    "ax1.bar(x, b2, w, bottom=[a+b for a,b in zip(b0,b1)], label='ë§ˆìŠ¤í„° FP32', color='#FF9800')\n",
    "ax1.bar(x, b3, w, bottom=[a+b+c for a,b,c in zip(b0,b1,b2)], label='Adam FP32', color='#F44336')\n",
    "ax1.axhline(80, color='darkred', linestyle='--', lw=2, label='H100 80GB')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xticks(x); ax1.set_xticklabels(labels, fontsize=9)\n",
    "ax1.set_ylabel('ë©”ëª¨ë¦¬ (GB, ë¡œê·¸ ìŠ¤ì¼€ì¼)')\n",
    "ax1.set_title('Mixed Precision + Adam í•™ìŠµ ë©”ëª¨ë¦¬', fontweight='bold')\n",
    "ax1.legend(fontsize=8, loc='upper left'); ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# êµ¬ì„± ë¹„ìœ¨ (7B ê¸°ì¤€)\n",
    "ax2 = axes[1]\n",
    "r7 = compute_training_memory(7)\n",
    "sizes = [r7['model'], r7['grad'], r7['master'], r7['optim']]\n",
    "lbls = [f'ëª¨ë¸ FP16\\n{r7[\"model\"]:.0f}GB',\n",
    "        f'ê·¸ë˜ë””ì–¸íŠ¸ FP16\\n{r7[\"grad\"]:.0f}GB',\n",
    "        f'ë§ˆìŠ¤í„° FP32\\n{r7[\"master\"]:.0f}GB',\n",
    "        f'Adam FP32\\n{r7[\"optim\"]:.0f}GB']\n",
    "ax2.pie(sizes, labels=lbls, colors=['#2196F3','#4CAF50','#FF9800','#F44336'],\n",
    "        autopct='%1.0f%%', startangle=90, textprops={'fontsize': 9})\n",
    "ax2.set_title(f'Llama-2 7B ë©”ëª¨ë¦¬ êµ¬ì„± (ì´ {r7[\"total\"]:.0f}GB)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"\\nâ†’ Adam ì˜µí‹°ë§ˆì´ì € ìƒíƒœ(FP32)ê°€ ì „ì²´ì˜ {r7['optim']/r7['total']*100:.0f}%ë¥¼ ì°¨ì§€!\")\n",
    "print(\"â†’ ì´ê²ƒì´ ZeRO Stage 1(ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ë¶„ì‚°)ë¶€í„° ì‹œì‘í•˜ëŠ” ì´ìœ ë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DP vs DDP\n",
    "\n",
    "### Data Parallelism (DP) â€” ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ë°©ì‹\n",
    "\n",
    "```\n",
    "                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                  â”‚         ë§ˆìŠ¤í„° GPU (GPU 0)           â”‚\n",
    "               â‘   â”‚  ì „ì²´ ë°°ì¹˜ ìˆ˜ì‹  â†’ ëª¨ë¸ ë³µì‚¬ë³¸ ë³´ìœ     â”‚\n",
    "                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â‘¡Scatter      â”‚                      â”‚  â‘¡Scatter\n",
    "                  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                  â”‚   GPU 1     â”‚        â”‚    GPU 2     â”‚\n",
    "                  â”‚ Forward+Bwd â”‚        â”‚  Forward+Bwd â”‚\n",
    "                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â‘¢Gather       â”‚                      â”‚  â‘¢Gather\n",
    "                  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                  â‘£ ë§ˆìŠ¤í„°ê°€ ê·¸ë˜ë””ì–¸íŠ¸ í•©ì‚° â†’ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
    "                  â‘¤ Broadcast: ì—…ë°ì´íŠ¸ëœ íŒŒë¼ë¯¸í„°ë¥¼ GPU 1,2ë¡œ ë³µì‚¬\n",
    "```\n",
    "\n",
    "**ë§ˆìŠ¤í„° ë³‘ëª©**: GPUê°€ Nê°œì´ë©´ ë§ˆìŠ¤í„°ëŠ” N-1ê°œë¡œë¶€í„° ë°ì´í„°ë¥¼ ë°›ì•„ì•¼ í•¨ â†’ $O(N)$ ë³‘ëª©\n",
    "\n",
    "### Distributed Data Parallel (DDP) â€” ë©€í‹° í”„ë¡œì„¸ìŠ¤ ë°©ì‹\n",
    "\n",
    "```\n",
    "    GPU 0 â†â”€â”€â”€â”€ Ring All-Reduce â”€â”€â”€â”€â†’ GPU 1\n",
    "      â†‘                                  â†‘\n",
    "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”˜\n",
    "    GPU 3 â†â”€â”€â”€â”€ Ring All-Reduce â”€â”€â”€â”€â†’ GPU 2\n",
    "    \n",
    "    ê° GPU: ë…ë¦½ í”„ë¡œì„¸ìŠ¤ â†’ ìì‹ ì˜ ëª¨ë¸ ë³µì œë³¸ ë³´ìœ \n",
    "    Forward / Backward â†’ All-Reduce(ê·¸ë˜ë””ì–¸íŠ¸ ë™ê¸°í™”) â†’ ë¡œì»¬ ì—…ë°ì´íŠ¸\n",
    "```\n",
    "\n",
    "**ë§ˆìŠ¤í„° ì—†ìŒ**: ëª¨ë“  GPUê°€ ë™ë“±í•˜ê²Œ ì°¸ì—¬ â†’ $O(K)$ (ëª¨ë¸ í¬ê¸°ì—ë§Œ ì˜ì¡´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# DP vs DDP í†µì‹  ë¹„ìš© ìˆ˜ì‹ ë¹„êµ\n",
    "# ---------------------------------------------------\n",
    "\n",
    "N_range = np.arange(2, 129)  # GPU ìˆ˜ 2~128\n",
    "K = 1.0  # ëª¨ë¸ í¬ê¸° ì •ê·œí™” (1.0 = ëª¨ë¸ ì „ì²´ í¬ê¸°)\n",
    "\n",
    "# DP: ë§ˆìŠ¤í„° GPUê°€ ë°›ëŠ” ì´ í†µì‹ ëŸ‰ = (N-1) Ã— K (Gather) + (N-1) Ã— K (Broadcast)\n",
    "dp_master_comm = 2 * (N_range - 1) * K\n",
    "\n",
    "# DDP(Ring All-Reduce): ê° GPUì˜ í†µì‹ ëŸ‰ = 2Ã—(N-1)/N Ã— K â†’ 2Kì— ìˆ˜ë ´\n",
    "ring_comm = 2 * (N_range - 1) / N_range * K\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.plot(N_range, dp_master_comm, 'r-', lw=2.5, label='DP: ë§ˆìŠ¤í„° GPU í†µì‹ ëŸ‰ (O(N))', zorder=3)\n",
    "ax1.plot(N_range, ring_comm, 'b-', lw=2.5, label='DDP Ring All-Reduce (â‰ˆ 2K)', zorder=3)\n",
    "ax1.axhline(y=2*K, color='blue', linestyle=':', alpha=0.5)\n",
    "ax1.fill_between(N_range, ring_comm, dp_master_comm, alpha=0.08, color='red',\n",
    "                 label='DPê°€ ë‚­ë¹„í•˜ëŠ” í†µì‹  ë¹„ìš©')\n",
    "ax1.set_xlabel('GPU ìˆ˜ (N)')\n",
    "ax1.set_ylabel('GPUë‹¹ í†µì‹ ëŸ‰ (K ë‹¨ìœ„, K=ëª¨ë¸ ì „ì²´ í¬ê¸°)')\n",
    "ax1.set_title('í†µì‹  ë°©ì‹ë³„ GPUë‹¹ í†µì‹ ëŸ‰ ë¹„êµ', fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.annotate('N=64ì¼ ë•Œ\\nDP: 126K vs Ring: â‰ˆ2K â†’ 63ë°° ì°¨ì´!',\n",
    "             xy=(64, 126), xytext=(70, 90),\n",
    "             arrowprops=dict(arrowstyle='->', color='red'),\n",
    "             fontsize=9, color='red')\n",
    "\n",
    "# ì´ìƒì  ì„ í˜• í™•ì¥ vs ì‹¤ì œ ìŠ¤í”¼ë“œì—…\n",
    "ax2 = axes[1]\n",
    "ideal = N_range\n",
    "# ì—°ì‚°:í†µì‹  ë¹„ìœ¨ = 4:1ë¡œ ê°€ì • (ì‹¤ì œ GPU workloadì— ë”°ë¼ ë‹¤ë¦„)\n",
    "comp_ratio = 4.0\n",
    "speedup_ring = N_range / (1 + ring_comm / comp_ratio)\n",
    "speedup_dp   = N_range / (1 + dp_master_comm / comp_ratio)\n",
    "\n",
    "ax2.plot(N_range, ideal, 'g--', lw=1.5, label='ì´ìƒì  ì„ í˜• í™•ì¥', alpha=0.6)\n",
    "ax2.plot(N_range, speedup_ring, 'b-', lw=2.5, label='DDP (Ring All-Reduce)')\n",
    "ax2.plot(N_range, speedup_dp, 'r-', lw=2.5, label='DP (ë§ˆìŠ¤í„° ì¤‘ì‹¬)')\n",
    "ax2.set_xlabel('GPU ìˆ˜ (N)')\n",
    "ax2.set_ylabel('í•™ìŠµ ì†ë„ í–¥ìƒ (ë°°ìˆ˜)')\n",
    "ax2.set_title('GPU í™•ì¥ì— ë”°ë¥¸ ì‹¤íš¨ ìŠ¤í”¼ë“œì—…', fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"ê²°ë¡ : DDPì˜ Ring All-ReduceëŠ” GPU ìˆ˜ê°€ ëŠ˜ì–´ë„ í†µì‹  ë¹„ìš©ì´ 2Kë¡œ ìˆ˜ë ´í•˜ì—¬\")\n",
    "print(\"      ì„ í˜•ì— ê°€ê¹Œìš´ í™•ì¥ì„±(linear scaling)ì„ ë‹¬ì„±í•œë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ring All-Reduce ì‹¬í™”\n",
    "\n",
    "### ì•Œê³ ë¦¬ì¦˜ ë‹¨ê³„ë³„ ìˆ˜ì‹ ë„ì¶œ\n",
    "\n",
    "**ì„¤ì •**: GPU $N$ê°œ, ê°ê° í¬ê¸° $K$ì˜ í…ì„œ $G_0, \\dots, G_{N-1}$ ë³´ìœ .  \n",
    "**ëª©í‘œ**: ëª¨ë“  GPUê°€ $\\bar{G} = \\sum_{i} G_i$ë¥¼ ë™ì¼í•˜ê²Œ ë³´ìœ \n",
    "\n",
    "ê° í…ì„œë¥¼ $N$ê°œì˜ ì²­í¬ë¡œ ë¶„í• : $G_i = [g_i^{(0)}, g_i^{(1)}, \\dots, g_i^{(N-1)}]$\n",
    "\n",
    "#### 1ë‹¨ê³„: Scatter-Reduce ($N-1$ ë¼ìš´ë“œ)\n",
    "\n",
    "- ë¼ìš´ë“œ $r$ì—ì„œ GPU $i$ëŠ” ì²­í¬ $(i - r) \\bmod N$ì„ ì˜¤ë¥¸ìª½ GPUë¡œ ì „ì†¡\n",
    "- ë™ì‹œì— ì™¼ìª½ì—ì„œ ë°›ì€ ì²­í¬ë¥¼ ìì‹ ì˜ í•´ë‹¹ ì²­í¬ì— ëˆ„ì  í•©ì‚°\n",
    "- ê²°ê³¼: ê° GPUëŠ” ì •í™•íˆ í•˜ë‚˜ì˜ ì²­í¬ì— ëŒ€í•´ **ì „ì²´ í•©ì‚°ê°’** ë³´ìœ \n",
    "\n",
    "$$\\text{GPUë‹¹ í†µì‹ ëŸ‰}_{1ë‹¨ê³„} = (N-1) \\times \\frac{K}{N}$$\n",
    "\n",
    "#### 2ë‹¨ê³„: All-Gather ($N-1$ ë¼ìš´ë“œ)\n",
    "\n",
    "- ì™„ì„±ëœ í•©ì‚° ì²­í¬ë¥¼ ë‹¤ì‹œ ë§ì„ ë”°ë¼ ì „íŒŒ\n",
    "- ê²°ê³¼: ëª¨ë“  GPUê°€ ì „ì²´ í•©ì‚° í…ì„œë¥¼ ì™„ì „íˆ ë³µì›\n",
    "\n",
    "$$\\text{GPUë‹¹ í†µì‹ ëŸ‰}_{2ë‹¨ê³„} = (N-1) \\times \\frac{K}{N}$$\n",
    "\n",
    "#### ìµœì¢… ë„ì¶œ\n",
    "\n",
    "$$T_{comm} = 2(N-1) \\times \\frac{K}{N} \\xrightarrow{N \\to \\infty} 2K \\quad \\text{(ìƒìˆ˜ ìˆ˜ë ´)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Ring All-Reduce ì™„ì „ êµ¬í˜„ ë° ë‹¨ê³„ë³„ ì‹œê°í™”\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def ring_all_reduce(gradients, operation='sum', verbose=True):\n",
    "    \"\"\"\n",
    "    Ring All-Reduceë¥¼ ìˆœìˆ˜ íŒŒì´ì¬ + NumPyë¡œ ì™„ì „ êµ¬í˜„.\n",
    "    \n",
    "    Args:\n",
    "        gradients (list of np.ndarray): Nê°œ GPUì˜ ê·¸ë˜ë””ì–¸íŠ¸ í…ì„œ  \n",
    "        operation (str): 'sum' ë˜ëŠ” 'mean'\n",
    "        verbose (bool): ë‹¨ê³„ë³„ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€\n",
    "    Returns:\n",
    "        results (list of np.ndarray): All-Reduce ì™„ë£Œëœ í…ì„œ (ëª¨ë“  GPU ë™ì¼)\n",
    "    \"\"\"\n",
    "    N = len(gradients)\n",
    "    K = gradients[0].size\n",
    "    chunk_size = K // N\n",
    "    assert K % N == 0, f\"í…ì„œ í¬ê¸°({K})ê°€ GPU ìˆ˜({N})ë¡œ ë‚˜ëˆ„ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤\"\n",
    "\n",
    "    # ë”¥ ì¹´í”¼ (ì…ë ¥ ë³€ê²½ ë°©ì§€)\n",
    "    buf = [[g[j*chunk_size:(j+1)*chunk_size].copy() for j in range(N)]\n",
    "           for g in gradients]\n",
    "\n",
    "    comm_bytes = 0\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[Ring All-Reduce] GPU={N}, í…ì„œ í¬ê¸°={K}, ì²­í¬ í¬ê¸°={chunk_size}\")\n",
    "        print(f\"ì´ë¡  í†µì‹ ëŸ‰: 2Ã—({N}-1)Ã—{K}/{N} = {2*(N-1)*K//N} ì›ì†Œ\")\n",
    "\n",
    "    # â”€â”€ 1ë‹¨ê³„: Scatter-Reduce â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if verbose: print(\"\\n[Phase 1] Scatter-Reduce:\")\n",
    "    for rnd in range(N - 1):\n",
    "        for gpu in range(N):\n",
    "            send_chunk  = (gpu - rnd) % N\n",
    "            recv_chunk  = (gpu - rnd - 1) % N\n",
    "            left_gpu    = (gpu - 1) % N\n",
    "            # ì™¼ìª½ì—ì„œ ë°›ì€ ì²­í¬ë¥¼ ìì‹ ì˜ ë²„í¼ì— í•©ì‚°\n",
    "            buf[gpu][recv_chunk] += buf[left_gpu][recv_chunk]\n",
    "            comm_bytes += chunk_size\n",
    "        if verbose:\n",
    "            print(f\"  Round {rnd+1}: ê° GPUê°€ ì²­í¬ 1ê°œ ì†¡ìˆ˜ì‹  ë° í•©ì‚° âœ”\")\n",
    "\n",
    "    # â”€â”€ 2ë‹¨ê³„: All-Gather â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if verbose: print(\"\\n[Phase 2] All-Gather:\")\n",
    "    for rnd in range(N - 1):\n",
    "        for gpu in range(N):\n",
    "            recv_chunk  = (gpu - rnd) % N\n",
    "            left_gpu    = (gpu - 1) % N\n",
    "            # ì™¼ìª½ì˜ ì™„ì„±ëœ ì²­í¬ë¥¼ ë³µì‚¬\n",
    "            buf[gpu][recv_chunk] = buf[left_gpu][recv_chunk].copy()\n",
    "            comm_bytes += chunk_size\n",
    "        if verbose:\n",
    "            print(f\"  Round {rnd+1}: ì™„ì„± ì²­í¬ ì „íŒŒ âœ”\")\n",
    "\n",
    "    results = [np.concatenate(buf[i]) for i in range(N)]\n",
    "    if operation == 'mean':\n",
    "        results = [r / N for r in results]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nì‹¤ì œ í†µì‹ ëŸ‰: {comm_bytes} ì›ì†Œ (ì´ë¡ : {2*(N-1)*K//N} âœ…)\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# â”€â”€ í…ŒìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "N_gpus = 4\n",
    "tensor_size = 8  # 8 / 4 = 2ê°œ ì²­í¬\n",
    "\n",
    "grads = [np.random.randint(1, 10, tensor_size).astype(float) for _ in range(N_gpus)]\n",
    "expected = sum(grads)\n",
    "\n",
    "print(\"ì´ˆê¸° ê·¸ë˜ë””ì–¸íŠ¸:\")\n",
    "for i, g in enumerate(grads):\n",
    "    print(f\"  GPU {i}: {g}\")\n",
    "print(f\"ê¸°ëŒ€ í•©ì‚°ê°’: {expected}\")\n",
    "\n",
    "results = ring_all_reduce(grads)\n",
    "\n",
    "print(\"\\n=== ê²€ì¦ ===\")\n",
    "all_ok = all(np.allclose(r, expected) for r in results)\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"  GPU {i}: {r}  {'âœ…' if np.allclose(r, expected) else 'âŒ'}\")\n",
    "print(f\"\\nëª¨ë“  GPUê°€ ë™ì¼í•œ í•©ì‚° ê²°ê³¼: {'âœ… ì„±ê³µ!' if all_ok else 'âŒ ì‹¤íŒ¨!'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MirroredStrategy ì‹¤ìŠµ\n",
    "\n",
    "`tf.distribute.MirroredStrategy`ëŠ” ë‹¨ì¼ ë…¸ë“œ ë‚´ì—ì„œ DDPì™€ ìœ ì‚¬í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ê·œì¹™**:\n",
    "1. ëª¨ë¸ì€ ë°˜ë“œì‹œ **`strategy.scope()` ë‚´ì—ì„œ** ìƒì„±\n",
    "2. ê¸€ë¡œë²Œ ë°°ì¹˜ í¬ê¸° = ë¡œì»¬ ë°°ì¹˜ Ã— ë ˆí”Œë¦¬ì¹´ ìˆ˜\n",
    "3. ì†ì‹¤ í•©ì‚°ì€ **`tf.reduce_sum` (í•©ì‚°)** ì‚¬ìš© (í‰ê·  ì•„ë‹˜!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# MirroredStrategy MNIST ë¶„ì‚° í•™ìŠµ\n",
    "# ---------------------------------------------------\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "NUM_REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'ë ˆí”Œë¦¬ì¹´(ì¥ì¹˜) ìˆ˜: {NUM_REPLICAS}')\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32')  / 255.0\n",
    "\n",
    "BATCH_PER_REPLICA = 64\n",
    "GLOBAL_BATCH = BATCH_PER_REPLICA * NUM_REPLICAS  # ë¶„ì‚° í•™ìŠµì˜ í•µì‹¬ ì„¤ì •\n",
    "\n",
    "train_ds = (tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "            .shuffle(10000).batch(GLOBAL_BATCH).prefetch(2))\n",
    "test_ds  = (tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "            .batch(GLOBAL_BATCH).prefetch(2))\n",
    "\n",
    "print(f\"ê¸€ë¡œë²Œ ë°°ì¹˜: {GLOBAL_BATCH} (ë ˆí”Œë¦¬ì¹´ë‹¹ {BATCH_PER_REPLICA})\")\n",
    "print(f\"í•™ìŠµ ìŠ¤í… ìˆ˜: {len(train_ds)}\")\n",
    "\n",
    "# ëª¨ë¸ì€ ë°˜ë“œì‹œ strategy.scope() ì•ˆì—ì„œ ì •ì˜\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(28, 28)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)  # from_logits=True â†’ í™œì„±í™” ì—†ìŒ\n",
    "    ], name='mnist_distributed')\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "model.summary()\n",
    "print(\"\\nâ†’ strategy.scope() ì•ˆì—ì„œ ìƒì„±ëœ ëª¨ë¸ì€ ê° ì¥ì¹˜ì— ë ˆí”Œë¦¬ì¹´ë¡œ ìë™ ë³µì œë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì»¤ìŠ¤í…€ í•™ìŠµ ë£¨í”„ë¡œ ë¶„ì‚° ë‚´ë¶€ ë™ì‘ ê´€ì°°\n",
    "# model.fit()ì€ ë‚´ë¶€ì—ì„œ All-Reduceë¥¼ ìë™ ìˆ˜í–‰í•˜ì§€ë§Œ,\n",
    "# ì—¬ê¸°ì„œëŠ” ê·¸ íë¦„ì„ ì§ì ‘ ì œì–´í•˜ì—¬ ì´í•´ë„ë¥¼ ë†’ì¸ë‹¤.\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs):\n",
    "    x_batch, y_batch = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x_batch, training=True)\n",
    "        # ë¶„ì‚° í•™ìŠµì—ì„œëŠ” ì†ì‹¤ì„ í•©ì‚°(sum)í•œ í›„ ê¸€ë¡œë²Œ ë°°ì¹˜ ìˆ˜ë¡œ ë‚˜ëˆ”\n",
    "        per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            y_batch, logits, from_logits=True)\n",
    "        loss = tf.reduce_sum(per_example_loss) / GLOBAL_BATCH  # â† ì¤‘ìš”!\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(inputs):\n",
    "    # strategy.runì´ ê° ë ˆí”Œë¦¬ì¹´ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ train_step ì‹¤í–‰\n",
    "    # ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ë‚´ë¶€ì—ì„œ ìë™ìœ¼ë¡œ All-Reduce ë™ê¸°í™”ë¨\n",
    "    per_replica_losses = strategy.run(train_step, args=(inputs,))\n",
    "    # ê° ë ˆí”Œë¦¬ì¹´ ì†ì‹¤ í•©ì‚°\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "dist_train_ds = strategy.experimental_distribute_dataset(train_ds)\n",
    "\n",
    "# 1 ì—í¬í¬ ìˆ˜ë™ í•™ìŠµ\n",
    "total_loss = 0.0\n",
    "num_batches = 0\n",
    "for batch in dist_train_ds:\n",
    "    loss = distributed_train_step(batch)\n",
    "    total_loss += loss.numpy()\n",
    "    num_batches += 1\n",
    "    if num_batches % 200 == 0:\n",
    "        print(f\"  Step {num_batches}: avg_loss = {total_loss / num_batches:.4f}\")\n",
    "\n",
    "print(f\"\\nì—í¬í¬ í‰ê·  ì†ì‹¤: {total_loss / num_batches:.4f}\")\n",
    "print(\"â†’ strategy.run() ë‚´ë¶€ì—ì„œ ê° ë ˆí”Œë¦¬ì¹´ê°€ ë…ë¦½ Forward/Backward ìˆ˜í–‰\")\n",
    "print(\"â†’ strategy.reduce(SUM)ì—ì„œ NCCL All-Reduceë¡œ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ë™ê¸°í™”ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit()ìœ¼ë¡œ ë‚˜ë¨¸ì§€ í•™ìŠµ ì™„ì„± (ì‹¤ì œë¡œëŠ” ì´ê²ƒì´ ë” ê°„í¸)\n",
    "history = model.fit(\n",
    "    train_ds, epochs=4, validation_data=test_ds, verbose=1\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for ax, key, title in zip(axes, ['loss', 'accuracy'], ['ì†ì‹¤(Loss)', 'ì •í™•ë„(Accuracy)']):\n",
    "    ax.plot(history.history[key], 'b-o', label='Train')\n",
    "    ax.plot(history.history[f'val_{key}'], 'r-o', label='Val')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'MirroredStrategy ({NUM_REPLICAS}ê°œ ì¥ì¹˜) MNIST', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í†µì‹  ë¹„ìš© ì‹œê°í™”\n",
    "\n",
    "ì‹¤ì œ ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„°ì—ì„œ DPì™€ DDPì˜ ë„¤íŠ¸ì›Œí¬ ì²˜ë¦¬ëŸ‰ ì°¨ì´ë¥¼ ê³„ì‚°í•´ ë³´ì."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# ì‹¤ì œ ëŒ€ì—­í­ ê¸°ë°˜ í†µì‹  ì‹œê°„ ë¹„êµ\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# GPT-3 175B ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸° (FP32 ê¸°ì¤€)\n",
    "model_params_B = 175  # 175B params\n",
    "grad_size_GB = model_params_B * 4  # FP32: 4bytes Ã— 175B â‰ˆ 700 GB\n",
    "\n",
    "# ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­\n",
    "nvlink_bandwidth_GBps = 600   # NVLink: 600 GB/s\n",
    "infiniband_GBps       = 50    # InfiniBand HDR: 400 Gb/s â‰ˆ 50 GB/s\n",
    "ethernet_GBps         = 12.5  # 100GbE â‰ˆ 12.5 GB/s\n",
    "\n",
    "N_values = [2, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "print(f\"GPT-3 175B ê·¸ë˜ë””ì–¸íŠ¸: {grad_size_GB} GB\")\n",
    "print(f\"\\n{'GPUìˆ˜':>6} | {'Ring(NVLink)':>13} | {'Ring(IB)':>10} | {'DP ë§ˆìŠ¤í„°(IB)':>14}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for N in N_values:\n",
    "    ring_gb  = 2 * (N-1) * grad_size_GB / N\n",
    "    ring_nv  = ring_gb / nvlink_bandwidth_GBps\n",
    "    ring_ib  = ring_gb / infiniband_GBps\n",
    "    dp_mast  = 2 * (N-1) * grad_size_GB / infiniband_GBps  # ë§ˆìŠ¤í„° ë³‘ëª©\n",
    "    print(f\"{N:>6} | {ring_nv:>12.2f}s | {ring_ib:>9.1f}s | {dp_mast:>13.1f}s\")\n",
    "\n",
    "print(\"\\nâ†’ 128-GPU ê¸°ì¤€, Ring All-Reduce(IB)ëŠ” â‰ˆ14ì´ˆ, DP ë§ˆìŠ¤í„°ëŠ” â‰ˆ1792ì´ˆ (128ë°° ì°¨ì´!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì •ë¦¬\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| í•­ëª© | Data Parallelism (DP) | Distributed Data Parallel (DDP) |\n",
    "|------|----------------------|---------------------------------|\n",
    "| ì•„í‚¤í…ì²˜ | ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ + ë©€í‹° ìŠ¤ë ˆë“œ | ë©€í‹° í”„ë¡œì„¸ìŠ¤ (GPUë‹¹ 1ê°œ) |\n",
    "| í†µì‹  êµ¬ì¡° | ë§ˆìŠ¤í„° ì¤‘ì‹¬ Fan-in/out | ë§(Ring) P2P |\n",
    "| ë§ˆìŠ¤í„° ë³‘ëª© | $O(N \\times K)$ â†’ âœ— | ì—†ìŒ â†’ âœ… |\n",
    "| GPUë‹¹ í†µì‹ ëŸ‰ | $2(N-1)K$ â†’ ì„ í˜• ì¦ê°€ | $2(N-1)K/N \\approx 2K$ â†’ ìƒìˆ˜ |\n",
    "| GIL ì˜í–¥ | ìˆìŒ | ì—†ìŒ |\n",
    "| ë©€í‹° ë…¸ë“œ | ë¶ˆê°€ | ê°€ëŠ¥ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$T_{Ring} = 2(N-1)\\frac{K}{N} \\xrightarrow{N \\to \\infty} 2K, \\qquad M_{training}^{Adam} = 16P \\text{ bytes}$$\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**Chapter 09-02: í…ì„œ ë³‘ë ¬í™” (Tensor Parallelism)** â€” ëª¨ë¸ì´ ë‹¨ì¼ GPU ë©”ëª¨ë¦¬ì— í†µì§¸ë¡œ ì˜¬ë¼ê°€ì§€ ì•Šì„ ë•Œ, ê°€ì¤‘ì¹˜ í–‰ë ¬ ìì²´ë¥¼ ì—´(Column)/í–‰(Row) ë°©í–¥ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì—¬ëŸ¬ GPUì— ë‚˜ëˆ„ëŠ” Megatron-LM ë°©ì‹ì˜ ì™„ì „í•œ ìˆ˜í•™ì  ì¦ëª…ê³¼ NumPy ì‹œë®¬ë ˆì´ì…˜ì„ í•™ìŠµí•œë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python (tf_study)", "language": "python", "name": "tf_study"},
  "language_info": {"name": "python", "version": "3.11.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}