{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: ê·¹ë‹¨ì  ì¶”ë¡  ìµœì í™” â€” ì¶”ë¡  ë³‘ëª© ë¶„ì„\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- LLM ì¶”ë¡ ì˜ ë‘ ë‹¨ê³„(Prefill / Decode)ê°€ **ë¬¼ë¦¬ì ìœ¼ë¡œ ë‹¤ë¥¸ ë³‘ëª©**ì„ ê°–ëŠ” ì›ì¸ì„ ì´í•´í•œë‹¤\n",
    "- Arithmetic Intensity(ì—°ì‚° ê°•ë„)ë¥¼ ì´ìš©í•´ ê° ë‹¨ê³„ê°€ **Compute-bound / Memory-bound**ì¸ì§€ íŒë³„í•œë‹¤\n",
    "- Roofline ëª¨ë¸ì„ LLM ì¶”ë¡ ì— ì ìš©í•˜ì—¬ **í•˜ë“œì›¨ì–´ í™œìš©ë¥ **ì„ ì‹œê°í™”í•œë‹¤\n",
    "- TTFT(Time To First Token)ì™€ TPOT(Time Per Output Token)ì˜ **ìˆ˜ì‹ì„ ë„ì¶œ**í•˜ê³  ì¸¡ì •í•œë‹¤\n",
    "- ë°°ì¹˜ í¬ê¸°(Batch Size)ê°€ **ì²˜ë¦¬ëŸ‰(Throughput)ê³¼ ì§€ì—°(Latency)**ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: ì—°ì‚° ê°•ë„ì™€ Roofline ëª¨ë¸](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [Prefill vs Decode ë‹¨ê³„ ë¶„ì„](#2.-Prefill-vs-Decode)\n",
    "3. [Roofline ì‹œê°í™”](#3.-Roofline-ì‹œê°í™”)\n",
    "4. [TTFT / TPOT ì¸¡ì • ì‹œë®¬ë ˆì´ì…˜](#4.-TTFT-/-TPOT)\n",
    "5. [ë°°ì¹˜ í¬ê¸°ì™€ ì²˜ë¦¬ëŸ‰ ê´€ê³„](#5.-ë°°ì¹˜-í¬ê¸°ì™€-ì²˜ë¦¬ëŸ‰)\n",
    "6. [ì •ë¦¬](#6.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>\n",
    "\n",
    "### Arithmetic Intensity (ì—°ì‚° ê°•ë„)\n",
    "\n",
    "í•˜ë“œì›¨ì–´ê°€ **ì—°ì‚° ë³‘ëª©(Compute-bound)**ì¸ì§€ **ë©”ëª¨ë¦¬ ë³‘ëª©(Memory-bound)**ì¸ì§€ íŒë‹¨í•˜ëŠ” í•µì‹¬ ì§€í‘œì…ë‹ˆë‹¤:\n",
    "\n",
    "$$\\text{AI} = \\frac{\\text{FLOPs (ì—°ì‚°ëŸ‰)}}{\\text{Bytes Transferred (ë©”ëª¨ë¦¬ ì´ë™ëŸ‰)}}$$\n",
    "\n",
    "- $\\text{AI}$: Arithmetic Intensity (ë‹¨ìœ„: FLOPs/Byte)\n",
    "- $\\text{FLOPs}$: ë¶€ë™ì†Œìˆ˜ì  ì—°ì‚° íšŸìˆ˜\n",
    "- $\\text{Bytes}$: HBM â†” ì—°ì‚° ìœ ë‹› ê°„ ë°ì´í„° ì´ë™ëŸ‰\n",
    "\n",
    "### Roofline ëª¨ë¸\n",
    "\n",
    "GPUì˜ ì´ë¡ ì  ìµœëŒ€ ì„±ëŠ¥ì„ ë‘ ê°€ì§€ í•œê³„ë¡œ ëª¨ë¸ë§í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$\\text{Performance} = \\min\\left(\\text{Peak FLOPs},\\; \\text{AI} \\times \\text{Memory Bandwidth}\\right)$$\n",
    "\n",
    "ê²½ê³„ì (Ridge Point):\n",
    "\n",
    "$$\\text{AI}_{ridge} = \\frac{\\text{Peak FLOPs (FLOPS)}}{\\text{Memory Bandwidth (Bytes/s)}}$$\n",
    "\n",
    "- $\\text{AI} < \\text{AI}_{ridge}$: **Memory-bound** (ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì´ ë³‘ëª©)\n",
    "- $\\text{AI} > \\text{AI}_{ridge}$: **Compute-bound** (ì—°ì‚° ëŠ¥ë ¥ì´ ë³‘ëª©)\n",
    "\n",
    "### Prefill vs Decodeì˜ ì—°ì‚° ê°•ë„\n",
    "\n",
    "| ë‹¨ê³„ | ì—°ì‚° | AI | ë³‘ëª© |\n",
    "|------|------|-----|------|\n",
    "| Prefill | $QK^T$ í–‰ë ¬ê³± ($S \\times S$) | $\\text{AI}_{prefill} \\approx \\frac{2 \\cdot S \\cdot d}{2d + 2S} \\approx S$ | **Compute-bound** |\n",
    "| Decode | ë²¡í„°-í–‰ë ¬ ê³± ($1 \\times S$) | $\\text{AI}_{decode} \\approx \\frac{2d}{2d + 2S} \\approx 1$ | **Memory-bound** |\n",
    "\n",
    "- $S$: ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "- $d$: íˆë“  ì°¨ì›\n",
    "\n",
    "### TTFTì™€ TPOT\n",
    "\n",
    "$$\\text{TTFT} = \\frac{2 \\cdot P \\cdot S_{input}}{\\text{GPU FLOPs}} \\quad \\text{(Prefill ì‹œê°„, Compute-bound)}$$\n",
    "\n",
    "$$\\text{TPOT} = \\frac{2P \\cdot \\text{bytes\\_per\\_param}}{\\text{Memory Bandwidth}} \\quad \\text{(Decode í•œ í† í°, Memory-bound)}$$\n",
    "\n",
    "- $P$: ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜\n",
    "- $S_{input}$: ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "- $\\text{bytes\\_per\\_param}$: íŒŒë¼ë¯¸í„°ë‹¹ ë°”ì´íŠ¸ (FP16=2, INT8=1)\n",
    "\n",
    "**ìš”ì•½ í‘œ:**\n",
    "\n",
    "| ì§€í‘œ | ìˆ˜ì‹ | ì˜ë¯¸ |\n",
    "|------|------|------|\n",
    "| Arithmetic Intensity | $\\text{FLOPs} / \\text{Bytes}$ | ì—°ì‚° ëŒ€ë¹„ ë©”ëª¨ë¦¬ ë¹„ìœ¨ |\n",
    "| Ridge Point | $\\text{Peak FLOPS} / \\text{BW}$ | Computeâ†”Memory ê²½ê³„ |\n",
    "| TTFT | $2PS_{in} / \\text{FLOPS}$ | ì²« í† í° ìƒì„± ì‹œê°„ |\n",
    "| TPOT | $2P \\cdot b / \\text{BW}$ | í† í° ë‹¹ ìƒì„± ì‹œê°„ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ì¶”ë¡  ë³‘ëª© ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ”¢ Prefillê³¼ Decodeê°€ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: LLMì´ ë‹µë³€í•˜ëŠ” ê³¼ì •ì„ **ì‹œí—˜**ì— ë¹„ìœ í•´ ë´…ì‹œë‹¤!\n",
    "\n",
    "**Prefill(ë¬¸ì œ ì½ê¸°)**: ì‹œí—˜ ë¬¸ì œë¥¼ ì­‰ ì½ëŠ” ë‹¨ê³„ì˜ˆìš”. ë¬¸ì œê°€ ê¸¸ë©´ ì½ëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ì§€ë§Œ, \n",
    "ëˆˆ(=GPU)ì€ ê³„ì† ë°”ì˜ê²Œ ì½ê³  ìˆì–´ìš”. â†’ **ê³„ì‚°ì´ ë°”ìœ(Compute-bound)** ìƒíƒœ!\n",
    "\n",
    "**Decode(ë‹µ ì“°ê¸°)**: í•œ ê¸€ìì”© ë‹µì„ ì“°ëŠ” ë‹¨ê³„ì˜ˆìš”. ë¨¸ë¦¿ì†(=GPU)ì€ ë¹ ë¥¸ë° \n",
    "ì†(=ë©”ëª¨ë¦¬)ì´ ëŠë ¤ì„œ í•œ ê¸€ìì”©ë§Œ ì“¸ ìˆ˜ ìˆì–´ìš”. â†’ **ë©”ëª¨ë¦¬ê°€ ë°”ìœ(Memory-bound)** ìƒíƒœ!\n",
    "\n",
    "#### ğŸ”ï¸ Rooflineì´ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: ìˆ˜ë„ê¼­ì§€ì™€ ë¬¼í†µì„ ìƒê°í•´ ë³´ì„¸ìš”!\n",
    "\n",
    "- **ìˆ˜ë„ê¼­ì§€** = ë©”ëª¨ë¦¬ ëŒ€ì—­í­ (ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì†ë„)\n",
    "- **ë¬¼í†µ** = GPU ì—°ì‚° ìœ ë‹› (ê³„ì‚°í•˜ëŠ” ì†ë„)\n",
    "- ë¬¼í†µì´ ì•„ë¬´ë¦¬ ì»¤ë„, ìˆ˜ë„ê¼­ì§€ê°€ ì¢ìœ¼ë©´ ë¬¼(=ë°ì´í„°)ì´ ì²œì²œíˆ ì°¨ìš” â†’ Memory-bound\n",
    "- ìˆ˜ë„ê¼­ì§€ê°€ ë„“ì–´ë„, ë¬¼í†µì´ ì‘ìœ¼ë©´ ë„˜ì³ìš” â†’ Compute-bound\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: Arithmetic Intensity ê³„ì‚°\n",
    "\n",
    "í–‰ë ¬ê³± $C = AB$ì—ì„œ $A \\in \\mathbb{R}^{M \\times K}$, $B \\in \\mathbb{R}^{K \\times N}$ì¼ ë•Œ:\n",
    "- FLOPs = $2MKN$\n",
    "- Bytes = $2(MK + KN + MN)$ (FP16 ê¸°ì¤€)\n",
    "\n",
    "$M=1, K=4096, N=4096$ (Decode ë‹¨ê³„)ì¼ ë•Œ AIë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$$\\text{FLOPs} = 2 \\times 1 \\times 4096 \\times 4096 = 33,554,432$$\n",
    "\n",
    "$$\\text{Bytes} = 2(1 \\times 4096 + 4096 \\times 4096 + 1 \\times 4096) = 2(4096 + 16,777,216 + 4096) = 33,570,816$$\n",
    "\n",
    "$$\\text{AI} = \\frac{33,554,432}{33,570,816} \\approx 1.0 \\;\\text{FLOPs/Byte}$$\n",
    "\n",
    "â†’ AI â‰ˆ 1ë¡œ **Memory-bound**! Decode ë‹¨ê³„ì—ì„œ ê°€ì¤‘ì¹˜ë¥¼ ì½ëŠ” ë¹„ìš©ì´ ì—°ì‚°ì„ ì••ë„í•©ë‹ˆë‹¤.\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: TTFT ì˜ˆì¸¡\n",
    "\n",
    "Llama 3 8B ($P = 8 \\times 10^9$), ì…ë ¥ 512 í† í°, A100 GPU (312 TFLOPS FP16) ì¼ ë•Œ TTFTëŠ”?\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$$\\text{TTFT} = \\frac{2 \\times 8 \\times 10^9 \\times 512}{312 \\times 10^{12}} = \\frac{8.192 \\times 10^{12}}{312 \\times 10^{12}} \\approx 26.3\\text{ ms}$$\n",
    "\n",
    "â†’ ì•½ 26msë¡œ, ì…ë ¥ ê¸¸ì´ì— ë¹„ë¡€í•˜ì—¬ ì¦ê°€í•©ë‹ˆë‹¤.\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "np.random.seed(42)\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n",
    "print(f\"NumPy ë²„ì „: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prefill vs Decode ë‹¨ê³„ ë¶„ì„ <a name='2.-Prefill-vs-Decode'></a>\n",
    "\n",
    "Llama 3 8Bì˜ ì‹¤ì œ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë‹¨ê³„ì˜ FLOPs, ë©”ëª¨ë¦¬ ì´ë™ëŸ‰, Arithmetic Intensityë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ê°’ |\n",
    "|---------|-----|\n",
    "| ë ˆì´ì–´ ìˆ˜ ($L$) | 32 |\n",
    "| íˆë“  ì°¨ì› ($d_{model}$) | 4096 |\n",
    "| Q í—¤ë“œ ìˆ˜ ($n_q$) | 32 |\n",
    "| KV í—¤ë“œ ìˆ˜ ($n_{kv}$) | 8 |\n",
    "| í—¤ë“œ ì°¨ì› ($d_{head}$) | 128 |\n",
    "| FFN ì°¨ì› ($d_{ff}$) | 14336 |\n",
    "| ì´ íŒŒë¼ë¯¸í„° | ~8B |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Prefill vs Decode FLOPs/ë©”ëª¨ë¦¬ ë¶„ì„ (Llama 3 8B) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Llama 3 8B íŒŒë¼ë¯¸í„°\n",
    "L = 32          # ë ˆì´ì–´ ìˆ˜\n",
    "d_model = 4096  # íˆë“  ì°¨ì›\n",
    "n_q = 32        # Q í—¤ë“œ ìˆ˜\n",
    "n_kv = 8        # KV í—¤ë“œ ìˆ˜\n",
    "d_head = 128    # í—¤ë“œ ì°¨ì›\n",
    "d_ff = 14336    # FFN ì°¨ì›\n",
    "P = 8e9         # ì´ íŒŒë¼ë¯¸í„°\n",
    "\n",
    "seq_lengths = [128, 256, 512, 1024, 2048, 4096]\n",
    "batch_size = 1\n",
    "\n",
    "print(f\"{'':=<70}\")\n",
    "print(f\"  Llama 3 8B: Prefill vs Decode ì—°ì‚° ë¶„ì„\")\n",
    "print(f\"{'':=<70}\")\n",
    "print(f\"{'Seq Len':>8} | {'Prefill FLOPs':>15} | {'Decode FLOPs':>15} | {'AI(Prefill)':>12} | {'AI(Decode)':>11}\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "prefill_ais = []\n",
    "decode_ais = []\n",
    "\n",
    "for S in seq_lengths:\n",
    "    # Prefill: ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬ (í–‰ë ¬-í–‰ë ¬ ê³±)\n",
    "    # Attention: Q*K^T + Attn*V â†’ 2 * n_q * S * S * d_head per layer\n",
    "    attn_flops_prefill = L * 2 * n_q * S * S * d_head * 2\n",
    "    # Linear projections: QKV + Output â†’ ê° d_model * d_model * S * 2\n",
    "    qkv_flops = L * 2 * S * d_model * (d_model + 2 * n_kv * d_head) * 2\n",
    "    # FFN: gate + up + down (SwiGLU)\n",
    "    ffn_flops = L * 2 * S * d_model * d_ff * 3 * 2\n",
    "    prefill_flops = attn_flops_prefill + qkv_flops + ffn_flops\n",
    "\n",
    "    # ë©”ëª¨ë¦¬: ëª¨ë“  ê°€ì¤‘ì¹˜ ì½ê¸° + í™œì„±í™”\n",
    "    weight_bytes = 2 * P * 2  # FP16, ì½ê¸° 1íšŒ\n",
    "    activation_bytes = 2 * L * S * d_model * 2\n",
    "    prefill_bytes = weight_bytes + activation_bytes\n",
    "\n",
    "    # Decode: í† í° 1ê°œì”© (ë²¡í„°-í–‰ë ¬ ê³±)\n",
    "    attn_flops_decode = L * 2 * n_q * 1 * S * d_head * 2\n",
    "    qkv_flops_d = L * 2 * 1 * d_model * (d_model + 2 * n_kv * d_head) * 2\n",
    "    ffn_flops_d = L * 2 * 1 * d_model * d_ff * 3 * 2\n",
    "    decode_flops = attn_flops_decode + qkv_flops_d + ffn_flops_d\n",
    "\n",
    "    # Decode ë©”ëª¨ë¦¬: ê°€ì¤‘ì¹˜ ì „ì²´ + KV cache ì½ê¸°\n",
    "    kv_cache_bytes = 2 * L * n_kv * d_head * S * 2 * 2  # K,V * layers * FP16\n",
    "    decode_bytes = weight_bytes + kv_cache_bytes\n",
    "\n",
    "    ai_prefill = prefill_flops / prefill_bytes\n",
    "    ai_decode = decode_flops / decode_bytes\n",
    "    prefill_ais.append(ai_prefill)\n",
    "    decode_ais.append(ai_decode)\n",
    "\n",
    "    print(f\"{S:>8} | {prefill_flops:>15.2e} | {decode_flops:>15.2e} | {ai_prefill:>12.1f} | {ai_decode:>11.1f}\")\n",
    "\n",
    "print(f\"\\nê²°ë¡ :\")\n",
    "print(f\"  Prefill AI: {min(prefill_ais):.0f} ~ {max(prefill_ais):.0f} (ì‹œí€€ìŠ¤ ê¸¸ì´ì— ë¹„ë¡€ ì¦ê°€)\")\n",
    "print(f\"  Decode AI:  {min(decode_ais):.1f} ~ {max(decode_ais):.1f} (í•­ìƒ ë‚®ìŒ â†’ Memory-bound)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Roofline ì‹œê°í™” <a name='3.-Roofline-ì‹œê°í™”'></a>\n",
    "\n",
    "A100 GPU ìŠ¤í™ì„ ê¸°ì¤€ìœ¼ë¡œ Roofline ëª¨ë¸ì„ ê·¸ë¦¬ê³ , Prefill/Decode ì—°ì‚° ì§€ì ì„ í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "\n",
    "| A100 ìŠ¤í™ | ê°’ |\n",
    "|-----------|-----|\n",
    "| FP16 Peak | 312 TFLOPS |\n",
    "| HBM ëŒ€ì—­í­ | 2.0 TB/s |\n",
    "| Ridge Point | 156 FLOPs/Byte |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Roofline ëª¨ë¸ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "peak_flops = 312e12   # A100 FP16: 312 TFLOPS\n",
    "mem_bw = 2.0e12       # A100 HBM: 2.0 TB/s\n",
    "ridge_point = peak_flops / mem_bw  # 156 FLOPs/Byte\n",
    "\n",
    "ai_range = np.logspace(-1, 4, 500)\n",
    "roofline = np.minimum(peak_flops, ai_range * mem_bw)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "ax.loglog(ai_range, roofline / 1e12, 'b-', lw=3, label='Roofline (A100)')\n",
    "ax.axvline(x=ridge_point, color='gray', ls='--', lw=1.5, alpha=0.7, label=f'Ridge Point = {ridge_point:.0f}')\n",
    "\n",
    "seq_labels = [128, 512, 2048, 4096]\n",
    "colors_p = ['#2196F3', '#1976D2', '#0D47A1', '#0A3069']\n",
    "colors_d = ['#FF9800', '#F57C00', '#E65100', '#BF360C']\n",
    "\n",
    "for i, S in enumerate(seq_labels):\n",
    "    idx = seq_lengths.index(S)\n",
    "    ai_p = prefill_ais[idx]\n",
    "    perf_p = min(peak_flops, ai_p * mem_bw)\n",
    "    ax.plot(ai_p, perf_p / 1e12, 'o', ms=12, color=colors_p[i],\n",
    "            label=f'Prefill S={S}', zorder=5)\n",
    "\n",
    "    ai_d = decode_ais[idx]\n",
    "    perf_d = min(peak_flops, ai_d * mem_bw)\n",
    "    ax.plot(ai_d, perf_d / 1e12, 's', ms=10, color=colors_d[i],\n",
    "            label=f'Decode S={S}', zorder=5)\n",
    "\n",
    "ax.fill_between([0.1, ridge_point], [0.0001, 0.0001], [1000, 1000],\n",
    "                alpha=0.05, color='orange')\n",
    "ax.fill_between([ridge_point, 10000], [0.0001, 0.0001], [1000, 1000],\n",
    "                alpha=0.05, color='blue')\n",
    "ax.text(2, 200, 'Memory\\nBound', fontsize=14, color='orange', fontweight='bold', alpha=0.6)\n",
    "ax.text(1500, 200, 'Compute\\nBound', fontsize=14, color='blue', fontweight='bold', alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('Arithmetic Intensity (FLOPs/Byte)', fontsize=11)\n",
    "ax.set_ylabel('Performance (TFLOPS)', fontsize=11)\n",
    "ax.set_title('Roofline Model: LLM Prefill vs Decode (A100 GPU)', fontweight='bold')\n",
    "ax.legend(fontsize=8, loc='lower right', ncol=2)\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "ax.set_xlim(0.1, 10000)\n",
    "ax.set_ylim(0.1, 500)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter14_extreme_inference/roofline_prefill_decode.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/roofline_prefill_decode.png\")\n",
    "print(f\"\\nRidge Point: {ridge_point:.0f} FLOPs/Byte\")\n",
    "print(f\"Prefill â†’ Compute-bound ì˜ì—­ (AI >> Ridge)\")\n",
    "print(f\"Decode  â†’ Memory-bound ì˜ì—­ (AI << Ridge)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "## 4. TTFT / TPOT ì¸¡ì • ì‹œë®¬ë ˆì´ì…˜ <a name='4.-TTFT-/-TPOT'></a>\n",
    "\n",
    "ì‹¤ì œ GPU ì—†ì´ë„ **ì´ë¡ ì  TTFTì™€ TPOTë¥¼ ê³„ì‚°**í•˜ì—¬ ì¶”ë¡  ì‹œê°„ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$\\text{TTFT} \\approx \\frac{2 \\cdot P \\cdot S_{input}}{\\text{GPU FLOPS}}, \\quad \\text{TPOT} \\approx \\frac{2P \\cdot \\text{bytes\\_per\\_param}}{\\text{Memory BW}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ TTFT / TPOT ì´ë¡  ê³„ì‚° ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# GPU ìŠ¤í™\n",
    "gpus = {\n",
    "    'A100 (FP16)': {'flops': 312e12, 'bw': 2.0e12},\n",
    "    'H100 (FP16)': {'flops': 989e12, 'bw': 3.35e12},\n",
    "    'H200 (FP16)': {'flops': 989e12, 'bw': 4.8e12},\n",
    "}\n",
    "\n",
    "P = 8e9\n",
    "bytes_per_param = 2  # FP16\n",
    "input_lengths = [128, 256, 512, 1024, 2048]\n",
    "output_length = 128\n",
    "\n",
    "print(f\"{'':=<80}\")\n",
    "print(f\"  Llama 3 8B ì¶”ë¡  ì‹œê°„ ì˜ˆì¸¡ (TTFT + TPOT)\")\n",
    "print(f\"{'':=<80}\")\n",
    "\n",
    "for gpu_name, specs in gpus.items():\n",
    "    flops = specs['flops']\n",
    "    bw = specs['bw']\n",
    "\n",
    "    tpot = (2 * P * bytes_per_param) / bw * 1000  # ms\n",
    "\n",
    "    print(f\"\\n  GPU: {gpu_name}\")\n",
    "    print(f\"  {'Input Len':>10} | {'TTFT (ms)':>10} | {'TPOT (ms)':>10} | {'Total 128tok (ms)':>18} | {'tok/s':>8}\")\n",
    "    print(f\"  {'-'*65}\")\n",
    "\n",
    "    for S_in in input_lengths:\n",
    "        ttft = (2 * P * S_in) / flops * 1000  # ms\n",
    "        total = ttft + tpot * output_length\n",
    "        tps = output_length / (total / 1000)\n",
    "\n",
    "        print(f\"  {S_in:>10} | {ttft:>10.1f} | {tpot:>10.2f} | {total:>18.1f} | {tps:>8.1f}\")\n",
    "\n",
    "print(f\"\\ní•µì‹¬ ì¸ì‚¬ì´íŠ¸:\")\n",
    "print(f\"  1. TTFTëŠ” ì…ë ¥ ê¸¸ì´ì— ë¹„ë¡€ (Compute-bound)\")\n",
    "print(f\"  2. TPOTëŠ” ì…ë ¥ ê¸¸ì´ì™€ ë¬´ê´€ (Memory-bound, ê°€ì¤‘ì¹˜ ì½ê¸° ì‹œê°„)\")\n",
    "print(f\"  3. H200ì˜ ë†’ì€ ëŒ€ì—­í­(4.8TB/s)ì´ TPOTë¥¼ í¬ê²Œ ê°œì„ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë°°ì¹˜ í¬ê¸°ì™€ ì²˜ë¦¬ëŸ‰ ê´€ê³„ <a name='5.-ë°°ì¹˜-í¬ê¸°ì™€-ì²˜ë¦¬ëŸ‰'></a>\n",
    "\n",
    "ë°°ì¹˜ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ë©´ **ë™ì¼í•œ ê°€ì¤‘ì¹˜ ì½ê¸°**ë¡œ ì—¬ëŸ¬ ìš”ì²­ì„ ì²˜ë¦¬í•˜ë¯€ë¡œ ì²˜ë¦¬ëŸ‰ì´ í–¥ìƒë©ë‹ˆë‹¤.\n",
    "ê·¸ëŸ¬ë‚˜ KV Cache ë©”ëª¨ë¦¬ê°€ ë°°ì¹˜ì— ë¹„ë¡€í•˜ì—¬ ì¦ê°€í•˜ë¯€ë¡œ GPU ë©”ëª¨ë¦¬ê°€ í•œê³„ì ì´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ë°°ì¹˜ í¬ê¸° vs ì²˜ë¦¬ëŸ‰/ì§€ì—° ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# A100 80GB ê¸°ì¤€\n",
    "gpu_mem = 80e9   # 80 GB\n",
    "peak_flops = 312e12\n",
    "mem_bw = 2.0e12\n",
    "P = 8e9\n",
    "\n",
    "L, n_kv, d_head = 32, 8, 128\n",
    "S_max = 2048\n",
    "bytes_per_param = 2\n",
    "\n",
    "model_mem = P * bytes_per_param\n",
    "print(f\"ëª¨ë¸ ê°€ì¤‘ì¹˜ ë©”ëª¨ë¦¬: {model_mem / 1e9:.1f} GB\")\n",
    "\n",
    "batch_sizes = list(range(1, 65))\n",
    "throughputs = []\n",
    "latencies = []\n",
    "kv_mems = []\n",
    "\n",
    "for B in batch_sizes:\n",
    "    kv_cache_per_token = 2 * L * n_kv * d_head * bytes_per_param\n",
    "    kv_cache = B * S_max * kv_cache_per_token\n",
    "    total_mem = model_mem + kv_cache\n",
    "\n",
    "    if total_mem > gpu_mem:\n",
    "        throughputs.append(None)\n",
    "        latencies.append(None)\n",
    "        kv_mems.append(kv_cache / 1e9)\n",
    "        continue\n",
    "\n",
    "    kv_mems.append(kv_cache / 1e9)\n",
    "\n",
    "    # Decode: ê°€ì¤‘ì¹˜ 1íšŒ ì½ê¸° + KV cache ì½ê¸°ë¡œ Bê°œ í† í° ë™ì‹œ ìƒì„±\n",
    "    weight_read_time = (P * bytes_per_param) / mem_bw\n",
    "    kv_read_time = (kv_cache) / mem_bw\n",
    "    compute_time = (2 * P * B) / peak_flops\n",
    "\n",
    "    step_time = max(weight_read_time + kv_read_time, compute_time)\n",
    "    latency = step_time * 1000  # ms per step\n",
    "    throughput = B / step_time  # tokens/s\n",
    "\n",
    "    throughputs.append(throughput)\n",
    "    latencies.append(latency)\n",
    "\n",
    "max_batch = max(i+1 for i, t in enumerate(throughputs) if t is not None)\n",
    "print(f\"ìµœëŒ€ ë°°ì¹˜ í¬ê¸° (A100 80GB, S={S_max}): {max_batch}\")\n",
    "print(f\"\\n{'Batch':>6} | {'Throughput':>12} | {'Latency':>10} | {'KV Cache':>10} | {'Total Mem':>10}\")\n",
    "print(f\"{'-'*58}\")\n",
    "\n",
    "for i, B in enumerate(batch_sizes):\n",
    "    if B in [1, 2, 4, 8, 16, 32, max_batch]:\n",
    "        if throughputs[i] is not None:\n",
    "            total = model_mem / 1e9 + kv_mems[i]\n",
    "            print(f\"{B:>6} | {throughputs[i]:>10.0f} t/s | {latencies[i]:>8.2f} ms | {kv_mems[i]:>8.1f} GB | {total:>8.1f} GB\")\n",
    "\n",
    "print(f\"\\nê²°ë¡ :\")\n",
    "print(f\"  ë°°ì¹˜ ì¦ê°€ â†’ ì²˜ë¦¬ëŸ‰ ì¦ê°€ (ê°€ì¤‘ì¹˜ ì½ê¸°ë¥¼ ê³µìœ )\")\n",
    "print(f\"  ë°°ì¹˜ ì¦ê°€ â†’ KV Cache ë©”ëª¨ë¦¬ ì¦ê°€ â†’ GPU ë©”ëª¨ë¦¬ í•œê³„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ë°°ì¹˜ í¬ê¸° vs ì²˜ë¦¬ëŸ‰ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "valid_b = [b for b, t in zip(batch_sizes, throughputs) if t is not None]\n",
    "valid_t = [t for t in throughputs if t is not None]\n",
    "valid_l = [l for l in latencies if l is not None]\n",
    "valid_kv = [kv_mems[i] for i, t in enumerate(throughputs) if t is not None]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.plot(valid_b, valid_t, 'b-o', lw=2, ms=4, label='Throughput')\n",
    "ax1.set_xlabel('Batch Size', fontsize=11)\n",
    "ax1.set_ylabel('Throughput (tokens/s)', fontsize=11)\n",
    "ax1.set_title('Batch Size vs Throughput', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(fontsize=9)\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.plot(valid_b, valid_l, 'r-s', lw=2, ms=4, label='Latency per step')\n",
    "ax2.set_xlabel('Batch Size', fontsize=11)\n",
    "ax2.set_ylabel('Latency (ms)', fontsize=11)\n",
    "ax2.set_title('Batch Size vs Latency', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(fontsize=9)\n",
    "\n",
    "ax3 = axes[2]\n",
    "total_mems = [model_mem / 1e9 + kv for kv in valid_kv]\n",
    "ax3.bar(valid_b, [model_mem / 1e9] * len(valid_b), color='steelblue', label='Model Weights')\n",
    "ax3.bar(valid_b, valid_kv, bottom=[model_mem / 1e9] * len(valid_b), color='coral', label='KV Cache')\n",
    "ax3.axhline(y=80, color='red', ls='--', lw=2, label='A100 80GB Limit')\n",
    "ax3.set_xlabel('Batch Size', fontsize=11)\n",
    "ax3.set_ylabel('Memory (GB)', fontsize=11)\n",
    "ax3.set_title('Memory Breakdown', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter14_extreme_inference/batch_throughput_analysis.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/batch_throughput_analysis.png\")\n",
    "print(f\"\\nìµœëŒ€ ì²˜ë¦¬ëŸ‰: {max(valid_t):.0f} tokens/s (Batch={valid_b[valid_t.index(max(valid_t))]})\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "## 6. ì •ë¦¬ <a name='6.-ì •ë¦¬'></a>\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |\n",
    "|------|------|--------|\n",
    "| Arithmetic Intensity | FLOPs / Bytes â€” ì—°ì‚° vs ë©”ëª¨ë¦¬ ë³‘ëª© íŒë³„ | â­â­â­ |\n",
    "| Prefill (Compute-bound) | ì „ì²´ ì‹œí€€ìŠ¤ í–‰ë ¬ê³±, AI âˆ S | â­â­â­ |\n",
    "| Decode (Memory-bound) | í•œ í† í°ì”© ë²¡í„°-í–‰ë ¬ê³±, AI â‰ˆ 1 | â­â­â­ |\n",
    "| Roofline Model | Peak FLOPSì™€ Bandwidthë¡œ ì„±ëŠ¥ ìƒí•œ ëª¨ë¸ë§ | â­â­â­ |\n",
    "| TTFT | ì²« í† í° ì‹œê°„, ì…ë ¥ ê¸¸ì´ì— ë¹„ë¡€ | â­â­ |\n",
    "| TPOT | í† í° ë‹¹ ì‹œê°„, ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì— ë°˜ë¹„ë¡€ | â­â­ |\n",
    "| Batch Size íš¨ê³¼ | ì²˜ë¦¬ëŸ‰â†‘, KV Cache ë©”ëª¨ë¦¬â†‘ | â­â­â­ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$\\text{AI} = \\frac{\\text{FLOPs}}{\\text{Bytes Transferred}}, \\quad \\text{Performance} = \\min(\\text{Peak FLOPS}, \\text{AI} \\times \\text{BW})$$\n",
    "\n",
    "$$\\text{TTFT} = \\frac{2PS_{in}}{\\text{GPU FLOPS}}, \\quad \\text{TPOT} = \\frac{2P \\cdot b}{\\text{Memory BW}}$$\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**02_flash_attention_deepdive.ipynb** â€” FlashAttentionì˜ IO ë³µì¡ë„ ìˆ˜ì‹, Tiling + Recomputation ì›ë¦¬, v1â†’v2â†’v3 ì„±ëŠ¥ ë°œì „ì‚¬ë¥¼ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}