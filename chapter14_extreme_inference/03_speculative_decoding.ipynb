{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: ê·¹ë‹¨ì  ì¶”ë¡  ìµœì í™” â€” Speculative Decoding\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- Speculative Decodingì˜ **Draft-Verify íŒ¨ëŸ¬ë‹¤ì„**ì´ ì™œ Memory-bound Decodeë¥¼ ê°€ì†í•˜ëŠ”ì§€ ì´í•´í•œë‹¤\n",
    "- ìˆ˜ìš©ë¥ (acceptance rate) $\\beta$ì™€ ë“œë˜í”„íŠ¸ ê¸¸ì´ $k$ë¡œë¶€í„° **ê¸°ëŒ€ ìˆ˜ìš© í† í° ìˆ˜ë¥¼ ìœ ë„**í•œë‹¤\n",
    "- ê²€ì¦(Verification) ë‹¨ê³„ì˜ **ìˆ˜í•™ì  ì •í™•ì„± ë³´ì¥ ë©”ì»¤ë‹ˆì¦˜**ì„ ì´í•´í•œë‹¤\n",
    "- Medusa, EAGLE ë“± **ë‹¤ì¤‘ í—¤ë“œ ë°©ì‹**ì˜ ì•„í‚¤í…ì²˜ì™€ Trade-offë¥¼ ë¹„êµí•œë‹¤\n",
    "- TensorFlowë¡œ Draft-Verify ì‹œë®¬ë ˆì´ì…˜ì„ êµ¬í˜„í•˜ê³  **ì†ë„ í–¥ìƒì„ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦**í•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: ìˆ˜ìš©ë¥ ê³¼ ê¸°ëŒ€ í† í° ìˆ˜](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [Draft-Verify ì‹œë®¬ë ˆì´ì…˜](#2.-Draft-Verify-ì‹œë®¬ë ˆì´ì…˜)\n",
    "3. [ê¸°ëŒ€ ì†ë„ í–¥ìƒ ë¶„ì„](#3.-ì†ë„-í–¥ìƒ-ë¶„ì„)\n",
    "4. [Medusa vs EAGLE ì•„í‚¤í…ì²˜ ë¹„êµ](#4.-Medusa-vs-EAGLE)\n",
    "5. [í† í° ìˆ˜ìš© ì‹œê°í™”](#5.-í† í°-ìˆ˜ìš©-ì‹œê°í™”)\n",
    "6. [ì •ë¦¬](#6.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>\n",
    "\n",
    "### Speculative Decoding í•µì‹¬ ì•„ì´ë””ì–´\n",
    "\n",
    "Decode ë‹¨ê³„ëŠ” **Memory-bound**ì´ë¯€ë¡œ, ì‘ì€ Draft ëª¨ë¸ë¡œ $k$ê°œ í† í°ì„ ë¹ ë¥´ê²Œ ìƒì„±í•œ í›„\n",
    "í° Target ëª¨ë¸ë¡œ **í•œ ë²ˆì˜ Forward Passë¡œ ë³‘ë ¬ ê²€ì¦**í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ìˆ˜ìš© í™•ë¥  (Acceptance Probability)\n",
    "\n",
    "Draft ëª¨ë¸ì˜ ë¶„í¬ $q(x)$, Target ëª¨ë¸ì˜ ë¶„í¬ $p(x)$ì— ëŒ€í•´:\n",
    "\n",
    "$$\\alpha(x) = \\min\\left(1, \\frac{p(x)}{q(x)}\\right)$$\n",
    "\n",
    "- $\\alpha(x)$: í† í° $x$ì˜ ìˆ˜ìš© í™•ë¥ \n",
    "- $q(x) \\leq p(x)$ì¸ í† í°ì€ í•­ìƒ ìˆ˜ìš©\n",
    "- $q(x) > p(x)$ì¸ í† í°ì€ $p(x)/q(x)$ í™•ë¥ ë¡œ ìˆ˜ìš©\n",
    "\n",
    "### ê¸°ëŒ€ ìˆ˜ìš© í† í° ìˆ˜\n",
    "\n",
    "ë“œë˜í”„íŠ¸ ê¸¸ì´ $k$, í‰ê·  ìˆ˜ìš©ë¥  $\\beta$ì¼ ë•Œ, ê¸°ëŒ€ ìˆ˜ìš© í† í° ìˆ˜:\n",
    "\n",
    "$$E[\\text{accepted}] = \\frac{1 - \\beta^{k+1}}{1 - \\beta}$$\n",
    "\n",
    "**ìœ ë„:**\n",
    "- ì²« ë²ˆì§¸ í† í° ìˆ˜ìš© í™•ë¥ : $\\beta$\n",
    "- $i$ë²ˆì§¸ í† í°ê¹Œì§€ **ëª¨ë‘** ìˆ˜ìš©ë  í™•ë¥ : $\\beta^i$\n",
    "- ê¸°ëŒ€ ìˆ˜ìš© ìˆ˜: $\\sum_{i=0}^{k} \\beta^i = \\frac{1 - \\beta^{k+1}}{1 - \\beta}$ (ë“±ë¹„ê¸‰ìˆ˜)\n",
    "\n",
    "ê±°ë¶€ ì‹œ Target ëª¨ë¸ì˜ ìˆ˜ì •ëœ ë¶„í¬ì—ì„œ 1ê°œ í† í°ì„ ìƒ˜í”Œë§í•˜ë¯€ë¡œ, ìµœì†Œ 1ê°œ í† í°ì€ í•­ìƒ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "\n",
    "### Speedup ê³µì‹\n",
    "\n",
    "$$\\text{Speedup} = \\frac{E[\\text{accepted}]}{c \\cdot k + 1}$$\n",
    "\n",
    "- $c$: Draft ëª¨ë¸ì˜ ìƒëŒ€ì  ë¹„ìš© ($c = T_{draft} / T_{target}$, ë³´í†µ $c \\approx 0.05 \\sim 0.1$)\n",
    "- $k$: ë“œë˜í”„íŠ¸ ê¸¸ì´\n",
    "- ë¶„ëª¨ì˜ 1: Target ëª¨ë¸ ê²€ì¦ 1íšŒ\n",
    "\n",
    "### ê²€ì¦ì˜ ì •í™•ì„±\n",
    "\n",
    "Speculative Decodingì€ **Target ëª¨ë¸ì˜ ì¶œë ¥ ë¶„í¬ë¥¼ ì •í™•íˆ ë³´ì¡´**í•©ë‹ˆë‹¤:\n",
    "\n",
    "ê±°ë¶€ ì‹œ ìˆ˜ì • ë¶„í¬: $p'(x) = \\text{norm}\\left(\\max(0, p(x) - q(x))\\right)$\n",
    "\n",
    "$$\\text{ìµœì¢… ë¶„í¬} = \\alpha \\cdot q(x) + (1-\\alpha) \\cdot p'(x) = p(x)$$\n",
    "\n",
    "**ìš”ì•½ í‘œ:**\n",
    "\n",
    "| ì§€í‘œ | ìˆ˜ì‹ | ì˜ë¯¸ |\n",
    "|------|------|------|\n",
    "| ìˆ˜ìš© í™•ë¥  | $\\min(1, p(x)/q(x))$ | í† í°ë³„ ìˆ˜ìš©/ê±°ë¶€ ê²°ì • |\n",
    "| ê¸°ëŒ€ í† í° ìˆ˜ | $(1-\\beta^{k+1})/(1-\\beta)$ | í•œ ë¼ìš´ë“œ í‰ê·  ìƒì„± ìˆ˜ |\n",
    "| Speedup | $E[\\text{acc}] / (ck + 1)$ | ì´ë¡ ì  ì†ë„ í–¥ìƒ |\n",
    "| ìˆ˜ì • ë¶„í¬ | $\\text{norm}(\\max(0, p-q))$ | ë¶„í¬ ì •í™•ì„± ë³´ì¥ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ Speculative Decoding ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ”¢ Draft-Verifyê°€ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: ìˆ˜í•™ ì‹œí—˜ì—ì„œ **ì—°ìŠµì¥ì— ë¹ ë¥´ê²Œ ë‹µì„ ì“°ê³ **, ì„ ìƒë‹˜ì´ í•œêº¼ë²ˆì— ì±„ì í•˜ëŠ” ê²ƒ!\n",
    "\n",
    "**ê¸°ì¡´ ë°©ì‹**: ì„ ìƒë‹˜(í° ëª¨ë¸)ì´ í•œ ë¬¸ì œì”© ì§ì ‘ í’€ì–´ìš”. ì •í™•í•˜ì§€ë§Œ ëŠë ¤ìš”! ğŸ¢\n",
    "\n",
    "**Speculative Decoding**: \n",
    "1. í•™ìƒ(ì‘ì€ Draft ëª¨ë¸)ì´ ì—°ìŠµì¥ì— 5ë¬¸ì œë¥¼ ë¹ ë¥´ê²Œ í’€ì–´ìš” âœï¸\n",
    "2. ì„ ìƒë‹˜(í° Target ëª¨ë¸)ì´ 5ë¬¸ì œë¥¼ **í•œ ë²ˆì—** ì±„ì í•´ìš” âœ…âŒ\n",
    "3. ë§ì€ ë°ê¹Œì§€ ì±„íƒí•˜ê³ , í‹€ë¦° ë¬¸ì œë¶€í„° ì„ ìƒë‹˜ì´ ì§ì ‘ ë‹µì„ ì¨ìš”\n",
    "\n",
    "ì„ ìƒë‹˜ì´ ì±„ì í•˜ëŠ” ì‹œê°„ = ë¬¸ì œ 1ê°œ í‘¸ëŠ” ì‹œê°„ì´ë‹ˆê¹Œ, í•™ìƒì´ ì˜ ë§ì¶œìˆ˜ë¡ ë¹¨ë¼ì ¸ìš”!\n",
    "\n",
    "#### ğŸ“Š ìˆ˜ìš©ë¥ ì´ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: í•™ìƒì˜ **ì •ë‹µë¥ **ì´ì—ìš”!\n",
    "\n",
    "- ìˆ˜ìš©ë¥  90% â†’ 10ë¬¸ì œ ì¤‘ 9ë¬¸ì œë¥¼ ë§ì¶°ìš” â†’ ê±°ì˜ 10ë°° ë¹¨ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”!\n",
    "- ìˆ˜ìš©ë¥  50% â†’ 10ë¬¸ì œ ì¤‘ 5ë¬¸ì œë¥¼ ë§ì¶°ìš” â†’ ì•½ 2ë°° ë¹¨ë¼ì ¸ìš”\n",
    "- ìˆ˜ìš©ë¥ ì´ ë‚®ìœ¼ë©´ ì˜¤íˆë ¤ í•™ìƒí•œí…Œ ì‹œí‚¤ëŠ” ê²ƒì´ ì†í•´ì˜ˆìš”\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: ê¸°ëŒ€ í† í° ìˆ˜ ê³„ì‚°\n",
    "\n",
    "$\\beta = 0.8$, $k = 5$ì¼ ë•Œ ê¸°ëŒ€ ìˆ˜ìš© í† í° ìˆ˜ëŠ”?\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$$E = \\frac{1 - 0.8^{5+1}}{1 - 0.8} = \\frac{1 - 0.8^6}{0.2} = \\frac{1 - 0.262144}{0.2} = \\frac{0.737856}{0.2} = 3.689$$\n",
    "\n",
    "â†’ í‰ê·  **3.69ê°œ** í† í°ì´ ìˆ˜ìš©ë©ë‹ˆë‹¤. (ìµœì†Œ 1ê°œ ë³´ì¥ì´ë¯€ë¡œ ì‹¤ì œë¡œëŠ” ë” ë†’ì„ ìˆ˜ ìˆìŒ)\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: ìµœì  ë“œë˜í”„íŠ¸ ê¸¸ì´\n",
    "\n",
    "$\\beta = 0.7$, Draft ë¹„ìš© $c = 0.05$ì¼ ë•Œ, Speedupì„ ìµœëŒ€í™”í•˜ëŠ” $k$ëŠ”?\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$k$ë³„ Speedup ê³„ì‚°:\n",
    "\n",
    "| $k$ | $E[\\text{acc}]$ | $ck+1$ | Speedup |\n",
    "|-----|---------|--------|---------|\n",
    "| 1 | $\\frac{1-0.49}{0.3}=1.70$ | 1.05 | 1.62 |\n",
    "| 3 | $\\frac{1-0.7^4}{0.3}=2.37$ | 1.15 | 2.06 |\n",
    "| 5 | $\\frac{1-0.7^6}{0.3}=2.72$ | 1.25 | 2.17 |\n",
    "| 7 | $\\frac{1-0.7^8}{0.3}=2.89$ | 1.35 | 2.14 |\n",
    "| 10 | $\\frac{1-0.7^{11}}{0.3}=2.98$ | 1.50 | 1.99 |\n",
    "\n",
    "â†’ $k=5$ ë¶€ê·¼ì—ì„œ Speedupì´ ìµœëŒ€ (**~2.17x**)! $k$ê°€ ë„ˆë¬´ í¬ë©´ Draft ë¹„ìš©ì´ ì¦ê°€í•˜ì—¬ ì—­íš¨ê³¼.\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "np.random.seed(42)\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n",
    "print(f\"NumPy ë²„ì „: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "## 2. Draft-Verify ì‹œë®¬ë ˆì´ì…˜ <a name='2.-Draft-Verify-ì‹œë®¬ë ˆì´ì…˜'></a>\n",
    "\n",
    "Draft ëª¨ë¸ê³¼ Target ëª¨ë¸ì˜ ë¶„í¬ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ Speculative Decodingì˜ ë™ì‘ì„ ê²€ì¦í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²€ì¦ ì•Œê³ ë¦¬ì¦˜:\n",
    "1. Draft ëª¨ë¸ì—ì„œ $k$ê°œ í† í° $x_1, \\ldots, x_k$ë¥¼ ìê¸°íšŒê·€ ìƒì„±\n",
    "2. Target ëª¨ë¸ì—ì„œ $x_1, \\ldots, x_k$ë¥¼ **í•œ ë²ˆì—** ê²€ì¦\n",
    "3. $\\alpha_i = \\min(1, p(x_i)/q(x_i))$ë¡œ ê° í† í° ìˆ˜ìš©/ê±°ë¶€\n",
    "4. ì²« ë²ˆì§¸ ê±°ë¶€ ìœ„ì¹˜ì—ì„œ ìˆ˜ì • ë¶„í¬ $p'$ì—ì„œ ìƒˆ í† í° ìƒ˜í”Œë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Draft-Verify ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "vocab_size = 100\n",
    "\n",
    "def create_model_distribution(vocab_size, temperature=1.0):\n",
    "    # ì‹œë®¬ë ˆì´ì…˜ìš©: ëœë¤ logitìœ¼ë¡œ ë¶„í¬ ìƒì„±\n",
    "    logits = np.random.randn(vocab_size) / temperature\n",
    "    probs = np.exp(logits) / np.sum(np.exp(logits))\n",
    "    return probs\n",
    "\n",
    "def speculative_decode_step(target_probs, draft_probs, k):\n",
    "    # Draft ë‹¨ê³„: kê°œ í† í° ìƒì„±\n",
    "    draft_tokens = []\n",
    "    for _ in range(k):\n",
    "        token = np.random.choice(len(draft_probs), p=draft_probs)\n",
    "        draft_tokens.append(token)\n",
    "\n",
    "    # Verify ë‹¨ê³„: Target ëª¨ë¸ë¡œ ê²€ì¦\n",
    "    accepted = []\n",
    "    for i, token in enumerate(draft_tokens):\n",
    "        p = target_probs[token]\n",
    "        q = draft_probs[token]\n",
    "        alpha = min(1.0, p / q)\n",
    "\n",
    "        if np.random.random() < alpha:\n",
    "            accepted.append(token)\n",
    "        else:\n",
    "            # ìˆ˜ì • ë¶„í¬ì—ì„œ ìƒˆ í† í° ìƒ˜í”Œë§\n",
    "            residual = np.maximum(0, target_probs - draft_probs)\n",
    "            residual_sum = np.sum(residual)\n",
    "            if residual_sum > 0:\n",
    "                residual /= residual_sum\n",
    "                bonus_token = np.random.choice(len(residual), p=residual)\n",
    "            else:\n",
    "                bonus_token = np.random.choice(len(target_probs), p=target_probs)\n",
    "            accepted.append(bonus_token)\n",
    "            break\n",
    "    else:\n",
    "        # ëª¨ë‘ ìˆ˜ìš©ëœ ê²½ìš°: Targetì—ì„œ ì¶”ê°€ 1ê°œ ìƒì„±\n",
    "        bonus = np.random.choice(len(target_probs), p=target_probs)\n",
    "        accepted.append(bonus)\n",
    "\n",
    "    return accepted, len(draft_tokens)\n",
    "\n",
    "# ë‹¤ì–‘í•œ ìˆ˜ìš©ë¥ ë¡œ ì‹¤í—˜\n",
    "draft_temps = [0.5, 1.0, 2.0, 5.0]\n",
    "k_values = [3, 5, 7]\n",
    "n_trials = 2000\n",
    "\n",
    "print(f\"{'':=<75}\")\n",
    "print(f\"  Speculative Decoding ì‹œë®¬ë ˆì´ì…˜ (vocab={vocab_size}, trials={n_trials})\")\n",
    "print(f\"{'':=<75}\")\n",
    "\n",
    "target_probs = create_model_distribution(vocab_size, temperature=1.0)\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\n  Draft ê¸¸ì´ k={k}:\")\n",
    "    print(f\"  {'Draft Temp':>12} | {'í‰ê·  ìˆ˜ìš©':>8} | {'ìˆ˜ìš©ë¥  Î²':>8} | {'ì´ë¡  E[acc]':>12} | {'ì‹¤ì œ E[acc]':>12}\")\n",
    "    print(f\"  {'-'*62}\")\n",
    "\n",
    "    for temp in draft_temps:\n",
    "        draft_probs = create_model_distribution(vocab_size, temperature=temp)\n",
    "\n",
    "        total_accepted = 0\n",
    "        total_drafted = 0\n",
    "\n",
    "        for _ in range(n_trials):\n",
    "            accepted, drafted = speculative_decode_step(target_probs, draft_probs, k)\n",
    "            total_accepted += len(accepted)\n",
    "            total_drafted += drafted\n",
    "\n",
    "        avg_accepted = total_accepted / n_trials\n",
    "        beta = 1.0 - (total_drafted - total_accepted + n_trials) / (total_drafted + n_trials)\n",
    "        beta = max(0.01, min(0.99, beta))\n",
    "        theoretical = (1 - beta**(k+1)) / (1 - beta)\n",
    "\n",
    "        print(f\"  {temp:>12.1f} | {avg_accepted:>8.2f} | {beta:>8.3f} | {theoretical:>12.2f} | {avg_accepted:>12.2f}\")\n",
    "\n",
    "print(f\"\\nê²°ë¡ : Draft ëª¨ë¸ì´ Targetì— ê°€ê¹Œìš¸ìˆ˜ë¡ (ì˜¨ë„ ìœ ì‚¬) ìˆ˜ìš©ë¥ ì´ ë†’ì•„ì§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "## 3. ê¸°ëŒ€ ì†ë„ í–¥ìƒ ë¶„ì„ <a name='3.-ì†ë„-í–¥ìƒ-ë¶„ì„'></a>\n",
    "\n",
    "ìˆ˜ìš©ë¥  $\\beta$ì™€ ë“œë˜í”„íŠ¸ ê¸¸ì´ $k$ì— ë”°ë¥¸ ì´ë¡ ì  Speedupì„ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$\\text{Speedup}(\\beta, k) = \\frac{(1-\\beta^{k+1}) / (1-\\beta)}{c \\cdot k + 1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ìˆ˜ìš©ë¥  vs ì†ë„ í–¥ìƒ ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "betas = np.linspace(0.01, 0.99, 200)\n",
    "c = 0.05  # Draft ëª¨ë¸ ë¹„ìš© ë¹„ìœ¨\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "for k in [1, 3, 5, 7, 10, 15]:\n",
    "    E_acc = (1 - betas**(k+1)) / (1 - betas)\n",
    "    speedup = E_acc / (c * k + 1)\n",
    "    ax1.plot(betas, speedup, lw=2, label=f'k={k}')\n",
    "\n",
    "ax1.axhline(y=1.0, color='gray', ls='--', lw=1.5, alpha=0.5)\n",
    "ax1.set_xlabel('Acceptance Rate (Î²)', fontsize=11)\n",
    "ax1.set_ylabel('Speedup', fontsize=11)\n",
    "ax1.set_title('Speedup vs Acceptance Rate (c=0.05)', fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 10)\n",
    "\n",
    "# ìµœì  k ì°¾ê¸°\n",
    "ax2 = axes[1]\n",
    "k_range = np.arange(1, 21)\n",
    "for beta in [0.5, 0.7, 0.8, 0.9, 0.95]:\n",
    "    speedups = []\n",
    "    for k in k_range:\n",
    "        E_acc = (1 - beta**(k+1)) / (1 - beta)\n",
    "        sp = E_acc / (c * k + 1)\n",
    "        speedups.append(sp)\n",
    "    optimal_k = k_range[np.argmax(speedups)]\n",
    "    ax2.plot(k_range, speedups, '-o', lw=2, ms=4, label=f'Î²={beta} (optimal k={optimal_k})')\n",
    "\n",
    "ax2.axhline(y=1.0, color='gray', ls='--', lw=1.5, alpha=0.5)\n",
    "ax2.set_xlabel('Draft Length (k)', fontsize=11)\n",
    "ax2.set_ylabel('Speedup', fontsize=11)\n",
    "ax2.set_title('Speedup vs Draft Length (c=0.05)', fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('speculative_speedup.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/speculative_speedup.png\")\n",
    "\n",
    "# ìµœì  k ìš”ì•½í‘œ\n",
    "print(f\"\\n{'Î²':>6} | {'ìµœì  k':>6} | {'ìµœëŒ€ Speedup':>14}\")\n",
    "print(f\"{'-'*32}\")\n",
    "for beta in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
    "    best_sp = 0\n",
    "    best_k = 1\n",
    "    for k in range(1, 30):\n",
    "        E_acc = (1 - beta**(k+1)) / (1 - beta)\n",
    "        sp = E_acc / (c * k + 1)\n",
    "        if sp > best_sp:\n",
    "            best_sp = sp\n",
    "            best_k = k\n",
    "    print(f\"{beta:>6.2f} | {best_k:>6} | {best_sp:>14.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Medusa vs EAGLE ì•„í‚¤í…ì²˜ ë¹„êµ <a name='4.-Medusa-vs-EAGLE'></a>\n",
    "\n",
    "ê¸°ì¡´ Speculative Decodingì€ ë³„ë„ Draft ëª¨ë¸ì´ í•„ìš”í•˜ì§€ë§Œ, **Medusa**ì™€ **EAGLE**ì€ \n",
    "Target ëª¨ë¸ ìì²´ì— ì¶”ê°€ í—¤ë“œë¥¼ ë¶€ì°©í•˜ì—¬ Draft ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ë°©ì‹ | êµ¬ì¡° | Draft ìƒì„± |\n",
    "|------|------|-----------|\n",
    "| ì „í†µ ë°©ì‹ | ë³„ë„ Draft ëª¨ë¸ | ìê¸°íšŒê·€ |\n",
    "| Medusa | Target + ë‹¤ì¤‘ MLP í—¤ë“œ | ë³‘ë ¬ (ë¹„ìê¸°íšŒê·€) |\n",
    "| EAGLE | Target + Feature ê¸°ë°˜ í—¤ë“œ | ìê¸°íšŒê·€ (feature-level) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Medusa vs EAGLE ë¹„êµí‘œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=\" * 95)\n",
    "print(\"  Speculative Decoding ë°©ì‹ ë¹„êµ: ì „í†µ vs Medusa vs EAGLE\")\n",
    "print(\"=\" * 95)\n",
    "\n",
    "headers = ['í•­ëª©', 'ì „í†µ Spec. Decoding', 'Medusa (2024)', 'EAGLE (2024)']\n",
    "rows = [\n",
    "    ['ë…¼ë¬¸', 'Leviathan et al. 2023', 'Cai et al. 2024', 'Li et al. 2024'],\n",
    "    ['Draft ì†ŒìŠ¤', 'ë³„ë„ ì†Œí˜• ëª¨ë¸', 'Target + MLP í—¤ë“œ', 'Target + Autoregressive í—¤ë“œ'],\n",
    "    ['Draft ë°©ì‹', 'ìê¸°íšŒê·€ (ìˆœì°¨)', 'ë¹„ìê¸°íšŒê·€ (ë³‘ë ¬)', 'ìê¸°íšŒê·€ (feature-level)'],\n",
    "    ['í† í° íŠ¸ë¦¬', 'ì„ í˜• ì²´ì¸', 'Tree Attention', 'Tree Attention'],\n",
    "    ['ì¶”ê°€ íŒŒë¼ë¯¸í„°', 'ë³„ë„ ëª¨ë¸ ì „ì²´', '~0.6% (MLP heads)', '~0.2-2% (feature head)'],\n",
    "    ['í•™ìŠµ í•„ìš”', 'Draft ëª¨ë¸ ì‚¬ì „í•™ìŠµ', 'MLP í—¤ë“œ í•™ìŠµ', 'Feature í—¤ë“œ í•™ìŠµ'],\n",
    "    ['í•™ìŠµ ë°ì´í„°', 'ì¼ë°˜ ì½”í¼ìŠ¤', 'Target ì¶œë ¥', 'Target hidden states'],\n",
    "    ['ë¶„í¬ ë³´ì¡´', 'ë³´ì¥ (rejection)', 'ê·¼ì‚¬ì ', 'ë³´ì¥ (rejection)'],\n",
    "    ['ì†ë„ í–¥ìƒ', '~2-3x', '~2-3x', '~2.5-4x'],\n",
    "    ['ë©”ëª¨ë¦¬ ì¶”ê°€', 'í¼ (Draft ëª¨ë¸)', 'ë§¤ìš° ì‘ìŒ', 'ì‘ìŒ'],\n",
    "    ['í˜¸í™˜ì„±', 'ëª¨ë¸ ìŒ í•„ìš”', 'Targetë§Œ ìˆ˜ì •', 'Targetë§Œ ìˆ˜ì •'],\n",
    "]\n",
    "\n",
    "col_widths = [18, 22, 22, 25]\n",
    "header_line = ' | '.join(h.ljust(w) for h, w in zip(headers, col_widths))\n",
    "print(header_line)\n",
    "print('-' * len(header_line))\n",
    "for row in rows:\n",
    "    line = ' | '.join(val.ljust(w) for val, w in zip(row, col_widths))\n",
    "    print(line)\n",
    "\n",
    "# ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”\n",
    "methods = ['Autoregressive\\n(Baseline)', 'Spec. Decoding\\n(70B+7B)', 'Medusa\\n(70B+heads)', 'EAGLE\\n(70B+head)']\n",
    "speedups = [1.0, 2.2, 2.5, 3.5]\n",
    "extra_params = [0, 100, 0.6, 1.5]  # % of base model\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "colors = ['#E0E0E0', '#90CAF9', '#A5D6A7', '#FFB74D']\n",
    "\n",
    "ax1 = axes[0]\n",
    "bars = ax1.bar(methods, speedups, color=colors, edgecolor='black', lw=0.5)\n",
    "for bar, val in zip(bars, speedups):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.08,\n",
    "             f'{val:.1f}x', ha='center', fontsize=11, fontweight='bold')\n",
    "ax1.axhline(y=1.0, color='red', ls='--', lw=1.5, alpha=0.5)\n",
    "ax1.set_ylabel('Speedup', fontsize=11)\n",
    "ax1.set_title('Speculative Decoding ë°©ì‹ë³„ ì†ë„ í–¥ìƒ', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.bar(methods, extra_params, color=colors, edgecolor='black', lw=0.5)\n",
    "for bar, val in zip(bars2, extra_params):\n",
    "    label = f'{val:.1f}%' if val < 10 else f'{val:.0f}%'\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1.5,\n",
    "             label, ha='center', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Extra Parameters (% of Target)', fontsize=11)\n",
    "ax2.set_title('ì¶”ê°€ íŒŒë¼ë¯¸í„° ì˜¤ë²„í—¤ë“œ', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('speculative_methods_comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"\\nê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/speculative_methods_comparison.png\")\n",
    "\n",
    "print(f\"\\ní•µì‹¬ ì¸ì‚¬ì´íŠ¸:\")\n",
    "print(f\"  1. EAGLE: Feature-level ìê¸°íšŒê·€ â†’ ë†’ì€ ìˆ˜ìš©ë¥ ê³¼ ë¶„í¬ ë³´ì¡´\")\n",
    "print(f\"  2. Medusa: ë¹„ìê¸°íšŒê·€ ë³‘ë ¬ â†’ ë¹ ë¥¸ Draft, í•˜ì§€ë§Œ ê·¼ì‚¬ì  ë¶„í¬\")\n",
    "print(f\"  3. ì „í†µ ë°©ì‹: ë³„ë„ ëª¨ë¸ í•„ìš” â†’ ë©”ëª¨ë¦¬ ë¶€ë‹´ì´ í¬ì§€ë§Œ ë²”ìš©ì \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. í† í° ìˆ˜ìš© ì‹œê°í™” <a name='5.-í† í°-ìˆ˜ìš©-ì‹œê°í™”'></a>\n",
    "\n",
    "ì‹¤ì œ Speculative Decodingì—ì„œ í† í°ì´ ì–´ë–»ê²Œ ìˆ˜ìš©/ê±°ë¶€ë˜ëŠ”ì§€ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ í† í° ìˆ˜ìš©/ê±°ë¶€ íŒ¨í„´ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "np.random.seed(42)\n",
    "vocab_size = 50\n",
    "k = 7  # ë“œë˜í”„íŠ¸ ê¸¸ì´\n",
    "n_rounds = 20\n",
    "\n",
    "target_logits = np.random.randn(vocab_size) * 2\n",
    "target_probs = np.exp(target_logits) / np.sum(np.exp(target_logits))\n",
    "\n",
    "draft_logits = target_logits + np.random.randn(vocab_size) * 0.5\n",
    "draft_probs = np.exp(draft_logits) / np.sum(np.exp(draft_logits))\n",
    "\n",
    "acceptance_map = np.zeros((n_rounds, k + 1))\n",
    "accepted_counts = []\n",
    "\n",
    "for r in range(n_rounds):\n",
    "    draft_tokens = [np.random.choice(vocab_size, p=draft_probs) for _ in range(k)]\n",
    "    n_accepted = 0\n",
    "\n",
    "    for i, token in enumerate(draft_tokens):\n",
    "        p = target_probs[token]\n",
    "        q = draft_probs[token]\n",
    "        alpha = min(1.0, p / q)\n",
    "\n",
    "        if np.random.random() < alpha:\n",
    "            acceptance_map[r, i] = 1  # ìˆ˜ìš©\n",
    "            n_accepted += 1\n",
    "        else:\n",
    "            acceptance_map[r, i] = -1  # ê±°ë¶€\n",
    "            break\n",
    "        if i < k - 1:\n",
    "            for j in range(i + 2, k + 1):\n",
    "                acceptance_map[r, j] = 0  # ë¯¸ë„ë‹¬\n",
    "\n",
    "    # ë³´ë„ˆìŠ¤ í† í° (í•­ìƒ 1ê°œ)\n",
    "    if n_accepted == k:\n",
    "        acceptance_map[r, k] = 2  # ë³´ë„ˆìŠ¤\n",
    "\n",
    "    accepted_counts.append(n_accepted + 1)  # +1 ë³´ë„ˆìŠ¤/ìˆ˜ì • í† í°\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 6))\n",
    "\n",
    "# íˆíŠ¸ë§µ\n",
    "ax1 = axes[0]\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(['#BDBDBD', '#EF5350', '#66BB6A', '#42A5F5'])\n",
    "# -1=ê±°ë¶€(ë¹¨), 0=ë¯¸ë„ë‹¬(íšŒ), 1=ìˆ˜ìš©(ì´ˆ), 2=ë³´ë„ˆìŠ¤(íŒŒ)\n",
    "mapped = np.zeros_like(acceptance_map)\n",
    "mapped[acceptance_map == 0] = 0\n",
    "mapped[acceptance_map == -1] = 1\n",
    "mapped[acceptance_map == 1] = 2\n",
    "mapped[acceptance_map == 2] = 3\n",
    "\n",
    "im = ax1.imshow(mapped, cmap=cmap, aspect='auto', interpolation='nearest')\n",
    "ax1.set_xlabel('Token Position', fontsize=11)\n",
    "ax1.set_ylabel('Round', fontsize=11)\n",
    "ax1.set_title(f'Token Acceptance Pattern (k={k})', fontweight='bold')\n",
    "ax1.set_xticks(range(k + 1))\n",
    "ax1.set_xticklabels([f'Draft {i+1}' for i in range(k)] + ['Bonus'])\n",
    "\n",
    "legend_labels = ['Not Reached', 'Rejected', 'Accepted', 'Bonus']\n",
    "legend_colors = ['#BDBDBD', '#EF5350', '#66BB6A', '#42A5F5']\n",
    "patches = [plt.Rectangle((0, 0), 1, 1, fc=c) for c in legend_colors]\n",
    "ax1.legend(patches, legend_labels, loc='lower right', fontsize=8)\n",
    "\n",
    "# ìˆ˜ìš© í† í° ìˆ˜ ë¶„í¬\n",
    "ax2 = axes[1]\n",
    "bins = range(1, k + 3)\n",
    "ax2.hist(accepted_counts, bins=bins, color='#42A5F5', edgecolor='black',\n",
    "         alpha=0.8, align='left', rwidth=0.8)\n",
    "ax2.axvline(x=np.mean(accepted_counts), color='red', ls='--', lw=2,\n",
    "            label=f'Mean = {np.mean(accepted_counts):.1f}')\n",
    "ax2.set_xlabel('Accepted Tokens per Round', fontsize=11)\n",
    "ax2.set_ylabel('Count', fontsize=11)\n",
    "ax2.set_title('Distribution of Accepted Tokens', fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('token_acceptance_pattern.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/token_acceptance_pattern.png\")\n",
    "\n",
    "avg_beta = np.mean([c - 1 for c in accepted_counts]) / k\n",
    "theoretical_E = (1 - avg_beta**(k+1)) / (1 - avg_beta)\n",
    "print(f\"\\nì‹¤í—˜ ê²°ê³¼:\")\n",
    "print(f\"  í‰ê·  ìˆ˜ìš© í† í°: {np.mean(accepted_counts):.2f}\")\n",
    "print(f\"  ì¶”ì • ìˆ˜ìš©ë¥  Î²: {avg_beta:.3f}\")\n",
    "print(f\"  ì´ë¡ ì  E[accepted]: {theoretical_E:.2f}\")\n",
    "print(f\"  Draft ê¸¸ì´: {k}\")\n",
    "print(f\"  ì˜ˆìƒ Speedup (c=0.05): {np.mean(accepted_counts) / (0.05 * k + 1):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "## 6. ì •ë¦¬ <a name='6.-ì •ë¦¬'></a>\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |\n",
    "|------|------|--------|\n",
    "| Draft-Verify | ì†Œí˜• ëª¨ë¸ ì¶”ì¸¡ + ëŒ€í˜• ëª¨ë¸ ë³‘ë ¬ ê²€ì¦ | â­â­â­ |\n",
    "| ìˆ˜ìš©ë¥  $\\beta$ | $\\min(1, p(x)/q(x))$ â€” Draft í’ˆì§ˆ ì§€í‘œ | â­â­â­ |\n",
    "| ê¸°ëŒ€ í† í° ìˆ˜ | $(1-\\beta^{k+1})/(1-\\beta)$ â€” ë“±ë¹„ê¸‰ìˆ˜ | â­â­â­ |\n",
    "| ë¶„í¬ ë³´ì¡´ | ìˆ˜ì • ë¶„í¬ $\\max(0, p-q)$ë¡œ ì •í™•ì„± ë³´ì¥ | â­â­â­ |\n",
    "| Medusa | ë¹„ìê¸°íšŒê·€ ë‹¤ì¤‘ MLP í—¤ë“œ | â­â­ |\n",
    "| EAGLE | Feature-level ìê¸°íšŒê·€ í—¤ë“œ, ìµœê³  ì„±ëŠ¥ | â­â­â­ |\n",
    "| ìµœì  $k$ | $\\beta$ì™€ $c$ì— ë”°ë¼ ìµœì ì  ì¡´ì¬ | â­â­ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$E[\\text{accepted}] = \\frac{1 - \\beta^{k+1}}{1 - \\beta}, \\quad \\text{Speedup} = \\frac{E[\\text{acc}]}{c \\cdot k + 1}$$\n",
    "\n",
    "$$\\alpha(x) = \\min\\left(1, \\frac{p(x)}{q(x)}\\right), \\quad p'(x) = \\text{norm}\\left(\\max(0, p(x) - q(x))\\right)$$\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**04_vllm_and_paged_attention.ipynb** â€” OSì˜ Page Table ê°œë…ì„ KV Cacheì— ì ìš©í•œ PagedAttention, Continuous Batching, ë™ì  KV Block ìŠ¤ì¼€ì¤„ë§ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}