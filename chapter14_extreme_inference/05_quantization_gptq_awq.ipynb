{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: ê·¹ë‹¨ì  ì¶”ë¡  ìµœì í™” â€” ì–‘ìí™” ì‹¬í™” (GPTQ & AWQ)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- **Post-Training Quantization(PTQ)**ì˜ ê¸°ë³¸ ì›ë¦¬ì™€ ê· ì¼ ì–‘ìí™”(Uniform Quantization)ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ì´í•´í•œë‹¤\n",
    "- **GPTQ**ì˜ Hessian ê¸°ë°˜ 2ì°¨ ìµœì í™”ê°€ ê°€ì¤‘ì¹˜ ì–‘ìí™” ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê³¼ì •ì„ ë„ì¶œí•œë‹¤\n",
    "- **AWQ(Activation-aware Weight Quantization)**ì˜ ì±„ë„ë³„ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ì¤‘ìš” ê°€ì¤‘ì¹˜ë¥¼ ë³´í˜¸í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•œë‹¤\n",
    "- W4A16, INT8, FP8 ë“± ë‹¤ì–‘í•œ ì–‘ìí™” í¬ë§·ì˜ **ì •ë°€ë„-ì†ë„-ë©”ëª¨ë¦¬ íŠ¸ë ˆì´ë“œì˜¤í”„**ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµí•œë‹¤\n",
    "- SNR(Signal-to-Noise Ratio)ê³¼ ë¹„íŠ¸í­ì˜ ê´€ê³„ë¥¼ ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦í•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: ì–‘ìí™” ì´ë¡ ](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [ê· ì¼ ì–‘ìí™” ë°ëª¨ (INT8, INT4)](#2.-ê· ì¼-ì–‘ìí™”-ë°ëª¨)\n",
    "3. [ì–‘ìí™” ì˜¤ì°¨ vs ë¹„íŠ¸í­ ì‹œê°í™”](#3.-ì–‘ìí™”-ì˜¤ì°¨-ì‹œê°í™”)\n",
    "4. [AWQ í•µì‹¬ ì±„ë„ íƒì§€ ì‹œë®¬ë ˆì´ì…˜](#4.-AWQ-í•µì‹¬-ì±„ë„)\n",
    "5. [W4A16 / INT8 / FP8 ë¹„êµ ë²¤ì¹˜ë§ˆí¬](#5.-í¬ë§·-ë¹„êµ)\n",
    "6. [ì •ë¦¬](#6.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>\n",
    "\n",
    "### ê· ì¼ ì–‘ìí™” (Uniform Quantization)\n",
    "\n",
    "ì‹¤ìˆ˜ê°’ì„ $b$-bit ì •ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ë³¸ ê³µì‹:\n",
    "\n",
    "$$\\Delta = \\frac{x_{max} - x_{min}}{2^b - 1}$$\n",
    "\n",
    "$$x_q = \\text{round}\\left(\\frac{x - x_{min}}{\\Delta}\\right), \\quad x_q \\in \\{0, 1, \\ldots, 2^b - 1\\}$$\n",
    "\n",
    "$$\\hat{x} = x_q \\cdot \\Delta + x_{min} \\quad \\text{(ì—­ì–‘ìí™”)}$$\n",
    "\n",
    "- $\\Delta$: ì–‘ìí™” ìŠ¤í… í¬ê¸° (step size)\n",
    "- $b$: ë¹„íŠ¸í­ (bit-width)\n",
    "- $x_q$: ì–‘ìí™”ëœ ì •ìˆ˜ê°’\n",
    "- $\\hat{x}$: ë³µì›ëœ ê·¼ì‚¬ê°’\n",
    "\n",
    "### ì–‘ìí™” ì˜¤ì°¨ì™€ SNR\n",
    "\n",
    "ì–‘ìí™” ì˜¤ì°¨ëŠ” ê· ì¼ ë¶„í¬ë¥¼ ë”°ë¥´ë©°:\n",
    "\n",
    "$$\\text{MSE}_{quant} = \\frac{\\Delta^2}{12}$$\n",
    "\n",
    "$$\\text{SNR} = \\frac{\\text{Signal Power}}{\\text{Noise Power}} = \\frac{\\sigma_x^2}{\\Delta^2/12} \\propto 2^{2b}$$\n",
    "\n",
    "$$\\text{SNR}_{dB} = 6.02b + C \\quad \\text{(ë¹„íŠ¸ë‹¹ ì•½ 6dB í–¥ìƒ)}$$\n",
    "\n",
    "### GPTQ: Hessian ê¸°ë°˜ ìµœì í™”\n",
    "\n",
    "GPTQëŠ” ì–‘ìí™”ëœ ê°€ì¤‘ì¹˜ $\\hat{W}$ê°€ **ì¶œë ¥ ì˜¤ì°¨**ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ 2ì°¨ ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$\\min_{\\hat{W}} \\|WX - \\hat{W}X\\|_F^2$$\n",
    "\n",
    "Hessian $H = 2XX^T$ë¥¼ ì´ìš©í•œ ìµœì  ë³´ì •:\n",
    "\n",
    "$$\\delta_i = \\frac{w_i - \\text{quant}(w_i)}{[H^{-1}]_{ii}}, \\quad w_j \\leftarrow w_j - \\frac{[H^{-1}]_{ij}}{[H^{-1}]_{ii}} \\cdot (w_i - \\text{quant}(w_i))$$\n",
    "\n",
    "- $w_i$: $i$ë²ˆì§¸ ì—´ì˜ ê°€ì¤‘ì¹˜\n",
    "- $H^{-1}$: Hessian ì—­í–‰ë ¬ (Cholesky ë¶„í•´ë¡œ íš¨ìœ¨ì  ê³„ì‚°)\n",
    "- í•œ ì—´ì„ ì–‘ìí™”í•  ë•Œ ë‚˜ë¨¸ì§€ ì—´ì— ì˜¤ì°¨ë¥¼ **ë¶„ì‚°**\n",
    "\n",
    "### AWQ: Activation-aware ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "AWQëŠ” í™œì„±í™”ê°€ í° **ì¤‘ìš” ì±„ë„**ì„ ë³´í˜¸í•˜ê¸° ìœ„í•´ ì±„ë„ë³„ ìŠ¤ì¼€ì¼ $S$ë¥¼ ì ìš©í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$\\min_Q \\|WX - Q(W \\cdot \\text{diag}(S)) \\cdot \\text{diag}(S)^{-1} X\\|^2$$\n",
    "\n",
    "$$S_j = \\left(\\frac{\\max(|X_j|)}{\\max(|W_j|)}\\right)^\\alpha, \\quad \\alpha \\in [0, 1]$$\n",
    "\n",
    "- $S_j$: $j$ë²ˆì§¸ ì±„ë„ì˜ ìŠ¤ì¼€ì¼ íŒ©í„°\n",
    "- $\\alpha$: í™œì„±í™”-ê°€ì¤‘ì¹˜ ê· í˜• í•˜ì´í¼íŒŒë¼ë¯¸í„° (ë³´í†µ $\\alpha \\approx 0.5$)\n",
    "- í° í™œì„±í™”ë¥¼ ê°€ì§„ ì±„ë„ â†’ í° $S_j$ â†’ ê°€ì¤‘ì¹˜ë¥¼ í‚¤ì›Œì„œ ì–‘ìí™” í•´ìƒë„ í™•ë³´\n",
    "\n",
    "**ìš”ì•½ í‘œ:**\n",
    "\n",
    "| ê¸°ë²• | ìˆ˜ì‹ | í•µì‹¬ ì•„ì´ë””ì–´ |\n",
    "|------|------|--------------|\n",
    "| ê· ì¼ ì–‘ìí™” | $\\Delta = (x_{max}-x_{min})/(2^b-1)$ | ë“±ê°„ê²© ë§¤í•‘ |\n",
    "| SNR | $\\propto 2^{2b}$ (ë¹„íŠ¸ë‹¹ 6dB) | ë¹„íŠ¸í­ â†‘ â†’ ì •ë°€ë„ â†‘ |\n",
    "| GPTQ | $\\min \\|WX - \\hat{W}X\\|_F^2$ | Hessianìœ¼ë¡œ ì˜¤ì°¨ ë¶„ì‚° |\n",
    "| AWQ | $S_j = (\\max|X_j| / \\max|W_j|)^\\alpha$ | ì¤‘ìš” ì±„ë„ ìŠ¤ì¼€ì¼ ë³´í˜¸ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ì–‘ìí™” ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ”¢ ì–‘ìí™”(Quantization)ê°€ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: ìƒ‰ì—°í•„ ì„¸íŠ¸ë¥¼ ì¤„ì´ëŠ” ê²ƒê³¼ ê°™ì•„ìš”!\n",
    "\n",
    "128ìƒ‰ ìƒ‰ì—°í•„(FP16)ì´ ìˆë‹¤ê³  í•´ë´ìš”. ë§¤ìš° ì •ë°€í•˜ê²Œ ê·¸ë¦´ ìˆ˜ ìˆì§€ë§Œ, ê°€ë°©ì´ ë¬´ê²ì£ .\n",
    "ì–‘ìí™”ëŠ” **16ìƒ‰(INT4)ì´ë‚˜ 8ìƒ‰(INT8)** ìƒ‰ì—°í•„ ì„¸íŠ¸ë¡œ ë°”ê¾¸ëŠ” ê±°ì˜ˆìš”. ê°€ë°©ì´ í›¨ì”¬ ê°€ë²¼ì›Œì ¸ìš”! ğŸ’\n",
    "\n",
    "#### ğŸ¨ GPTQ vs AWQì˜ ì°¨ì´\n",
    "\n",
    "| ë°©ë²• | ë¹„ìœ  | ì „ëµ |\n",
    "|------|------|------|\n",
    "| GPTQ | ìƒ‰ì„ ì¤„ì¼ ë•Œ **ë¹„ìŠ·í•œ ìƒ‰ë¼ë¦¬ ë¬¶ì–´ì„œ** ì˜¤ì°¨ë¥¼ ê³ ë¥´ê²Œ ë‚˜ëˆ” | Hessianìœ¼ë¡œ ì˜¤ì°¨ ìµœì†Œí™” |\n",
    "| AWQ | **ìì£¼ ì“°ëŠ” ìƒ‰(ì¤‘ìš” ì±„ë„)**ì€ ê¼­ ë‚¨ê¸°ê³ , ì•ˆ ì“°ëŠ” ìƒ‰ë§Œ í•©ì¹¨ | í™œì„±í™” ê¸°ë°˜ ì±„ë„ ë³´í˜¸ |\n",
    "\n",
    "GPTQëŠ” \"ìˆ˜í•™ì ìœ¼ë¡œ ê°€ì¥ ì ì€ ì˜¤ì°¨\"ë¥¼ ì¶”êµ¬í•˜ê³ ,\n",
    "AWQëŠ” \"ì‹¤ì œë¡œ ë§ì´ ì“°ëŠ” ê²ƒì„ ë³´í˜¸\"í•˜ëŠ” ì‹¤ìš©ì  ì ‘ê·¼ì´ì—ìš”!\n",
    "\n",
    "#### ğŸ’¾ ëª¨ë¸ í¬ê¸° ë¹„êµ\n",
    "\n",
    "| ì •ë°€ë„ | Llama 3 8B í¬ê¸° | ë¹„ìœ  |\n",
    "|--------|-----------------|------|\n",
    "| FP16 (16ë¹„íŠ¸) | ~16 GB | ğŸ“š ë°±ê³¼ì‚¬ì „ ì „ì§‘ |\n",
    "| INT8 (8ë¹„íŠ¸) | ~8 GB | ğŸ“– ìš”ì•½ë³¸ |\n",
    "| INT4 (4ë¹„íŠ¸) | ~4 GB | ğŸ“ í•µì‹¬ ë©”ëª¨ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: ì–‘ìí™” ìŠ¤í… í¬ê¸°\n",
    "\n",
    "ê°€ì¤‘ì¹˜ ë²”ìœ„ê°€ $[-2.0, 2.0]$ì¼ ë•Œ INT8($b=8$)ê³¼ INT4($b=4$)ì˜ ì–‘ìí™” ìŠ¤í… í¬ê¸° $\\Delta$ë¥¼ ê°ê° êµ¬í•˜ì„¸ìš”.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$$\\Delta_{INT8} = \\frac{2.0 - (-2.0)}{2^8 - 1} = \\frac{4.0}{255} \\approx 0.0157$$\n",
    "\n",
    "$$\\Delta_{INT4} = \\frac{2.0 - (-2.0)}{2^4 - 1} = \\frac{4.0}{15} \\approx 0.267$$\n",
    "\n",
    "INT4ì˜ ìŠ¤í… í¬ê¸°ëŠ” INT8ì˜ ì•½ 17ë°° â†’ ê·¸ë§Œí¼ ì–‘ìí™” ì˜¤ì°¨ê°€ í½ë‹ˆë‹¤.\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: SNR ê³„ì‚°\n",
    "\n",
    "8ë¹„íŠ¸ â†’ 4ë¹„íŠ¸ë¡œ ì–‘ìí™”í•  ë•Œ SNRì€ ëª‡ dB ê°ì†Œí•˜ë‚˜ìš”?\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$$\\Delta \\text{SNR} = 6.02 \\times (8 - 4) = 24.08 \\text{ dB ê°ì†Œ}$$\n",
    "\n",
    "ë¹„íŠ¸í­ì„ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ë©´ SNRì´ ì•½ 24dB(â‰ˆ250ë°°) ì•…í™”ë©ë‹ˆë‹¤.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ í™˜ê²½ ì„¤ì • ë° ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "np.random.seed(42)\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n",
    "print(f\"NumPy ë²„ì „: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ê· ì¼ ì–‘ìí™” ë°ëª¨ (INT8, INT4) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì •ê·œë¶„í¬ ê°€ì¤‘ì¹˜ì— ëŒ€í•´ ë‹¤ì–‘í•œ ë¹„íŠ¸í­ìœ¼ë¡œ ì–‘ìí™”í•©ë‹ˆë‹¤\n",
    "\n",
    "def uniform_quantize(x, num_bits):\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    n_levels = 2**num_bits - 1\n",
    "    delta = (x_max - x_min) / n_levels\n",
    "    x_q = np.round((x - x_min) / delta).astype(int)\n",
    "    x_q = np.clip(x_q, 0, n_levels)\n",
    "    x_hat = x_q * delta + x_min\n",
    "    return x_hat, delta\n",
    "\n",
    "np.random.seed(42)\n",
    "weights = np.random.randn(1000) * 0.5\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'ë¹„íŠ¸í­':>8} | {'ìŠ¤í…(Î”)':>10} | {'MSE':>12} | {'SNR(dB)':>10} | {'ìµœëŒ€ì˜¤ì°¨':>10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "bit_widths = [2, 3, 4, 6, 8, 16]\n",
    "results = {}\n",
    "\n",
    "for bits in bit_widths:\n",
    "    w_hat, delta = uniform_quantize(weights, bits)\n",
    "    mse = np.mean((weights - w_hat)**2)\n",
    "    signal_power = np.var(weights)\n",
    "    snr_db = 10 * np.log10(signal_power / mse) if mse > 0 else float('inf')\n",
    "    max_err = np.max(np.abs(weights - w_hat))\n",
    "    results[bits] = {\"mse\": mse, \"snr\": snr_db, \"delta\": delta, \"w_hat\": w_hat}\n",
    "    print(f\"{bits:>8} | {delta:>10.6f} | {mse:>12.8f} | {snr_db:>10.2f} | {max_err:>10.6f}\")\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(f\"\\nì´ë¡ ì  SNR ì¦ê°€: ë¹„íŠ¸ë‹¹ ì•½ 6.02 dB\")\n",
    "for i in range(1, len(bit_widths)):\n",
    "    b1, b2 = bit_widths[i-1], bit_widths[i]\n",
    "    snr_diff = results[b2][\"snr\"] - results[b1][\"snr\"]\n",
    "    per_bit = snr_diff / (b2 - b1)\n",
    "    print(f\"  {b1}â†’{b2}ë¹„íŠ¸: {snr_diff:.2f} dB ì¦ê°€ ({per_bit:.2f} dB/bit)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ì–‘ìí™” ì˜¤ì°¨ vs ë¹„íŠ¸í­ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "np.random.seed(42)\n",
    "weights = np.random.randn(5000) * 0.5\n",
    "\n",
    "test_bits = list(range(1, 17))\n",
    "mse_list = []\n",
    "snr_list = []\n",
    "theoretical_snr = []\n",
    "signal_power = np.var(weights)\n",
    "\n",
    "for b in test_bits:\n",
    "    w_hat, delta = uniform_quantize(weights, b)\n",
    "    mse = np.mean((weights - w_hat)**2)\n",
    "    snr_db = 10 * np.log10(signal_power / mse) if mse > 0 else 100\n",
    "    mse_list.append(mse)\n",
    "    snr_list.append(snr_db)\n",
    "    theoretical_snr.append(6.02 * b + 10 * np.log10(12 * signal_power / (np.max(weights) - np.min(weights))**2))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ì™¼ìª½: MSE vs ë¹„íŠ¸í­\n",
    "ax1 = axes[0]\n",
    "ax1.semilogy(test_bits, mse_list, 'b-o', lw=2, ms=6, label='ì‹¤ì¸¡ MSE')\n",
    "ax1.set_xlabel('ë¹„íŠ¸í­ (bits)', fontsize=11)\n",
    "ax1.set_ylabel('MSE (log scale)', fontsize=11)\n",
    "ax1.set_title('ì–‘ìí™” MSE vs ë¹„íŠ¸í­', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(fontsize=9)\n",
    "for b_mark in [4, 8]:\n",
    "    idx = test_bits.index(b_mark)\n",
    "    ax1.axvline(x=b_mark, color='red', ls='--', lw=1, alpha=0.5)\n",
    "    ax1.annotate(f'INT{b_mark}\\nMSE={mse_list[idx]:.2e}',\n",
    "                 xy=(b_mark, mse_list[idx]), xytext=(b_mark+1, mse_list[idx]*5),\n",
    "                 fontsize=8, arrowprops=dict(arrowstyle='->', color='red'))\n",
    "\n",
    "# ì˜¤ë¥¸ìª½: SNR vs ë¹„íŠ¸í­\n",
    "ax2 = axes[1]\n",
    "ax2.plot(test_bits, snr_list, 'r-o', lw=2, ms=6, label='ì‹¤ì¸¡ SNR')\n",
    "ax2.plot(test_bits, theoretical_snr, 'g--', lw=2, label='ì´ë¡  SNR (6.02b + C)')\n",
    "ax2.set_xlabel('ë¹„íŠ¸í­ (bits)', fontsize=11)\n",
    "ax2.set_ylabel('SNR (dB)', fontsize=11)\n",
    "ax2.set_title('SNR vs ë¹„íŠ¸í­ (ì´ë¡  vs ì‹¤ì¸¡)', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.axhline(y=snr_list[test_bits.index(4)], color='gray', ls=':', lw=1, alpha=0.5)\n",
    "ax2.axhline(y=snr_list[test_bits.index(8)], color='gray', ls=':', lw=1, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('quantization_error_vs_bits.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/quantization_error_vs_bits.png\")\n",
    "print(f\"\\nINT4 SNR: {snr_list[test_bits.index(4)]:.2f} dB\")\n",
    "print(f\"INT8 SNR: {snr_list[test_bits.index(8)]:.2f} dB\")\n",
    "print(f\"ì°¨ì´: {snr_list[test_bits.index(8)] - snr_list[test_bits.index(4)]:.2f} dB \"\n",
    "      f\"(ì´ë¡ : {6.02*4:.2f} dB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AWQ í•µì‹¬ ì±„ë„ íƒì§€ ì‹œë®¬ë ˆì´ì…˜ <a name='4.-AWQ-í•µì‹¬-ì±„ë„'></a>\n",
    "\n",
    "### AWQì˜ í•µì‹¬ ê´€ì°°\n",
    "\n",
    "ëª¨ë“  ê°€ì¤‘ì¹˜ ì±„ë„ì´ ë™ë“±í•˜ê²Œ ì¤‘ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤:\n",
    "- ì†Œìˆ˜(1~5%)ì˜ ì±„ë„ì´ **í™œì„±í™” í¬ê¸°ê°€ ê·¹ë‹¨ì ìœ¼ë¡œ í°** \"salient channel\"\n",
    "- ì´ ì±„ë„ì„ ì–‘ìí™”í•˜ë©´ ì¶œë ¥ ì˜¤ì°¨ê°€ ê¸‰ê²©íˆ ì¦ê°€\n",
    "\n",
    "### ìŠ¤ì¼€ì¼ íŒ©í„°ì˜ ì—­í• \n",
    "\n",
    "$$W'_j = W_j \\cdot S_j \\quad \\rightarrow \\quad \\text{ì–‘ìí™”} \\quad \\rightarrow \\quad \\hat{W}'_j$$\n",
    "$$\\text{ì¶œë ¥} = \\hat{W}'_j \\cdot (X_j / S_j)$$\n",
    "\n",
    "$S_j > 1$ì´ë©´ ê°€ì¤‘ì¹˜ê°€ ì»¤ì ¸ì„œ ì–‘ìí™” í•´ìƒë„(ë ˆë²¨ ìˆ˜ ëŒ€ë¹„ ìœ íš¨ ë²”ìœ„)ê°€ í–¥ìƒë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ AWQ í•µì‹¬ ì±„ë„(Salient Channel) íƒì§€ ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Llama-like ê°€ì¤‘ì¹˜ì—ì„œ í™œì„±í™” ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš” ì±„ë„ì„ ì‹ë³„í•©ë‹ˆë‹¤\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "hidden_dim = 256\n",
    "seq_len = 128\n",
    "out_dim = 256\n",
    "\n",
    "W = np.random.randn(out_dim, hidden_dim) * 0.02\n",
    "X = np.random.randn(seq_len, hidden_dim) * 0.5\n",
    "\n",
    "# ì¼ë¶€ ì±„ë„ì— í° í™œì„±í™”(salient channel) ìƒì„±\n",
    "salient_channels = [10, 42, 100, 180, 220]\n",
    "for ch in salient_channels:\n",
    "    X[:, ch] *= 15.0\n",
    "\n",
    "activation_magnitude = np.max(np.abs(X), axis=0)\n",
    "weight_magnitude = np.max(np.abs(W), axis=1)[:hidden_dim]\n",
    "\n",
    "# ìƒìœ„ 5% ì±„ë„ì„ salientë¡œ ì‹ë³„\n",
    "threshold = np.percentile(activation_magnitude, 95)\n",
    "detected_salient = np.where(activation_magnitude > threshold)[0]\n",
    "\n",
    "print(\"=== AWQ Salient Channel íƒì§€ ===\\n\")\n",
    "print(f\"íˆë“  ì°¨ì›: {hidden_dim}\")\n",
    "print(f\"í™œì„±í™” í¬ê¸° ê¸°ì¤€ ìƒìœ„ 5% ì„ê³„ê°’: {threshold:.4f}\")\n",
    "print(f\"íƒì§€ëœ salient ì±„ë„ ìˆ˜: {len(detected_salient)}\")\n",
    "print(f\"íƒì§€ëœ ì±„ë„: {detected_salient.tolist()}\")\n",
    "print(f\"ì‹¤ì œ salient ì±„ë„: {salient_channels}\")\n",
    "print(f\"ì •í™•ë„: {len(set(detected_salient) & set(salient_channels))}/{len(salient_channels)}\")\n",
    "\n",
    "# AWQ ìŠ¤ì¼€ì¼ íŒ©í„° ê³„ì‚°\n",
    "alpha = 0.5\n",
    "S = np.ones(hidden_dim)\n",
    "for j in range(hidden_dim):\n",
    "    act_mag = activation_magnitude[j]\n",
    "    w_mag = np.max(np.abs(W[:, j]))\n",
    "    if w_mag > 0:\n",
    "        S[j] = (act_mag / w_mag) ** alpha\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ ì ìš© ì „í›„ ì–‘ìí™” ì˜¤ì°¨ ë¹„êµ\n",
    "Y_original = X @ W.T\n",
    "\n",
    "# ì–‘ìí™” ì—†ì´ (ê¸°ì¤€)\n",
    "Y_fp = Y_original\n",
    "\n",
    "# ì¼ë°˜ INT4 ì–‘ìí™”\n",
    "W_q_naive, _ = uniform_quantize(W, 4)\n",
    "Y_naive = X @ W_q_naive.T\n",
    "mse_naive = np.mean((Y_fp - Y_naive)**2)\n",
    "\n",
    "# AWQ INT4 ì–‘ìí™”\n",
    "W_scaled = W * S[np.newaxis, :]\n",
    "W_scaled_q, _ = uniform_quantize(W_scaled, 4)\n",
    "X_descaled = X / S[np.newaxis, :]\n",
    "Y_awq = X_descaled @ W_scaled_q.T\n",
    "mse_awq = np.mean((Y_fp - Y_awq)**2)\n",
    "\n",
    "print(f\"\\n{'ë°©ë²•':<25} | {'MSE':>15} | {'ìƒëŒ€ ì˜¤ì°¨':>12}\")\n",
    "print(\"-\" * 58)\n",
    "print(f\"{'Naive INT4'::<25} | {mse_naive:>15.8f} | {1.0:>12.4f}x\")\n",
    "print(f\"{'AWQ INT4 (Î±=0.5)'::<25} | {mse_awq:>15.8f} | {mse_awq/mse_naive:>12.4f}x\")\n",
    "print(f\"\\nAWQ ì˜¤ì°¨ ê°ì†Œ: {(1 - mse_awq/mse_naive)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ AWQ ì±„ë„ë³„ í™œì„±í™”/ìŠ¤ì¼€ì¼ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "\n",
    "# 1. ì±„ë„ë³„ í™œì„±í™” í¬ê¸°\n",
    "ax1 = axes[0]\n",
    "ax1.bar(range(hidden_dim), activation_magnitude, color='steelblue', alpha=0.6, width=1.0)\n",
    "for ch in salient_channels:\n",
    "    ax1.bar(ch, activation_magnitude[ch], color='red', alpha=0.9, width=2.0)\n",
    "ax1.axhline(y=threshold, color='orange', ls='--', lw=2, label=f'95th percentile = {threshold:.1f}')\n",
    "ax1.set_xlabel('ì±„ë„ ì¸ë±ìŠ¤', fontsize=11)\n",
    "ax1.set_ylabel('ìµœëŒ€ í™œì„±í™” í¬ê¸°', fontsize=11)\n",
    "ax1.set_title('ì±„ë„ë³„ í™œì„±í™” í¬ê¸° (ë¹¨ê°„ìƒ‰=salient)', fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. AWQ ìŠ¤ì¼€ì¼ íŒ©í„°\n",
    "ax2 = axes[1]\n",
    "ax2.bar(range(hidden_dim), S, color='forestgreen', alpha=0.6, width=1.0)\n",
    "for ch in salient_channels:\n",
    "    ax2.bar(ch, S[ch], color='red', alpha=0.9, width=2.0)\n",
    "ax2.set_xlabel('ì±„ë„ ì¸ë±ìŠ¤', fontsize=11)\n",
    "ax2.set_ylabel('ìŠ¤ì¼€ì¼ íŒ©í„° S', fontsize=11)\n",
    "ax2.set_title('AWQ ìŠ¤ì¼€ì¼ íŒ©í„° ë¶„í¬', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. ì–‘ìí™” ì˜¤ì°¨ ë¹„êµ\n",
    "ax3 = axes[2]\n",
    "methods = ['Naive\\nINT4', 'AWQ\\nINT4']\n",
    "mses = [mse_naive, mse_awq]\n",
    "colors = ['salmon', 'lightgreen']\n",
    "bars = ax3.bar(methods, mses, color=colors, edgecolor='black', width=0.5)\n",
    "ax3.set_ylabel('MSE', fontsize=11)\n",
    "ax3.set_title('ì–‘ìí™” ë°©ë²•ë³„ ì¶œë ¥ MSE', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "for bar, mse_val in zip(bars, mses):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.02,\n",
    "             f'{mse_val:.6f}', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('awq_channel_analysis.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/awq_channel_analysis.png\")\n",
    "print(f\"\\nSalient ì±„ë„ì˜ í‰ê·  ìŠ¤ì¼€ì¼: {np.mean([S[ch] for ch in salient_channels]):.2f}\")\n",
    "print(f\"ì¼ë°˜ ì±„ë„ì˜ í‰ê·  ìŠ¤ì¼€ì¼: {np.mean(np.delete(S, salient_channels)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. W4A16 / INT8 / FP8 ë¹„êµ ë²¤ì¹˜ë§ˆí¬ <a name='5.-í¬ë§·-ë¹„êµ'></a>\n",
    "\n",
    "### ì–‘ìí™” í¬ë§· ë¹„êµ\n",
    "\n",
    "| í¬ë§· | ê°€ì¤‘ì¹˜ | í™œì„±í™” | ë©”ëª¨ë¦¬(7B ê¸°ì¤€) | íŠ¹ì§• |\n",
    "|------|--------|--------|----------------|------|\n",
    "| FP16 | 16-bit | 16-bit | ~14 GB | ê¸°ì¤€ì„  |\n",
    "| W8A8 (INT8) | 8-bit | 8-bit | ~7 GB | GPTQ/SmoothQuant |\n",
    "| W4A16 | 4-bit | 16-bit | ~3.5 GB | GPTQ/AWQ, í™œì„±í™” ìœ ì§€ |\n",
    "| FP8 (E4M3) | 8-bit | 8-bit | ~7 GB | H100 ë„¤ì´í‹°ë¸Œ, ë†’ì€ ì •ë°€ë„ |\n",
    "| W4A8 | 4-bit | 8-bit | ~3.5 GB | QoQ ë“± ìµœì‹  ê¸°ë²• |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ W4A16 / INT8 / FP8 ë¹„êµ ë²¤ì¹˜ë§ˆí¬ ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ë‹¤ì–‘í•œ ì–‘ìí™” í¬ë§·ì˜ ë©”ëª¨ë¦¬, ì†ë„, ì •ë°€ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ (Llama 3 8B ê¸°ì¤€)\n",
    "model_params_B = 8.03\n",
    "formats = {\n",
    "    \"FP16\": {\"w_bits\": 16, \"a_bits\": 16, \"memory_gb\": model_params_B * 2,\n",
    "             \"relative_speed\": 1.0, \"ppl_degradation\": 0.0},\n",
    "    \"FP8 (E4M3)\": {\"w_bits\": 8, \"a_bits\": 8, \"memory_gb\": model_params_B * 1,\n",
    "                    \"relative_speed\": 1.8, \"ppl_degradation\": 0.05},\n",
    "    \"INT8 (W8A8)\": {\"w_bits\": 8, \"a_bits\": 8, \"memory_gb\": model_params_B * 1,\n",
    "                     \"relative_speed\": 1.7, \"ppl_degradation\": 0.1},\n",
    "    \"W4A16 (GPTQ)\": {\"w_bits\": 4, \"a_bits\": 16, \"memory_gb\": model_params_B * 0.5,\n",
    "                      \"relative_speed\": 2.2, \"ppl_degradation\": 0.3},\n",
    "    \"W4A16 (AWQ)\": {\"w_bits\": 4, \"a_bits\": 16, \"memory_gb\": model_params_B * 0.5,\n",
    "                     \"relative_speed\": 2.3, \"ppl_degradation\": 0.15},\n",
    "}\n",
    "\n",
    "print(\"=\" * 85)\n",
    "print(f\"{'í¬ë§·':<18} | {'Wë¹„íŠ¸':>5} | {'Aë¹„íŠ¸':>5} | {'ë©”ëª¨ë¦¬(GB)':>10} | \"\n",
    "      f\"{'ìƒëŒ€ì†ë„':>8} | {'PPL ì—´í™”':>8}\")\n",
    "print(\"-\" * 85)\n",
    "for name, f in formats.items():\n",
    "    print(f\"{name:<18} | {f['w_bits']:>5} | {f['a_bits']:>5} | \"\n",
    "          f\"{f['memory_gb']:>10.2f} | {f['relative_speed']:>7.1f}x | \"\n",
    "          f\"+{f['ppl_degradation']:>6.2f}\")\n",
    "print(\"=\" * 85)\n",
    "\n",
    "# ì‹¤ì œ ì–‘ìí™” ì •ë°€ë„ ì‹œë®¬ë ˆì´ì…˜\n",
    "weight_matrix = np.random.randn(512, 512) * 0.02\n",
    "calibration_data = np.random.randn(64, 512) * 0.5\n",
    "\n",
    "bit_configs = [\n",
    "    (\"FP16\", 16),\n",
    "    (\"FP8\", 8),\n",
    "    (\"INT8\", 8),\n",
    "    (\"INT4 (GPTQ)\", 4),\n",
    "    (\"INT4 (AWQ)\", 4),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'í¬ë§·':<18} | {'ì¶œë ¥ MSE':>15} | {'Cosine Sim':>12} | {'Max Error':>10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "Y_ref = calibration_data @ weight_matrix.T\n",
    "\n",
    "for name, bits in bit_configs:\n",
    "    if \"AWQ\" in name:\n",
    "        act_mag = np.max(np.abs(calibration_data), axis=0)\n",
    "        w_mag = np.max(np.abs(weight_matrix), axis=0)\n",
    "        S = np.where(w_mag > 0, (act_mag / np.maximum(w_mag, 1e-8))**0.5, 1.0)\n",
    "        W_s = weight_matrix * S[np.newaxis, :]\n",
    "        W_q, _ = uniform_quantize(W_s, bits)\n",
    "        X_d = calibration_data / S[np.newaxis, :]\n",
    "        Y_q = X_d @ W_q.T\n",
    "    else:\n",
    "        W_q, _ = uniform_quantize(weight_matrix, bits)\n",
    "        Y_q = calibration_data @ W_q.T\n",
    "\n",
    "    mse = np.mean((Y_ref - Y_q)**2)\n",
    "    cos_sim = np.mean([\n",
    "        np.dot(Y_ref[i], Y_q[i]) / (np.linalg.norm(Y_ref[i]) * np.linalg.norm(Y_q[i]) + 1e-10)\n",
    "        for i in range(len(Y_ref))\n",
    "    ])\n",
    "    max_err = np.max(np.abs(Y_ref - Y_q))\n",
    "    print(f\"{name:<18} | {mse:>15.10f} | {cos_sim:>12.8f} | {max_err:>10.6f}\")\n",
    "\n",
    "print(\"-\" * 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ì–‘ìí™” í¬ë§· ì¢…í•© ë¹„êµ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "names = list(formats.keys())\n",
    "memories = [formats[n][\"memory_gb\"] for n in names]\n",
    "speeds = [formats[n][\"relative_speed\"] for n in names]\n",
    "ppls = [formats[n][\"ppl_degradation\"] for n in names]\n",
    "colors_bar = ['#4C72B0', '#55A868', '#C44E52', '#8172B2', '#CCB974']\n",
    "\n",
    "# 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.barh(range(len(names)), memories, color=colors_bar, edgecolor='black', height=0.6)\n",
    "ax1.set_xlabel('ë©”ëª¨ë¦¬ (GB)', fontsize=11)\n",
    "ax1.set_title('ëª¨ë¸ ë©”ëª¨ë¦¬ (Llama 3 8B)', fontweight='bold')\n",
    "ax1.set_yticks(range(len(names)))\n",
    "ax1.set_yticklabels(names, fontsize=9)\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "for i, (bar, mem) in enumerate(zip(bars1, memories)):\n",
    "    ax1.text(mem + 0.2, i, f'{mem:.1f} GB', va='center', fontsize=9)\n",
    "\n",
    "# 2. ìƒëŒ€ ì¶”ë¡  ì†ë„\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.barh(range(len(names)), speeds, color=colors_bar, edgecolor='black', height=0.6)\n",
    "ax2.set_xlabel('ìƒëŒ€ ì†ë„ (FP16 = 1.0x)', fontsize=11)\n",
    "ax2.set_title('ì¶”ë¡  ì†ë„ ë¹„êµ', fontweight='bold')\n",
    "ax2.set_yticks(range(len(names)))\n",
    "ax2.set_yticklabels(names, fontsize=9)\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "for i, (bar, spd) in enumerate(zip(bars2, speeds)):\n",
    "    ax2.text(spd + 0.02, i, f'{spd:.1f}x', va='center', fontsize=9)\n",
    "\n",
    "# 3. ì •ë°€ë„ ì—´í™”\n",
    "ax3 = axes[2]\n",
    "bars3 = ax3.barh(range(len(names)), ppls, color=colors_bar, edgecolor='black', height=0.6)\n",
    "ax3.set_xlabel('Perplexity ì—´í™” (+)', fontsize=11)\n",
    "ax3.set_title('ì •ë°€ë„ ì—´í™” (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)', fontweight='bold')\n",
    "ax3.set_yticks(range(len(names)))\n",
    "ax3.set_yticklabels(names, fontsize=9)\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "for i, (bar, ppl) in enumerate(zip(bars3, ppls)):\n",
    "    ax3.text(ppl + 0.005, i, f'+{ppl:.2f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('quantization_format_comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/quantization_format_comparison.png\")\n",
    "print(f\"\\nìµœì  ê· í˜•: AWQ W4A16 â€” ë©”ëª¨ë¦¬ {formats['W4A16 (AWQ)']['memory_gb']:.1f}GB, \"\n",
    "      f\"ì†ë„ {formats['W4A16 (AWQ)']['relative_speed']:.1f}x, \"\n",
    "      f\"PPL ì—´í™” +{formats['W4A16 (AWQ)']['ppl_degradation']:.2f}\")\n",
    "print(\"AWQëŠ” GPTQ ëŒ€ë¹„ PPL ì—´í™”ê°€ ì ˆë°˜ ìˆ˜ì¤€ìœ¼ë¡œ ì‹¤ìš©ì  ê´€ì ì—ì„œ ìš°ìˆ˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì •ë¦¬ <a name='6.-ì •ë¦¬'></a>\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |\n",
    "|------|------|--------|\n",
    "| ê· ì¼ ì–‘ìí™” | $\\Delta = (x_{max}-x_{min})/(2^b-1)$ | â­â­ |\n",
    "| SNRê³¼ ë¹„íŠ¸í­ | $\\text{SNR} \\propto 2^{2b}$, ë¹„íŠ¸ë‹¹ 6dB | â­â­â­ |\n",
    "| GPTQ | Hessian 2ì°¨ ìµœì í™”ë¡œ ì—´ë³„ ì˜¤ì°¨ ìµœì†Œí™” | â­â­â­ |\n",
    "| AWQ | í™œì„±í™” ê¸°ë°˜ ì±„ë„ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ì¤‘ìš” ê°€ì¤‘ì¹˜ ë³´í˜¸ | â­â­â­ |\n",
    "| W4A16 | ê°€ì¤‘ì¹˜ 4ë¹„íŠ¸, í™œì„±í™” 16ë¹„íŠ¸ â€” ì‹¤ìš©ì  ìµœì ì  | â­â­â­ |\n",
    "| FP8 (E4M3) | H100 ë„¤ì´í‹°ë¸Œ, í›ˆë ¨/ì¶”ë¡  ëª¨ë‘ ì ìš© ê°€ëŠ¥ | â­â­ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$\\Delta = \\frac{x_{max} - x_{min}}{2^b - 1}, \\quad \\text{SNR}_{dB} = 6.02b + C$$\n",
    "\n",
    "$$\\text{GPTQ}: \\min_{\\hat{W}} \\|WX - \\hat{W}X\\|_F^2 \\quad \\text{(Hessian ê¸°ë°˜ ì—´ë³„ ìµœì í™”)}$$\n",
    "\n",
    "$$\\text{AWQ}: S_j = \\left(\\frac{\\max|X_j|}{\\max|W_j|}\\right)^\\alpha \\quad \\text{(í™œì„±í™” ê¸°ë°˜ ìŠ¤ì¼€ì¼)}$$\n",
    "\n",
    "### ì°¸ê³  ë…¼ë¬¸\n",
    "- Frantar et al., \"GPTQ: Accurate Post-Training Quantization for Generative Pre-Trained Transformers\" (arxiv 2210.17323)\n",
    "- Lin et al., \"AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration\" (arxiv 2306.00978)\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**Chapter 15: AI ì–¼ë¼ì¸ë¨¼íŠ¸ì™€ ê°•í™”í•™ìŠµ (RLHF/DPO)** â€” Policy Gradientì—ì„œ PPO-Clipê¹Œì§€ ìˆ˜ì‹ì„ ì™„ì „ ë„ì¶œí•˜ê³ , RLHF íŒŒì´í”„ë¼ì¸ê³¼ DPOì˜ ìˆ˜í•™ì  ë“±ê°€ì„±ì„ ì¦ëª…í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}