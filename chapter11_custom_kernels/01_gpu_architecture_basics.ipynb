{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11-01: GPU ì•„í‚¤í…ì²˜ ê¸°ì´ˆ (GPU Architecture Basics)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- GPUì˜ **SM(Streaming Multiprocessor)**, **Warp**, **Thread Block** ê°œë…ê³¼ ì´ë“¤ì˜ ê³„ì¸µì  ê´€ê³„ë¥¼ ì •í™•íˆ ì´í•´í•œë‹¤\n",
    "- GPU ë©”ëª¨ë¦¬ ê³„ì¸µ (**Global / Shared / Register**)ì˜ ìš©ëŸ‰, ì†ë„, ì ‘ê·¼ ë°©ì‹ì„ CPUì™€ ë¹„êµí•œë‹¤\n",
    "- **Arithmetic Intensity** ì§€í‘œë¡œ ì—°ì‚°ì´ Compute-boundì¸ì§€ Memory-boundì¸ì§€ íŒë³„í•˜ëŠ” Roofline ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤\n",
    "- ë”¥ëŸ¬ë‹ì˜ í•µì‹¬ ì—°ì‚°(GEMM, Softmax, LayerNorm)ì˜ AIë¥¼ ê³„ì‚°í•˜ê³ , GPUì—ì„œ ìµœì í™” ë°©í–¥ì„ ì œì‹œí•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: Arithmetic Intensityì™€ Roofline Model](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [GPU vs CPU ì•„í‚¤í…ì²˜ ë¹„êµ](#2.-GPU-vs-CPU)\n",
    "3. [ë©”ëª¨ë¦¬ ê³„ì¸µ êµ¬ì¡° ì‹¬í™”](#3.-ë©”ëª¨ë¦¬-ê³„ì¸µ)\n",
    "4. [Roofline ë¶„ì„: ë”¥ëŸ¬ë‹ ì—°ì‚° ë¶„ë¥˜](#4.-Roofline-ë¶„ì„)\n",
    "5. [Warpê³¼ Occupancy ì´í•´](#5.-Warpê³¼-Occupancy)\n",
    "6. [ì •ë¦¬ ë° ì—°ìŠµ ë¬¸ì œ](#6.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ\n",
    "\n",
    "### Arithmetic Intensity (ì‚°ìˆ  ì§‘ì•½ë„)\n",
    "\n",
    "$$\\text{AI} = \\frac{\\text{FLOPs}}{\\text{ë©”ëª¨ë¦¬ ì ‘ê·¼ëŸ‰ (Bytes)}}$$\n",
    "\n",
    "### Roofline Model: ì‹¤ì œ ì„±ëŠ¥ ìƒí•œ\n",
    "\n",
    "$$\\text{Attainable Performance} = \\min\\left(\\text{Peak FLOPs}, \\; \\text{AI} \\times \\text{Peak BW}\\right)$$\n",
    "\n",
    "- **Memory-bound**: $\\text{AI} < \\text{Operational Intensity}_{ridge}$ â†’ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ì´ ë³‘ëª©\n",
    "- **Compute-bound**: $\\text{AI} > \\text{Operational Intensity}_{ridge}$ â†’ ì—°ì‚° ëŠ¥ë ¥ì´ ë³‘ëª©\n",
    "\n",
    "Ridge Point (ì „í™˜ì ):\n",
    "$$\\text{AI}_{ridge} = \\frac{\\text{Peak FLOPs}}{\\text{Peak Memory BW}}$$\n",
    "\n",
    "H100 ì˜ˆ: $\\frac{989 \\text{ TFLOPS}}{3.35 \\text{ TB/s}} \\approx 295$ FLOPs/Byte\n",
    "\n",
    "### í•µì‹¬ ì—°ì‚°ì˜ Arithmetic Intensity\n",
    "\n",
    "| ì—°ì‚° | FLOPs | ë©”ëª¨ë¦¬ ì½ê¸° | AI | êµ¬ë¶„ |\n",
    "|------|-------|-----------|-----|------|\n",
    "| GEMM ($m\\times k \\times n$) | $2mkn$ | $\\approx 2(mk+kn+mn)$ bytes | $\\sim mn/({m+n})$ | **Compute-bound** (í° í–‰ë ¬) |\n",
    "| Softmax ($S$ ì›ì†Œ) | $5S$ | $4S$ bytes (ì½ê¸°+ì“°ê¸°) | $\\sim 1.25$ | **Memory-bound** |\n",
    "| LayerNorm ($H$ íˆë“ ) | $7H$ | $8H$ bytes | $\\sim 0.9$ | **Memory-bound** |\n",
    "| Elementwise (add, relu) | $1S$ | $3S$ bytes | $\\sim 0.33$ | **ê·¹ë‹¨ì  Memory-bound** |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸï¸ GPUê°€ ì™œ AI í•™ìŠµì— ì¢‹ì€ê°€ìš”?\n",
    "\n",
    "> - **CPU**: ìš”ë¦¬ì‚¬ 4ëª…ì´ ê°ì ë³µì¡í•œ ìš”ë¦¬ë¥¼ ë§Œë“œëŠ” ê²ƒ (ì†Œìˆ˜ì˜ ê°•ë ¥í•œ ì½”ì–´)\n",
    "> - **GPU**: ìš”ë¦¬ì‚¬ 1ë§Œ ëª…ì´ ê°„ë‹¨í•œ ì‘ì—…ì„ ë™ì‹œì— í•˜ëŠ” ê²ƒ (ìˆ˜ì²œ ê°œì˜ ì‘ì€ ì½”ì–´)\n",
    ">\n",
    "> ë”¥ëŸ¬ë‹ì˜ í–‰ë ¬ ê³±ì€ ì„œë¡œ ë…ë¦½ì ì¸ ìˆ˜ì‹­ì–µ ê°œì˜ ì‘ì€ ê³±ì…ˆì˜ í•© â†’ GPUê°€ ì™„ë²½!\n",
    "\n",
    "#### ğŸ“Š Arithmetic Intensityê°€ ì™œ ì¤‘ìš”í•œê°€ìš”?\n",
    "\n",
    "> ìš”ë¦¬ì‚¬(GPU ì½”ì–´)ë“¤ì´ ì¬ë£Œ(ë°ì´í„°)ë¥¼ ê³„ì† ê¸°ë‹¤ë¦¬ë©´ ë‚­ë¹„ì˜ˆìš”!\n",
    "> - **AIê°€ ë‚®ìŒ**: ì¬ë£Œ(ë©”ëª¨ë¦¬)ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²Œ ëŠë ¤ì„œ ìš”ë¦¬ì‚¬ë“¤ì´ ëŒ€ê¸° â†’ Memory-bound\n",
    "> - **AIê°€ ë†’ìŒ**: ì¬ë£ŒëŠ” ì¶©ë¶„, ìš”ë¦¬ì‚¬ë“¤ì´ í’€ê°€ë™ â†’ Compute-bound (ì´ìƒì !)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: GEMMì˜ Arithmetic Intensity\n",
    "\n",
    "Llama-2 7Bì˜ í•œ FFN ë ˆì´ì–´: $A \\in \\mathbb{R}^{4096 \\times 11008}$, ë°°ì¹˜/ì‹œí€€ìŠ¤ í•©ì³ $X \\in \\mathbb{R}^{2048 \\times 4096}$.  \n",
    "ì´ GEMMì˜ FLOPsì™€ AIë¥¼ ê³„ì‚°í•˜ê³ , H100 ê¸°ì¤€ Compute/Memory boundë¥¼ íŒë³„í•˜ë¼.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$m=2048, k=4096, n=11008$  \n",
    "FLOPs = $2 \\times 2048 \\times 4096 \\times 11008 \\approx 184.5$ GFLOPS  \n",
    "ë©”ëª¨ë¦¬ = $(2048\\times4096 + 4096\\times11008 + 2048\\times11008) \\times 2$ bytes â‰ˆ 263 MB  \n",
    "AI = $184.5\\times10^9 / 263\\times10^6 \\approx \\mathbf{701}$ FLOPs/Byte\n",
    "\n",
    "H100 Ridge Point â‰ˆ 295 FLOPs/Byte  \n",
    "**AI (701) > Ridge (295) â†’ Compute-bound** âœ… (GPUê°€ ìµœëŒ€ í™œìš©ë¨)\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: Warp ì˜¤ííŒì‹œ\n",
    "\n",
    "H100 SMë‹¹ ìµœëŒ€ 2048 Thread, Warp í¬ê¸° 32.  \n",
    "ì»¤ë„ì´ Thread Blockë‹¹ 128 Thread, SMë‹¹ ìµœëŒ€ Block ìˆ˜ = 8ì´ë¼ë©´,  \n",
    "ì´ë¡  Occupancy(ì ìœ ìœ¨)ëŠ”?\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "SMë‹¹ í™œì„± Thread = $128 \\times 8 = 1024$  \n",
    "SMë‹¹ í™œì„± Warp = $1024 / 32 = 32$  \n",
    "ìµœëŒ€ Warp = $2048 / 32 = 64$  \n",
    "Occupancy = $32/64 = \\mathbf{50\\%}$\n",
    "\n",
    "ë‚®ì€ Occupancy â†’ ë©”ëª¨ë¦¬ ì§€ì—° ìˆ¨ê¸°ê¸° ì–´ë ¤ì›€ â†’ ë ˆì§€ìŠ¤í„° ì‚¬ìš©ëŸ‰ ì¤„ì—¬ Block í¬ê¸° ëŠ˜ë¦´ ê²ƒ\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU vs CPU ì•„í‚¤í…ì²˜ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# GPU(H100) vs CPU(Intel Xeon) ìŠ¤í™ ë¹„êµ\n",
    "# ---------------------------------------------------\n",
    "\n",
    "specs = {\n",
    "    'í•­ëª©': ['ì½”ì–´ ìˆ˜', 'Clock (GHz)', 'FP32 TFLOPS', 'ë©”ëª¨ë¦¬ ëŒ€ì—­í­ (GB/s)', 'L1/SRAM (MB)', 'ì „ë ¥ (W)'],\n",
    "    'CPU\\n(Intel Xeon 8490H)': ['60 ì½”ì–´', '1.9 (Boost 3.5)', '~3', '~300', '~240', '350W'],\n",
    "    'GPU\\n(NVIDIA H100 SXM)': ['16,896 CUDA ì½”ì–´\\n+528 TCs', '1.98 (Boost 2.28)', '989 (BF16: 1979)', '3,350', '~50 (SharedÃ—132)', '700W'],\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "ax.axis('off')\n",
    "table = ax.table(\n",
    "    cellText=[[s, c, g] for s, c, g in zip(specs['í•­ëª©'],\n",
    "                                            specs['CPU\\n(Intel Xeon 8490H)'],\n",
    "                                            specs['GPU\\n(NVIDIA H100 SXM)'])],\n",
    "    colLabels=['í•­ëª©', 'CPU (Intel Xeon 8490H)', 'GPU (NVIDIA H100 SXM)'],\n",
    "    cellLoc='center', loc='center',\n",
    "    colWidths=[0.25, 0.35, 0.4]\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "for (r, c), cell in table.get_celld().items():\n",
    "    if r == 0:\n",
    "        cell.set_facecolor('#1E88E5'); cell.set_text_props(color='white', fontweight='bold')\n",
    "    elif c == 2:\n",
    "        cell.set_facecolor('#E3F2FD')\n",
    "    cell.set_edgecolor('white')\n",
    "    cell.set_height(0.18)\n",
    "ax.set_title('GPU vs CPU ì•„í‚¤í…ì²˜ ë¹„êµ (H100 SXM vs Intel Xeon)', fontweight='bold', fontsize=12, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"í•µì‹¬ ì°¨ì´:\")\n",
    "print(f\"  FP32 ì„±ëŠ¥: H100({989:.0f} TFLOPS) / Xeon({3:.0f} TFLOPS) = {989/3:.0f}ë°°\")\n",
    "print(f\"  ë©”ëª¨ë¦¬ BW: H100({3350:.0f} GB/s) / Xeon({300:.0f} GB/s) = {3350/300:.0f}ë°°\")\n",
    "print(f\"  ì½”ì–´ ìˆ˜:  H100(16,896) / Xeon(60) = {16896//60}ë°°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë©”ëª¨ë¦¬ ê³„ì¸µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# GPU ë©”ëª¨ë¦¬ ê³„ì¸µ êµ¬ì¡° ì‹œê°í™”\n",
    "# ---------------------------------------------------\n",
    "\n",
    "memory_hierarchy = [\n",
    "    # (ì´ë¦„,  í¬ê¸°,          ëŒ€ì—­í­,      ì§€ì—°,    ë²”ìœ„,       ìƒ‰)\n",
    "    ('Register\\n(ìŠ¤ë ˆë“œ ì „ìš©)', '256KB/SM', '>100 TB/s', '~1 cycle', 'ìŠ¤ë ˆë“œ', '#1B5E20'),\n",
    "    ('Shared Memory\\n(SRAM)', '228KB/SM', '~10 TB/s',  '~5 cycles', 'Thread Block', '#1565C0'),\n",
    "    ('L2 Cache',             '50 MB',    '~4 TB/s',   '~200 cycles', 'ì „ì²´ GPU', '#4527A0'),\n",
    "    ('Global Memory\\n(HBM)', '80 GB',    '3.35 TB/s', '~600 cycles', 'ì „ì²´ GPU', '#B71C1C'),\n",
    "    ('CPU RAM (PCIe)',        'ìˆ˜ TB',    '~64 GB/s',  '~ìˆ˜ì²œ cycles', 'í˜¸ìŠ¤íŠ¸', '#E65100'),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 7))\n",
    "ax.set_xlim(0, 10); ax.set_ylim(-0.5, len(memory_hierarchy) + 0.5)\n",
    "ax.axis('off')\n",
    "ax.set_title('GPU ë©”ëª¨ë¦¬ ê³„ì¸µ êµ¬ì¡° (H100 ê¸°ì¤€)\\'\\nì†ë„â†‘ ìš©ëŸ‰â†“ â† Register | HBM â†’ ì†ë„â†“ ìš©ëŸ‰â†‘',\n",
    "             fontsize=11, fontweight='bold')\n",
    "\n",
    "widths = [9.5, 8.0, 6.5, 5.0, 3.5]\n",
    "\n",
    "for i, ((name, size, bw, lat, scope, color), w) in enumerate(zip(reversed(memory_hierarchy), widths)):\n",
    "    idx = len(memory_hierarchy) - 1 - i\n",
    "    x_off = (10 - w) / 2\n",
    "    rect = plt.Rectangle((x_off, idx * 0.95 + 0.05), w, 0.82,\n",
    "                          color=color, alpha=0.80, ec='white', lw=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(5, idx * 0.95 + 0.46,\n",
    "            f'{name}   |   {size}   |   BW: {bw}   |   ì§€ì—°: {lat}   |   ë²”ìœ„: {scope}',\n",
    "            ha='center', va='center', fontsize=9, color='white', fontweight='bold')\n",
    "\n",
    "ax.annotate('', xy=(0.2, 4.7), xytext=(0.2, 0.2),\n",
    "            arrowprops=dict(arrowstyle='<->', color='gray', lw=2))\n",
    "ax.text(0.05, 2.5, 'ì†ë„â†‘\\nìš©ëŸ‰â†“', ha='center', fontsize=9, color='gray', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ë©”ëª¨ë¦¬ ì„¤ê³„ ì›ì¹™:\")\n",
    "print(\"  âœ… ìì£¼ ì“°ëŠ” ë°ì´í„° â†’ Register / Shared Memoryì— ìºì‹œ\")\n",
    "print(\"  âœ… Global Memory(HBM) ì ‘ê·¼ íšŸìˆ˜ ìµœì†Œí™” â†’ Kernel Fusionì˜ í•µì‹¬!\")\n",
    "print(\"  âœ… Coalesced Access: ì¸ì ‘í•œ ìŠ¤ë ˆë“œê°€ ì¸ì ‘í•œ ë©”ëª¨ë¦¬ ì½ê¸° â†’ ëŒ€ì—­í­ ìµœëŒ€ í™œìš©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Roofline ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Roofline Model + ë”¥ëŸ¬ë‹ ì—°ì‚° ë¶„ë¥˜\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# H100 SXM ìŠ¤í™\n",
    "peak_compute_TFLOPS = 989.0    # FP32\n",
    "peak_bw_TBps        = 3.35     # HBM\n",
    "ridge_AI = peak_compute_TFLOPS / peak_bw_TBps   # FLOPs/Byte\n",
    "\n",
    "print(f\"H100 Ridge Point: {ridge_AI:.0f} FLOPs/Byte\")\n",
    "print(f\"(AI < {ridge_AI:.0f}: Memory-bound, AI > {ridge_AI:.0f}: Compute-bound)\\n\")\n",
    "\n",
    "# ë”¥ëŸ¬ë‹ ì—°ì‚°ë³„ AI ê³„ì‚°\n",
    "ops = {\n",
    "    # (ì´ë¦„, FLOPs/element, Bytes/element)\n",
    "    'GEMM\\n(m=4096,k=4096,n=4096)': (2 * 4096**3, (3 * 4096**2) * 2),  # 3 í–‰ë ¬ Ã— FP16\n",
    "    'GEMM\\n(m=64,k=4096,n=4096)':   (2 * 64 * 4096 * 4096, (64*4096 + 4096**2 + 64*4096) * 2),\n",
    "    'Self-Attention\\n(S=2048,H=64)': (4 * 2048**2 * 64, 4 * 2048**2 * 2),\n",
    "    'Softmax\\n(S=2048)':             (5 * 2048, 4 * 2048 * 2),\n",
    "    'LayerNorm\\n(H=4096)':           (7 * 4096, 8 * 4096 * 2),\n",
    "    'ReLU / GeLU\\n(element-wise)':   (5, 3 * 2),  # per element\n",
    "    'Dropout':                        (1, 3 * 2),\n",
    "}\n",
    "\n",
    "ai_values = {name: flops / bytes_ for name, (flops, bytes_) in ops.items()}\n",
    "\n",
    "print(f\"{'ì—°ì‚°':<35} {'AI (FLOPs/Byte)':>18} {'êµ¬ë¶„'}\")\n",
    "print(\"-\" * 65)\n",
    "for name, ai in ai_values.items():\n",
    "    bound = 'Compute-bound âš¡' if ai > ridge_AI else 'Memory-bound ğŸŒ'\n",
    "    clean_name = name.replace('\\n', ' ')\n",
    "    print(f\"{clean_name:<35} {ai:>18.1f} {bound}\")\n",
    "\n",
    "# Roofline ì‹œê°í™”\n",
    "ai_range = np.logspace(-1, 4, 500)\n",
    "perf_limit = np.minimum(peak_compute_TFLOPS, ai_range * peak_bw_TBps)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "ax.loglog(ai_range, perf_limit, 'k-', lw=3, label='Roofline (H100 SXM)')\n",
    "ax.axvline(x=ridge_AI, color='gray', ls=':', lw=1.5, label=f'Ridge: {ridge_AI:.0f} FLOPs/B')\n",
    "\n",
    "colors_ops = ['#1E88E5','#1E88E5','#43A047','#FB8C00','#FB8C00','#E53935','#E53935']\n",
    "markers_ops = ['o', 's', 'D', '^', 'v', 'P', '*']\n",
    "\n",
    "for (name, ai), c, m in zip(ai_values.items(), colors_ops, markers_ops):\n",
    "    perf = min(peak_compute_TFLOPS, ai * peak_bw_TBps)\n",
    "    ax.scatter(ai, perf, s=120, color=c, marker=m, zorder=5)\n",
    "    ax.annotate(name.replace('\\n', '\\n'), (ai, perf),\n",
    "                xytext=(ai * 1.2, perf * 0.8), fontsize=7.5,\n",
    "                arrowprops=dict(arrowstyle='->', lw=0.6, color='gray'))\n",
    "\n",
    "ax.fill_between(ai_range[ai_range < ridge_AI], perf_limit[ai_range < ridge_AI],\n",
    "                alpha=0.06, color='red', label='Memory-bound êµ¬ê°„')\n",
    "ax.fill_between(ai_range[ai_range > ridge_AI], perf_limit[ai_range > ridge_AI],\n",
    "                alpha=0.06, color='blue', label='Compute-bound êµ¬ê°„')\n",
    "\n",
    "ax.set_xlabel('Arithmetic Intensity (FLOPs / Byte)', fontsize=11)\n",
    "ax.set_ylabel('Attainable Performance (TFLOPS)', fontsize=11)\n",
    "ax.set_title('Roofline Model: H100 SXM + ë”¥ëŸ¬ë‹ ì—°ì‚° ë¶„ë¥˜', fontweight='bold')\n",
    "ax.legend(fontsize=9); ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nê²°ë¡ :\")\n",
    "print(\"  GEMM(large): Compute-bound â†’ GPU ìµœëŒ€ í™œìš© ê°€ëŠ¥\")\n",
    "print(\"  Softmax, LayerNorm, Elementwise: Memory-bound â†’ Kernel Fusionìœ¼ë¡œ HBM ì ‘ê·¼ ìµœì†Œí™” í•„ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Warpê³¼ Occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Warp ê°œë… ë° Occupancy ê³„ì‚°ê¸°\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# H100 SM ìŠ¤í™\n",
    "h100_sm_specs = {\n",
    "    'SM ìˆ˜':              132,\n",
    "    'ìµœëŒ€ Thread/SM':    2048,\n",
    "    'ìµœëŒ€ Block/SM':        32,\n",
    "    'Warp í¬ê¸°':            32,\n",
    "    'Register/SM (K)':      256,   # 256K 32-bit registers\n",
    "    'Shared Memory/SM (KB)': 228,\n",
    "}\n",
    "\n",
    "print(\"=== H100 SM (Streaming Multiprocessor) ìŠ¤í™ ===\")\n",
    "for k, v in h100_sm_specs.items():\n",
    "    print(f\"  {k:<28}: {v}\")\n",
    "\n",
    "print(\"\\n=== Occupancy ê³„ì‚°ê¸° ===\")\n",
    "print(f\"{'Block í¬ê¸°':>12} | {'Block/SM':>8} | {'Thread/SM':>10} | {'Warp/SM':>8} | {'Occupancy':>10}\")\n",
    "print(\"-\" * 58)\n",
    "\n",
    "max_threads = h100_sm_specs['ìµœëŒ€ Thread/SM']\n",
    "max_blocks  = h100_sm_specs['ìµœëŒ€ Block/SM']\n",
    "warp_size   = h100_sm_specs['Warp í¬ê¸°']\n",
    "max_warps   = max_threads // warp_size\n",
    "\n",
    "for block_size in [32, 64, 128, 256, 512, 1024]:\n",
    "    blocks_by_threads = max_threads // block_size\n",
    "    active_blocks = min(blocks_by_threads, max_blocks)\n",
    "    active_threads = active_blocks * block_size\n",
    "    active_warps   = active_threads // warp_size\n",
    "    occupancy      = active_warps / max_warps\n",
    "    print(f\"{block_size:>12} | {active_blocks:>8} | {active_threads:>10} | {active_warps:>8} | {occupancy:>9.1%}\")\n",
    "\n",
    "print(f\"\\nH100 ìµœëŒ€ Warp/SM: {max_warps}\")\n",
    "print(\"Block í¬ê¸° 256ì´ 100% Occupancyì—ì„œ ê¶Œì¥ (ì‹¤ì œ ë ˆì§€ìŠ¤í„° ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ë‹¤ë¦„)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# GPU ìŠ¤ë ˆë“œ ê³„ì¸µ ì‹œê°í™”\n",
    "# ---------------------------------------------------\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "ax.set_xlim(0, 13); ax.set_ylim(0, 6)\n",
    "ax.axis('off')\n",
    "ax.set_title('GPU ìŠ¤ë ˆë“œ ê³„ì¸µ: Grid â†’ Block â†’ Warp â†’ Thread', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Grid\n",
    "grid = plt.Rectangle((0.3, 0.5), 12.4, 5, color='#E8EAF6', ec='#3949AB', lw=2.5, zorder=1)\n",
    "ax.add_patch(grid)\n",
    "ax.text(6.5, 5.3, 'Grid (ì»¤ë„ ì „ì²´ ì‹¤í–‰ ë‹¨ìœ„)', ha='center', fontsize=10, fontweight='bold', color='#3949AB')\n",
    "\n",
    "# Thread Blocks\n",
    "block_positions = [(0.6, 2.8), (4.7, 2.8), (8.8, 2.8)]\n",
    "for bx, by in block_positions:\n",
    "    block = plt.Rectangle((bx, by), 3.8, 2.3, color='#E3F2FD', ec='#1565C0', lw=2, zorder=2)\n",
    "    ax.add_patch(block)\n",
    "    ax.text(bx+1.9, by+2.05, 'Thread Block (128 threads)', ha='center', fontsize=8, color='#1565C0', fontweight='bold')\n",
    "\n",
    "    # Warps within each block\n",
    "    for w in range(4):\n",
    "        wx = bx + 0.1 + w * 0.9\n",
    "        wy = by + 0.2\n",
    "        warp = plt.Rectangle((wx, wy), 0.8, 1.6, color='#BBDEFB', ec='white', lw=1, zorder=3)\n",
    "        ax.add_patch(warp)\n",
    "        ax.text(wx+0.4, wy+1.3, f'W{w}', ha='center', fontsize=8, fontweight='bold', color='#1565C0')\n",
    "        # Threads in warp\n",
    "        for t in range(4):\n",
    "            tx = wx + 0.15 + (t % 2) * 0.3\n",
    "            ty = wy + 0.15 + (t // 2) * 0.4\n",
    "            ax.scatter(tx, ty, s=30, color='#1565C0', zorder=4)\n",
    "\n",
    "# SM ë°°ì¹˜ë„\n",
    "ax.text(6.5, 2.4, 'â†‘ ìœ„: Thread Hierarchy', ha='center', fontsize=9, color='gray')\n",
    "\n",
    "# SM â†’ í•˜ë‹¨ ë©”ëª¨ë¦¬ ê³„ì¸µ\n",
    "for i, (mem, y, color) in enumerate([\n",
    "    ('Register (ìŠ¤ë ˆë“œ ì „ìš©)', 1.9, '#1B5E20'),\n",
    "    ('Shared Memory (Block ê³µìœ )', 1.4, '#1565C0'),\n",
    "    ('Global Memory/HBM (ì „ì²´)', 0.9, '#B71C1C'),\n",
    "]):\n",
    "    rect = plt.Rectangle((0.4, y), 12.2, 0.38, color=color, alpha=0.7, ec='white', lw=1, zorder=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(6.5, y + 0.19, mem, ha='center', va='center', fontsize=9, color='white', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì •ë¦¬\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |\n",
    "|------|------|-------|\n",
    "| **SM** | GPUì˜ ë³‘ë ¬ ì²˜ë¦¬ ë‹¨ìœ„, H100ì€ 132ê°œ SM | â­â­â­ |\n",
    "| **Warp** | 32ê°œ Threadê°€ SIMD ë°©ì‹ìœ¼ë¡œ ë™ì‹œ ì‹¤í–‰ | â­â­â­ |\n",
    "| **Occupancy** | SMì˜ í™œì„± Warp ë¹„ìœ¨ â†’ ë†’ì„ìˆ˜ë¡ ì§€ì—° ìˆ¨ê¸°ê¸° ì¢‹ìŒ | â­â­ |\n",
    "| **AI** | FLOPs/Bytes â†’ Compute vs Memory bound íŒë³„ | â­â­â­ |\n",
    "| **Roofline** | ì‹¤ì œ ì„±ëŠ¥ ìƒí•œ = min(Peak FLOPs, AI Ã— Peak BW) | â­â­â­ |\n",
    "| **Shared Memory** | Block ë‚´ ìŠ¤ë ˆë“œ ê°„ ê³ ì† ê³µìœ , Tilingì— í•„ìˆ˜ | â­â­â­ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$\\text{AI} = \\frac{\\text{FLOPs}}{\\text{Bytes}}, \\quad \\text{Roof} = \\min\\left(P_{compute}, \\; \\text{AI} \\times P_{bw}\\right)$$\n",
    "\n",
    "$$\\text{AI}_{ridge}^{H100} = \\frac{989 \\text{ TFLOPS}}{3.35 \\text{ TB/s}} \\approx 295 \\text{ FLOPs/Byte}$$\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**Chapter 11-02: CUDA C++ í™•ì¥** â€” Python ìˆ˜ì¤€ì˜ TensorFlow/PyTorch ì—°ì‚°ìœ¼ë¡œëŠ” í‘œí˜„ì´ ë¶ˆê°€ëŠ¥í•œ **ì»¤ìŠ¤í…€ CUDA C++ ì»¤ë„**ì„ pybind11ë¡œ íŒŒì´ì¬ì— ì—°ê²°í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•œë‹¤. ê°„ë‹¨í•œ ë²¡í„° ì—°ì‚°ë¶€í„° Shared Memoryë¥¼ í™œìš©í•˜ëŠ” í–‰ë ¬ Tilingê¹Œì§€ ë‹¨ê³„ë³„ êµ¬í˜„í•œë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python (tf_study)", "language": "python", "name": "tf_study"},
  "language_info": {"name": "python", "version": "3.11.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}