{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11-02: CUDA C++ ì»¤ë„ ì‘ì„±ê³¼ Python ì—°ë™\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- **CUDA C++** ì»¤ë„ ë¬¸ë²•(`__global__`, `blockIdx`, `threadIdx`, `blockDim`)ì„ ì´í•´í•˜ê³  ë²¡í„°/í–‰ë ¬ ì—°ì‚° ì»¤ë„ì„ ì‘ì„±í•œë‹¤\n",
    "- **Shared Memory Tiling**ìœ¼ë¡œ Global Memory ì ‘ê·¼ì„ ìµœì†Œí™”í•˜ëŠ” í–‰ë ¬ ê³± ì»¤ë„ì„ êµ¬í˜„í•œë‹¤\n",
    "- **pybind11** ë˜ëŠ” TensorFlow `tf.custom_op` / **CuPy**ë¡œ ì»¤ìŠ¤í…€ ì»¤ë„ì„ Pythonì— ë…¸ì¶œí•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•œë‹¤\n",
    "- Naive CUDA GEMM vs cuBLAS vs Tiled CUDAì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ Roofline ê´€ì ì—ì„œ ë¶„ì„í•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: GEMMì˜ Shared Memory Tiling](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [CUDA ì»¤ë„ êµ¬ì¡° ì´í•´ (ì˜ì‚¬ì½”ë“œ ë¶„ì„)](#2.-CUDA-ì»¤ë„-êµ¬ì¡°)\n",
    "3. [Python ë ˆë²¨ GPU ì—°ì‚° ì„±ëŠ¥ ë¶„ì„](#3.-Python-GPU-ì„±ëŠ¥)\n",
    "4. [Tiled GEMM ì‹œë®¬ë ˆì´ì…˜ (NumPy)](#4.-Tiled-GEMM-ì‹œë®¬ë ˆì´ì…˜)\n",
    "5. [ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´ ë¹„êµ ì‹œê°í™”](#5.-ë©”ëª¨ë¦¬-ì ‘ê·¼-íŒ¨í„´)\n",
    "6. [ì •ë¦¬ ë° ì—°ìŠµ ë¬¸ì œ](#6.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ\n",
    "\n",
    "### Tiled GEMM: Shared Memory í™œìš©\n",
    "\n",
    "í‘œì¤€ GEMM $C = A \\times B$ ($A: M\\times K$, $B: K\\times N$, $C: M\\times N$)ì—ì„œ,  \n",
    "íƒ€ì¼ í¬ê¸° $T$ë¡œ ë¶„í• í•˜ë©´:\n",
    "\n",
    "$$C_{ij} = \\sum_{k=0}^{K-1} A_{ik} B_{kj} = \\sum_{t=0}^{K/T - 1} \\sum_{\\ell=0}^{T-1} A_{i, tT+\\ell} \\cdot B_{tT+\\ell, j}$$\n",
    "\n",
    "ê° íƒ€ì¼ $t$ì—ì„œ:\n",
    "1. $A$ì˜ $M \\times T$ ì„œë¸Œí–‰ë ¬ì„ Shared Memoryì— ë¡œë“œ\n",
    "2. $B$ì˜ $T \\times N$ ì„œë¸Œí–‰ë ¬ì„ Shared Memoryì— ë¡œë“œ\n",
    "3. ë‘ ì„œë¸Œí–‰ë ¬ì˜ ê³±ì„ ë ˆì§€ìŠ¤í„°ì— ëˆ„ì \n",
    "4. ë‹¤ìŒ íƒ€ì¼ë¡œ ì´ë™ (`__syncthreads()`ë¡œ ë™ê¸°í™”)\n",
    "\n",
    "### ë©”ëª¨ë¦¬ ì ‘ê·¼ ì ˆì•½ ë¶„ì„\n",
    "\n",
    "- **Naive**: ê° $C_{ij}$ ì—°ì‚° ì‹œ $A$ì˜ Kê°œ + $B$ì˜ Kê°œ ì›ì†Œë¥¼ Global Memoryì—ì„œ ì§ì ‘ ì½ìŒ\n",
    "  â†’ ì´ Global Memory ì½ê¸°: $MNK + MNK = 2MNK$ elements\n",
    "- **Tiled**: íƒ€ì¼ 1ê°œë¥¼ Shared Memoryì— 1ë²ˆ ë¡œë“œ í›„ $T$ë²ˆ ì¬ì‚¬ìš©\n",
    "  â†’ ì´ Global Memory ì½ê¸°: $\\frac{2MNK}{T}$ elements â†’ **$T$ë°° ì ˆì•½**!\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ“¦ Shared Memory Tilingì´ ë­”ê°€ìš”?\n",
    "\n",
    "> ë„ì„œê´€(Global Memory)ì—ì„œ ì±…ì„ ë¹Œë¦´ ë•Œë§ˆë‹¤ ë¨¼ ê³³ê¹Œì§€ ê°€ì•¼ í•´ìš” (ëŠë¦¼!).  \n",
    "> **í•´ê²°ì±…**: ì±… ì—¬ëŸ¬ ê¶Œì„ í•œ ë²ˆì— ë¹Œë ¤ì„œ ì±…ìƒ(Shared Memory) ìœ„ì— ìŒ“ì•„ë‘ê³ ,  \n",
    "> ì—¬ëŸ¬ ê³„ì‚°ì— ì¬ì‚¬ìš©í•œë‹¤ë©´? â†’ ë„ì„œê´€ ë°©ë¬¸ íšŸìˆ˜ë¥¼ Të°° ì¤„ì¼ ìˆ˜ ìˆì–´ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: Tiled GEMM ë©”ëª¨ë¦¬ ì ˆì•½ ê³„ì‚°\n",
    "\n",
    "$M=K=N=4096$, íƒ€ì¼ í¬ê¸° $T=32$ì¼ ë•Œ  \n",
    "Naive vs Tiled GEMMì˜ Global Memory ì½ê¸° íšŸìˆ˜ë¥¼ ë¹„êµí•˜ë¼.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$M = K = N = 4096$, $T = 32$\n",
    "\n",
    "- **Naive**: $2MNK = 2 \\times 4096^3 \\approx 137.4 \\text{ G elements}$\n",
    "- **Tiled**: $2MNK/T = 137.4 / 32 \\approx 4.3 \\text{ G elements}$  \n",
    "- ì ˆì•½ëŸ‰: **32ë°°** (íƒ€ì¼ í¬ê¸°ì™€ ë™ì¼!)\n",
    "\n",
    "FP16 ê¸°ì¤€ ë°”ì´íŠ¸: Naive $\\approx 275$ GB, Tiled $\\approx 8.6$ GB\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: ì´ìƒì  AI (Tiled GEMM)\n",
    "\n",
    "$M=K=N=4096$, FP16 Tiled GEMM(T=32)ì˜ FLOPsì™€ ë©”ëª¨ë¦¬ ì ‘ê·¼ëŸ‰ìœ¼ë¡œ AIë¥¼ ê³„ì‚°í•˜ê³   \n",
    "H100 Ridge Point(295 FLOPs/Byte)ì™€ ë¹„êµí•˜ë¼.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "FLOPs = $2 \\times 4096^3 \\approx 137.4$ GFLOPS  \n",
    "Bytes = $2MNK/T \\times 2$ bytes (FP16) â‰ˆ $17.2$ GB  \n",
    "AI = $137.4/17.2 \\approx \\mathbf{8000}$ FLOPs/Byte\n",
    "\n",
    "AI (8000) â‰« Ridge (295) â†’ **ê°•í•œ Compute-bound** â†’ cuBLASì™€ ë§ë¨¹ëŠ” íš¨ìœ¨ ë‹¬ì„± ê°€ëŠ¥!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CUDA ì»¤ë„ êµ¬ì¡°\n",
    "\n",
    "ì•„ë˜ëŠ” CUDA C++ë¡œ ì‘ì„±í•œ Tiled GEMM ì»¤ë„ì˜ ì˜ì‚¬ì½”ë“œì…ë‹ˆë‹¤.  \n",
    "ì‹¤ì œ GPU ì—†ì´ë„ ì•Œê³ ë¦¬ì¦˜ ë¡œì§ì„ ì™„ì „íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# CUDA Tiled GEMM ì»¤ë„ ì˜ì‚¬ì½”ë“œ ì„¤ëª…\n",
    "# (ì‹¤ì œ CUDA C++ ì½”ë“œë¥¼ ì£¼ì„ìœ¼ë¡œ ìƒì„¸íˆ ì„¤ëª…)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "cuda_pseudocode = '''\n",
    "/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   CUDA Tiled GEMM Kernel  (C = A Ã— B)\n",
    "   íƒ€ì¼ í¬ê¸°: TILE_SIZE x TILE_SIZE\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */\n",
    "\n",
    "__global__ void tiled_gemm(float* A, float* B, float* C,\n",
    "                            int M, int K, int N) {\n",
    "\n",
    "    // â‘  ê° ìŠ¤ë ˆë“œì˜ ì „ì—­ í–‰/ì—´ ì¢Œí‘œ ê³„ì‚°\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;  // Cì˜ í–‰ ì¢Œí‘œ\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;  // Cì˜ ì—´ ì¢Œí‘œ\n",
    "\n",
    "    // â‘¡ Shared Memory ì„ ì–¸ (íƒ€ì¼ 2ê°œ)\n",
    "    __shared__ float tileA[TILE_SIZE][TILE_SIZE];  // Aì˜ ì„œë¸Œí–‰ë ¬\n",
    "    __shared__ float tileB[TILE_SIZE][TILE_SIZE];  // Bì˜ ì„œë¸Œí–‰ë ¬\n",
    "\n",
    "    float result = 0.0f;  // ë ˆì§€ìŠ¤í„°ì— ë¶€ë¶„ í•©ì‚° ëˆ„ì \n",
    "\n",
    "    // â‘¢ íƒ€ì¼ ë‹¨ìœ„ ë£¨í”„ (K ì°¨ì›ì„ TILE_SIZEì”© ì²˜ë¦¬)\n",
    "    for (int tile = 0; tile < K / TILE_SIZE; tile++) {\n",
    "\n",
    "        // â‘£ ê° ìŠ¤ë ˆë“œê°€ A, Bì˜ ì›ì†Œ í•˜ë‚˜ì”© Shared Memoryì— ë¡œë“œ\n",
    "        tileA[threadIdx.y][threadIdx.x] = A[row * K + tile * TILE_SIZE + threadIdx.x];\n",
    "        tileB[threadIdx.y][threadIdx.x] = B[(tile * TILE_SIZE + threadIdx.y) * N + col];\n",
    "\n",
    "        __syncthreads();  // â‘¤ ëª¨ë“  ìŠ¤ë ˆë“œ ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°\n",
    "\n",
    "        // â‘¥ ë¡œë“œëœ íƒ€ì¼ë¡œ ë‚´ì  ê³„ì‚° (Global Memory ì ‘ê·¼ ì—†ìŒ!)\n",
    "        for (int k = 0; k < TILE_SIZE; k++)\n",
    "            result += tileA[threadIdx.y][k] * tileB[k][threadIdx.x];\n",
    "\n",
    "        __syncthreads();  // â‘¦ ë‹¤ìŒ íƒ€ì¼ ë¡œë“œ ì „ ë™ê¸°í™”\n",
    "    }\n",
    "\n",
    "    // â‘§ ìµœì¢… ê²°ê³¼ë¥¼ Global Memoryì— ì“°ê¸° (1íšŒ)\n",
    "    if (row < M && col < N)\n",
    "        C[row * N + col] = result;\n",
    "}\n",
    "'''\n",
    "\n",
    "print(cuda_pseudocode)\n",
    "\n",
    "print(\"\\nì£¼ìš” CUDA ê°œë… ì •ë¦¬:\")\n",
    "print(\"  __global__        : GPU ì»¤ë„ í•¨ìˆ˜ (Hostì—ì„œ í˜¸ì¶œ, Deviceì—ì„œ ì‹¤í–‰)\")\n",
    "print(\"  blockIdx.x/y      : ì´ Blockì˜ Grid ë‚´ ì¢Œí‘œ\")\n",
    "print(\"  threadIdx.x/y     : ì´ Threadì˜ Block ë‚´ ì¢Œí‘œ\")\n",
    "print(\"  __shared__        : Block ë‚´ ìŠ¤ë ˆë“œê°€ ê³µìœ í•˜ëŠ” ê³ ì† Shared Memory\")\n",
    "print(\"  __syncthreads()   : Block ë‚´ ëª¨ë“  ìŠ¤ë ˆë“œê°€ ì´ ì¤„ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ëŒ€ê¸°\")\n",
    "print(\"  â‘¥ Global Memory ì ‘ê·¼ = 0 â†’ Tilingì˜ í•µì‹¬!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python GPU ì„±ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# TF/NumPyë¡œ GEMM ì„±ëŠ¥ ì¸¡ì • ë° ì´ë¡  ëŒ€ë¹„ íš¨ìœ¨ ë¶„ì„\n",
    "# ---------------------------------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def benchmark_gemm(M, K, N, n_warmup=5, n_runs=20):\n",
    "    \"\"\"í–‰ë ¬ ê³± ì„±ëŠ¥ ì¸¡ì • (GFLOPS, ì´ë¡  peak ëŒ€ë¹„ íš¨ìœ¨)\"\"\"\n",
    "    A = tf.random.normal([M, K], dtype=tf.float32)\n",
    "    B = tf.random.normal([K, N], dtype=tf.float32)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(n_warmup):\n",
    "        _ = tf.matmul(A, B)\n",
    "\n",
    "    # ì¸¡ì •\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(n_runs):\n",
    "        C = tf.matmul(A, B)\n",
    "    # CPU ë™ê¸°í™”\n",
    "    _ = C.numpy()\n",
    "    elapsed = (time.perf_counter() - start) / n_runs\n",
    "\n",
    "    flops = 2 * M * K * N  # ê³±ì…ˆ + ë§ì…ˆ\n",
    "    gflops = flops / elapsed / 1e9\n",
    "    return elapsed * 1000, gflops  # ms, GFLOPS\n",
    "\n",
    "sizes = [\n",
    "    (64, 4096, 4096),\n",
    "    (256, 4096, 4096),\n",
    "    (1024, 4096, 4096),\n",
    "    (4096, 4096, 4096),\n",
    "]\n",
    "\n",
    "print(f\"{'M':>6} | {'K':>6} | {'N':>6} | {'ì‹œê°„(ms)':>10} | {'GFLOPS':>10} | {'FP32 ì´ë¡  ëŒ€ë¹„'}\")  \n",
    "print(\"-\" * 65)\n",
    "\n",
    "peak_fp32_gflops = 989 * 1000  # H100 FP32 â‰ˆ 989 TFLOPS â†’ 989,000 GFLOPS\n",
    "# Apple M3 (í…ŒìŠ¤íŠ¸ í™˜ê²½)ì€ ì•½ 14 TFLOPS\n",
    "peak_estimate = 14 * 1000\n",
    "\n",
    "results = []\n",
    "for M, K, N in sizes:\n",
    "    try:\n",
    "        ms, gflops = benchmark_gemm(M, K, N)\n",
    "        efficiency = gflops / peak_estimate * 100\n",
    "        print(f\"{M:>6} | {K:>6} | {N:>6} | {ms:>10.2f} | {gflops:>10.1f} | {efficiency:.1f}%\")\n",
    "        results.append((M, K, N, ms, gflops))\n",
    "    except Exception as e:\n",
    "        print(f\"{M:>6} | ... (ì˜¤ë¥˜: {str(e)[:40]})\")\n",
    "\n",
    "print(\"\\nâ†’ í–‰ë ¬ì´ í´ìˆ˜ë¡ GFLOPS íš¨ìœ¨ ì¦ê°€ (Compute-bound êµ¬ê°„ì— ì§„ì…)\")\n",
    "print(\"â†’ ì‘ì€ ë°°ì¹˜(M=64): Memory-bound â†’ íš¨ìœ¨ ë‚®ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tiled GEMM ì‹œë®¬ë ˆì´ì…˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Tiled GEMMì„ ìˆœìˆ˜ NumPyë¡œ êµ¬í˜„í•˜ê³  ì •í™•ë„ ê²€ì¦\n",
    "# (CUDA Shared Memory Tiling ì•Œê³ ë¦¬ì¦˜ì˜ Python êµ¬í˜„)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def tiled_gemm_numpy(A, B, tile_size=4):\n",
    "    \"\"\"\n",
    "    CUDA Tiled GEMMì˜ Python/NumPy êµ¬í˜„.\n",
    "    CUDAì˜ Shared Memoryë¥¼ Python ë°°ì—´ë¡œ ì‹œë®¬ë ˆì´ì…˜.\n",
    "    \n",
    "    ì´ êµ¬í˜„ì€ CUDA ì»¤ë„ì˜ ë…¼ë¦¬ë¥¼ 1:1ë¡œ ë§¤í•‘:\n",
    "      - outer loop = íƒ€ì¼ ì¸ë±ìŠ¤ (blockIdxì²˜ëŸ¼)\n",
    "      - inner loop = ê° íƒ€ì¼ ë‚´ ì—°ì‚° (threadIdxì²˜ëŸ¼)\n",
    "    \"\"\"\n",
    "    M, K = A.shape\n",
    "    K2, N = B.shape\n",
    "    assert K == K2, \"í–‰ë ¬ ì°¨ì› ë¶ˆì¼ì¹˜\"\n",
    "    C = np.zeros((M, N), dtype=A.dtype)\n",
    "\n",
    "    global_mem_reads = 0\n",
    "    shared_mem_reads = 0\n",
    "\n",
    "    for tile_k in range(0, K, tile_size):\n",
    "        t_end = min(tile_k + tile_size, K)\n",
    "\n",
    "        for row_start in range(0, M, tile_size):\n",
    "            r_end = min(row_start + tile_size, M)\n",
    "\n",
    "            for col_start in range(0, N, tile_size):\n",
    "                c_end = min(col_start + tile_size, N)\n",
    "\n",
    "                # â”€â”€ Shared Memory ë¡œë“œ (Global Memory ì ‘ê·¼) â”€â”€\n",
    "                tileA = A[row_start:r_end, tile_k:t_end]      # Shared Memì— ë¡œë“œ\n",
    "                tileB = B[tile_k:t_end, col_start:c_end]      # Shared Memì— ë¡œë“œ\n",
    "                global_mem_reads += tileA.size + tileB.size\n",
    "\n",
    "                # â”€â”€ íƒ€ì¼ ë‚´ ì—°ì‚° (Shared Memoryì—ì„œ ì½ê¸°) â”€â”€\n",
    "                C[row_start:r_end, col_start:c_end] += tileA @ tileB\n",
    "                shared_mem_reads += tileA.size + tileB.size  # ì¬ì‚¬ìš© íšŸìˆ˜ ì¶”ì \n",
    "\n",
    "    return C, global_mem_reads, shared_mem_reads\n",
    "\n",
    "\n",
    "# ê²€ì¦\n",
    "M, K, N = 8, 8, 8\n",
    "A = np.random.randn(M, K).astype(np.float32)\n",
    "B = np.random.randn(K, N).astype(np.float32)\n",
    "\n",
    "C_ref   = A @ B   # í‘œì¤€ GEMM\n",
    "C_tiled, glb_reads, shr_reads = tiled_gemm_numpy(A, B, tile_size=4)\n",
    "\n",
    "err = np.abs(C_ref - C_tiled).max()\n",
    "print(f\"[Tiled GEMM ê²€ì¦] M={M}, K={K}, N={N}, tile=4\")\n",
    "print(f\"  ìµœëŒ€ ì˜¤ì°¨: {err:.2e}\")\n",
    "print(f\"  ì •í™•ë„:    {'âœ… ì™„ì „ ì¼ì¹˜' if err < 1e-5 else 'âŒ ë¶ˆì¼ì¹˜'}\")\n",
    "print(f\"\\nGlobal Memory ì½ê¸°: {glb_reads} elements (Naive = {2*M*K*N//4})\")  # ê·¼ì‚¬\n",
    "print(\"â†’ íƒ€ì¼ë§ìœ¼ë¡œ Global Memory ì ‘ê·¼ íšŸìˆ˜ë¥¼ í¬ê²Œ ì¤„ì„\")\n",
    "\n",
    "# ë” í° í–‰ë ¬ë¡œ ì„±ëŠ¥ ë¹„êµ\n",
    "M2 = K2 = N2 = 64\n",
    "A2 = np.random.randn(M2, K2).astype(np.float32)\n",
    "B2 = np.random.randn(K2, N2).astype(np.float32)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "C_ref2 = A2 @ B2\n",
    "t_std = time.perf_counter() - t0\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "C_tiled2, _, _ = tiled_gemm_numpy(A2, B2, tile_size=8)\n",
    "t_tiled = time.perf_counter() - t0\n",
    "\n",
    "err2 = np.abs(C_ref2 - C_tiled2).max()\n",
    "print(f\"\\n[{M2}Ã—{K2}Ã—{N2} GEMM ì •í™•ë„]: ìµœëŒ€ ì˜¤ì°¨={err2:.2e} {'âœ…' if err2 < 1e-4 else 'âŒ'}\")\n",
    "print(f\"(ì°¸ê³ : Python êµ¬í˜„ì€ CUDA ë³‘ë ¬í™” ì—†ì–´ ëŠë¦¼. ì‹¤ì œ CUDAì—ì„œëŠ” ì••ë„ì ìœ¼ë¡œ ë¹ ë¦„)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# íƒ€ì¼ í¬ê¸°ì— ë”°ë¥¸ Global Memory ì ‘ê·¼ íšŸìˆ˜ ë¹„êµ\n",
    "# ---------------------------------------------------\n",
    "\n",
    "M = K = N = 4096\n",
    "tile_sizes = [1, 2, 4, 8, 16, 32, 64]\n",
    "\n",
    "naive_reads = 2 * M * K * N  # Naive: 2MNK ì›ì†Œ ì½ê¸°\n",
    "tiled_reads = [2 * M * K * N / T for T in tile_sizes]\n",
    "savings_pct  = [(1 - t / naive_reads) * 100 for t in tiled_reads]\n",
    "\n",
    "print(f\"Naive GEMM Global Memory ì½ê¸°: {naive_reads/1e9:.1f}G elements ({naive_reads*2/1e9:.0f}GB FP16)\")\n",
    "print(f\"\\n{'íƒ€ì¼ í¬ê¸° T':>12} | {'ì½ê¸° íšŸìˆ˜':>14} | {'ì ˆì•½ë¥ ':>8}\")\n",
    "print(\"-\" * 40)\n",
    "for T, r, s in zip(tile_sizes, tiled_reads, savings_pct):\n",
    "    print(f\"{T:>12} | {r/1e9:>12.2f}G | {s:>7.1f}%\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# ì™¼ìª½: Global Memory ì½ê¸° íšŸìˆ˜\n",
    "ax1 = axes[0]\n",
    "ax1.semilogy(tile_sizes, [naive_reads/1e9]*len(tile_sizes), 'r--', lw=2.5, label='Naive')\n",
    "ax1.semilogy(tile_sizes, [r/1e9 for r in tiled_reads], 'b-o', lw=2.5, ms=8, label='Tiled')\n",
    "for T, r in zip(tile_sizes, tiled_reads):\n",
    "    ax1.text(T, r/1e9*1.3, f'{r/1e9:.1f}G', ha='center', fontsize=8, color='blue')\n",
    "ax1.set_xlabel('íƒ€ì¼ í¬ê¸° T', fontsize=11)\n",
    "ax1.set_ylabel('Global Memory ì½ê¸° (G elements, log)', fontsize=10)\n",
    "ax1.set_title(f'Tiled GEMM: íƒ€ì¼ í¬ê¸°ë³„\\nGlobal Memory ì ‘ê·¼ ê°ì†Œ (M=K=N={M})', fontweight='bold')\n",
    "ax1.legend(fontsize=10); ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ì˜¤ë¥¸ìª½: Naive vs Tiled ë©”ëª¨ë¦¬ vs ì—°ì‚° ë¹„êµ (Roofline ê°œë…)\n",
    "ax2 = axes[1]\n",
    "methods = ['Naive\\nT=1', 'Tiled\\nT=4', 'Tiled\\nT=16', 'Tiled\\nT=32', 'Ideal\\n(cuBLAS)']\n",
    "ai_vals  = [1.0, 4.0, 16.0, 32.0, 65.0]   # ì •ê·œí™”ëœ AI\n",
    "perf_pct = [2.0, 12.0, 45.0, 80.0, 95.0]  # ì´ë¡  Peak ë‹¬ì„±ë¥  (ì¶”ì •)\n",
    "colors_m = ['#E53935', '#FB8C00', '#FDD835', '#43A047', '#1E88E5']\n",
    "\n",
    "bars = ax2.bar(methods, perf_pct, color=colors_m, alpha=0.85, edgecolor='white', lw=2)\n",
    "for bar, pct in zip(bars, perf_pct):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, pct + 1.5,\n",
    "             f'{pct}%', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax2.axhline(y=100, color='k', ls='--', lw=1.5, alpha=0.5, label='ì´ë¡  Peak 100%')\n",
    "ax2.set_ylabel('ì´ë¡  Peak FLOPS ë‹¬ì„±ë¥  (%)', fontsize=11)\n",
    "ax2.set_title('êµ¬í˜„ ë°©ì‹ë³„ GPU ì—°ì‚° íš¨ìœ¨\\n(ì»¤ìŠ¤í…€ ì»¤ë„ â†’ cuBLAS ìˆ˜ì¤€ ëª©í‘œ)', fontweight='bold')\n",
    "ax2.set_ylim(0, 115)\n",
    "ax2.legend(fontsize=9); ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì •ë¦¬\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… |\n",
    "|------|------|\n",
    "| **`__global__`** | GPUì—ì„œ ì‹¤í–‰ë  ì»¤ë„ í•¨ìˆ˜ ì„ ì–¸ |\n",
    "| **`__shared__`** | Block ë‚´ ìŠ¤ë ˆë“œ ê³µìœ  ê³ ì† ë©”ëª¨ë¦¬ |\n",
    "| **`__syncthreads()`** | Block ë‚´ ìŠ¤ë ˆë“œ ë°°ë¦¬ì–´ ë™ê¸°í™” |\n",
    "| **Tiling** | Shared Memoryë¥¼ ì´ìš©í•´ Global Memory ì ‘ê·¼ $T$ë°° ì ˆì•½ |\n",
    "| **Coalesced Access** | ì¸ì ‘ ìŠ¤ë ˆë“œê°€ ì—°ì† ë©”ëª¨ë¦¬ ì ‘ê·¼ â†’ ëŒ€ì—­í­ ìµœëŒ€í™” |\n",
    "| **AI í–¥ìƒ** | Tilingìœ¼ë¡œ AI â‰ˆ $T\\times$ ì¦ê°€ â†’ Compute-boundë¡œ ì „í™˜ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$\\text{Global Memory ì ˆê°} = T \\text{ë°°}, \\quad \\text{AI}_{tiled} \\approx T \\times \\text{AI}_{naive}$$\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**Chapter 11-03: Triton ì»¤ë„ í”„ë¡œê·¸ë˜ë°** â€” C++ ì—†ì´ Python ë¬¸ë²•ìœ¼ë¡œ GPU ì»¤ë„ì„ ì‘ì„±í•˜ëŠ” Triton. Block Pointer, ìë™ íƒ€ì¼ë§, OpenAI Tritonìœ¼ë¡œ Fused Softmax ë“±ì˜ ì»¤ìŠ¤í…€ ì—°ì‚°ì„ êµ¬í˜„í•œë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python (tf_study)", "language": "python", "name": "tf_study"},
  "language_info": {"name": "python", "version": "3.11.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}