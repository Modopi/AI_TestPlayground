import sys, os
sys.path.insert(0, '/workspace/scripts')
from nb_helper import md, code, create_notebook

cells = []

# â”€â”€ Cell 1: Header â”€â”€
cells.append(md(r"""# Chapter 17: ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸ê³¼ DiT â€” Flow Matchingê³¼ Rectified Flow

## í•™ìŠµ ëª©í‘œ
- Flow Matchingì˜ ODE ê¸°ë°˜ ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ìˆ˜ì‹ ìˆ˜ì¤€ì—ì„œ ì´í•´í•œë‹¤
- Rectified Flowì˜ ì§ì„  ê²½ë¡œ(straight-line path) ì„¤ê³„ë¥¼ ë„ì¶œí•˜ê³  ì‹œê°í™”í•œë‹¤
- DDPMì˜ ê³¡ì„  ë…¸ì´ì¦ˆ ê²½ë¡œì™€ Flow Matchingì˜ ì§ì„  ê²½ë¡œë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµí•œë‹¤
- Flow Matching Lossë¥¼ TensorFlowë¡œ êµ¬í˜„í•˜ê³  í•™ìŠµ ê³¼ì •ì„ ì‹¤í—˜í•œë‹¤
- Euler ODE Solverë¥¼ ì´ìš©í•œ ìƒ˜í”Œë§ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ êµ¬í˜„í•œë‹¤
- SD3Â·Fluxì™€ DDPMì˜ í›ˆë ¨ ë°©ì‹ ì°¨ì´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¹„êµí•œë‹¤

## ëª©ì°¨
1. [ìˆ˜í•™ì  ê¸°ì´ˆ: Flow Matchingê³¼ Rectified Flow](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)
2. [ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì •](#2.-í™˜ê²½-ì„¤ì •)
3. [Rectified Flow ê²½ë¡œ ì‹œê°í™” (ì§ì„  vs DDPM ê³¡ì„ )](#3.-ê²½ë¡œ-ì‹œê°í™”)
4. [Flow Matching Loss êµ¬í˜„](#4.-FM-Loss-êµ¬í˜„)
5. [Euler ODE Solver ìƒ˜í”Œë§](#5.-Euler-ìƒ˜í”Œë§)
6. [SD3/Flux vs DDPM í›ˆë ¨ ë°©ì‹ ë¹„êµ](#6.-í›ˆë ¨-ë¹„êµ)
7. [ì •ë¦¬](#7.-ì •ë¦¬)"""))

# â”€â”€ Cell 2: Math Section â”€â”€
cells.append(md(r"""## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>

### Flow Matching ODE

ì—°ì† ì •ê·œí™” íë¦„(Continuous Normalizing Flow)ì—ì„œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ODE:

$$\frac{dx}{dt} = v_\theta(x, t), \quad t \in [0, 1]$$

- $x_0 \sim p_0$: ë…¸ì´ì¦ˆ ë¶„í¬ (ì˜ˆ: $\mathcal{N}(0, I)$)
- $x_1 \sim p_1$: ë°ì´í„° ë¶„í¬
- $v_\theta$: ì‹ ê²½ë§ì´ í•™ìŠµí•˜ëŠ” **ì†ë„ì¥(velocity field)**
- $t=0$ì—ì„œ $t=1$ë¡œ ì ë¶„í•˜ë©´ ë…¸ì´ì¦ˆ â†’ ë°ì´í„° ë³€í™˜

### Rectified Flow (ì§ì„  ê²½ë¡œ)

ê°€ì¥ ê°„ë‹¨í•œ ë³´ê°„(interpolation) ê²½ë¡œë¥¼ ì •ì˜í•©ë‹ˆë‹¤:

$$x_t = (1-t)x_0 + tx_1$$

ì´ë•Œ ìµœì  ì†ë„ì¥(Optimal Transport)ì€:

$$v^{OT}(x_t, t) = x_1 - x_0$$

- $x_0$: ë…¸ì´ì¦ˆ ìƒ˜í”Œ
- $x_1$: ë°ì´í„° ìƒ˜í”Œ
- ê²½ë¡œê°€ **ì§ì„ **ì´ë¯€ë¡œ ì†ë„ê°€ ì‹œê°„ì— ë¬´ê´€(ìƒìˆ˜)
- ì´ë¡ ì ìœ¼ë¡œ 1-step ìƒì„±ì´ ê°€ëŠ¥ (ì‹¤ì œë¡œëŠ” ìˆ˜ ìŠ¤í… í•„ìš”)

### Flow Matching Loss

$$\mathcal{L}_{FM} = \mathbb{E}_{t \sim U[0,1],\, x_0 \sim p_0,\, x_1 \sim p_1}\left[\|v_\theta(x_t, t) - (x_1 - x_0)\|^2\right]$$

- $v_\theta(x_t, t)$: ì‹ ê²½ë§ì˜ ì†ë„ ì˜ˆì¸¡
- $(x_1 - x_0)$: GT(ground truth) ì§ì„  ì†ë„
- MSE ì†ì‹¤ë¡œ ì†ë„ì¥ì„ íšŒê·€(regression) í•™ìŠµ

### DDPM vs Flow Matching ë¹„êµ

| êµ¬ë¶„ | DDPM | Flow Matching (Rectified Flow) |
|------|------|------|
| ê²½ë¡œ | $x_t = \sqrt{\bar\alpha_t}x_0 + \sqrt{1-\bar\alpha_t}\epsilon$ (ê³¡ì„ ) | $x_t = (1-t)x_0 + tx_1$ (ì§ì„ ) |
| ì˜ˆì¸¡ ëŒ€ìƒ | ë…¸ì´ì¦ˆ $\epsilon$ | ì†ë„ $v = x_1 - x_0$ |
| ìƒ˜í”Œë§ | $T$ ìŠ¤í… ì—­ë°©í–¥ SDE/ODE | Euler ODE (ì†Œìˆ˜ ìŠ¤í… ê°€ëŠ¥) |
| ì´ë¡  ê¸°ë°˜ | ë§ˆë¥´ì½”í”„ ì²´ì¸ + ë³€ë¶„ ì¶”ë¡  | ì—°ì† ì •ê·œí™” íë¦„ + OT |

**ìš”ì•½ í‘œ:**

| êµ¬ë¶„ | ìˆ˜ì‹ | ì„¤ëª… |
|------|------|------|
| FM ODE | $dx/dt = v_\theta(x,t)$ | ì†ë„ì¥ ê¸°ë°˜ ìƒì„± |
| Rectified ë³´ê°„ | $x_t = (1-t)x_0 + tx_1$ | ì§ì„  ê²½ë¡œ |
| ìµœì  ì†ë„ | $v^{OT} = x_1 - x_0$ | ì‹œê°„ ë¬´ê´€ ìƒìˆ˜ |
| FM Loss | $\mathbb{E}[\|v_\theta - v^{OT}\|^2]$ | MSE íšŒê·€ ì†ì‹¤ |
| Euler ìŠ¤í… | $x_{t+\Delta t} = x_t + \Delta t \cdot v_\theta(x_t, t)$ | ODE ì´ì‚° ì ë¶„ |

---

### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ Flow Matching ì¹œì ˆ ì„¤ëª…!

#### ğŸ”¢ Flow Matchingì´ ë­”ê°€ìš”?

> ğŸ’¡ **ë¹„ìœ **: ì§€ë„ ì•±ì—ì„œ ì¶œë°œì§€(ë…¸ì´ì¦ˆ)ì—ì„œ ëª©ì ì§€(ì´ë¯¸ì§€)ê¹Œì§€ "ê°€ì¥ ë¹ ë¥¸ ê¸¸"ì„ ì°¾ëŠ” ê²ƒ!

DDPMì€ êµ¬ë¶ˆêµ¬ë¶ˆí•œ ê³¨ëª©ê¸¸ë¡œ ëŒì•„ê°€ëŠ” ë°©ë²•ì´ì—ìš”. ì—¬ëŸ¬ ë²ˆ ë°©í–¥ì„ ë°”ê¿”ì•¼ í•˜ì£  (1000 ìŠ¤í…!).
Flow Matchingì€ **ê³ ì†ë„ë¡œì²˜ëŸ¼ ì§ì„ **ìœ¼ë¡œ ë°”ë¡œ ê°€ëŠ” ë°©ë²•ì´ì—ìš”. í›¨ì”¬ ì ì€ ìŠ¤í…ìœ¼ë¡œ ë„ì°©í•  ìˆ˜ ìˆì£ !

- ğŸ›£ï¸ **Rectified Flow**: "ì§ì„  ë„ë¡œ"ë¥¼ ê·¸ì–´ë†“ê³ , AIì—ê²Œ "ì´ ë„ë¡œ ìœ„ì—ì„œ ì†ë„ë¥¼ ë§ì¶°ë´"ë¼ê³  í•™ìŠµì‹œí‚´
- ğŸ§­ **ì†ë„ì¥**: ê° ìœ„ì¹˜ì—ì„œ "ì–´ëŠ ë°©í–¥ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ê°€ì•¼ í•˜ëŠ”ì§€" ì•Œë ¤ì£¼ëŠ” ë‚˜ì¹¨ë°˜
- ğŸ“ **ODE**: ë‚˜ì¹¨ë°˜ ë°©í–¥ëŒ€ë¡œ í•œ ê±¸ìŒì”© ê±¸ìœ¼ë©´ ëª©ì ì§€ì— ë„ì°©! (ê±¸ìŒ ìˆ˜ = ìŠ¤í… ìˆ˜)

---

### ğŸ“ ì—°ìŠµ ë¬¸ì œ

#### ë¬¸ì œ 1: Rectified Flow ë³´ê°„ ê³„ì‚°

$x_0 = [1, 0]$, $x_1 = [0, 1]$ì¼ ë•Œ, $t=0.3$ì—ì„œì˜ $x_t$ì™€ ì†ë„ $v^{OT}$ë¥¼ êµ¬í•˜ì„¸ìš”.

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$$x_t = (1-0.3)[1,0] + 0.3[0,1] = [0.7, 0.3]$$

$$v^{OT} = x_1 - x_0 = [0,1] - [1,0] = [-1, 1]$$

ê²€ì¦: $x_t + (1-t) \cdot v^{OT} = [0.7, 0.3] + 0.7 \cdot [-1, 1] = [0, 1] = x_1$ âœ“
</details>

#### ë¬¸ì œ 2: Euler ìŠ¤í… ìˆ˜ì™€ ì˜¤ì°¨

2ìŠ¤í… Euler ($\Delta t = 0.5$)ë¡œ $x_0 = [1, 0]$ì—ì„œ ì‹œì‘í•˜ì—¬ $x_1 = [0, 1]$ì„ ë³µì›í•˜ì„¸ìš” (ì†ë„ê°€ ìƒìˆ˜ $v = [-1, 1]$ì¼ ë•Œ).

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

**ìŠ¤í… 1**: $x_{0.5} = x_0 + 0.5 \cdot v = [1,0] + 0.5[-1,1] = [0.5, 0.5]$

**ìŠ¤í… 2**: $x_1 = x_{0.5} + 0.5 \cdot v = [0.5,0.5] + 0.5[-1,1] = [0, 1]$

ì§ì„  ê²½ë¡œì—ì„œ ìƒìˆ˜ ì†ë„ë©´ **Euler ì ë¶„ì´ ì •í™•í•©ë‹ˆë‹¤** (ì˜¤ì°¨ = 0)!
ì´ê²ƒì´ Rectified Flowì˜ í•µì‹¬ ì¥ì ì…ë‹ˆë‹¤.
</details>"""))

# â”€â”€ Cell 3: Section 2 MD â”€â”€
cells.append(md(r"""## 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì • <a name='2.-í™˜ê²½-ì„¤ì •'></a>"""))

# â”€â”€ Cell 4: Imports â”€â”€
cells.append(code(r"""# â”€â”€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import tensorflow as tf
import time

np.random.seed(42)
tf.random.set_seed(42)
print(f"TensorFlow ë²„ì „: {tf.__version__}")
print(f"GPU ì‚¬ìš© ê°€ëŠ¥: {len(tf.config.list_physical_devices('GPU')) > 0}")"""))

# â”€â”€ Cell 4: MD for section 3 â”€â”€
cells.append(md(r"""## 3. Rectified Flow ê²½ë¡œ ì‹œê°í™” (ì§ì„  vs DDPM ê³¡ì„ ) <a name='3.-ê²½ë¡œ-ì‹œê°í™”'></a>

DDPMì˜ ë…¸ì´ì¦ˆ í™•ì‚° ê²½ë¡œì™€ Rectified Flowì˜ ì§ì„  ê²½ë¡œë¥¼ 2D ê³µê°„ì—ì„œ ë¹„êµí•©ë‹ˆë‹¤.

- **DDPM**: $x_t = \sqrt{\bar\alpha_t} x_0 + \sqrt{1-\bar\alpha_t} \epsilon$ (ë¹„ì„ í˜• ê³¡ì„  ê²½ë¡œ)
- **Rectified Flow**: $x_t = (1-t)x_0 + tx_1$ (ì§ì„  ê²½ë¡œ)"""))

# â”€â”€ Cell 5: Path Visualization â”€â”€
cells.append(code(r"""# â”€â”€ Rectified Flow vs DDPM ê²½ë¡œ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2D ê³µê°„ì—ì„œ ë…¸ì´ì¦ˆ(x0) â†’ ë°ì´í„°(x1)ë¡œì˜ ê²½ë¡œ ë¹„êµ

x0 = np.array([2.0, -1.0])
x1 = np.array([-1.0, 2.0])
epsilon = x0.copy()

T = 50
t_values = np.linspace(0, 1, T)

# DDPM ê²½ë¡œ: cosine schedule ëª¨ì‚¬
betas = np.linspace(1e-4, 0.02, T)
alphas = 1.0 - betas
alpha_bar = np.cumprod(alphas)

ddpm_path = np.zeros((T, 2))
rf_path = np.zeros((T, 2))

for i, t in enumerate(t_values):
    idx = min(i, len(alpha_bar) - 1)
    sqrt_ab = np.sqrt(alpha_bar[idx])
    sqrt_1_ab = np.sqrt(1 - alpha_bar[idx])
    ddpm_path[i] = sqrt_ab * x1 + sqrt_1_ab * epsilon
    rf_path[i] = (1 - t) * x0 + t * x1

fig, axes = plt.subplots(1, 2, figsize=(13, 5))

ax1 = axes[0]
ax1.plot(ddpm_path[:, 0], ddpm_path[:, 1], 'r-o', lw=2, ms=3, alpha=0.7, label='DDPM ê²½ë¡œ (ê³¡ì„ )')
ax1.plot(rf_path[:, 0], rf_path[:, 1], 'b-s', lw=2, ms=3, alpha=0.7, label='Rectified Flow (ì§ì„ )')
ax1.plot(*x0, 'ko', ms=12, zorder=5)
ax1.annotate('$x_0$ (ë…¸ì´ì¦ˆ)', xy=x0, xytext=(x0[0]+0.3, x0[1]-0.5), fontsize=10)
ax1.plot(*x1, 'k*', ms=15, zorder=5)
ax1.annotate('$x_1$ (ë°ì´í„°)', xy=x1, xytext=(x1[0]+0.3, x1[1]+0.3), fontsize=10)
ax1.set_xlabel('Dimension 1', fontsize=11)
ax1.set_ylabel('Dimension 2', fontsize=11)
ax1.set_title('ê²½ë¡œ ë¹„êµ: DDPM vs Rectified Flow', fontweight='bold')
ax1.legend(fontsize=9)
ax1.grid(True, alpha=0.3)

ax2 = axes[1]
ddpm_dist = np.sqrt(np.sum(np.diff(ddpm_path, axis=0)**2, axis=1))
rf_dist = np.sqrt(np.sum(np.diff(rf_path, axis=0)**2, axis=1))
ddpm_cumlen = np.concatenate([[0], np.cumsum(ddpm_dist)])
rf_cumlen = np.concatenate([[0], np.cumsum(rf_dist)])
ax2.plot(t_values, ddpm_cumlen, 'r-', lw=2.5, label=f'DDPM (ì´ ê¸¸ì´: {ddpm_cumlen[-1]:.2f})')
ax2.plot(t_values, rf_cumlen, 'b-', lw=2.5, label=f'RF (ì´ ê¸¸ì´: {rf_cumlen[-1]:.2f})')
ax2.set_xlabel('ì‹œê°„ t', fontsize=11)
ax2.set_ylabel('ëˆ„ì  ê²½ë¡œ ê¸¸ì´', fontsize=11)
ax2.set_title('ëˆ„ì  ê²½ë¡œ ê¸¸ì´ ë¹„êµ', fontweight='bold')
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter17_diffusion_transformers/flow_matching_paths.png', dpi=100, bbox_inches='tight')
plt.close()

straight_line_dist = np.linalg.norm(x1 - x0)
print(f"ì§ì„  ê±°ë¦¬ (ìµœì ): {straight_line_dist:.4f}")
print(f"DDPM ê²½ë¡œ ì´ ê¸¸ì´: {ddpm_cumlen[-1]:.4f}")
print(f"Rectified Flow ê²½ë¡œ ì´ ê¸¸ì´: {rf_cumlen[-1]:.4f}")
print(f"DDPM ê²½ë¡œ ë¹„íš¨ìœ¨: {ddpm_cumlen[-1]/straight_line_dist:.2f}x")
print(f"RF ê²½ë¡œ ë¹„íš¨ìœ¨: {rf_cumlen[-1]/straight_line_dist:.2f}x")
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter17_diffusion_transformers/flow_matching_paths.png")"""))

# â”€â”€ Cell 6: MD for FM Loss â”€â”€
cells.append(md(r"""## 4. Flow Matching Loss êµ¬í˜„ <a name='4.-FM-Loss-êµ¬í˜„'></a>

Flow Matchingì˜ í•™ìŠµ ëª©í‘œëŠ” ì†ë„ì¥ $v_\theta$ê°€ ì§ì„  ì†ë„ $v^{OT} = x_1 - x_0$ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:

$$\mathcal{L}_{FM} = \mathbb{E}_{t,x_0,x_1}\left[\|v_\theta(x_t, t) - (x_1 - x_0)\|^2\right]$$

ê°„ë‹¨í•œ 2D ë°ì´í„°ì—ì„œ MLP ì†ë„ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."""))

# â”€â”€ Cell 7: FM Loss Implementation â”€â”€
cells.append(code(r"""# â”€â”€ Flow Matching Loss êµ¬í˜„ ë° í•™ìŠµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê°„ë‹¨í•œ 2D ìŠ¤ìœ„ìŠ¤ë¡¤ ë°ì´í„°ì—ì„œ FM í•™ìŠµ

def make_swiss_roll_2d(n=1000):
    t = np.random.uniform(1.5 * np.pi, 4.5 * np.pi, n)
    x = t * np.cos(t) * 0.05
    y = t * np.sin(t) * 0.05
    return np.stack([x, y], axis=-1).astype(np.float32)

data = make_swiss_roll_2d(2000)
print(f"í•™ìŠµ ë°ì´í„° shape: {data.shape}, ë²”ìœ„: [{data.min():.3f}, {data.max():.3f}]")

class VelocityMLP(tf.keras.Model):
    def __init__(self, hidden_dim=128):
        super().__init__()
        self.net = tf.keras.Sequential([
            tf.keras.layers.Dense(hidden_dim, activation='silu'),
            tf.keras.layers.Dense(hidden_dim, activation='silu'),
            tf.keras.layers.Dense(hidden_dim, activation='silu'),
            tf.keras.layers.Dense(2)
        ])

    def call(self, x_t, t):
        t_embed = tf.concat([tf.sin(t * np.pi * 2), tf.cos(t * np.pi * 2)], axis=-1)
        inp = tf.concat([x_t, t_embed], axis=-1)
        return self.net(inp)

model = VelocityMLP(hidden_dim=128)
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

@tf.function
def train_step(x1_batch):
    batch_size = tf.shape(x1_batch)[0]
    t = tf.random.uniform([batch_size, 1], 0.0, 1.0)
    x0 = tf.random.normal([batch_size, 2])
    x_t = (1.0 - t) * x0 + t * x1_batch
    v_target = x1_batch - x0

    with tf.GradientTape() as tape:
        v_pred = model(x_t, t)
        loss = tf.reduce_mean(tf.square(v_pred - v_target))

    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    return loss

dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(2000).batch(256).repeat()
iterator = iter(dataset)

losses = []
for step in range(800):
    batch = next(iterator)
    loss = train_step(batch)
    losses.append(float(loss))
    if (step + 1) % 200 == 0:
        print(f"ìŠ¤í… {step+1:4d} | FM Loss: {loss:.6f}")

print(f"\nìµœì¢… FM Loss: {losses[-1]:.6f}")
print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numpy().size for p in model.trainable_variables):,}")"""))

# â”€â”€ Cell 8: MD for Euler Sampling â”€â”€
cells.append(md(r"""## 5. Euler ODE Solver ìƒ˜í”Œë§ <a name='5.-Euler-ìƒ˜í”Œë§'></a>

í•™ìŠµëœ ì†ë„ì¥ $v_\theta$ë¥¼ ì‚¬ìš©í•˜ì—¬ Euler ë°©ë²•ìœ¼ë¡œ ODEë¥¼ ì ë¶„í•©ë‹ˆë‹¤:

$$x_{t+\Delta t} = x_t + \Delta t \cdot v_\theta(x_t, t)$$

$t=0$ (ë…¸ì´ì¦ˆ)ì—ì„œ ì‹œì‘í•˜ì—¬ $t=1$ (ë°ì´í„°)ê¹Œì§€ $N$ ìŠ¤í…ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤."""))

# â”€â”€ Cell 9: Euler Sampling â”€â”€
cells.append(code(r"""# â”€â”€ Euler ODE Solver ìƒ˜í”Œë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def euler_sample(model, n_samples=500, n_steps=50):
    x = tf.random.normal([n_samples, 2])
    dt = 1.0 / n_steps
    trajectory = [x.numpy()]

    for i in range(n_steps):
        t_val = i * dt
        t = tf.fill([n_samples, 1], t_val)
        v = model(x, t)
        x = x + dt * v
        if i % (n_steps // 5) == 0:
            trajectory.append(x.numpy())
    trajectory.append(x.numpy())
    return x.numpy(), trajectory

step_counts = [5, 20, 50]
fig, axes = plt.subplots(1, len(step_counts) + 1, figsize=(16, 4))

ax0 = axes[0]
ax0.scatter(data[:, 0], data[:, 1], s=2, alpha=0.5, c='green')
ax0.set_title('ì›ë³¸ ë°ì´í„° (GT)', fontweight='bold')
ax0.set_xlim(-1.0, 1.0)
ax0.set_ylim(-1.0, 1.0)
ax0.grid(True, alpha=0.3)

for idx, n_steps in enumerate(step_counts):
    samples, _ = euler_sample(model, n_samples=500, n_steps=n_steps)
    ax = axes[idx + 1]
    ax.scatter(samples[:, 0], samples[:, 1], s=2, alpha=0.5, c='blue')
    ax.set_title(f'Euler {n_steps} ìŠ¤í…', fontweight='bold')
    ax.set_xlim(-1.0, 1.0)
    ax.set_ylim(-1.0, 1.0)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter17_diffusion_transformers/euler_sampling_steps.png', dpi=100, bbox_inches='tight')
plt.close()

print("ìŠ¤í… ìˆ˜ì— ë”°ë¥¸ ìƒ˜í”Œë§ í’ˆì§ˆ:")
for n in step_counts:
    samples, _ = euler_sample(model, n_samples=1000, n_steps=n)
    mean_val = np.mean(samples, axis=0)
    std_val = np.std(samples, axis=0)
    print(f"  {n:3d} ìŠ¤í… | í‰ê· : [{mean_val[0]:+.4f}, {mean_val[1]:+.4f}] | í‘œì¤€í¸ì°¨: [{std_val[0]:.4f}, {std_val[1]:.4f}]")

gt_mean = np.mean(data, axis=0)
gt_std = np.std(data, axis=0)
print(f"  GT í†µê³„ | í‰ê· : [{gt_mean[0]:+.4f}, {gt_mean[1]:+.4f}] | í‘œì¤€í¸ì°¨: [{gt_std[0]:.4f}, {gt_std[1]:.4f}]")
print("\nê·¸ë˜í”„ ì €ì¥ë¨: chapter17_diffusion_transformers/euler_sampling_steps.png")"""))

# â”€â”€ Cell 10: MD for Training Comparison â”€â”€
cells.append(md(r"""## 6. SD3/Flux vs DDPM í›ˆë ¨ ë°©ì‹ ë¹„êµ <a name='6.-í›ˆë ¨-ë¹„êµ'></a>

Stable Diffusion 3(SD3)ì™€ FluxëŠ” Flow Matching (Rectified Flow)ì„ ì±„íƒí•˜ì—¬ DDPMê³¼ ê·¼ë³¸ì ìœ¼ë¡œ ë‹¤ë¥¸ í›ˆë ¨ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

| íŠ¹ì„± | DDPM/DDIM | SD3/Flux (Flow Matching) |
|------|-----------|--------------------------|
| ì´ë¡  ê¸°ë°˜ | ë³€ë¶„ ì¶”ë¡  + ë§ˆë¥´ì½”í”„ ì²´ì¸ | ODE + Optimal Transport |
| ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ | $\beta$ ìŠ¤ì¼€ì¤„ (linear/cosine) | ì‹œê°„ $t \in [0,1]$ ê· ì¼ ìƒ˜í”Œë§ |
| ë³´ê°„ | $x_t = \sqrt{\bar\alpha_t}x_0 + \sqrt{1-\bar\alpha_t}\epsilon$ | $x_t = (1-t)x_0 + tx_1$ |
| ì˜ˆì¸¡ ëŒ€ìƒ | $\epsilon$ (ë…¸ì´ì¦ˆ) | $v$ (ì†ë„) |
| ì•„í‚¤í…ì²˜ | U-Net | DiT (MM-DiT in SD3) |"""))

# â”€â”€ Cell 11: Training Comparison Code â”€â”€
cells.append(code(r"""# â”€â”€ SD3/Flux vs DDPM í›ˆë ¨ ë°©ì‹ ì •ëŸ‰ ë¹„êµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë™ì¼ ë°ì´í„°ì— ëŒ€í•´ ë‘ íŒ¨ëŸ¬ë‹¤ì„ì˜ í•™ìŠµ íš¨ìœ¨ ë¹„êµ

# DDPM-style: epsilon prediction
class EpsilonMLP(tf.keras.Model):
    def __init__(self, hidden_dim=128):
        super().__init__()
        self.net = tf.keras.Sequential([
            tf.keras.layers.Dense(hidden_dim, activation='silu'),
            tf.keras.layers.Dense(hidden_dim, activation='silu'),
            tf.keras.layers.Dense(hidden_dim, activation='silu'),
            tf.keras.layers.Dense(2)
        ])

    def call(self, x_t, t):
        t_embed = tf.concat([tf.sin(t * np.pi * 2), tf.cos(t * np.pi * 2)], axis=-1)
        inp = tf.concat([x_t, t_embed], axis=-1)
        return self.net(inp)

ddpm_model = EpsilonMLP(128)
ddpm_opt = tf.keras.optimizers.Adam(1e-3)

T_ddpm = 100
betas_tf = tf.cast(tf.linspace(1e-4, 0.02, T_ddpm), tf.float32)
alphas_tf = 1.0 - betas_tf
alpha_bar_tf = tf.math.cumprod(alphas_tf)

@tf.function
def ddpm_train_step(x0_batch):
    bs = tf.shape(x0_batch)[0]
    t_idx = tf.random.uniform([bs], 0, T_ddpm, dtype=tf.int32)
    ab = tf.gather(alpha_bar_tf, t_idx)
    ab = tf.reshape(ab, [-1, 1])
    eps = tf.random.normal(tf.shape(x0_batch))
    x_t = tf.sqrt(ab) * x0_batch + tf.sqrt(1.0 - ab) * eps
    t_norm = tf.cast(t_idx, tf.float32) / float(T_ddpm)
    t_norm = tf.reshape(t_norm, [-1, 1])

    with tf.GradientTape() as tape:
        eps_pred = ddpm_model(x_t, t_norm)
        loss = tf.reduce_mean(tf.square(eps_pred - eps))

    grads = tape.gradient(loss, ddpm_model.trainable_variables)
    ddpm_opt.apply_gradients(zip(grads, ddpm_model.trainable_variables))
    return loss

fm_model2 = VelocityMLP(128)
fm_opt2 = tf.keras.optimizers.Adam(1e-3)

@tf.function
def fm_train_step2(x1_batch):
    bs = tf.shape(x1_batch)[0]
    t = tf.random.uniform([bs, 1], 0.0, 1.0)
    x0 = tf.random.normal(tf.shape(x1_batch))
    x_t = (1.0 - t) * x0 + t * x1_batch
    v_target = x1_batch - x0

    with tf.GradientTape() as tape:
        v_pred = fm_model2(x_t, t)
        loss = tf.reduce_mean(tf.square(v_pred - v_target))

    grads = tape.gradient(loss, fm_model2.trainable_variables)
    fm_opt2.apply_gradients(zip(grads, fm_model2.trainable_variables))
    return loss

ddpm_losses, fm_losses = [], []
n_compare_steps = 500
dataset2 = tf.data.Dataset.from_tensor_slices(data).shuffle(2000).batch(256).repeat()
it2 = iter(dataset2)

for step in range(n_compare_steps):
    batch = next(it2)
    dl = ddpm_train_step(batch)
    fl = fm_train_step2(batch)
    ddpm_losses.append(float(dl))
    fm_losses.append(float(fl))

fig, ax = plt.subplots(figsize=(10, 5))
window = 20
ddpm_smooth = np.convolve(ddpm_losses, np.ones(window)/window, mode='valid')
fm_smooth = np.convolve(fm_losses, np.ones(window)/window, mode='valid')
ax.plot(ddpm_smooth, 'r-', lw=2, label='DDPM (epsilon prediction)', alpha=0.8)
ax.plot(fm_smooth, 'b-', lw=2, label='Flow Matching (velocity prediction)', alpha=0.8)
ax.set_xlabel('í•™ìŠµ ìŠ¤í…', fontsize=11)
ax.set_ylabel('Loss (ì´ë™ í‰ê· )', fontsize=11)
ax.set_title('DDPM vs Flow Matching í•™ìŠµ ê³¡ì„  ë¹„êµ', fontweight='bold')
ax.legend(fontsize=9)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter17_diffusion_transformers/ddpm_vs_fm_training.png', dpi=100, bbox_inches='tight')
plt.close()

print(f"{'ë°©ë²•':<25} | {'ìµœì¢… Loss':>12} | {'ìˆ˜ë ´ ì†ë„':>12}")
print("-" * 55)
print(f"{'DDPM (eps prediction)':<25} | {ddpm_losses[-1]:>12.6f} | {np.mean(ddpm_losses[-50:]):>12.6f}")
print(f"{'FM (velocity prediction)':<25} | {fm_losses[-1]:>12.6f} | {np.mean(fm_losses[-50:]):>12.6f}")
print()

print("SD3/Flux vs DDPM í•µì‹¬ ì°¨ì´ì :")
headers = ['íŠ¹ì„±', 'DDPM', 'SD3/Flux (FM)']
rows = [
    ['ë³´ê°„ ê²½ë¡œ', 'ê³¡ì„  (sqrt(alpha_bar))', 'ì§ì„  ((1-t)x0 + tx1)'],
    ['ì˜ˆì¸¡ ëŒ€ìƒ', 'ë…¸ì´ì¦ˆ epsilon', 'ì†ë„ v = x1 - x0'],
    ['ìƒ˜í”ŒëŸ¬', 'DDPM/DDIM (50~1000 ìŠ¤í…)', 'Euler ODE (5~50 ìŠ¤í…)'],
    ['ì•„í‚¤í…ì²˜', 'U-Net', 'MM-DiT (Transformer)'],
    ['SD3 íŠ¹ì§•', '-', 'Rectified Flow + 3-text encoder'],
    ['Flux íŠ¹ì§•', '-', 'Rectified Flow + rotary PE'],
]
print(f"{headers[0]:<22} | {headers[1]:<28} | {headers[2]:<28}")
print("-" * 84)
for r in rows:
    print(f"{r[0]:<22} | {r[1]:<28} | {r[2]:<28}")

print("\nê·¸ë˜í”„ ì €ì¥ë¨: chapter17_diffusion_transformers/ddpm_vs_fm_training.png")"""))

# â”€â”€ Cell 12: Loss Landscape Visualization â”€â”€
cells.append(code(r"""# â”€â”€ Flow Matching ì†ë„ì¥ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•™ìŠµëœ ì†ë„ì¥ì„ 2D ë²¡í„° í•„ë“œë¡œ ì‹œê°í™”

fig, axes = plt.subplots(1, 3, figsize=(15, 5))
time_points = [0.0, 0.5, 0.9]

for idx, t_val in enumerate(time_points):
    ax = axes[idx]
    grid_x = np.linspace(-1.5, 1.5, 15)
    grid_y = np.linspace(-1.5, 1.5, 15)
    X, Y = np.meshgrid(grid_x, grid_y)
    points = np.stack([X.ravel(), Y.ravel()], axis=-1).astype(np.float32)

    t_input = tf.fill([points.shape[0], 1], t_val)
    v_pred = model(tf.constant(points), t_input).numpy()

    ax.quiver(X, Y, v_pred[:, 0].reshape(X.shape), v_pred[:, 1].reshape(Y.shape),
              color='blue', alpha=0.6, scale=20)
    ax.scatter(data[:300, 0], data[:300, 1], s=3, alpha=0.3, c='green', label='ë°ì´í„°')
    ax.set_title(f't = {t_val:.1f}', fontweight='bold', fontsize=12)
    ax.set_xlim(-1.5, 1.5)
    ax.set_ylim(-1.5, 1.5)
    ax.grid(True, alpha=0.3)
    if idx == 0:
        ax.legend(fontsize=9)

plt.suptitle('í•™ìŠµëœ ì†ë„ì¥ $v_\\theta(x, t)$ (ì‹œê°„ì— ë”°ë¥¸ ë³€í™”)', fontweight='bold', fontsize=13)
plt.tight_layout()
plt.savefig('chapter17_diffusion_transformers/velocity_field.png', dpi=100, bbox_inches='tight')
plt.close()
print("ì†ë„ì¥ ì‹œê°í™” ì €ì¥ë¨: chapter17_diffusion_transformers/velocity_field.png")
print(f"t=0.0: ë…¸ì´ì¦ˆ ë¶„í¬ì—ì„œ ë°ì´í„° ë°©í–¥ìœ¼ë¡œ ê°•í•œ ì†ë„")
print(f"t=0.5: ì¤‘ê°„ ì§€ì ì—ì„œ ìˆ˜ë ´í•˜ëŠ” íë¦„")
print(f"t=0.9: ë°ì´í„° ê·¼ì²˜ì—ì„œ ë¯¸ì„¸ ì¡°ì • ì†ë„")"""))

# â”€â”€ Cell 13: Summary â”€â”€
cells.append(md(r"""## 7. ì •ë¦¬ <a name='7.-ì •ë¦¬'></a>

### í•µì‹¬ ê°œë… ìš”ì•½

| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |
|------|------|--------|
| Flow Matching ODE | $dx/dt = v_\theta(x,t)$ë¡œ ë…¸ì´ì¦ˆâ†’ë°ì´í„° ë³€í™˜ | â­â­â­ |
| Rectified Flow | $(1-t)x_0 + tx_1$ ì§ì„  ë³´ê°„, ì†ë„ $= x_1 - x_0$ | â­â­â­ |
| FM Loss | ì†ë„ì¥ MSE íšŒê·€: $\|v_\theta - (x_1-x_0)\|^2$ | â­â­â­ |
| Euler Solver | $x_{t+\Delta t} = x_t + \Delta t \cdot v_\theta$ | â­â­ |
| DDPM vs FM ê²½ë¡œ | ê³¡ì„ (ë§ˆë¥´ì½”í”„) vs ì§ì„ (OT) | â­â­â­ |
| SD3/Flux | Rectified Flow + MM-DiT ì•„í‚¤í…ì²˜ | â­â­ |

### í•µì‹¬ ìˆ˜ì‹

$$\frac{dx}{dt} = v_\theta(x, t)$$

$$x_t = (1-t)x_0 + tx_1, \quad v^{OT} = x_1 - x_0$$

$$\mathcal{L}_{FM} = \mathbb{E}_{t,x_0,x_1}\left[\|v_\theta(x_t, t) - (x_1 - x_0)\|^2\right]$$

### ë‹¤ìŒ ì±•í„° ì˜ˆê³ 
**05_sora_and_hunyuan_architecture** â€” Soraì˜ NaViT ê°€ë³€ í•´ìƒë„ ê¸°ë²•ê³¼ HunyuanVideoì˜ Dual/Single-stream ë©€í‹°ëª¨ë‹¬ í“¨ì „ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤."""))

path = '/workspace/chapter17_diffusion_transformers/04_flow_matching_and_rectified_flow.ipynb'
create_notebook(cells, path)
