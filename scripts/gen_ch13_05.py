#!/usr/bin/env python3
"""Generate chapter13_genai_diffusion/05_score_matching_and_sde.ipynb"""
import sys, os
sys.path.insert(0, '/workspace/scripts')
from nb_helper import md, code, create_notebook

cells = []

# â”€â”€ Cell 1: Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""# Chapter 13: ìƒì„± AI ì‹¬í™” â€” Score Matchingê³¼ SDE

## í•™ìŠµ ëª©í‘œ
- **Score function** $\nabla_x \log p(x)$ì˜ ì •ì˜ì™€ ê¸°í•˜í•™ì  ì˜ë¯¸ë¥¼ ì´í•´í•œë‹¤
- **Denoising Score Matching**ì„ í†µí•´ ìŠ¤ì½”ì–´ í•¨ìˆ˜ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ìœ ë„í•œë‹¤
- **Langevin Dynamics**ë¡œ ìŠ¤ì½”ì–´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œ ìƒ˜í”Œë§ ì›ë¦¬ë¥¼ êµ¬í˜„í•œë‹¤
- í™•ì‚° ëª¨ë¸ì„ **ì—°ì† ì‹œê°„ SDE/ODE** í”„ë ˆì„ì›Œí¬(Song et al., 2021)ë¡œ í†µí•©í•˜ì—¬ ì´í•´í•œë‹¤
- **VE-SDE**ì™€ **VP-SDE**ì˜ ì°¨ì´ì ì„ ìˆ˜ì‹ê³¼ ì½”ë“œë¡œ ë¹„êµí•œë‹¤

## ëª©ì°¨
1. [ìˆ˜í•™ì  ê¸°ì´ˆ: Score Function, Langevin Dynamics, SDE](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)
2. [2D Score Field ì‹œê°í™”](#2.-Score-Field-ì‹œê°í™”)
3. [Langevin Dynamics ìƒ˜í”Œë§](#3.-Langevin-Dynamics-ìƒ˜í”Œë§)
4. [VE-SDE vs VP-SDE ë¹„êµ](#4.-VE-SDE-vs-VP-SDE)
5. [Probability Flow ODE](#5.-Probability-Flow-ODE)
6. [ì •ë¦¬](#6.-ì •ë¦¬)"""))

# â”€â”€ Cell 2: Math Section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>

### Score Function (ìŠ¤ì½”ì–´ í•¨ìˆ˜)

ë°ì´í„° ë¶„í¬ $p(x)$ì˜ **ìŠ¤ì½”ì–´ í•¨ìˆ˜**ëŠ” ë¡œê·¸ í™•ë¥  ë°€ë„ì˜ ê·¸ë˜ë””ì–¸íŠ¸ì…ë‹ˆë‹¤:

$$\boxed{s(x) = \nabla_x \log p(x)}$$

- $s(x) \in \mathbb{R}^d$: ë°ì´í„° ê³µê°„ì—ì„œì˜ ë²¡í„°ì¥ (ê° ì ì—ì„œ í™•ë¥ ì´ ë†’ì€ ë°©í–¥ì„ ê°€ë¦¬í‚´)
- $\nabla_x$: ë°ì´í„° $x$ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸
- $p(x)$ë¥¼ ì§ì ‘ ì•Œ í•„ìš” ì—†ì´ **ìŠ¤ì½”ì–´ë§Œìœ¼ë¡œ** ìƒ˜í”Œë§ ê°€ëŠ¥

**ê¸°í•˜í•™ì  ì˜ë¯¸**: ìŠ¤ì½”ì–´ ë²¡í„°ëŠ” ë°ì´í„°ì˜ **í™•ë¥  ë°€ë„ê°€ ë†’ì•„ì§€ëŠ” ë°©í–¥**ì„ ê°€ë¦¬í‚µë‹ˆë‹¤.

### Score Matching (HyvÃ¤rinen, 2005)

ë¶„í¬ $p(x)$ë¥¼ ëª¨ë¥´ëŠ” ìƒíƒœì—ì„œ ìŠ¤ì½”ì–´ë¥¼ í•™ìŠµí•˜ëŠ” ëª©ì í•¨ìˆ˜:

$$J_{SM}(\theta) = \mathbb{E}_{p(x)}\!\left[\frac{1}{2}\|s_\theta(x) - \nabla_x \log p(x)\|^2\right]$$

ì´ë¥¼ ë¶€ë¶„ì ë¶„ìœ¼ë¡œ ë³€í™˜í•˜ë©´ ($p(x)$ ì—†ì´ ê³„ì‚° ê°€ëŠ¥):

$$J_{SM}(\theta) = \mathbb{E}_{p(x)}\!\left[\text{tr}(\nabla_x s_\theta(x)) + \frac{1}{2}\|s_\theta(x)\|^2\right] + C$$

### Denoising Score Matching (DSM)

ì‹¤ì œë¡œëŠ” **ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ ë°ì´í„°**ì—ì„œ ìŠ¤ì½”ì–´ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤:

$$q_\sigma(x) = \int p(y)\,\mathcal{N}(x;\, y,\, \sigma^2 I)\,dy$$

$$J_{DSM}(\theta) = \mathbb{E}_{p(y)}\mathbb{E}_{q_\sigma(x|y)}\!\left[\left\|s_\theta(x) - \nabla_x \log q_\sigma(x|y)\right\|^2\right]$$

ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆì˜ ê²½ìš°:

$$\nabla_x \log q_\sigma(x|y) = -\frac{x - y}{\sigma^2} = -\frac{\epsilon}{\sigma}$$

ë”°ë¼ì„œ **DDPMì˜ Simple Lossì™€ ë³¸ì§ˆì ìœ¼ë¡œ ë™ì¼**í•©ë‹ˆë‹¤!

### Langevin Dynamics (ë‘ì£¼ë±… ì—­í•™)

ìŠ¤ì½”ì–´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ $p(x)$ì—ì„œ ìƒ˜í”Œì„ ì¶”ì¶œí•˜ëŠ” ë°˜ë³µì  ê³¼ì •:

$$\boxed{x_{t+1} = x_t + \frac{\delta}{2}\nabla_x \log p(x_t) + \sqrt{\delta}\,\epsilon_t, \quad \epsilon_t \sim \mathcal{N}(0, I)}$$

- $\delta > 0$: ìŠ¤í… í¬ê¸° (step size)
- $\frac{\delta}{2}\nabla_x \log p(x_t)$: í™•ë¥ ì´ ë†’ì€ ë°©í–¥ìœ¼ë¡œì˜ ë“œë¦¬í”„íŠ¸
- $\sqrt{\delta}\,\epsilon_t$: í™•ë¥ ì  íƒìƒ‰ì„ ìœ„í•œ ë…¸ì´ì¦ˆ
- $\delta \to 0$, $t \to \infty$ì¼ ë•Œ $x_t \sim p(x)$ë¡œ ìˆ˜ë ´

### SDE í”„ë ˆì„ì›Œí¬ (Song et al., 2021)

í™•ì‚° ëª¨ë¸ì„ **í™•ë¥  ë¯¸ë¶„ ë°©ì •ì‹(SDE)**ìœ¼ë¡œ í†µí•©:

**Forward SDE** (ë°ì´í„° â†’ ë…¸ì´ì¦ˆ):

$$\boxed{dx = f(x, t)\,dt + g(t)\,dw}$$

- $f(x, t)$: ë“œë¦¬í”„íŠ¸ ê³„ìˆ˜ (drift coefficient)
- $g(t)$: í™•ì‚° ê³„ìˆ˜ (diffusion coefficient)
- $w$: í‘œì¤€ ìœ„ë„ˆ í”„ë¡œì„¸ìŠ¤ (Brownian motion)

**Reverse SDE** (ë…¸ì´ì¦ˆ â†’ ë°ì´í„°):

$$dx = \left[f(x,t) - g(t)^2 \nabla_x \log p_t(x)\right] dt + g(t)\,d\bar{w}$$

| SDE ìœ í˜• | $f(x,t)$ | $g(t)$ | ëŒ€ì‘ ëª¨ë¸ |
|----------|----------|--------|-----------|
| VP-SDE | $-\frac{1}{2}\beta(t)x$ | $\sqrt{\beta(t)}$ | DDPM |
| VE-SDE | $0$ | $\sqrt{\frac{d[\sigma^2(t)]}{dt}}$ | NCSN/SMLD |
| sub-VP SDE | $-\frac{1}{2}\beta(t)x$ | $\sqrt{\beta(t)(1-e^{-2\int_0^t\beta(s)ds})}$ | ê°œì„ ëœ VP |

### Probability Flow ODE

SDEì˜ **ê²°ì •ë¡ ì (deterministic)** ë²„ì „ìœ¼ë¡œ, ë™ì¼í•œ ì£¼ë³€ ë¶„í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

$$\boxed{\frac{dx}{dt} = f(x,t) - \frac{1}{2}g(t)^2 \nabla_x \log p_t(x)}$$

- ê²°ì •ë¡ ì  â†’ ê°™ì€ ì´ˆê¸°ê°’ì—ì„œ í•­ìƒ ê°™ì€ ê²°ê³¼
- ì •í™•í•œ ë¡œê·¸ ìš°ë„ ê³„ì‚° ê°€ëŠ¥ (ì—°ì† ì •ê·œí™” íë¦„ê³¼ ì—°ê²°)
- DDIMì€ ì´ ODEì˜ ì´ì‚°í™”ë¡œ í•´ì„ ê°€ëŠ¥

**ìš”ì•½ í‘œ:**

| ê°œë… | ìˆ˜ì‹ | í•µì‹¬ |
|------|------|------|
| Score Function | $s(x) = \nabla_x \log p(x)$ | í™•ë¥  ì¦ê°€ ë°©í–¥ |
| Langevin Dynamics | $x' = x + \frac{\delta}{2}s(x) + \sqrt{\delta}\epsilon$ | ìŠ¤ì½”ì–´ ê¸°ë°˜ ìƒ˜í”Œë§ |
| Forward SDE | $dx = f\,dt + g\,dw$ | ë°ì´í„° â†’ ë…¸ì´ì¦ˆ |
| Reverse SDE | $dx = [f - g^2 s_\theta]\,dt + g\,d\bar{w}$ | ë…¸ì´ì¦ˆ â†’ ë°ì´í„° |
| Prob. Flow ODE | $dx/dt = f - \frac{1}{2}g^2 s_\theta$ | ê²°ì •ë¡ ì  ì—­ë°©í–¥ |"""))

# â”€â”€ Cell 3: ğŸ£ Friendly Explanation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""---

### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ Score Functionê³¼ SDE ì¹œì ˆ ì„¤ëª…!

#### ğŸ§­ Score Functionì´ ë­”ê°€ìš”?

> ğŸ’¡ **ë¹„ìœ **: ì‚°ì—ì„œ ë‚´ë ¤ì˜¤ëŠ” ë¬¼ì˜ íë¦„ì„ ìƒê°í•´ë³´ì„¸ìš”!

ì‚° ìœ„ì— ë¬¼ì„ ë¿Œë¦¬ë©´, ë¬¼ì€ **ê°€ì¥ ë‚®ì€ ê³³(ê³¨ì§œê¸°)**ì„ í–¥í•´ í˜ëŸ¬ê°‘ë‹ˆë‹¤. Score functionì€ ë°”ë¡œ ì´ **ë¬¼ì´ í˜ëŸ¬ê°€ëŠ” ë°©í–¥**ì„ ì•Œë ¤ì£¼ëŠ” í™”ì‚´í‘œì…ë‹ˆë‹¤.

- ğŸ”ï¸ **ë†’ì€ í™•ë¥  = ê¹Šì€ ê³¨ì§œê¸°**: ë°ì´í„°ê°€ ë§ì´ ëª¨ì—¬ìˆëŠ” ê³³
- â¡ï¸ **Score í™”ì‚´í‘œ**: ê³¨ì§œê¸°(ë°ì´í„°)ë¥¼ í–¥í•´ ê°€ë¦¬í‚´
- ğŸ² **Langevin Dynamics**: ê³µì„ êµ´ë¦¬ë©´ì„œ ì•½ê°„ í”ë“¤ì–´ì„œ ê³¨ì§œê¸°ë¥¼ ì°¾ê¸°

| ê³¼ì • | ë¹„ìœ  | ìˆ˜í•™ |
|------|------|------|
| Score Function | ë¬¼ì´ í˜ëŸ¬ê°€ëŠ” ë°©í–¥ | $\nabla_x \log p(x)$ |
| Drift (ë“œë¦¬í”„íŠ¸) | ê³¨ì§œê¸°ë¡œ ëŒì–´ë‹¹ê¸°ê¸° | $\frac{\delta}{2}s(x)$ |
| Noise (ë…¸ì´ì¦ˆ) | ì‚´ì§ í”ë“¤ì–´ì„œ íƒìƒ‰ | $\sqrt{\delta}\epsilon$ |
| SDE | ë¬¼ì¤„ê¸°ê°€ ê°ˆë¼ì¡Œë‹¤ í•©ì¹˜ê¸° | $dx = f\,dt + g\,dw$ |

#### ğŸ”„ SDEì™€ ODEì˜ ì°¨ì´ëŠ”?

- **SDE** = ë¬¼ì— ë°”ëŒì´ ë¶ˆì–´ì„œ ë°©í–¥ì´ **ëœë¤í•˜ê²Œ í”ë“¤ë¦¼** (í™•ë¥ ì )
- **ODE** = ë°”ëŒ ì—†ì´ ë¬¼ì´ **í•œ ë°©í–¥ìœ¼ë¡œë§Œ** í˜ëŸ¬ê° (ê²°ì •ë¡ ì )

ë‘˜ ë‹¤ ê°™ì€ ê³³(ë°ì´í„° ë¶„í¬)ì— ë„ì°©í•˜ì§€ë§Œ, ODEëŠ” ë§¤ë²ˆ ê°™ì€ ê²½ë¡œë¡œ!"""))

# â”€â”€ Cell 4: ğŸ“ Practice Problems â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""---

### ğŸ“ ì—°ìŠµ ë¬¸ì œ

#### ë¬¸ì œ 1: Score Function ê³„ì‚°

1D ê°€ìš°ì‹œì•ˆ ë¶„í¬ $p(x) = \mathcal{N}(x;\, \mu, \sigma^2)$ì˜ ìŠ¤ì½”ì–´ í•¨ìˆ˜ë¥¼ êµ¬í•˜ì„¸ìš”.

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$$\log p(x) = -\frac{(x-\mu)^2}{2\sigma^2} + C$$

$$s(x) = \nabla_x \log p(x) = -\frac{x - \mu}{\sigma^2}$$

**í•´ì„**: ìŠ¤ì½”ì–´ ë²¡í„°ëŠ” í‰ê·  $\mu$ë¥¼ í–¥í•˜ëŠ” ë°©í–¥ì´ë©°, í‰ê· ì—ì„œ ë©€ìˆ˜ë¡ í¬ê¸°ê°€ í½ë‹ˆë‹¤. ë¶„ì‚° $\sigma^2$ê°€ ì‘ìœ¼ë©´ ë” ê°•í•˜ê²Œ ëŒì–´ë‹¹ê¹ë‹ˆë‹¤.
</details>

#### ë¬¸ì œ 2: Langevin Dynamics ìˆ˜ë ´

$p(x) = \mathcal{N}(0, 1)$ì— ëŒ€í•´ Langevin dynamicsë¥¼ ì ìš©í•©ë‹ˆë‹¤. $x_0 = 5$ì´ê³  $\delta = 0.1$ì¼ ë•Œ, ì²« ìŠ¤í…ì˜ ë“œë¦¬í”„íŠ¸ í•­ $\frac{\delta}{2}s(x_0)$ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$$s(x_0) = -\frac{x_0 - 0}{1} = -5$$

$$\frac{\delta}{2}s(x_0) = \frac{0.1}{2} \times (-5) = -0.25$$

$x_0 = 5$ì—ì„œ í‰ê·  $0$ ë°©í–¥ìœ¼ë¡œ $-0.25$ë§Œí¼ ì´ë™í•©ë‹ˆë‹¤. ë…¸ì´ì¦ˆ í•­ $\sqrt{0.1}\epsilon \approx 0.316\epsilon$ì´ ì¶”ê°€ë˜ì–´ ìµœì¢… ìœ„ì¹˜ê°€ ê²°ì •ë©ë‹ˆë‹¤.
</details>"""))

# â”€â”€ Cell 5: Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import tensorflow as tf

np.random.seed(42)
tf.random.set_seed(42)
print(f"TensorFlow ë²„ì „: {tf.__version__}")
print(f"NumPy ë²„ì „: {np.__version__}")"""))

# â”€â”€ Cell 6: 2D Score Field Visualization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 2. 2D Score Field ì‹œê°í™” <a name='2.-Score-Field-ì‹œê°í™”'></a>

ê°€ìš°ì‹œì•ˆ í˜¼í•© ë¶„í¬(GMM)ì˜ ìŠ¤ì½”ì–´ í•„ë“œë¥¼ 2D ë²¡í„°ì¥ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤. ê° í™”ì‚´í‘œëŠ” í™•ë¥ ì´ ë†’ì€ ë°©í–¥ì„ ê°€ë¦¬í‚µë‹ˆë‹¤."""))

cells.append(code(r"""# â”€â”€ 2D Score Field ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2D ê°€ìš°ì‹œì•ˆ í˜¼í•© ë¶„í¬ì˜ ìŠ¤ì½”ì–´ í•„ë“œ

def gmm_log_prob(x, means, covs, weights):
    # ê°€ìš°ì‹œì•ˆ í˜¼í•© ë¶„í¬ì˜ ë¡œê·¸ í™•ë¥  ê³„ì‚°
    log_probs = []
    for mu, cov, w in zip(means, covs, weights):
        diff = x - mu
        inv_cov = np.linalg.inv(cov)
        log_p = -0.5 * np.sum(diff @ inv_cov * diff, axis=-1)
        log_p += np.log(w) - 0.5 * np.log(np.linalg.det(2 * np.pi * cov))
        log_probs.append(log_p)
    log_probs = np.stack(log_probs, axis=-1)
    return np.log(np.sum(np.exp(log_probs - log_probs.max(axis=-1, keepdims=True)), axis=-1)) + log_probs.max(axis=-1)

def gmm_score(x, means, covs, weights):
    # ìˆ˜ì¹˜ì ìœ¼ë¡œ ìŠ¤ì½”ì–´ ê³„ì‚° (ìœ í•œ ì°¨ë¶„)
    eps = 1e-4
    score = np.zeros_like(x)
    for d in range(x.shape[-1]):
        x_plus = x.copy()
        x_minus = x.copy()
        x_plus[..., d] += eps
        x_minus[..., d] -= eps
        score[..., d] = (gmm_log_prob(x_plus, means, covs, weights) -
                         gmm_log_prob(x_minus, means, covs, weights)) / (2 * eps)
    return score

# GMM íŒŒë¼ë¯¸í„° (3ê°œ ëª¨ë“œ)
means = [np.array([-2, -1]), np.array([2, 1]), np.array([0, 3])]
covs = [np.eye(2) * 0.5, np.eye(2) * 0.4, np.eye(2) * 0.6]
weights = [0.4, 0.35, 0.25]

# ê·¸ë¦¬ë“œ ìƒì„±
grid_size = 25
x_range = np.linspace(-5, 5, grid_size)
y_range = np.linspace(-4, 6, grid_size)
X, Y = np.meshgrid(x_range, y_range)
grid_points = np.stack([X.ravel(), Y.ravel()], axis=-1)

# ìŠ¤ì½”ì–´ ê³„ì‚°
scores = gmm_score(grid_points, means, covs, weights)
log_probs = gmm_log_prob(grid_points, means, covs, weights)

# ì‹œê°í™”
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# í™•ë¥  ë°€ë„
ax1 = axes[0]
prob_grid = np.exp(log_probs.reshape(grid_size, grid_size))
c1 = ax1.contourf(X, Y, prob_grid, levels=30, cmap='viridis')
plt.colorbar(c1, ax=ax1, label='p(x)')
for mu in means:
    ax1.scatter(*mu, c='red', s=100, marker='*', zorder=5, edgecolors='white')
ax1.set_title('í™•ë¥  ë°€ë„ p(x)', fontweight='bold')
ax1.set_xlabel('$x_1$', fontsize=11)
ax1.set_ylabel('$x_2$', fontsize=11)
ax1.grid(True, alpha=0.3)

# ìŠ¤ì½”ì–´ ë²¡í„°ì¥
ax2 = axes[1]
S_x = scores[:, 0].reshape(grid_size, grid_size)
S_y = scores[:, 1].reshape(grid_size, grid_size)
magnitude = np.sqrt(S_x**2 + S_y**2)
ax2.contourf(X, Y, prob_grid, levels=15, cmap='viridis', alpha=0.3)
ax2.quiver(X[::2, ::2], Y[::2, ::2], S_x[::2, ::2], S_y[::2, ::2],
           magnitude[::2, ::2], cmap='Reds', scale=30, width=0.004, alpha=0.8)
for mu in means:
    ax2.scatter(*mu, c='red', s=100, marker='*', zorder=5, edgecolors='white')
ax2.set_title(r'Score Field $\nabla_x \log p(x)$', fontweight='bold')
ax2.set_xlabel('$x_1$', fontsize=11)
ax2.set_ylabel('$x_2$', fontsize=11)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter13_genai_diffusion/score_field_2d.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/score_field_2d.png")
print("ìŠ¤ì½”ì–´ ë²¡í„°ê°€ ê° ê°€ìš°ì‹œì•ˆ ì¤‘ì‹¬(ë¹¨ê°„ ë³„)ì„ í–¥í•˜ëŠ” ê²ƒì„ ê´€ì°°í•˜ì„¸ìš”")
print(f"ìŠ¤ì½”ì–´ ìµœëŒ€ í¬ê¸°: {np.max(magnitude):.2f}")
print(f"ìŠ¤ì½”ì–´ í‰ê·  í¬ê¸°: {np.mean(magnitude):.2f}")"""))

# â”€â”€ Cell 7: Langevin Dynamics Sampling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 3. Langevin Dynamics ìƒ˜í”Œë§ <a name='3.-Langevin-Dynamics-ìƒ˜í”Œë§'></a>

ëœë¤ ë…¸ì´ì¦ˆì—ì„œ ì‹œì‘í•˜ì—¬ Langevin dynamicsë¡œ GMM ë¶„í¬ì—ì„œ ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤:

$$x_{t+1} = x_t + \frac{\delta}{2}\nabla_x \log p(x_t) + \sqrt{\delta}\,\epsilon_t$$"""))

cells.append(code(r"""# â”€â”€ Langevin Dynamics ìƒ˜í”Œë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GMMì—ì„œ Langevin dynamicsë¡œ ìƒ˜í”Œ ìƒì„±

def langevin_dynamics(score_fn, n_samples, n_steps, step_size, init_std=4.0):
    # Langevin dynamics ìƒ˜í”ŒëŸ¬
    x = np.random.randn(n_samples, 2) * init_std
    trajectory = [x.copy()]

    for t in range(n_steps):
        score = score_fn(x)
        noise = np.random.randn(*x.shape)
        x = x + 0.5 * step_size * score + np.sqrt(step_size) * noise
        if t % (n_steps // 20) == 0 or t == n_steps - 1:
            trajectory.append(x.copy())

    return x, trajectory

score_fn = lambda x: gmm_score(x, means, covs, weights)

n_samples = 500
n_steps = 1000
step_size = 0.01

final_samples, trajectories = langevin_dynamics(score_fn, n_samples, n_steps, step_size)

# ì‹œê°í™”: ê¶¤ì ê³¼ ìµœì¢… ìƒ˜í”Œ
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# ì´ˆê¸° ë¶„í¬
ax1 = axes[0]
ax1.scatter(trajectories[0][:, 0], trajectories[0][:, 1],
            c='blue', s=5, alpha=0.3, label='ì´ˆê¸° ìƒ˜í”Œ')
ax1.set_title('Step 0 (ëœë¤ ì´ˆê¸°í™”)', fontweight='bold')
ax1.set_xlim(-6, 6)
ax1.set_ylim(-5, 8)
ax1.legend(fontsize=9)
ax1.grid(True, alpha=0.3)
ax1.set_xlabel('$x_1$', fontsize=11)
ax1.set_ylabel('$x_2$', fontsize=11)

# ì¤‘ê°„ ê³¼ì •
mid_idx = len(trajectories) // 2
ax2 = axes[1]
ax2.scatter(trajectories[mid_idx][:, 0], trajectories[mid_idx][:, 1],
            c='orange', s=5, alpha=0.3, label=f'Step {n_steps//2}')
for mu in means:
    ax2.scatter(*mu, c='red', s=100, marker='*', zorder=5)
ax2.set_title(f'Step {n_steps//2} (ìˆ˜ë ´ ì¤‘)', fontweight='bold')
ax2.set_xlim(-6, 6)
ax2.set_ylim(-5, 8)
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)
ax2.set_xlabel('$x_1$', fontsize=11)
ax2.set_ylabel('$x_2$', fontsize=11)

# ìµœì¢… ë¶„í¬
ax3 = axes[2]
ax3.scatter(final_samples[:, 0], final_samples[:, 1],
            c='green', s=5, alpha=0.3, label=f'Step {n_steps}')
for mu in means:
    ax3.scatter(*mu, c='red', s=100, marker='*', zorder=5)
ax3.set_title(f'Step {n_steps} (ìˆ˜ë ´)', fontweight='bold')
ax3.set_xlim(-6, 6)
ax3.set_ylim(-5, 8)
ax3.legend(fontsize=9)
ax3.grid(True, alpha=0.3)
ax3.set_xlabel('$x_1$', fontsize=11)
ax3.set_ylabel('$x_2$', fontsize=11)

plt.tight_layout()
plt.savefig('chapter13_genai_diffusion/langevin_dynamics_sampling.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/langevin_dynamics_sampling.png")

# í†µê³„
for i, mu in enumerate(means):
    dists = np.linalg.norm(final_samples - mu, axis=1)
    near = np.sum(dists < 1.5)
    print(f"ëª¨ë“œ {i+1} (Î¼={mu}) ê·¼ì²˜ ìƒ˜í”Œ ìˆ˜: {near}/{n_samples} ({near/n_samples*100:.1f}%)")"""))

# â”€â”€ Cell 8: VE-SDE vs VP-SDE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 4. VE-SDE vs VP-SDE ë¹„êµ <a name='4.-VE-SDE-vs-VP-SDE'></a>

ë‘ ê°€ì§€ ì£¼ìš” SDE ìœ í˜•ì˜ ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ê³¼ Forward processë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

| ìœ í˜• | Forward SDE | ë…¸ì´ì¦ˆ ì¶”ê°€ ë°©ì‹ | ëŒ€ì‘ ëª¨ë¸ |
|------|-------------|-----------------|-----------|
| **VP-SDE** | $dx = -\frac{1}{2}\beta(t)x\,dt + \sqrt{\beta(t)}\,dw$ | ì‹ í˜¸ ê°ì‡  + ë…¸ì´ì¦ˆ ì¦ê°€ | DDPM |
| **VE-SDE** | $dx = \sqrt{\frac{d[\sigma^2(t)]}{dt}}\,dw$ | ì‹ í˜¸ ìœ ì§€ + ë…¸ì´ì¦ˆë§Œ ì¦ê°€ | NCSN/SMLD |"""))

cells.append(code(r"""# â”€â”€ VE-SDE vs VP-SDE Forward Process ë¹„êµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1D ë°ì´í„°ì— ëŒ€í•œ Forward process ì‹œë®¬ë ˆì´ì…˜

T_continuous = 1.0
n_steps_sde = 200
dt = T_continuous / n_steps_sde
t_values = np.linspace(0, T_continuous, n_steps_sde + 1)

x0 = 3.0
n_trajectories = 50

# VP-SDE: dx = -0.5*beta(t)*x*dt + sqrt(beta(t))*dw
def vp_sde_forward(x0, n_traj, beta_min=0.1, beta_max=20.0):
    trajectories = np.zeros((n_traj, n_steps_sde + 1))
    trajectories[:, 0] = x0

    for i in range(n_steps_sde):
        t = t_values[i]
        beta_t = beta_min + t * (beta_max - beta_min)
        drift = -0.5 * beta_t * trajectories[:, i]
        diffusion = np.sqrt(beta_t)
        dw = np.random.randn(n_traj) * np.sqrt(dt)
        trajectories[:, i+1] = trajectories[:, i] + drift * dt + diffusion * dw

    return trajectories

# VE-SDE: dx = sqrt(d[sigma^2]/dt) * dw
def ve_sde_forward(x0, n_traj, sigma_min=0.01, sigma_max=50.0):
    trajectories = np.zeros((n_traj, n_steps_sde + 1))
    trajectories[:, 0] = x0

    for i in range(n_steps_sde):
        t = t_values[i]
        sigma_t = sigma_min * (sigma_max / sigma_min) ** t
        dsigma2_dt = 2 * sigma_t * np.log(sigma_max / sigma_min) * sigma_t
        diffusion = np.sqrt(np.abs(dsigma2_dt))
        dw = np.random.randn(n_traj) * np.sqrt(dt)
        trajectories[:, i+1] = trajectories[:, i] + diffusion * dw

    return trajectories

np.random.seed(42)
vp_trajs = vp_sde_forward(x0, n_trajectories)
np.random.seed(42)
ve_trajs = ve_sde_forward(x0, n_trajectories)

# VP-SDE í•´ì„ì  ë¶„í¬ íŒŒë¼ë¯¸í„°
beta_min, beta_max = 0.1, 20.0
vp_mean = np.zeros_like(t_values)
vp_std = np.zeros_like(t_values)
for i, t in enumerate(t_values):
    integral_beta = beta_min * t + 0.5 * (beta_max - beta_min) * t**2
    vp_mean[i] = x0 * np.exp(-0.5 * integral_beta)
    vp_std[i] = np.sqrt(1 - np.exp(-integral_beta))

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# VP-SDE
ax1 = axes[0]
for j in range(min(20, n_trajectories)):
    ax1.plot(t_values, vp_trajs[j], 'b-', alpha=0.1, lw=0.5)
ax1.plot(t_values, vp_mean, 'r-', lw=2.5, label=r'$E[x_t]$ (í•´ì„ì )')
ax1.fill_between(t_values, vp_mean - 2*vp_std, vp_mean + 2*vp_std,
                 alpha=0.15, color='red', label=r'$\pm 2\sigma$ êµ¬ê°„')
ax1.axhline(y=0, color='gray', ls='--', lw=1)
ax1.set_title('VP-SDE (Variance Preserving)', fontweight='bold')
ax1.set_xlabel('t', fontsize=11)
ax1.set_ylabel('$x_t$', fontsize=11)
ax1.legend(fontsize=9)
ax1.grid(True, alpha=0.3)

# VE-SDE
ax2 = axes[1]
for j in range(min(20, n_trajectories)):
    ax2.plot(t_values, ve_trajs[j], 'g-', alpha=0.1, lw=0.5)
ve_empirical_mean = np.mean(ve_trajs, axis=0)
ve_empirical_std = np.std(ve_trajs, axis=0)
ax2.plot(t_values, ve_empirical_mean, 'r-', lw=2.5, label=r'$E[x_t]$ (ê²½í—˜ì )')
ax2.fill_between(t_values, ve_empirical_mean - 2*ve_empirical_std,
                 ve_empirical_mean + 2*ve_empirical_std,
                 alpha=0.15, color='red', label=r'$\pm 2\sigma$ êµ¬ê°„')
ax2.axhline(y=x0, color='gray', ls='--', lw=1, label=f'$x_0 = {x0}$')
ax2.set_title('VE-SDE (Variance Exploding)', fontweight='bold')
ax2.set_xlabel('t', fontsize=11)
ax2.set_ylabel('$x_t$', fontsize=11)
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter13_genai_diffusion/ve_vs_vp_sde.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/ve_vs_vp_sde.png")

print(f"\n{'SDE ìœ í˜•':<15} | {'ìµœì¢… E[x_T]':>12} | {'ìµœì¢… Std[x_T]':>12} | {'ì‹ í˜¸ ë³´ì¡´':>10}")
print("-" * 58)
print(f"{'VP-SDE':<15} | {np.mean(vp_trajs[:, -1]):>12.3f} | {np.std(vp_trajs[:, -1]):>12.3f} | {'ì•„ë‹ˆì˜¤':>10}")
print(f"{'VE-SDE':<15} | {np.mean(ve_trajs[:, -1]):>12.3f} | {np.std(ve_trajs[:, -1]):>12.3f} | {'ì˜ˆ (í‰ê· )':>10}")"""))

# â”€â”€ Cell 9: Probability Flow ODE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 5. Probability Flow ODE <a name='5.-Probability-Flow-ODE'></a>

SDEì™€ ë™ì¼í•œ ì£¼ë³€ ë¶„í¬ë¥¼ ê°–ëŠ” **ê²°ì •ë¡ ì  ODE**:

$$\frac{dx}{dt} = f(x,t) - \frac{1}{2}g(t)^2 \nabla_x \log p_t(x)$$

SDE(í™•ë¥ ì ) ê²½ë¡œì™€ ODE(ê²°ì •ë¡ ì ) ê²½ë¡œë¥¼ ë¹„êµí•©ë‹ˆë‹¤."""))

cells.append(code(r"""# â”€â”€ SDE vs Probability Flow ODE ê²½ë¡œ ë¹„êµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1D ê°€ìš°ì‹œì•ˆì—ì„œì˜ SDE vs ODE ì—­ë°©í–¥ ê²½ë¡œ

def reverse_vp_sde(x_T, score_fn, n_steps=200, beta_min=0.1, beta_max=20.0):
    # VP-SDE ì—­ë°©í–¥ (í™•ë¥ ì )
    dt = 1.0 / n_steps
    x = x_T.copy()
    trajectory = [x.copy()]

    for i in range(n_steps):
        t = 1.0 - i * dt
        beta_t = beta_min + t * (beta_max - beta_min)
        drift = -0.5 * beta_t * x
        diffusion = np.sqrt(beta_t)
        score = score_fn(x, t)
        dx = (drift - diffusion**2 * score) * (-dt) + diffusion * np.random.randn(*x.shape) * np.sqrt(dt)
        x = x + dx
        if i % (n_steps // 50) == 0:
            trajectory.append(x.copy())

    trajectory.append(x.copy())
    return x, trajectory

def reverse_probability_flow_ode(x_T, score_fn, n_steps=200, beta_min=0.1, beta_max=20.0):
    # Probability Flow ODE (ê²°ì •ë¡ ì )
    dt = 1.0 / n_steps
    x = x_T.copy()
    trajectory = [x.copy()]

    for i in range(n_steps):
        t = 1.0 - i * dt
        beta_t = beta_min + t * (beta_max - beta_min)
        drift = -0.5 * beta_t * x
        diffusion = np.sqrt(beta_t)
        score = score_fn(x, t)
        dx = (drift - 0.5 * diffusion**2 * score) * (-dt)
        x = x + dx
        if i % (n_steps // 50) == 0:
            trajectory.append(x.copy())

    trajectory.append(x.copy())
    return x, trajectory

# ê°„ë‹¨í•œ ìŠ¤ì½”ì–´ í•¨ìˆ˜ (1D ê°€ìš°ì‹œì•ˆ íƒ€ê²Ÿ mu=2, sigma=0.5)
target_mu, target_sigma = 2.0, 0.5

def simple_score(x, t):
    beta_min, beta_max = 0.1, 20.0
    integral_beta = beta_min * t + 0.5 * (beta_max - beta_min) * t**2
    alpha_bar_t = np.exp(-integral_beta)
    effective_mu = np.sqrt(alpha_bar_t) * target_mu
    effective_var = alpha_bar_t * target_sigma**2 + (1 - alpha_bar_t)
    return -(x - effective_mu) / effective_var

# ë‹¤ìˆ˜ì˜ ê²½ë¡œ ìƒì„±
np.random.seed(42)
n_paths = 8
x_T_init = np.random.randn(n_paths) * 1.0

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# SDE ê²½ë¡œ (í™•ë¥ ì )
ax1 = axes[0]
for i in range(n_paths):
    np.random.seed(i + 100)
    _, traj_sde = reverse_vp_sde(np.array([x_T_init[i]]), simple_score, n_steps=200)
    traj_arr = np.array([t[0] for t in traj_sde])
    ax1.plot(np.linspace(1, 0, len(traj_arr)), traj_arr, alpha=0.6, lw=1.5)
ax1.axhline(y=target_mu, color='red', ls='--', lw=2, label=f'target Î¼ = {target_mu}')
ax1.set_title('Reverse SDE (í™•ë¥ ì  ê²½ë¡œ)', fontweight='bold')
ax1.set_xlabel('t (ì—­ë°©í–¥: 1â†’0)', fontsize=11)
ax1.set_ylabel('$x_t$', fontsize=11)
ax1.legend(fontsize=9)
ax1.grid(True, alpha=0.3)

# ODE ê²½ë¡œ (ê²°ì •ë¡ ì )
ax2 = axes[1]
for i in range(n_paths):
    _, traj_ode = reverse_probability_flow_ode(np.array([x_T_init[i]]), simple_score, n_steps=200)
    traj_arr = np.array([t[0] for t in traj_ode])
    ax2.plot(np.linspace(1, 0, len(traj_arr)), traj_arr, alpha=0.6, lw=1.5)
ax2.axhline(y=target_mu, color='red', ls='--', lw=2, label=f'target Î¼ = {target_mu}')
ax2.set_title('Probability Flow ODE (ê²°ì •ë¡ ì  ê²½ë¡œ)', fontweight='bold')
ax2.set_xlabel('t (ì—­ë°©í–¥: 1â†’0)', fontsize=11)
ax2.set_ylabel('$x_t$', fontsize=11)
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter13_genai_diffusion/sde_vs_ode_paths.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/sde_vs_ode_paths.png")
print("\nSDE: ê°™ì€ ì´ˆê¸°ê°’ì—ì„œë„ ë§¤ë²ˆ ë‹¤ë¥¸ ê²½ë¡œ (í™•ë¥ ì  ë…¸ì´ì¦ˆ)")
print("ODE: ê°™ì€ ì´ˆê¸°ê°’ì´ë©´ í•­ìƒ ê°™ì€ ê²½ë¡œ (ê²°ì •ë¡ ì )")
print(f"ODEì˜ ì¥ì : ì •í™•í•œ ë¡œê·¸ ìš°ë„ ê³„ì‚° ê°€ëŠ¥, DDIMì€ ODEì˜ ì´ì‚°í™”")"""))

# â”€â”€ Cell 10: Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 6. ì •ë¦¬ <a name='6.-ì •ë¦¬'></a>

### í•µì‹¬ ê°œë… ìš”ì•½

| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |
|------|------|--------|
| Score Function | ë¡œê·¸ í™•ë¥  ë°€ë„ì˜ ê·¸ë˜ë””ì–¸íŠ¸ $\nabla_x \log p(x)$ | â­â­â­ |
| Denoising Score Matching | ë…¸ì´ì¦ˆ ë°ì´í„°ì—ì„œ ìŠ¤ì½”ì–´ í•™ìŠµ (DDPM Lossì™€ ë™ì¼) | â­â­â­ |
| Langevin Dynamics | ìŠ¤ì½”ì–´ ê¸°ë°˜ ë°˜ë³µì  ìƒ˜í”Œë§ | â­â­â­ |
| VP-SDE | ì‹ í˜¸ ê°ì‡  + ë…¸ì´ì¦ˆ ì¦ê°€ (DDPMì— ëŒ€ì‘) | â­â­â­ |
| VE-SDE | ì‹ í˜¸ ìœ ì§€ + ë…¸ì´ì¦ˆ í­ë°œ (NCSNì— ëŒ€ì‘) | â­â­ |
| Probability Flow ODE | ê²°ì •ë¡ ì  ì—­ë°©í–¥, ì •í™•í•œ ìš°ë„ ê³„ì‚° ê°€ëŠ¥ | â­â­â­ |

### í•µì‹¬ ìˆ˜ì‹

$$s(x) = \nabla_x \log p(x) \quad \text{(Score Function)}$$

$$x_{t+1} = x_t + \frac{\delta}{2}s(x_t) + \sqrt{\delta}\,\epsilon_t \quad \text{(Langevin Dynamics)}$$

$$dx = f(x,t)\,dt + g(t)\,dw \quad \text{(Forward SDE)}$$

$$\frac{dx}{dt} = f(x,t) - \frac{1}{2}g(t)^2 s_\theta(x,t) \quad \text{(Probability Flow ODE)}$$

### DDPM â†” Score ì—°ê²°

$$\epsilon_\theta(x_t, t) = -\sqrt{1 - \bar\alpha_t} \cdot s_\theta(x_t, t)$$

ë…¸ì´ì¦ˆ ì˜ˆì¸¡($\epsilon$-prediction)ê³¼ ìŠ¤ì½”ì–´ ì˜ˆì¸¡($s$-prediction)ì€ **ìŠ¤ì¼€ì¼ë§ ê³„ìˆ˜**ë§Œ ë‹¤ë¥¸ **ë™ì¼í•œ í•™ìŠµ**ì…ë‹ˆë‹¤.

### ë‹¤ìŒ ì±•í„° ì˜ˆê³ 
**Chapter 14: ê·¹í•œ ì¶”ë¡  ìµœì í™”** â€” FlashAttention, Speculative Decoding, PagedAttention, ì–‘ìí™”ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤."""))

# â”€â”€ Create notebook â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
path = '/workspace/chapter13_genai_diffusion/05_score_matching_and_sde.ipynb'
create_notebook(cells, path)
