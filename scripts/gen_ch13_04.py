#!/usr/bin/env python3
"""Generate chapter13_genai_diffusion/04_conditional_diffusion_cfg.ipynb"""
import sys, os
sys.path.insert(0, '/workspace/scripts')
from nb_helper import md, code, create_notebook

cells = []

# â”€â”€ Cell 1: Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""# Chapter 13: ìƒì„± AI ì‹¬í™” â€” Classifier-Free Guidance (CFG)

## í•™ìŠµ ëª©í‘œ
- **Classifier Guidance**ì™€ **Classifier-Free Guidance**ì˜ ì°¨ì´ë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ ì´í•´í•œë‹¤
- CFG ìˆ˜ì‹ $\tilde\epsilon_\theta(x_t,c) = \epsilon_\theta(x_t) + w[\epsilon_\theta(x_t,c) - \epsilon_\theta(x_t)]$ë¥¼ ìœ ë„í•œë‹¤
- **Guidance Scale $w$**ê°€ ìƒì„± í’ˆì§ˆ(Quality)ê³¼ ë‹¤ì–‘ì„±(Diversity)ì— ë¯¸ì¹˜ëŠ” íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì‹¤í—˜í•œë‹¤
- **ControlNet** ì¡°ê±´ë¶€ ì œì–´ ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ ì›ë¦¬ë¥¼ ì´í•´í•œë‹¤
- TensorFlowë¡œ CFG ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ê³¼ Guidance Scale ì‹¤í—˜ì„ êµ¬í˜„í•œë‹¤

## ëª©ì°¨
1. [ìˆ˜í•™ì  ê¸°ì´ˆ: Classifier-Free Guidance](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)
2. [CFG ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜](#2.-CFG-ì‹œë®¬ë ˆì´ì…˜)
3. [Guidance Scale Sweep ì‹œê°í™”](#3.-Guidance-Scale-Sweep)
4. [í’ˆì§ˆ vs ë‹¤ì–‘ì„± íŠ¸ë ˆì´ë“œì˜¤í”„](#4.-í’ˆì§ˆ-vs-ë‹¤ì–‘ì„±)
5. [ControlNet ì•„í‚¤í…ì²˜ ê°œìš”](#5.-ControlNet-ê°œìš”)
6. [ì •ë¦¬](#6.-ì •ë¦¬)"""))

# â”€â”€ Cell 2: Math Section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>

### Classifier Guidance (Dhariwal & Nichol, 2021)

ì¡°ê±´ë¶€ ìƒì„±ì˜ ì²« ë²ˆì§¸ ì ‘ê·¼ì€ ë³„ë„ì˜ **ë¶„ë¥˜ê¸°(classifier)** $p_\phi(c|x_t)$ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:

$$\nabla_{x_t} \log p(x_t | c) = \nabla_{x_t} \log p(x_t) + \gamma \nabla_{x_t} \log p_\phi(c | x_t)$$

- $\nabla_{x_t} \log p(x_t)$: ë¹„ì¡°ê±´ë¶€ ìŠ¤ì½”ì–´ í•¨ìˆ˜
- $\nabla_{x_t} \log p_\phi(c | x_t)$: ë¶„ë¥˜ê¸°ì˜ ê·¸ë˜ë””ì–¸íŠ¸
- $\gamma$: guidance ê°•ë„

**í•œê³„**: ë³„ë„ì˜ ë…¸ì´ì¦ˆ-ê°•ê±´ ë¶„ë¥˜ê¸°ë¥¼ í•™ìŠµì‹œì¼œì•¼ í•˜ë©°, ë¶„ë¥˜ê¸° í•™ìŠµì´ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Classifier-Free Guidance (Ho & Salimans, 2022)

ë¶„ë¥˜ê¸° ì—†ì´ **í•˜ë‚˜ì˜ ëª¨ë¸**ë¡œ ì¡°ê±´ë¶€/ë¹„ì¡°ê±´ë¶€ ì˜ˆì¸¡ì„ ëª¨ë‘ ìˆ˜í–‰í•©ë‹ˆë‹¤:

$$\boxed{\tilde\epsilon_\theta(x_t, c) = \epsilon_\theta(x_t, \varnothing) + w \cdot \left[\epsilon_\theta(x_t, c) - \epsilon_\theta(x_t, \varnothing)\right]}$$

- $\epsilon_\theta(x_t, c)$: ì¡°ê±´ $c$ë¥¼ ë°›ì€ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
- $\epsilon_\theta(x_t, \varnothing)$: ë¹ˆ ì¡°ê±´(null condition)ìœ¼ë¡œì˜ ë¹„ì¡°ê±´ë¶€ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
- $w$: **guidance scale** (ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼)
- $\varnothing$: í•™ìŠµ ì‹œ ì¼ì • í™•ë¥ (ë³´í†µ 10~20%)ë¡œ ì¡°ê±´ì„ ë“œë¡­í•˜ì—¬ í•™ìŠµ

ì´ë¥¼ ì •ë¦¬í•˜ë©´:

$$\tilde\epsilon_\theta = (1 - w) \cdot \epsilon_\theta(x_t, \varnothing) + w \cdot \epsilon_\theta(x_t, c)$$

| $w$ ê°’ | ì˜ë¯¸ | íš¨ê³¼ |
|---------|------|------|
| $w = 0$ | ë¹„ì¡°ê±´ë¶€ ìƒì„± | ìµœëŒ€ ë‹¤ì–‘ì„±, ì¡°ê±´ ë¬´ì‹œ |
| $w = 1$ | í‘œì¤€ ì¡°ê±´ë¶€ ìƒì„± | ì¡°ê±´ ë°˜ì˜, ë³´í†µ í’ˆì§ˆ |
| $w > 1$ | ê³¼ë„í•œ ì¡°ê±´ ê°•ì¡° | ë†’ì€ í’ˆì§ˆ(FIDâ†“), ë‚®ì€ ë‹¤ì–‘ì„± |
| $w = 7.5$ | Stable Diffusion ê¸°ë³¸ê°’ | í’ˆì§ˆ-ë‹¤ì–‘ì„± ê· í˜•ì  |

### ìˆ˜í•™ì  í•´ì„: Score Function ê´€ì 

CFGëŠ” ìŠ¤ì½”ì–´ í•¨ìˆ˜ ê´€ì ì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ í•´ì„ë©ë‹ˆë‹¤:

$$\nabla_{x_t} \log p_w(x_t | c) = (1-w)\nabla_{x_t}\log p(x_t) + w\nabla_{x_t}\log p(x_t|c)$$

$$= \nabla_{x_t}\log p(x_t) + w\nabla_{x_t}\log p(c|x_t)$$

ì´ëŠ” **implicit classifier** $p(c|x_t)$ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ $w$ë°° ê°•í™”í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤.

**ìš”ì•½ í‘œ:**

| êµ¬ë¶„ | ìˆ˜ì‹ | í•µì‹¬ |
|------|------|------|
| Classifier Guidance | $\nabla \log p(x_t) + \gamma \nabla \log p_\phi(c\|x_t)$ | ë³„ë„ ë¶„ë¥˜ê¸° í•„ìš” |
| Classifier-Free Guidance | $\epsilon_\theta(\varnothing) + w[\epsilon_\theta(c) - \epsilon_\theta(\varnothing)]$ | ë‹¨ì¼ ëª¨ë¸, ì¡°ê±´ ë“œë¡­ |
| Score í•´ì„ | $\nabla\log p(x_t) + w\nabla\log p(c\|x_t)$ | ì•”ì‹œì  ë¶„ë¥˜ê¸° ê°•í™” |"""))

# â”€â”€ Cell 3: ğŸ£ Friendly Explanation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""---

### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ CFG ì¹œì ˆ ì„¤ëª…!

#### ğŸ¨ Classifier-Free Guidanceê°€ ë­”ê°€ìš”?

> ğŸ’¡ **ë¹„ìœ **: ê·¸ë¦¼ ê·¸ë¦¬ê¸° ëŒ€íšŒë¥¼ ìƒìƒí•´ë³´ì„¸ìš”!

ì„ ìƒë‹˜(ëª¨ë¸)ì—ê²Œ "ê³ ì–‘ì´ë¥¼ ê·¸ë ¤ì£¼ì„¸ìš”"ë¼ê³  ë§í•˜ë©´, ì„ ìƒë‹˜ì€ ë‘ ê°€ì§€ ê·¸ë¦¼ì„ ë¨¸ë¦¿ì†ì— ë– ì˜¬ë¦½ë‹ˆë‹¤:

1. ğŸ² **ì•„ë¬´ê±°ë‚˜ ê·¸ë¦° ê·¸ë¦¼** (ë¹„ì¡°ê±´ë¶€): ê·¸ëƒ¥ ììœ ë¡­ê²Œ ê·¸ë¦° ê·¸ë¦¼
2. ğŸ± **ê³ ì–‘ì´ ê·¸ë¦¼** (ì¡°ê±´ë¶€): "ê³ ì–‘ì´"ë¼ëŠ” ì¡°ê±´ì„ ë“£ê³  ê·¸ë¦° ê·¸ë¦¼

**Guidance Scale $w$**ëŠ” "ê³ ì–‘ì´ìŠ¤ëŸ¬ì›€"ì„ **ì–¼ë§ˆë‚˜ ê°•ì¡°í• ì§€** ì •í•˜ëŠ” ë‹¤ì´ì–¼ì…ë‹ˆë‹¤:

| ë‹¤ì´ì–¼ | ê²°ê³¼ |
|--------|------|
| $w = 0$ | ê·¸ëƒ¥ ììœ í™” â†’ ê³ ì–‘ì´ ì•„ë‹ ìˆ˜ë„! |
| $w = 1$ | ë³´í†µ ê³ ì–‘ì´ ê·¸ë¦¼ |
| $w = 7$ | ì•„ì£¼ ê³ ì–‘ì´ìŠ¤ëŸ¬ìš´ ê·¸ë¦¼! ğŸ±âœ¨ |
| $w = 20$ | ë„ˆë¬´ ê³ ì–‘ì´ë§Œ ê°•ì¡° â†’ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ê·¸ë¦¼ ğŸ˜µ |

$$\text{ìµœì¢… ê·¸ë¦¼} = \text{ììœ í™”} + w \times (\text{ê³ ì–‘ì´ ê·¸ë¦¼} - \text{ììœ í™”})$$

ì¦‰, **"ê³ ì–‘ì´ ëŠë‚Œ"ë§Œ ë½‘ì•„ì„œ $w$ë°°ë¡œ ê°•í™”**í•˜ëŠ” ê²ë‹ˆë‹¤!"""))

# â”€â”€ Cell 4: ğŸ“ Practice Problems â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""---

### ğŸ“ ì—°ìŠµ ë¬¸ì œ

#### ë¬¸ì œ 1: CFG ì¶œë ¥ ê³„ì‚°

ëª¨ë¸ì´ ë‹¤ìŒ ë…¸ì´ì¦ˆë¥¼ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤:
- ë¹„ì¡°ê±´ë¶€: $\epsilon_\theta(x_t, \varnothing) = [0.3, -0.5, 0.8]$
- ì¡°ê±´ë¶€: $\epsilon_\theta(x_t, c) = [0.1, -0.2, 1.2]$

Guidance scale $w = 3.0$ì¼ ë•Œ, CFG ê²°í•© ë…¸ì´ì¦ˆ $\tilde\epsilon$ì„ ê³„ì‚°í•˜ì„¸ìš”.

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$$\tilde\epsilon = \epsilon_\theta(\varnothing) + w[\epsilon_\theta(c) - \epsilon_\theta(\varnothing)]$$

$$= [0.3, -0.5, 0.8] + 3.0 \times ([0.1, -0.2, 1.2] - [0.3, -0.5, 0.8])$$

$$= [0.3, -0.5, 0.8] + 3.0 \times [-0.2, 0.3, 0.4]$$

$$= [0.3, -0.5, 0.8] + [-0.6, 0.9, 1.2]$$

$$= [-0.3, 0.4, 2.0]$$

$w > 1$ì´ë¯€ë¡œ ì¡°ê±´ë¶€ ë°©í–¥ì´ **ê³¼ê°•ì¡°**ë˜ì–´, ë¹„ì¡°ê±´ë¶€ ì˜ˆì¸¡ë³´ë‹¤ ë” í° í­ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.
</details>

#### ë¬¸ì œ 2: Guidance Scale íš¨ê³¼

$w = 1$ê³¼ $w = 0$ì—ì„œ ê°ê° $\tilde\epsilon$ì€ ë¬´ì—‡ê³¼ ê°™ì•„ì§€ëŠ”ì§€ ì„œìˆ í•˜ì„¸ìš”.

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

- $w = 1$: $\tilde\epsilon = \epsilon_\theta(\varnothing) + 1 \cdot [\epsilon_\theta(c) - \epsilon_\theta(\varnothing)] = \epsilon_\theta(c)$
  â†’ **í‘œì¤€ ì¡°ê±´ë¶€ ì˜ˆì¸¡**ê³¼ ë™ì¼

- $w = 0$: $\tilde\epsilon = \epsilon_\theta(\varnothing) + 0 \cdot [\cdots] = \epsilon_\theta(\varnothing)$
  â†’ **ë¹„ì¡°ê±´ë¶€ ì˜ˆì¸¡**ê³¼ ë™ì¼

ì¦‰, $w$ëŠ” ë¹„ì¡°ê±´ë¶€($w=0$)ì™€ ì¡°ê±´ë¶€($w=1$) ì‚¬ì´ë¥¼ **ì—°ì†ì ìœ¼ë¡œ ë³´ê°„**í•˜ë©°, $w > 1$ì€ ì¡°ê±´ ë°©í–¥ìœ¼ë¡œì˜ **ì™¸ì‚½(extrapolation)**ì…ë‹ˆë‹¤.
</details>"""))

# â”€â”€ Cell 5: Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import tensorflow as tf

np.random.seed(42)
tf.random.set_seed(42)
print(f"TensorFlow ë²„ì „: {tf.__version__}")
print(f"NumPy ë²„ì „: {np.__version__}")"""))

# â”€â”€ Cell 6: CFG Noise Prediction Simulation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 2. CFG ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ <a name='2.-CFG-ì‹œë®¬ë ˆì´ì…˜'></a>

ê°„ë‹¨í•œ ì‹ ê²½ë§ìœ¼ë¡œ ì¡°ê±´ë¶€/ë¹„ì¡°ê±´ë¶€ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê³ , CFG ê³µì‹ì„ ì ìš©í•©ë‹ˆë‹¤."""))

cells.append(code(r"""# â”€â”€ CFG ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2D ê°€ìš°ì‹œì•ˆ í˜¼í•© ë°ì´í„°ë¡œ CFG ì‹œë®¬ë ˆì´ì…˜

data_dim = 2
n_timesteps = 50

# ë² íƒ€ ìŠ¤ì¼€ì¤„
betas = np.linspace(1e-4, 0.02, n_timesteps).astype(np.float32)
alphas = 1.0 - betas
alpha_bars = np.cumprod(alphas)

# ê°„ë‹¨í•œ ì¡°ê±´ë¶€/ë¹„ì¡°ê±´ë¶€ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ëª¨ë¸
class SimpleCFGModel(tf.keras.Model):
    # CFG ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ê°„ë‹¨í•œ MLP ëª¨ë¸
    def __init__(self, dim=2, cond_dim=4):
        super().__init__()
        self.uncond_net = tf.keras.Sequential([
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(dim)
        ])
        self.cond_net = tf.keras.Sequential([
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(dim)
        ])
        self.time_embed = tf.keras.layers.Dense(16, activation='relu')

    def call(self, x_t, t_emb, condition=None):
        t_feat = self.time_embed(t_emb)
        if condition is None:
            inp = tf.concat([x_t, t_feat], axis=-1)
            return self.uncond_net(inp)
        else:
            inp = tf.concat([x_t, t_feat, condition], axis=-1)
            return self.cond_net(inp)

model = SimpleCFGModel(dim=data_dim, cond_dim=4)

# ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ëª¨ë¸ ë¹Œë“œ
dummy_x = tf.zeros((1, data_dim))
dummy_t = tf.zeros((1, 1))
dummy_c = tf.zeros((1, 4))
_ = model(dummy_x, dummy_t, condition=None)
_ = model(dummy_x, dummy_t, condition=dummy_c)

print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ (ë¹„ì¡°ê±´ë¶€): {sum(np.prod(w.shape) for w in model.uncond_net.trainable_weights)}")
print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ (ì¡°ê±´ë¶€):   {sum(np.prod(w.shape) for w in model.cond_net.trainable_weights)}")

# CFG ì ìš© í•¨ìˆ˜
def apply_cfg(model, x_t, t_emb, condition, guidance_scale):
    # ë¹„ì¡°ê±´ë¶€ ì˜ˆì¸¡
    eps_uncond = model(x_t, t_emb, condition=None)
    # ì¡°ê±´ë¶€ ì˜ˆì¸¡
    eps_cond = model(x_t, t_emb, condition=condition)
    # CFG ê³µì‹
    eps_cfg = eps_uncond + guidance_scale * (eps_cond - eps_uncond)
    return eps_cfg, eps_uncond, eps_cond

# í…ŒìŠ¤íŠ¸
test_x = tf.random.normal((5, data_dim))
test_t = tf.constant([[0.5]] * 5)
test_c = tf.one_hot([0, 1, 2, 3, 0], depth=4)

for w in [0.0, 1.0, 3.0, 7.5]:
    eps_cfg, eps_u, eps_c = apply_cfg(model, test_x, test_t, test_c, w)
    magnitude = tf.reduce_mean(tf.norm(eps_cfg, axis=-1)).numpy()
    print(f"  w = {w:>4.1f} â†’ CFG ë…¸ì´ì¦ˆ í‰ê·  í¬ê¸°: {magnitude:.4f}")"""))

# â”€â”€ Cell 7: Guidance Scale Sweep â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 3. Guidance Scale Sweep ì‹œê°í™” <a name='3.-Guidance-Scale-Sweep'></a>

ë‹¤ì–‘í•œ guidance scale $w$ì—ì„œ CFG ë…¸ì´ì¦ˆ ë°©í–¥ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ 2Dë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤."""))

cells.append(code(r"""# â”€â”€ Guidance Scale Sweep ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2Dì—ì„œ ë¹„ì¡°ê±´ë¶€ vs ì¡°ê±´ë¶€ vs CFG ë…¸ì´ì¦ˆ ë°©í–¥ ë¹„êµ

n_points = 200
np.random.seed(42)

# 2D í¬ì¸íŠ¸ ìƒì„±
x_points = np.random.randn(n_points, 2).astype(np.float32) * 1.5

# ì‹œë®¬ë ˆì´ì…˜: ë¹„ì¡°ê±´ë¶€ = ì›ì  ë°©í–¥, ì¡°ê±´ë¶€ = íŠ¹ì • í´ë˜ìŠ¤ ì¤‘ì‹¬ ë°©í–¥
target_center = np.array([3.0, 2.0])
eps_uncond = -x_points * 0.3 + np.random.randn(n_points, 2).astype(np.float32) * 0.2
eps_cond = (target_center - x_points) * 0.3 + np.random.randn(n_points, 2).astype(np.float32) * 0.1

guidance_scales = [0.0, 1.0, 3.0, 7.5]
fig, axes = plt.subplots(1, 4, figsize=(20, 5))

for idx, w in enumerate(guidance_scales):
    ax = axes[idx]
    eps_cfg = eps_uncond + w * (eps_cond - eps_uncond)

    ax.scatter(x_points[:, 0], x_points[:, 1], c='gray', s=10, alpha=0.5, label='í˜„ì¬ ìœ„ì¹˜')
    scale = 0.8
    ax.quiver(x_points[::5, 0], x_points[::5, 1],
              eps_cfg[::5, 0] * scale, eps_cfg[::5, 1] * scale,
              color='blue', alpha=0.6, scale=15, width=0.004)
    ax.scatter(*target_center, c='red', s=150, marker='*', zorder=5, label='ì¡°ê±´ íƒ€ê²Ÿ')
    ax.set_xlim(-5, 7)
    ax.set_ylim(-5, 7)
    ax.set_title(f'w = {w}', fontweight='bold', fontsize=13)
    ax.set_xlabel('$x_1$', fontsize=11)
    ax.set_ylabel('$x_2$', fontsize=11)
    ax.legend(fontsize=8, loc='upper left')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter13_genai_diffusion/cfg_guidance_scale_sweep.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/cfg_guidance_scale_sweep.png")
print(f"Guidance scale ê°’: {guidance_scales}")
print("w=0: ë¹„ì¡°ê±´ë¶€ (ë°œì‚°), w=1: í‘œì¤€ ì¡°ê±´ë¶€, w=7.5: ê°•í•œ ì¡°ê±´ ë°©í–¥")"""))

# â”€â”€ Cell 8: Quality vs Diversity Tradeoff â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 4. í’ˆì§ˆ vs ë‹¤ì–‘ì„± íŠ¸ë ˆì´ë“œì˜¤í”„ <a name='4.-í’ˆì§ˆ-vs-ë‹¤ì–‘ì„±'></a>

Guidance scale $w$ë¥¼ ë†’ì´ë©´:
- **FID(í’ˆì§ˆ) â†“** â€” ì¡°ê±´ì— ë” ì˜ ë§ëŠ” ìƒ˜í”Œ ìƒì„± (ì¢‹ìŒ)
- **ë‹¤ì–‘ì„± â†“** â€” ëª¨ë“œ ë¶•ê´´(mode collapse)ì— ê°€ê¹Œì›Œì§ (ë‚˜ì¨)

ì´ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤."""))

cells.append(code(r"""# â”€â”€ í’ˆì§ˆ vs ë‹¤ì–‘ì„± íŠ¸ë ˆì´ë“œì˜¤í”„ ê³¡ì„  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹œë®¬ë ˆì´ì…˜: w ì¦ê°€ â†’ í’ˆì§ˆâ†‘(FIDâ†“), ë‹¤ì–‘ì„±â†“

w_values = np.linspace(0, 20, 100)

# FID ì‹œë®¬ë ˆì´ì…˜ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ): w=0ì—ì„œ ë†’ê³ , w=7~8ì—ì„œ ìµœì €, ì´í›„ ë‹¤ì‹œ ìƒìŠ¹
fid_sim = 50 * np.exp(-0.5 * w_values) + 5 + 0.3 * (w_values - 7.5)**2
fid_sim = np.clip(fid_sim, 3, 100)

# ë‹¤ì–‘ì„± ì‹œë®¬ë ˆì´ì…˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ): w ì¦ê°€í•˜ë©´ ê°ì†Œ
diversity_sim = 1.0 / (1.0 + 0.15 * w_values**1.5)

# CLIP Score ì‹œë®¬ë ˆì´ì…˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ): w ì¦ê°€í•˜ë©´ ìƒìŠ¹ í›„ í¬í™”
clip_score_sim = 0.35 * (1 - np.exp(-0.4 * w_values)) + 0.15

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# FID
ax1 = axes[0]
ax1.plot(w_values, fid_sim, 'b-', lw=2.5, label='FID (â†“ ì¢‹ìŒ)')
ax1.axvline(x=7.5, color='red', ls='--', lw=1.5, alpha=0.7, label='w=7.5 (SD ê¸°ë³¸)')
best_fid_w = w_values[np.argmin(fid_sim)]
ax1.axvline(x=best_fid_w, color='green', ls=':', lw=1.5, label=f'ìµœì  wâ‰ˆ{best_fid_w:.1f}')
ax1.set_xlabel('Guidance Scale (w)', fontsize=11)
ax1.set_ylabel('FID', fontsize=11)
ax1.set_title('FID vs Guidance Scale', fontweight='bold')
ax1.legend(fontsize=9)
ax1.grid(True, alpha=0.3)

# ë‹¤ì–‘ì„±
ax2 = axes[1]
ax2.plot(w_values, diversity_sim, 'g-', lw=2.5, label='ë‹¤ì–‘ì„± (â†‘ ì¢‹ìŒ)')
ax2.axvline(x=7.5, color='red', ls='--', lw=1.5, alpha=0.7, label='w=7.5')
ax2.fill_between(w_values, diversity_sim, alpha=0.1, color='green')
ax2.set_xlabel('Guidance Scale (w)', fontsize=11)
ax2.set_ylabel('Diversity (ì •ê·œí™”)', fontsize=11)
ax2.set_title('Diversity vs Guidance Scale', fontweight='bold')
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)

# CLIP Score
ax3 = axes[2]
ax3.plot(w_values, clip_score_sim, 'r-', lw=2.5, label='CLIP Score (â†‘ ì¢‹ìŒ)')
ax3.axvline(x=7.5, color='red', ls='--', lw=1.5, alpha=0.7, label='w=7.5')
ax3.set_xlabel('Guidance Scale (w)', fontsize=11)
ax3.set_ylabel('CLIP Score', fontsize=11)
ax3.set_title('CLIP Score vs Guidance Scale', fontweight='bold')
ax3.legend(fontsize=9)
ax3.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter13_genai_diffusion/cfg_quality_diversity_tradeoff.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/cfg_quality_diversity_tradeoff.png")

# ìˆ˜ì¹˜ ë¹„êµ í‘œ
print(f"\n{'Guidance Scale w':<20} | {'FID (â†“)':>10} | {'Diversity':>10} | {'CLIP (â†‘)':>10}")
print("-" * 58)
for w_test in [0, 1, 3, 5, 7.5, 10, 15, 20]:
    idx = np.argmin(np.abs(w_values - w_test))
    print(f"w = {w_test:<14.1f} | {fid_sim[idx]:>10.1f} | {diversity_sim[idx]:>10.3f} | {clip_score_sim[idx]:>10.3f}")"""))

# â”€â”€ Cell 9: Pareto Curve â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ í’ˆì§ˆ-ë‹¤ì–‘ì„± íŒŒë ˆí†  í”„ë¡ í‹°ì–´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig, ax = plt.subplots(1, 1, figsize=(8, 6))

scatter = ax.scatter(diversity_sim, fid_sim, c=w_values, cmap='viridis', s=30, alpha=0.8)
cbar = plt.colorbar(scatter, ax=ax, label='Guidance Scale (w)')

# íŠ¹ì • w ê°’ ê°•ì¡°
for w_mark in [0, 1, 3, 7.5, 15]:
    idx = np.argmin(np.abs(w_values - w_mark))
    ax.annotate(f'w={w_mark}', (diversity_sim[idx], fid_sim[idx]),
                fontsize=10, fontweight='bold',
                xytext=(10, 10), textcoords='offset points',
                arrowprops=dict(arrowstyle='->', color='red'))

ax.set_xlabel('Diversity (â†‘ ì¢‹ìŒ)', fontsize=11)
ax.set_ylabel('FID (â†“ ì¢‹ìŒ)', fontsize=11)
ax.set_title('Quality-Diversity Pareto Front (CFG)', fontweight='bold')
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter13_genai_diffusion/cfg_pareto_front.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/cfg_pareto_front.png")
print("íŒŒë ˆí†  í”„ë¡ íŠ¸: wë¥¼ ì¡°ì ˆí•˜ë©´ í’ˆì§ˆ-ë‹¤ì–‘ì„± ê³¡ì„  ìœ„ë¥¼ ì´ë™í•©ë‹ˆë‹¤")
print(f"ìµœì  FID ì§€ì : w â‰ˆ {w_values[np.argmin(fid_sim)]:.1f} (FID = {np.min(fid_sim):.1f})")"""))

# â”€â”€ Cell 10: ControlNet Section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 5. ControlNet ì•„í‚¤í…ì²˜ ê°œìš” <a name='5.-ControlNet-ê°œìš”'></a>

### ControlNet (Zhang et al., 2023)

ControlNetì€ **ì¶”ê°€ ì¡°ê±´(ì—ì§€ë§µ, ê¹Šì´ë§µ, í¬ì¦ˆ ë“±)**ìœ¼ë¡œ í™•ì‚° ëª¨ë¸ì„ ì œì–´í•˜ëŠ” ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.

#### í•µì‹¬ ìˆ˜ì‹

ê¸°ì¡´ U-Netì˜ ê°€ì¤‘ì¹˜ $\Theta$ë¥¼ ë³µì œí•œ í•™ìŠµ ê°€ëŠ¥í•œ ì‚¬ë³¸ $\Theta_c$ë¥¼ ë§Œë“¤ê³ , **zero convolution**ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤:

$$y_c = F(x;\, \Theta) + \mathcal{Z}(F(x + \mathcal{Z}(c;\, \Theta_{z1});\, \Theta_c);\, \Theta_{z2})$$

- $F(\cdot;\, \Theta)$: ì›ë³¸ U-Net ë¸”ë¡ (ê°€ì¤‘ì¹˜ ë™ê²°)
- $F(\cdot;\, \Theta_c)$: ë³µì œëœ í•™ìŠµ ê°€ëŠ¥í•œ U-Net ë¸”ë¡
- $\mathcal{Z}(\cdot;\, \Theta_z)$: **Zero Convolution** â€” $1 \times 1$ Conv, ê°€ì¤‘ì¹˜/ë°”ì´ì–´ìŠ¤ ëª¨ë‘ $0$ìœ¼ë¡œ ì´ˆê¸°í™”
- $c$: ì¶”ê°€ ì¡°ê±´ ì…ë ¥ (ì—ì§€ë§µ, ê¹Šì´ë§µ, ì„¸ê·¸ë©˜í…Œì´ì…˜ ë“±)

#### í•™ìŠµ ì•ˆì •ì„±ì˜ ë¹„ë°€: Zero Convolution

$$\mathcal{Z}(x;\, \{W, b\}) = W \cdot x + b, \quad W = 0,\; b = 0$$

í•™ìŠµ ì‹œì‘ ì‹œ $\mathcal{Z}$ì˜ ì¶œë ¥ì´ $0$ì´ë¯€ë¡œ, ì›ë³¸ ëª¨ë¸ì˜ ì¶œë ¥ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šì•„ **ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµ**ì´ ì‹œì‘ë©ë‹ˆë‹¤.

| êµ¬ì„± ìš”ì†Œ | ì—­í•  | í•™ìŠµ ì—¬ë¶€ |
|-----------|------|-----------|
| ì›ë³¸ U-Net | ê¸°ì¡´ ìƒì„± ëŠ¥ë ¥ ìœ ì§€ | â„ï¸ ë™ê²° |
| ë³µì œ U-Net | ì¶”ê°€ ì¡°ê±´ í•™ìŠµ | ğŸ”¥ í•™ìŠµ ê°€ëŠ¥ |
| Zero Conv | ì•ˆì „í•œ ì—°ê²° | ğŸ”¥ í•™ìŠµ ê°€ëŠ¥ |
| ì¡°ê±´ ì¸ì½”ë” | ì¡°ê±´ ì…ë ¥ ì²˜ë¦¬ | ğŸ”¥ í•™ìŠµ ê°€ëŠ¥ |"""))

# â”€â”€ Cell 11: ControlNet Architecture Diagram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ ControlNet ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig, ax = plt.subplots(1, 1, figsize=(14, 8))
ax.set_xlim(0, 14)
ax.set_ylim(0, 10)
ax.axis('off')
ax.set_title('ControlNet Architecture Overview', fontweight='bold', fontsize=14, pad=15)

# ìƒ‰ìƒ ì •ì˜
frozen_color = '#4A90D9'
trainable_color = '#E8744F'
zero_color = '#50C878'
arrow_color = '#333333'

box_style = dict(boxstyle='round,pad=0.5', facecolor=frozen_color, edgecolor='black', alpha=0.8)
train_style = dict(boxstyle='round,pad=0.5', facecolor=trainable_color, edgecolor='black', alpha=0.8)
zero_style = dict(boxstyle='round,pad=0.3', facecolor=zero_color, edgecolor='black', alpha=0.8)

# ì›ë³¸ U-Net (ìƒë‹¨, ë™ê²°)
ax.text(4, 8.5, 'ì›ë³¸ U-Net Encoder\n(â„ï¸ ë™ê²°)', ha='center', va='center',
        fontsize=11, fontweight='bold', color='white', bbox=box_style)
ax.text(10, 8.5, 'ì›ë³¸ U-Net Decoder\n(â„ï¸ ë™ê²°)', ha='center', va='center',
        fontsize=11, fontweight='bold', color='white', bbox=box_style)

# í™”ì‚´í‘œ: ì¸ì½”ë” â†’ ë””ì½”ë”
ax.annotate('', xy=(7.5, 8.5), xytext=(6.3, 8.5),
            arrowprops=dict(arrowstyle='->', color=arrow_color, lw=2))
ax.text(7.0, 9.0, 'skip connection', ha='center', fontsize=8, style='italic')

# ë³µì œ U-Net (í•˜ë‹¨, í•™ìŠµ ê°€ëŠ¥)
ax.text(4, 4.5, 'ControlNet ë³µì œ ë¸”ë¡\n(ğŸ”¥ í•™ìŠµ ê°€ëŠ¥)', ha='center', va='center',
        fontsize=11, fontweight='bold', color='white', bbox=train_style)

# ì¡°ê±´ ì…ë ¥
ax.text(1, 2, 'ì¡°ê±´ ì…ë ¥ c\n(ì—ì§€ë§µ/ê¹Šì´ë§µ)', ha='center', va='center',
        fontsize=9, fontweight='bold', bbox=dict(boxstyle='round', facecolor='#FFD700', alpha=0.8))

# Zero Conv 1
ax.text(2.5, 3.5, 'Zâ‚\n(zero)', ha='center', va='center',
        fontsize=9, fontweight='bold', color='white', bbox=zero_style)
ax.annotate('', xy=(2.5, 4.0), xytext=(1.5, 2.5),
            arrowprops=dict(arrowstyle='->', color=arrow_color, lw=1.5))

# ì…ë ¥ x_t
ax.text(1, 6.5, 'x_t\n(ë…¸ì´ì¦ˆ ì…ë ¥)', ha='center', va='center',
        fontsize=9, fontweight='bold', bbox=dict(boxstyle='round', facecolor='#D3D3D3', alpha=0.8))
ax.annotate('', xy=(2.5, 8.2), xytext=(1.5, 7.0),
            arrowprops=dict(arrowstyle='->', color=arrow_color, lw=1.5))
ax.annotate('', xy=(2.5, 5.0), xytext=(1.5, 6.5),
            arrowprops=dict(arrowstyle='->', color=arrow_color, lw=1.5))

# Zero Conv 2
ax.text(7, 4.5, 'Zâ‚‚\n(zero)', ha='center', va='center',
        fontsize=9, fontweight='bold', color='white', bbox=zero_style)
ax.annotate('', xy=(6.5, 4.5), xytext=(5.8, 4.5),
            arrowprops=dict(arrowstyle='->', color=arrow_color, lw=1.5))

# ê²°í•© í™”ì‚´í‘œ
ax.annotate('', xy=(8.5, 7.5), xytext=(7.5, 5.0),
            arrowprops=dict(arrowstyle='->', color='red', lw=2.5, ls='--'))
ax.text(8.5, 6.0, '+ (í•©ì‚°)', ha='center', fontsize=10, fontweight='bold', color='red')

# ì¶œë ¥
ax.text(12.5, 6.5, 'ìµœì¢… ì¶œë ¥\nÎµ_Î¸(x_t, t, c)', ha='center', va='center',
        fontsize=10, fontweight='bold', bbox=dict(boxstyle='round', facecolor='#E8E8E8', alpha=0.8))
ax.annotate('', xy=(11.5, 7.0), xytext=(11.0, 8.0),
            arrowprops=dict(arrowstyle='->', color=arrow_color, lw=2))

# ë²”ë¡€
legend_y = 1.0
ax.add_patch(plt.Rectangle((8, legend_y-0.15), 0.4, 0.3, fc=frozen_color, ec='black', alpha=0.8))
ax.text(8.6, legend_y, 'ë™ê²° (Frozen)', fontsize=9, va='center')
ax.add_patch(plt.Rectangle((10, legend_y-0.15), 0.4, 0.3, fc=trainable_color, ec='black', alpha=0.8))
ax.text(10.6, legend_y, 'í•™ìŠµ ê°€ëŠ¥', fontsize=9, va='center')
ax.add_patch(plt.Rectangle((12, legend_y-0.15), 0.4, 0.3, fc=zero_color, ec='black', alpha=0.8))
ax.text(12.6, legend_y, 'Zero Conv', fontsize=9, va='center')

plt.tight_layout()
plt.savefig('chapter13_genai_diffusion/controlnet_architecture.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/controlnet_architecture.png")
print("\nControlNet í•µì‹¬:")
print("  1. ì›ë³¸ U-Net ê°€ì¤‘ì¹˜ëŠ” ë™ê²° â†’ ê¸°ì¡´ ìƒì„± ëŠ¥ë ¥ ë³´ì¡´")
print("  2. ë³µì œ ë¸”ë¡ì´ ì¶”ê°€ ì¡°ê±´ì„ í•™ìŠµ")
print("  3. Zero Convolutionìœ¼ë¡œ ì•ˆì •ì  í•™ìŠµ ì‹œì‘ (ì´ˆê¸° ì¶œë ¥ = 0)")"""))

# â”€â”€ Cell 12: Zero Conv Demo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ Zero Convolution ë™ì‘ ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Zero Convolutionì˜ í•™ìŠµ ê³¼ì • ì‹œë®¬ë ˆì´ì…˜

class ZeroConv(tf.keras.layers.Layer):
    # ê°€ì¤‘ì¹˜ì™€ ë°”ì´ì–´ìŠ¤ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ëŠ” 1x1 Conv
    def __init__(self, out_channels):
        super().__init__()
        self.conv = tf.keras.layers.Dense(out_channels,
                                           kernel_initializer='zeros',
                                           bias_initializer='zeros')

    def call(self, x):
        return self.conv(x)

zero_conv = ZeroConv(out_channels=8)

# ì´ˆê¸° ìƒíƒœ: ì¶œë ¥ì´ 0
test_input = tf.random.normal((4, 16))
initial_output = zero_conv(test_input)

print("Zero Convolution ì´ˆê¸° ìƒíƒœ:")
print(f"  ì…ë ¥ í¬ê¸°: {test_input.shape}")
print(f"  ì¶œë ¥ í¬ê¸°: {initial_output.shape}")
print(f"  ì¶œë ¥ ìµœëŒ€ê°’: {tf.reduce_max(tf.abs(initial_output)).numpy():.6f}")
print(f"  ì¶œë ¥ì´ 0ì¸ê°€? {tf.reduce_all(initial_output == 0).numpy()}")

# í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜: ê·¸ë˜ë””ì–¸íŠ¸ ì—…ë°ì´íŠ¸ í›„
optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
target = tf.random.normal((4, 8))

for step in range(5):
    with tf.GradientTape() as tape:
        out = zero_conv(test_input)
        loss = tf.reduce_mean((out - target) ** 2)
    grads = tape.gradient(loss, zero_conv.trainable_variables)
    optimizer.apply_gradients(zip(grads, zero_conv.trainable_variables))

updated_output = zero_conv(test_input)
print(f"\n5 ìŠ¤í… í•™ìŠµ í›„:")
print(f"  ì¶œë ¥ ìµœëŒ€ê°’: {tf.reduce_max(tf.abs(updated_output)).numpy():.4f}")
print(f"  ì†ì‹¤: {loss.numpy():.4f}")
print("  â†’ í•™ìŠµì´ ì§„í–‰ë˜ë©´ì„œ ì ì§„ì ìœ¼ë¡œ ì¡°ê±´ ì •ë³´ë¥¼ ì£¼ì…!")"""))

# â”€â”€ Cell 13: Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 6. ì •ë¦¬ <a name='6.-ì •ë¦¬'></a>

### í•µì‹¬ ê°œë… ìš”ì•½

| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |
|------|------|--------|
| Classifier Guidance | ë³„ë„ ë¶„ë¥˜ê¸° ê·¸ë˜ë””ì–¸íŠ¸ë¡œ ì¡°ê±´ë¶€ ìƒì„± | â­â­ |
| Classifier-Free Guidance | ë‹¨ì¼ ëª¨ë¸, ì¡°ê±´ ë“œë¡­ìœ¼ë¡œ ì¡°ê±´ë¶€/ë¹„ì¡°ê±´ë¶€ í•™ìŠµ | â­â­â­ |
| Guidance Scale $w$ | í’ˆì§ˆ-ë‹¤ì–‘ì„± íŠ¸ë ˆì´ë“œì˜¤í”„ ì œì–´ | â­â­â­ |
| ControlNet | Zero Convë¡œ ì¶”ê°€ ì¡°ê±´ ì œì–´ | â­â­â­ |
| Zero Convolution | 0 ì´ˆê¸°í™”ë¡œ ì•ˆì •ì  í•™ìŠµ ì‹œì‘ | â­â­ |

### í•µì‹¬ ìˆ˜ì‹

$$\tilde\epsilon_\theta(x_t, c) = \underbrace{\epsilon_\theta(x_t, \varnothing)}_{\text{ë¹„ì¡°ê±´ë¶€}} + w \cdot \underbrace{\left[\epsilon_\theta(x_t, c) - \epsilon_\theta(x_t, \varnothing)\right]}_{\text{ì¡°ê±´ ë°©í–¥}}$$

$$y_c = F(x;\, \Theta) + \mathcal{Z}\!\left(F\!\left(x + \mathcal{Z}(c;\, \Theta_{z1});\, \Theta_c\right);\, \Theta_{z2}\right)$$

### ë‹¤ìŒ ì±•í„° ì˜ˆê³ 
**Chapter 13-05: Score Matchingê³¼ SDE** â€” Score function, Langevin dynamics, ì—°ì† ì‹œê°„ SDE/ODE í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤."""))

# â”€â”€ Create notebook â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
path = '/workspace/chapter13_genai_diffusion/04_conditional_diffusion_cfg.ipynb'
create_notebook(cells, path)
