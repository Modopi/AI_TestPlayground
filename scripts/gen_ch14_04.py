#!/usr/bin/env python3
import sys, os
sys.path.insert(0, '/workspace/scripts')
from nb_helper import md, code, create_notebook

cells = []

# â”€â”€ Cell 1: Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""# Chapter 14: ê·¹ë‹¨ì  ì¶”ë¡  ìµœì í™” â€” vLLMê³¼ PagedAttention

## í•™ìŠµ ëª©í‘œ
- OSì˜ **ê°€ìƒ ë©”ëª¨ë¦¬(Page Table)** ê°œë…ì´ LLM KV Cache ê´€ë¦¬ì— ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€ ì´í•´í•œë‹¤
- **PagedAttention**ì˜ ë¸”ë¡ í• ë‹¹Â·í•´ì œÂ·Copy-on-Write ë©”ì»¤ë‹ˆì¦˜ì„ ìˆ˜ì‹ìœ¼ë¡œ ë„ì¶œí•œë‹¤
- **Continuous Batching**ì´ Static Batching ëŒ€ë¹„ ì²˜ë¦¬ëŸ‰ì„ ì–´ë–»ê²Œ í–¥ìƒì‹œí‚¤ëŠ”ì§€ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•œë‹¤
- vLLMì˜ **ë™ì  KV Block ìŠ¤ì¼€ì¤„ë§** ì „ëµì„ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ê²€ì¦í•œë‹¤
- ë©”ëª¨ë¦¬ ë‹¨í¸í™”(Fragmentation)ì˜ ë‚´ë¶€/ì™¸ë¶€ ë‚­ë¹„ë¥¼ ì‹œê°í™”í•˜ê³  PagedAttentionì˜ í•´ê²° ë°©ì‹ì„ ì´í•´í•œë‹¤

## ëª©ì°¨
1. [ìˆ˜í•™ì  ê¸°ì´ˆ: í˜ì´ì§€ í…Œì´ë¸”ê³¼ ë©”ëª¨ë¦¬ ê´€ë¦¬](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)
2. [PagedAttention ë¸”ë¡ í• ë‹¹ ì‹œë®¬ë ˆì´í„°](#2.-PagedAttention-ë¸”ë¡-í• ë‹¹)
3. [Continuous Batching vs Static Batching](#3.-Continuous-Batching)
4. [ë©”ëª¨ë¦¬ ë‹¨í¸í™” ì‹œê°í™”](#4.-ë©”ëª¨ë¦¬-ë‹¨í¸í™”)
5. [ì •ë¦¬](#5.-ì •ë¦¬)"""))

# â”€â”€ Cell 2: Math Foundations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>

### ê°€ìƒ ë©”ëª¨ë¦¬ì™€ í˜ì´ì§€ í…Œì´ë¸”

OSëŠ” ë¬¼ë¦¬ ë©”ëª¨ë¦¬ë¥¼ ê³ ì • í¬ê¸° **í˜ì´ì§€(Page)**ë¡œ ë‚˜ëˆ„ê³ , **í˜ì´ì§€ í…Œì´ë¸”**ë¡œ ê°€ìƒ â†’ ë¬¼ë¦¬ ì£¼ì†Œë¥¼ ë§¤í•‘í•©ë‹ˆë‹¤.
PagedAttentionì€ ì´ ì•„ì´ë””ì–´ë¥¼ KV Cacheì— ì ìš©í•©ë‹ˆë‹¤:

$$\text{PageTable}: \text{VirtualBlock}[i] \;\rightarrow\; \text{PhysicalBlock}[j]$$

- ê° ë¸”ë¡ì€ $B_{tok}$ê°œì˜ í† í°ì— ëŒ€í•œ KV ë²¡í„°ë¥¼ ì €ì¥
- ë¸”ë¡ í¬ê¸°: $B_{tok} \times 2 \times n_{kv} \times d_{head} \times \text{bytes}$ (Kì™€ V ê°ê°)

### KV Cache ë©”ëª¨ë¦¬ â€” ì „í†µ ë°©ì‹ vs PagedAttention

**ì „í†µ ë°©ì‹ (ì—°ì† í• ë‹¹):**

$$M_{KV}^{trad} = 2 \times L \times n_{kv} \times d_{head} \times S_{max} \times B \times \text{bytes\_per\_elem}$$

- $L$: ë ˆì´ì–´ ìˆ˜, $n_{kv}$: KV í—¤ë“œ ìˆ˜, $d_{head}$: í—¤ë“œ ì°¨ì›
- $S_{max}$: **ìµœëŒ€** ì‹œí€€ìŠ¤ ê¸¸ì´ (ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë¶€ë¶„ë„ í• ë‹¹)
- $B$: ë°°ì¹˜ í¬ê¸°

**PagedAttention (ë¸”ë¡ ë‹¨ìœ„ í• ë‹¹):**

$$M_{KV}^{paged} = N_{blocks}^{used} \times B_{tok} \times 2 \times n_{kv} \times d_{head} \times \text{bytes}$$

$$N_{blocks}^{used} = \sum_{r=1}^{R} \left\lceil \frac{S_r}{B_{tok}} \right\rceil$$

- $S_r$: ìš”ì²­ $r$ì˜ **ì‹¤ì œ** ì‹œí€€ìŠ¤ ê¸¸ì´
- $R$: ë™ì‹œ ìš”ì²­ ìˆ˜

### ë©”ëª¨ë¦¬ ì ˆì•½ë¥ 

$$\text{Savings} = 1 - \frac{M_{KV}^{paged}}{M_{KV}^{trad}} = 1 - \frac{\sum_r \lceil S_r / B_{tok} \rceil \cdot B_{tok}}{R \cdot S_{max}}$$

### ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë¶„ì„

| ìœ í˜• | ì •ì˜ | ìˆ˜ì‹ |
|------|------|------|
| ë‚´ë¶€ ë‹¨í¸í™” | ë§ˆì§€ë§‰ ë¸”ë¡ì˜ ë¯¸ì‚¬ìš© ìŠ¬ë¡¯ | $W_{int} = \sum_r (B_{tok} - S_r \bmod B_{tok}) \bmod B_{tok}$ |
| ì™¸ë¶€ ë‹¨í¸í™” | ì—°ì† ê³µê°„ ë¶€ì¡±ìœ¼ë¡œ í• ë‹¹ ë¶ˆê°€ | PagedAttentionì—ì„œëŠ” **0** (ë¹„ì—°ì† í• ë‹¹) |

### Continuous Batching ì²˜ë¦¬ëŸ‰

$$\text{Throughput}_{static} = \frac{B}{\max_r T_r}, \quad \text{Throughput}_{cont} \approx \frac{\sum_r 1/T_r}{1} \cdot B_{eff}$$

- $T_r$: ìš”ì²­ $r$ì˜ ì²˜ë¦¬ ì‹œê°„
- Static Batchingì€ ê°€ì¥ ê¸´ ìš”ì²­ì´ ëë‚  ë•Œê¹Œì§€ GPU ìì›ì´ ë‚­ë¹„ë¨

**ìš”ì•½ í‘œ:**

| ê°œë… | ìˆ˜ì‹ | ì„¤ëª… |
|------|------|------|
| í˜ì´ì§€ ë§¤í•‘ | $\text{VBlock}[i] \to \text{PBlock}[j]$ | ë¹„ì—°ì† ë©”ëª¨ë¦¬ í• ë‹¹ |
| ë¸”ë¡ ë©”ëª¨ë¦¬ | $B_{tok} \times 2 n_{kv} d_h \times \text{bytes}$ | ë¸”ë¡ë‹¹ KV ì €ì¥ëŸ‰ |
| ë‚´ë¶€ ë‹¨í¸í™” | $(B_{tok} - S \bmod B_{tok}) \bmod B_{tok}$ | ë§ˆì§€ë§‰ ë¸”ë¡ ë‚­ë¹„ |
| ì ˆì•½ë¥  | $1 - M_{paged}/M_{trad}$ | ì‹¤ì œ ëŒ€ë¹„ ìµœëŒ€ í• ë‹¹ |"""))

# â”€â”€ Cell 3: ğŸ£ Friendly Explanation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ PagedAttention ì¹œì ˆ ì„¤ëª…!

#### ğŸ”¢ PagedAttentionì´ ë­”ê°€ìš”?

> ğŸ’¡ **ë¹„ìœ **: ë„ì„œê´€ì—ì„œ ì±…ì„ ë¹Œë¦¬ëŠ” ê²ƒê³¼ ê°™ì•„ìš”!

ì „í†µ ë°©ì‹ì€ ë§ˆì¹˜ **"ì´ ì‚¬ëŒì€ ìµœëŒ€ 100ê¶Œê¹Œì§€ ë¹Œë¦´ ìˆ˜ ìˆìœ¼ë‹ˆ, 100ì¹¸ì§œë¦¬ ì±…ì¥ì„ í†µì§¸ë¡œ ì˜ˆì•½í•´ì¤˜!"** ë¼ê³  í•˜ëŠ” ê±°ì˜ˆìš”.
ì‹¤ì œë¡œ 10ê¶Œë§Œ ë¹Œë ¤ë„ ë‚˜ë¨¸ì§€ 90ì¹¸ì€ í…… ë¹„ì–´ ìˆì£ . ğŸ˜¢

PagedAttentionì€ **"ì±… 5ê¶Œì´ ë“¤ì–´ê°€ëŠ” ì‘ì€ ë°”êµ¬ë‹ˆë¥¼ í•„ìš”í•  ë•Œë§ˆë‹¤ í•˜ë‚˜ì”© ë¹Œë ¤ì¤„ê²Œ!"** ë¼ê³  í•˜ëŠ” ê±°ì˜ˆìš”.
10ê¶Œ ë¹Œë¦¬ë©´ ë°”êµ¬ë‹ˆ 2ê°œë§Œ ì“°ë©´ ë˜ê³ , ë°”êµ¬ë‹ˆê°€ ê½‰ ì°¨ë©´ ìƒˆ ë°”êµ¬ë‹ˆë¥¼ í•˜ë‚˜ ë” ì£¼ë©´ ë©ë‹ˆë‹¤! ğŸ‰

#### ğŸ—ï¸ ê°€ìƒ ë¸”ë¡ê³¼ ë¬¼ë¦¬ ë¸”ë¡

| ê°œë… | ë¹„ìœ  |
|------|------|
| ê°€ìƒ ë¸”ë¡ | ë¹Œë¦° ì±…ì˜ **ëª©ë¡ ë²ˆí˜¸** (1ë²ˆ, 2ë²ˆ, 3ë²ˆ...) |
| ë¬¼ë¦¬ ë¸”ë¡ | ì‹¤ì œ **ì±…ì¥ ìœ„ì¹˜** (A-3ì„ ë°˜, B-7ì„ ë°˜...) |
| í˜ì´ì§€ í…Œì´ë¸” | ëª©ë¡ ë²ˆí˜¸ â†’ ì‹¤ì œ ìœ„ì¹˜ë¥¼ ì•Œë ¤ì£¼ëŠ” **ì§€ë„** |

ë°”êµ¬ë‹ˆ(ë¸”ë¡)ê°€ ë¹„ì—°ì†ì ì¸ ìœ„ì¹˜ì— ìˆì–´ë„ ëª©ë¡ë§Œ ìˆìœ¼ë©´ ìˆœì„œëŒ€ë¡œ ì°¾ì„ ìˆ˜ ìˆì–´ìš”!"""))

# â”€â”€ Cell 4: ğŸ“ Practice Problems â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""### ğŸ“ ì—°ìŠµ ë¬¸ì œ

#### ë¬¸ì œ 1: ë¸”ë¡ ìˆ˜ ê³„ì‚°

ëª¨ë¸ ì„¤ì •: $B_{tok} = 16$, ìš”ì²­ Aì˜ ì‹œí€€ìŠ¤ ê¸¸ì´ $S_A = 50$, ìš”ì²­ Bì˜ ì‹œí€€ìŠ¤ ê¸¸ì´ $S_B = 30$.
ê° ìš”ì²­ì— í•„ìš”í•œ ë¸”ë¡ ìˆ˜ì™€ ì´ ë‚´ë¶€ ë‹¨í¸í™”ë¥¼ êµ¬í•˜ì„¸ìš”.

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$$N_A = \lceil 50 / 16 \rceil = 4 \text{ ë¸”ë¡}, \quad N_B = \lceil 30 / 16 \rceil = 2 \text{ ë¸”ë¡}$$

ë‚´ë¶€ ë‹¨í¸í™”:
$$W_A = (16 - 50 \bmod 16) \bmod 16 = (16 - 2) = 14 \text{ ìŠ¬ë¡¯}$$
$$W_B = (16 - 30 \bmod 16) \bmod 16 = (16 - 14) = 2 \text{ ìŠ¬ë¡¯}$$
$$W_{total} = 14 + 2 = 16 \text{ ìŠ¬ë¡¯ ë‚­ë¹„}$$
</details>

#### ë¬¸ì œ 2: ë©”ëª¨ë¦¬ ì ˆì•½ë¥ 

ì „í†µ ë°©ì‹: $S_{max} = 2048$, ë°°ì¹˜ 2ê°œ (ì‹¤ì œ ê¸¸ì´ 50, 30).
PagedAttention($B_{tok}=16$) ëŒ€ë¹„ ì ˆì•½ë¥ ì„ êµ¬í•˜ì„¸ìš”.

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$$M_{trad} \propto 2 \times 2048 = 4096 \text{ (ìŠ¬ë¡¯ ê¸°ì¤€)}$$
$$M_{paged} \propto (4 + 2) \times 16 = 96 \text{ (ìŠ¬ë¡¯ ê¸°ì¤€)}$$
$$\text{Savings} = 1 - \frac{96}{4096} = 1 - 0.0234 = 97.7\%$$
</details>"""))

# â”€â”€ Cell 5: Import Cell â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ í™˜ê²½ ì„¤ì • ë° ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import tensorflow as tf
import time

np.random.seed(42)
print(f"TensorFlow ë²„ì „: {tf.__version__}")
print(f"NumPy ë²„ì „: {np.__version__}")"""))

# â”€â”€ Cell 6: Section 2 Markdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 2. PagedAttention ë¸”ë¡ í• ë‹¹ ì‹œë®¬ë ˆì´í„° <a name='2.-PagedAttention-ë¸”ë¡-í• ë‹¹'></a>

### PagedAttention ë¸”ë¡ í• ë‹¹ ë‹¤ì´ì–´ê·¸ë¨

ì•„ë˜ëŠ” 3ê°œì˜ ìš”ì²­ì´ ë¬¼ë¦¬ ë¸”ë¡ í’€ì—ì„œ ë¹„ì—°ì†ì ìœ¼ë¡œ ë¸”ë¡ì„ í• ë‹¹ë°›ëŠ” ê³¼ì •ì…ë‹ˆë‹¤:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Physical Block Pool                â”‚
â”‚  [PB0] [PB1] [PB2] [PB3] [PB4] [PB5] [PB6] [PB7]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Request A (seq_len=50, 4 blocks needed):
  Virtual:  [VB0] â†’ [VB1] â†’ [VB2] â†’ [VB3]
  Physical: [PB0]   [PB1]   [PB4]   [PB6]   â† ë¹„ì—°ì†!

Request B (seq_len=30, 2 blocks needed):
  Virtual:  [VB0] â†’ [VB1]
  Physical: [PB2]   [PB3]

Free Pool: [PB5] [PB7]

Page Table:
  Req A: {VB0â†’PB0, VB1â†’PB1, VB2â†’PB4, VB3â†’PB6}
  Req B: {VB0â†’PB2, VB1â†’PB3}
```

í•µì‹¬: ë¬¼ë¦¬ ë¸”ë¡ì´ **ë¹„ì—°ì†**ì´ì–´ë„ í˜ì´ì§€ í…Œì´ë¸”ë¡œ ìˆœì„œë¥¼ ì¶”ì í•˜ë¯€ë¡œ ë¬¸ì œì—†ìŠµë‹ˆë‹¤."""))

# â”€â”€ Cell 7: PagedAttention Simulator Code â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ PagedAttention ë¸”ë¡ í• ë‹¹ ì‹œë®¬ë ˆì´í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¬¼ë¦¬/ê°€ìƒ ë¸”ë¡ ë§¤í•‘ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤

class PagedAttentionAllocator:
    def __init__(self, num_physical_blocks, block_size):
        self.num_physical_blocks = num_physical_blocks
        self.block_size = block_size
        self.free_blocks = list(range(num_physical_blocks))
        self.page_tables = {}
        self.seq_lengths = {}

    def allocate(self, request_id, seq_len):
        num_blocks_needed = int(np.ceil(seq_len / self.block_size))
        if num_blocks_needed > len(self.free_blocks):
            print(f"  [ERROR] ìš”ì²­ {request_id}: {num_blocks_needed}ë¸”ë¡ í•„ìš”, "
                  f"ê°€ìš© {len(self.free_blocks)}ë¸”ë¡ â€” í• ë‹¹ ì‹¤íŒ¨!")
            return False
        allocated = []
        for _ in range(num_blocks_needed):
            pb = self.free_blocks.pop(0)
            allocated.append(pb)
        self.page_tables[request_id] = allocated
        self.seq_lengths[request_id] = seq_len
        internal_frag = (self.block_size - seq_len % self.block_size) % self.block_size
        print(f"  ìš”ì²­ {request_id}: seq_len={seq_len}, "
              f"ë¸”ë¡ {num_blocks_needed}ê°œ í• ë‹¹ â†’ ë¬¼ë¦¬ë¸”ë¡ {allocated}")
        print(f"    ë‚´ë¶€ ë‹¨í¸í™”: {internal_frag} ìŠ¬ë¡¯ "
              f"(ë§ˆì§€ë§‰ ë¸”ë¡ {seq_len % self.block_size or self.block_size}/{self.block_size} ì‚¬ìš©)")
        return True

    def free(self, request_id):
        if request_id in self.page_tables:
            freed = self.page_tables.pop(request_id)
            self.free_blocks.extend(freed)
            self.free_blocks.sort()
            del self.seq_lengths[request_id]
            print(f"  ìš”ì²­ {request_id} í•´ì œ: ë¬¼ë¦¬ë¸”ë¡ {freed} ë°˜í™˜")
            return freed
        return []

    def status(self):
        used = sum(len(v) for v in self.page_tables.values())
        free = len(self.free_blocks)
        total_slots = self.num_physical_blocks * self.block_size
        used_slots = sum(self.seq_lengths.values())
        internal_frag = sum(
            (self.block_size - s % self.block_size) % self.block_size
            for s in self.seq_lengths.values()
        )
        print(f"\n{'='*55}")
        print(f"  ë¸”ë¡ ì‚¬ìš©: {used}/{self.num_physical_blocks} "
              f"({used/self.num_physical_blocks*100:.1f}%)")
        print(f"  ê°€ìš© ë¸”ë¡: {free} â†’ {self.free_blocks}")
        print(f"  ì‹¤ì œ í† í°: {used_slots}/{total_slots} ìŠ¬ë¡¯ "
              f"(í™œìš©ë¥ : {used_slots/total_slots*100:.1f}%)")
        print(f"  ë‚´ë¶€ ë‹¨í¸í™”: {internal_frag} ìŠ¬ë¡¯")
        print(f"  ì™¸ë¶€ ë‹¨í¸í™”: 0 (ë¹„ì—°ì† í• ë‹¹)")
        print(f"{'='*55}")

print("=== PagedAttention ë¸”ë¡ í• ë‹¹ ì‹œë®¬ë ˆì´ì…˜ ===\n")
allocator = PagedAttentionAllocator(num_physical_blocks=16, block_size=16)

print("[1ë‹¨ê³„] 3ê°œ ìš”ì²­ ë™ì‹œ í• ë‹¹")
allocator.allocate("A", seq_len=50)
allocator.allocate("B", seq_len=30)
allocator.allocate("C", seq_len=75)
allocator.status()

print("\n[2ë‹¨ê³„] ìš”ì²­ B ì™„ë£Œ â†’ ë¸”ë¡ í•´ì œ")
allocator.free("B")
allocator.status()

print("\n[3ë‹¨ê³„] ìƒˆ ìš”ì²­ D í• ë‹¹ (í•´ì œëœ ë¸”ë¡ ì¬ì‚¬ìš©)")
allocator.allocate("D", seq_len=40)
allocator.status()

print("\n[í˜ì´ì§€ í…Œì´ë¸” ë‚´ìš©]")
for req_id, blocks in allocator.page_tables.items():
    vblocks = [f"VB{i}â†’PB{pb}" for i, pb in enumerate(blocks)]
    print(f"  ìš”ì²­ {req_id}: {{{', '.join(vblocks)}}}")"""))

# â”€â”€ Cell 8: Section 3 Markdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 3. Continuous Batching vs Static Batching <a name='3.-Continuous-Batching'></a>

### Static Batchingì˜ ë¬¸ì œ

Static Batchingì—ì„œëŠ” ë°°ì¹˜ ë‚´ **ëª¨ë“  ìš”ì²­ì´ ëë‚  ë•Œê¹Œì§€** ê¸°ë‹¤ë ¤ì•¼ í•©ë‹ˆë‹¤:

$$T_{static} = \max_{r \in \text{batch}} T_r$$

ì§§ì€ ìš”ì²­ì´ ë¨¼ì € ëë‚˜ë„ í•´ë‹¹ ìŠ¬ë¡¯ì˜ GPU ìì›ì€ ìœ íœ´ ìƒíƒœì…ë‹ˆë‹¤.

### Continuous Batchingì˜ í•´ê²°

ì™„ë£Œëœ ìš”ì²­ì˜ ìŠ¬ë¡¯ì— **ì¦‰ì‹œ ìƒˆ ìš”ì²­ì„ ì‚½ì…**í•©ë‹ˆë‹¤:

$$\text{GPU Utilization}_{cont} \approx 1 - \frac{\text{swap overhead}}{\text{total time}} \gg \text{GPU Util}_{static}$$"""))

# â”€â”€ Cell 9: Continuous vs Static Batching Code â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ Continuous Batching vs Static Batching ë¹„êµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìš”ì²­ë³„ ìƒì„± í† í° ìˆ˜ê°€ ë‹¤ë¥¸ ìƒí™©ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤

np.random.seed(42)

num_requests = 20
max_batch_size = 4
output_lengths = np.random.randint(10, 200, size=num_requests)
time_per_token = 0.01

# --- Static Batching ---
static_total_time = 0.0
static_tokens_generated = 0
idx = 0
while idx < num_requests:
    batch = output_lengths[idx:idx + max_batch_size]
    batch_time = max(batch) * time_per_token
    static_total_time += batch_time
    static_tokens_generated += sum(batch)
    idx += max_batch_size

static_throughput = static_tokens_generated / static_total_time

# --- Continuous Batching ---
cont_total_time = 0.0
cont_tokens_generated = 0
active_slots = np.zeros(max_batch_size, dtype=int)
waiting_queue = list(output_lengths)
step = 0

for slot_i in range(min(max_batch_size, len(waiting_queue))):
    active_slots[slot_i] = waiting_queue.pop(0)

while np.any(active_slots > 0) or waiting_queue:
    active_slots = np.maximum(active_slots - 1, 0)
    tokens_this_step = np.sum(active_slots > 0) + np.sum(active_slots == 0)
    cont_tokens_generated += int(np.sum(active_slots >= 0) - np.sum(active_slots == 0)) + np.sum(active_slots == 0)
    for slot_i in range(max_batch_size):
        if active_slots[slot_i] == 0 and waiting_queue:
            active_slots[slot_i] = waiting_queue.pop(0)
    cont_total_time += time_per_token
    step += 1
    if step > 10000:
        break

cont_tokens_generated = sum(output_lengths)
cont_throughput = cont_tokens_generated / cont_total_time

print("=" * 60)
print(f"{'ë°°ì¹­ ë°©ì‹':<25} | {'ì´ ì‹œê°„(s)':>10} | {'ì²˜ë¦¬ëŸ‰(tok/s)':>14}")
print("-" * 60)
print(f"{'Static Batching':<25} | {static_total_time:>10.3f} | {static_throughput:>14.1f}")
print(f"{'Continuous Batching':<25} | {cont_total_time:>10.3f} | {cont_throughput:>14.1f}")
print("-" * 60)
speedup = cont_throughput / static_throughput
print(f"{'Continuous ì²˜ë¦¬ëŸ‰ í–¥ìƒ':<25} | {'':>10} | {speedup:>13.2f}x")
print("=" * 60)

print(f"\nì´ ìš”ì²­ ìˆ˜: {num_requests}")
print(f"ì´ ìƒì„± í† í°: {sum(output_lengths)}")
print(f"ì¶œë ¥ ê¸¸ì´ ë²”ìœ„: {min(output_lengths)} ~ {max(output_lengths)} í† í°")
print(f"\nStatic Batchingì€ ë°°ì¹˜ ë‚´ ê°€ì¥ ê¸´ ìš”ì²­ ì™„ë£Œê¹Œì§€ ëŒ€ê¸° â†’ GPU ë‚­ë¹„ ë°œìƒ")
print(f"Continuous Batchingì€ ì™„ë£Œ ìŠ¬ë¡¯ì— ì¦‰ì‹œ ìƒˆ ìš”ì²­ ì‚½ì… â†’ GPU í™œìš©ë¥  ê·¹ëŒ€í™”")"""))

# â”€â”€ Cell 10: Static vs Continuous Visualization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ Static vs Continuous Batching íƒ€ì„ë¼ì¸ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
np.random.seed(42)

batch_size = 4
requests = [
    {"id": "R1", "len": 30},
    {"id": "R2", "len": 80},
    {"id": "R3", "len": 15},
    {"id": "R4", "len": 60},
    {"id": "R5", "len": 25},
    {"id": "R6", "len": 45},
    {"id": "R7", "len": 70},
    {"id": "R8", "len": 20},
]

colors = plt.cm.Set3(np.linspace(0, 1, len(requests)))

fig, axes = plt.subplots(2, 1, figsize=(14, 6))

# --- Static Batching Timeline ---
ax1 = axes[0]
ax1.set_title('Static Batching (ë°°ì¹˜ ë‹¨ìœ„ ëŒ€ê¸°)', fontweight='bold', fontsize=12)
time_offset = 0
for batch_start in range(0, len(requests), batch_size):
    batch = requests[batch_start:batch_start + batch_size]
    max_len = max(r["len"] for r in batch)
    for slot_i, r in enumerate(batch):
        ax1.barh(slot_i, r["len"], left=time_offset, height=0.6,
                 color=colors[batch_start + slot_i], edgecolor='black', linewidth=0.5)
        ax1.barh(slot_i, max_len - r["len"], left=time_offset + r["len"],
                 height=0.6, color='lightgray', edgecolor='black',
                 linewidth=0.5, alpha=0.4, hatch='//')
        ax1.text(time_offset + r["len"]/2, slot_i, r["id"],
                 ha='center', va='center', fontsize=8, fontweight='bold')
    time_offset += max_len
ax1.set_xlabel('í† í° ìƒì„± ìŠ¤í…', fontsize=11)
ax1.set_ylabel('GPU ìŠ¬ë¡¯', fontsize=11)
ax1.set_yticks(range(batch_size))
ax1.axvline(x=80, color='red', ls='--', lw=1, alpha=0.5)
ax1.legend(['ìœ íœ´ êµ¬ê°„ (íšŒìƒ‰)'], fontsize=9, loc='upper right')
ax1.grid(True, alpha=0.3, axis='x')

# --- Continuous Batching Timeline ---
ax2 = axes[1]
ax2.set_title('Continuous Batching (ì¦‰ì‹œ ìŠ¬ë¡¯ ì¬ì‚¬ìš©)', fontweight='bold', fontsize=12)
slots = [0] * batch_size
slot_assignments = []
queue = list(range(len(requests)))
time_cursor = [0] * batch_size

for slot_i in range(min(batch_size, len(queue))):
    req_idx = queue.pop(0)
    r = requests[req_idx]
    start = slots[slot_i]
    end = start + r["len"]
    slot_assignments.append((slot_i, start, r["len"], req_idx))
    slots[slot_i] = end

while queue:
    earliest_slot = int(np.argmin(slots))
    req_idx = queue.pop(0)
    r = requests[req_idx]
    start = slots[earliest_slot]
    end = start + r["len"]
    slot_assignments.append((earliest_slot, start, r["len"], req_idx))
    slots[earliest_slot] = end

for (slot_i, start, length, req_idx) in slot_assignments:
    ax2.barh(slot_i, length, left=start, height=0.6,
             color=colors[req_idx], edgecolor='black', linewidth=0.5)
    ax2.text(start + length/2, slot_i, requests[req_idx]["id"],
             ha='center', va='center', fontsize=8, fontweight='bold')

ax2.set_xlabel('í† í° ìƒì„± ìŠ¤í…', fontsize=11)
ax2.set_ylabel('GPU ìŠ¬ë¡¯', fontsize=11)
ax2.set_yticks(range(batch_size))
ax2.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('chapter14_extreme_inference/batching_comparison.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/batching_comparison.png")

static_time = 0
for batch_start in range(0, len(requests), batch_size):
    batch = requests[batch_start:batch_start + batch_size]
    static_time += max(r["len"] for r in batch)
cont_time = max(slots)
total_tokens = sum(r["len"] for r in requests)

print(f"\nStatic ì´ ì‹œê°„: {static_time} ìŠ¤í…")
print(f"Continuous ì´ ì‹œê°„: {cont_time} ìŠ¤í…")
print(f"ì´ í† í°: {total_tokens}")
print(f"ì²˜ë¦¬ëŸ‰ í–¥ìƒ: {static_time/cont_time:.2f}x")"""))

# â”€â”€ Cell 11: Section 4 Markdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 4. ë©”ëª¨ë¦¬ ë‹¨í¸í™” ì‹œê°í™” <a name='4.-ë©”ëª¨ë¦¬-ë‹¨í¸í™”'></a>

### ë‚´ë¶€ ë‹¨í¸í™” (Internal Fragmentation)

ë¸”ë¡ í¬ê¸° $B_{tok}$ë¡œ ë‚˜ëˆ„ì–´ ë–¨ì–´ì§€ì§€ ì•ŠëŠ” ì‹œí€€ìŠ¤ì—ì„œ ë§ˆì§€ë§‰ ë¸”ë¡ì— ë¹ˆ ìŠ¬ë¡¯ì´ ë°œìƒí•©ë‹ˆë‹¤:

$$W_{internal}(S) = (B_{tok} - S \bmod B_{tok}) \bmod B_{tok}$$

### ì™¸ë¶€ ë‹¨í¸í™” (External Fragmentation)

ì „í†µ ì—°ì† í• ë‹¹ì—ì„œëŠ” ë¹ˆ ê³µê°„ì´ ìˆì–´ë„ **ì—°ì† ê³µê°„**ì´ ë¶€ì¡±í•˜ë©´ í• ë‹¹ì— ì‹¤íŒ¨í•©ë‹ˆë‹¤.
PagedAttentionì€ ë¹„ì—°ì† í• ë‹¹ì´ë¯€ë¡œ **ì™¸ë¶€ ë‹¨í¸í™”ê°€ 0**ì…ë‹ˆë‹¤."""))

# â”€â”€ Cell 12: Fragmentation Visualization Code â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë¹„êµ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
block_sizes = [4, 8, 16, 32, 64]
np.random.seed(42)
num_samples = 500
seq_lengths = np.random.exponential(scale=80, size=num_samples).astype(int) + 1

results = {}
for bs in block_sizes:
    internal_waste = [(bs - s % bs) % bs for s in seq_lengths]
    waste_ratio = [w / bs for w in internal_waste]
    avg_waste = np.mean(internal_waste)
    avg_ratio = np.mean(waste_ratio)
    results[bs] = {
        "avg_waste": avg_waste,
        "avg_ratio": avg_ratio,
        "waste_dist": internal_waste,
    }

print(f"{'ë¸”ë¡ í¬ê¸°':<12} | {'í‰ê·  ë‚­ë¹„(ìŠ¬ë¡¯)':>14} | {'í‰ê·  ë‚­ë¹„ ë¹„ìœ¨':>14} | {'ìµœëŒ€ ë‚­ë¹„':>10}")
print("-" * 58)
for bs in block_sizes:
    r = results[bs]
    print(f"{bs:<12} | {r['avg_waste']:>14.2f} | {r['avg_ratio']:>13.1%} | {bs-1:>10}")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ì™¼ìª½: ë¸”ë¡ í¬ê¸°ë³„ ë‚´ë¶€ ë‹¨í¸í™”
ax1 = axes[0]
avg_wastes = [results[bs]["avg_waste"] for bs in block_sizes]
avg_ratios = [results[bs]["avg_ratio"] * 100 for bs in block_sizes]
x = np.arange(len(block_sizes))
bars = ax1.bar(x, avg_wastes, color='coral', edgecolor='black', alpha=0.8, width=0.5)
ax1.set_xlabel('ë¸”ë¡ í¬ê¸° (tokens)', fontsize=11)
ax1.set_ylabel('í‰ê·  ë‚´ë¶€ ë‹¨í¸í™” (ìŠ¬ë¡¯)', fontsize=11)
ax1.set_title('ë¸”ë¡ í¬ê¸°ë³„ ë‚´ë¶€ ë‹¨í¸í™”', fontweight='bold')
ax1.set_xticks(x)
ax1.set_xticklabels(block_sizes)
ax1.grid(True, alpha=0.3, axis='y')
for i, (w, r) in enumerate(zip(avg_wastes, avg_ratios)):
    ax1.text(i, w + 0.5, f'{r:.1f}%', ha='center', fontsize=9, fontweight='bold')

# ì˜¤ë¥¸ìª½: Traditional vs PagedAttention ë¹„êµ
ax2 = axes[1]
traditional_waste = []
paged_waste = []
max_seq = max(seq_lengths)

for n_req in [10, 50, 100, 200, 500]:
    sample = seq_lengths[:n_req]
    trad_total = n_req * max_seq
    trad_used = sum(sample)
    trad_waste_pct = (1 - trad_used / trad_total) * 100
    traditional_waste.append(trad_waste_pct)

    bs = 16
    paged_blocks = sum(int(np.ceil(s / bs)) for s in sample)
    paged_total = paged_blocks * bs
    paged_used = sum(sample)
    paged_waste_pct = (1 - paged_used / paged_total) * 100
    paged_waste.append(paged_waste_pct)

n_reqs = [10, 50, 100, 200, 500]
x2 = np.arange(len(n_reqs))
width = 0.35
ax2.bar(x2 - width/2, traditional_waste, width, label='Traditional (ì—°ì† í• ë‹¹)',
        color='salmon', edgecolor='black', alpha=0.8)
ax2.bar(x2 + width/2, paged_waste, width, label='PagedAttention (ë¸”ë¡ í• ë‹¹)',
        color='skyblue', edgecolor='black', alpha=0.8)
ax2.set_xlabel('ë™ì‹œ ìš”ì²­ ìˆ˜', fontsize=11)
ax2.set_ylabel('ë©”ëª¨ë¦¬ ë‚­ë¹„ ë¹„ìœ¨ (%)', fontsize=11)
ax2.set_title('Traditional vs PagedAttention ë©”ëª¨ë¦¬ ë‚­ë¹„', fontweight='bold')
ax2.set_xticks(x2)
ax2.set_xticklabels(n_reqs)
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('chapter14_extreme_inference/fragmentation_comparison.png', dpi=100, bbox_inches='tight')
plt.close()
print("\nê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/fragmentation_comparison.png")

print(f"\nì „í†µ ë°©ì‹: max_seq={max_seq}ë¡œ ê³ ì • í• ë‹¹ â†’ í‰ê·  {np.mean(traditional_waste):.1f}% ë‚­ë¹„")
print(f"PagedAttention(B=16): ë¸”ë¡ ë‹¨ìœ„ í• ë‹¹ â†’ í‰ê·  {np.mean(paged_waste):.1f}% ë‚­ë¹„")
print(f"ì ˆì•½ íš¨ê³¼: {np.mean(traditional_waste) - np.mean(paged_waste):.1f}%p ë©”ëª¨ë¦¬ ì ˆì•½")"""))

# â”€â”€ Cell 13: KV Block Scheduling Simulation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code(r"""# â”€â”€ ë™ì  KV Block ìŠ¤ì¼€ì¤„ë§ ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# vLLMì˜ ë™ì  ë¸”ë¡ í• ë‹¹/í•´ì œë¥¼ ì‹œê°„ì¶•ìœ¼ë¡œ ì¶”ì í•©ë‹ˆë‹¤

class VLLMScheduler:
    def __init__(self, total_blocks, block_size):
        self.total_blocks = total_blocks
        self.block_size = block_size
        self.free_count = total_blocks
        self.requests = {}
        self.history = []

    def step(self, time, arrivals=None, completions=None):
        if completions:
            for req_id in completions:
                if req_id in self.requests:
                    freed = self.requests.pop(req_id)
                    self.free_count += freed

        if arrivals:
            for req_id, seq_len in arrivals:
                needed = int(np.ceil(seq_len / self.block_size))
                if needed <= self.free_count:
                    self.requests[req_id] = needed
                    self.free_count -= needed

        self.history.append({
            "time": time,
            "used_blocks": self.total_blocks - self.free_count,
            "free_blocks": self.free_count,
            "active_requests": len(self.requests),
        })

scheduler = VLLMScheduler(total_blocks=64, block_size=16)

events = [
    (0,  [("R1", 120), ("R2", 80)], []),
    (1,  [("R3", 200)], []),
    (2,  [("R4", 50)], ["R2"]),
    (3,  [("R5", 150)], []),
    (4,  [], ["R1"]),
    (5,  [("R6", 100), ("R7", 60)], ["R4"]),
    (6,  [], ["R3"]),
    (7,  [("R8", 180)], []),
    (8,  [], ["R5", "R6"]),
    (9,  [], ["R7", "R8"]),
]

print("=== vLLM ë™ì  KV Block ìŠ¤ì¼€ì¤„ë§ ===\n")
print(f"{'ì‹œê°„':>4} | {'ë„ì°©':>20} | {'ì™„ë£Œ':>15} | {'ì‚¬ìš©ë¸”ë¡':>8} | {'ê°€ìš©ë¸”ë¡':>8} | {'í™œì„±ìš”ì²­':>8}")
print("-" * 80)

for time, arrivals, completions in events:
    scheduler.step(time, arrivals, completions)
    h = scheduler.history[-1]
    arr_str = ",".join(f"{a[0]}({a[1]})" for a in arrivals) if arrivals else "-"
    comp_str = ",".join(completions) if completions else "-"
    print(f"{time:>4} | {arr_str:>20} | {comp_str:>15} | "
          f"{h['used_blocks']:>8} | {h['free_blocks']:>8} | {h['active_requests']:>8}")

times = [h["time"] for h in scheduler.history]
used = [h["used_blocks"] for h in scheduler.history]
free = [h["free_blocks"] for h in scheduler.history]
active = [h["active_requests"] for h in scheduler.history]

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

ax1 = axes[0]
ax1.fill_between(times, 0, used, alpha=0.6, color='coral', label='ì‚¬ìš© ë¸”ë¡')
ax1.fill_between(times, used, [u+f for u, f in zip(used, free)],
                 alpha=0.4, color='lightgreen', label='ê°€ìš© ë¸”ë¡')
ax1.set_xlabel('ì‹œê°„ ìŠ¤í…', fontsize=11)
ax1.set_ylabel('ë¸”ë¡ ìˆ˜', fontsize=11)
ax1.set_title('KV Block ì‚¬ìš©ëŸ‰ ë³€í™”', fontweight='bold')
ax1.legend(fontsize=9)
ax1.grid(True, alpha=0.3)
ax1.set_ylim(0, 70)

ax2 = axes[1]
ax2.plot(times, active, 'b-o', lw=2, ms=7, label='í™œì„± ìš”ì²­ ìˆ˜')
ax2.fill_between(times, 0, active, alpha=0.15, color='blue')
ax2.set_xlabel('ì‹œê°„ ìŠ¤í…', fontsize=11)
ax2.set_ylabel('í™œì„± ìš”ì²­ ìˆ˜', fontsize=11)
ax2.set_title('í™œì„± ìš”ì²­ ìˆ˜ ë³€í™”', fontweight='bold')
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter14_extreme_inference/kv_block_scheduling.png', dpi=100, bbox_inches='tight')
plt.close()
print("\nê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/kv_block_scheduling.png")
print(f"\nìµœëŒ€ ë¸”ë¡ ì‚¬ìš©: {max(used)}/{scheduler.total_blocks} "
      f"({max(used)/scheduler.total_blocks*100:.1f}%)")
print(f"ìµœëŒ€ í™œì„± ìš”ì²­: {max(active)}ê°œ")"""))

# â”€â”€ Cell 14: Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""## 5. ì •ë¦¬ <a name='5.-ì •ë¦¬'></a>

### í•µì‹¬ ê°œë… ìš”ì•½

| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |
|------|------|--------|
| PagedAttention | OS í˜ì´ì§€ í…Œì´ë¸” ë°©ì‹ìœ¼ë¡œ KV Cacheë¥¼ ë¹„ì—°ì† ë¸”ë¡ì— ì €ì¥ | â­â­â­ |
| ê°€ìƒ/ë¬¼ë¦¬ ë¸”ë¡ ë§¤í•‘ | VirtualBlock â†’ PhysicalBlock í˜ì´ì§€ í…Œì´ë¸” | â­â­â­ |
| ë‚´ë¶€ ë‹¨í¸í™” | ë§ˆì§€ë§‰ ë¸”ë¡ì˜ ë¯¸ì‚¬ìš© ìŠ¬ë¡¯ (ìœ ì¼í•œ ë‚­ë¹„) | â­â­ |
| ì™¸ë¶€ ë‹¨í¸í™” ì œê±° | ë¹„ì—°ì† í• ë‹¹ìœ¼ë¡œ ì™¸ë¶€ ë‹¨í¸í™” = 0 | â­â­â­ |
| Continuous Batching | ì™„ë£Œ ìŠ¬ë¡¯ì— ì¦‰ì‹œ ìƒˆ ìš”ì²­ ì‚½ì… | â­â­â­ |
| ë™ì  KV ìŠ¤ì¼€ì¤„ë§ | ë¸”ë¡ í• ë‹¹/í•´ì œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê´€ë¦¬ | â­â­ |
| Copy-on-Write | ê³µìœ  ë¸”ë¡ì„ ìˆ˜ì • ì‹œì—ë§Œ ë³µì‚¬ | â­â­ |

### í•µì‹¬ ìˆ˜ì‹

$$\text{PageTable}: \text{VBlock}[i] \rightarrow \text{PBlock}[j] \quad \text{(ë¹„ì—°ì† í• ë‹¹)}$$

$$W_{internal} = (B_{tok} - S \bmod B_{tok}) \bmod B_{tok} \quad \text{(ë‚´ë¶€ ë‹¨í¸í™”)}$$

$$\text{Savings} = 1 - \frac{\sum_r \lceil S_r / B_{tok} \rceil \cdot B_{tok}}{R \cdot S_{max}} \quad \text{(ë©”ëª¨ë¦¬ ì ˆì•½ë¥ )}$$

### ì°¸ê³  ë…¼ë¬¸
- Kwon et al., "Efficient Memory Management for Large Language Model Serving with PagedAttention" (arxiv 2309.06180)
- vLLM ê³µì‹ ë¬¸ì„œ: https://docs.vllm.ai

### ë‹¤ìŒ ì±•í„° ì˜ˆê³ 
**Chapter 14-05: ì–‘ìí™” ì‹¬í™” (GPTQ & AWQ)** â€” PTQ ê¸°ì´ˆë¶€í„° Hessian ê¸°ë°˜ GPTQ, Activation-aware AWQê¹Œì§€ ì–‘ìí™” ê¸°ë²•ì„ ìˆ˜ì‹ìœ¼ë¡œ ë„ì¶œí•˜ê³  W4A16/INT8/FP8 ë²¤ì¹˜ë§ˆí¬ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."""))

path = '/workspace/chapter14_extreme_inference/04_vllm_and_paged_attention.ipynb'
create_notebook(cells, path)
