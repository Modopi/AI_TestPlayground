"""Generate Chapter 12-02: KV Cache and Memory."""
import sys, os
sys.path.insert(0, os.path.dirname(__file__))
from nb_helper import md, code, create_notebook

cells = [
# â”€â”€â”€ Cell 0: í—¤ë” â”€â”€â”€
md("""# Chapter 12: ìµœì‹  LLM ì•„í‚¤í…ì²˜ â€” KV Cacheì™€ ë©”ëª¨ë¦¬ ê´€ë¦¬

## í•™ìŠµ ëª©í‘œ
- Autoregressive ìƒì„±ì—ì„œ **KV Cacheì˜ ì—­í• ê³¼ ë©”ëª¨ë¦¬ ê³µì‹**ì„ ì •í™•íˆ ì´í•´í•˜ê³  ê³„ì‚°í•œë‹¤
- Llama 3 8B ì‹¤ì œ íŒŒë¼ë¯¸í„°ë¡œ **ë°°ì¹˜/ì‹œí€€ìŠ¤ë³„ KV ìºì‹œ ë©”ëª¨ë¦¬**ë¥¼ ê³„ì‚°í•œë‹¤
- **Rolling Buffer**(Sliding Window) ë°©ì‹ìœ¼ë¡œ ê³ ì • ë©”ëª¨ë¦¬ KV ê´€ë¦¬ë¥¼ êµ¬í˜„í•œë‹¤
- **Multi-Turn ëŒ€í™”**ì—ì„œ KV ìºì‹œ ë©”ëª¨ë¦¬ ì¦ê°€ íŒ¨í„´ì„ ì‹œê°í™”í•˜ê³  ë¶„ì„í•œë‹¤
- **Prefix Caching** ê°œìš”ì™€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¬ì‚¬ìš© ì´ì ì„ ì´í•´í•œë‹¤

## ëª©ì°¨
1. [ìˆ˜í•™ì  ê¸°ì´ˆ: KV Cache ë©”ëª¨ë¦¬ ê³µì‹](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)
2. [Autoregressive ìƒì„±ê³¼ KV Cache](#2.-KV-Cache-ì›ë¦¬)
3. [Rolling Buffer (Sliding Window)](#3.-Rolling-Buffer)
4. [Multi-Turn ëŒ€í™” ë©”ëª¨ë¦¬ ë¶„ì„](#4.-Multi-Turn-ë¶„ì„)
5. [Prefix Caching ì‹œë®¬ë ˆì´ì…˜](#5.-Prefix-Caching)
6. [ì •ë¦¬](#6.-ì •ë¦¬)"""),

# â”€â”€â”€ Cell 1: ìˆ˜í•™ì  ê¸°ì´ˆ â”€â”€â”€
md(r"""## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>

### KV Cache ë©”ëª¨ë¦¬ ê³µì‹

Autoregressive ë””ì½”ë”©ì—ì„œ ë§¤ í† í° ìƒì„± ì‹œ ì´ì „ í† í°ë“¤ì˜ K, Vë¥¼ **ì¬ê³„ì‚°í•˜ì§€ ì•Šê³  ìºì‹œ**í•©ë‹ˆë‹¤:

$$M_{KV} = 2 \times L \times H_{kv} \times d_{head} \times S \times B \times \text{bytes\_per\_element}$$

- $2$: Kì™€ V ë‘ í…ì„œ
- $L$: ë ˆì´ì–´(ë¸”ë¡) ìˆ˜
- $H_{kv}$: KV í—¤ë“œ ìˆ˜ (GQAì—ì„œ Q í—¤ë“œë³´ë‹¤ ì ìŒ)
- $d_{head}$: í—¤ë“œ ì°¨ì›
- $S$: í˜„ì¬ê¹Œì§€ ìƒì„±ëœ ì‹œí€€ìŠ¤ ê¸¸ì´
- $B$: ë°°ì¹˜ í¬ê¸°
- bytes: FP16=2, FP32=4, INT8=1

**Llama 3 8B ì˜ˆì‹œ ($L=32, H_{kv}=8, d_{head}=128$, FP16):**

| ì‹œí€€ìŠ¤ ê¸¸ì´ | ë°°ì¹˜=1 | ë°°ì¹˜=8 | ë°°ì¹˜=32 |
|------------|--------|--------|---------|
| $S=512$ | 64 MB | 512 MB | 2.0 GB |
| $S=2048$ | 256 MB | 2.0 GB | 8.0 GB |
| $S=8192$ | 1.0 GB | 8.0 GB | 32 GB |

### KV Cache ì—†ì´ vs ìˆì„ ë•Œ ë³µì¡ë„

| í•­ëª© | Cache ì—†ìŒ | Cache ìˆìŒ |
|------|-----------|-----------|
| í† í°ë‹¹ K,V ê³„ì‚° | $O(S \cdot d)$ ì „ì²´ ì¬ê³„ì‚° | $O(d)$ ìƒˆ í† í°ë§Œ |
| Attention FLOPs | $O(S^2 \cdot d)$ ë§¤ë²ˆ | $O(S \cdot d)$ ìƒˆ Që§Œ |
| ì¶”ê°€ ë©”ëª¨ë¦¬ | ì—†ìŒ | $O(L \cdot H_{kv} \cdot d \cdot S)$ |
| ì´ ìƒì„± FLOPs ($T$í† í°) | $O(T \cdot S^2 \cdot d)$ | $O(T \cdot S \cdot d)$ |

---

### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ KV Cache ì¹œì ˆ ì„¤ëª…!

#### ğŸ“ KV Cacheê°€ ë­”ê°€ìš”?

> ğŸ’¡ **ë¹„ìœ **: ìˆ˜í•™ ì‹œí—˜ì—ì„œ **ì• ë¬¸ì œì˜ í’€ì´ë¥¼ ë©”ëª¨ì¥ì— ì ì–´ë‘ëŠ” ê²ƒ**ê³¼ ê°™ì•„ìš”!
> 
> AIê°€ ê¸€ì„ ì“¸ ë•Œ, "ë‚˜ëŠ” ì˜¤ëŠ˜ í•™êµì—..."ê¹Œì§€ ì“°ê³  ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë ¤ë©´ ì• ë‹¨ì–´ë“¤ì˜ ì •ë³´(K,V)ê°€ í•„ìš”í•´ìš”.
> **ë©”ëª¨ì¥ ì—†ìœ¼ë©´**: ë§¤ë²ˆ ì• ë‹¨ì–´ë“¤ì„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ê³„ì‚° â†’ ëŠë¦¼! ğŸ¢
> **ë©”ëª¨ì¥ ìˆìœ¼ë©´**: ì´ì „ ê³„ì‚°ì„ ê¸°ì–µí•˜ê³  ìƒˆ ë‹¨ì–´ë§Œ ì¶”ê°€ ê³„ì‚° â†’ ë¹ ë¦„! ğŸš€

| ìƒí™© | ë¹„ìœ  | ì†ë„ |
|------|------|------|
| Cache ì—†ìŒ | ë§¤ë²ˆ 1ë²ˆ ë¬¸ì œë¶€í„° ë‹¤ì‹œ í’€ê¸° | ğŸ¢ğŸ¢ğŸ¢ |
| Cache ìˆìŒ | ë©”ëª¨ì¥ ë³´ê³  ë§ˆì§€ë§‰ ë¬¸ì œë§Œ í’€ê¸° | ğŸš€ |
| ë©”ëª¨ì¥ì´ ê½‰ ì°¸ | ì˜¤ë˜ëœ ë©”ëª¨ ì§€ìš°ê¸° (Rolling Buffer) | ğŸš€ (ê³ ì • ë©”ëª¨ë¦¬) |"""),

# â”€â”€â”€ Cell 2: ğŸ“ ì—°ìŠµ ë¬¸ì œ â”€â”€â”€
md(r"""---

### ğŸ“ ì—°ìŠµ ë¬¸ì œ

#### ë¬¸ì œ 1: KV Cache ë©”ëª¨ë¦¬ ê³„ì‚°

Llama 3 8B ($L=32, H_{kv}=8, d_{head}=128$)ì—ì„œ ë°°ì¹˜ í¬ê¸° $B=4$, ì‹œí€€ìŠ¤ ê¸¸ì´ $S=4096$ì¼ ë•Œ FP16 KV ìºì‹œ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ì‹œì˜¤.

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$$M_{KV} = 2 \times 32 \times 8 \times 128 \times 4096 \times 4 \times 2 \text{ bytes}$$
$$= 2 \times 32 \times 8 \times 128 \times 4096 \times 4 \times 2$$
$$= 2,147,483,648 \text{ bytes} = 2.0 \text{ GB}$$

ë°°ì¹˜ 1 ê¸°ì¤€ 512 MB Ã— ë°°ì¹˜ 4 = 2.0 GB
</details>

#### ë¬¸ì œ 2: GQA vs MHA KV Cache ë¹„êµ

ë™ì¼ ëª¨ë¸ì—ì„œ MHA($H_{kv}=32$)ë¥¼ ì‚¬ìš©í–ˆë‹¤ë©´ KV CacheëŠ” ëª‡ GBì¸ê°€? GQA ëŒ€ë¹„ ëª‡ ë°°ì¸ê°€?

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$$M_{MHA} = 2 \times 32 \times 32 \times 128 \times 4096 \times 4 \times 2 = 8.0 \text{ GB}$$

$$\frac{M_{MHA}}{M_{GQA}} = \frac{32}{8} = 4\text{ë°°}$$

GQA($H_{kv}=8$)ê°€ MHA($H_{kv}=32$) ëŒ€ë¹„ **KV ë©”ëª¨ë¦¬ 75% ì ˆê°!**
</details>"""),

# â”€â”€â”€ Cell 3: ì„í¬íŠ¸ â”€â”€â”€
code("""import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import tensorflow as tf
import time

np.random.seed(42)
tf.random.set_seed(42)
print(f"TensorFlow ë²„ì „: {tf.__version__}")"""),

# â”€â”€â”€ Cell 4: ì„¹ì…˜2 â”€â”€â”€
md("""## 2. Autoregressive ìƒì„±ê³¼ KV Cache <a name='2.-KV-Cache-ì›ë¦¬'></a>"""),

# â”€â”€â”€ Cell 5: KV Cache ì›ë¦¬ êµ¬í˜„ â”€â”€â”€
code(r"""# â”€â”€ KV Cache ìˆ/ì—†ì´ Autoregressive ìƒì„± ë¹„êµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê°„ë‹¨í•œ Attention ì—°ì‚°ì—ì„œ KV Cacheì˜ íš¨ê³¼ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤

d_model = 256
n_heads = 8
d_head = d_model // n_heads
seq_len = 64
gen_len = 32  # ìƒì„±í•  í† í° ìˆ˜

# ëœë¤ ê°€ì¤‘ì¹˜ (ë°ëª¨ìš©)
Wq = tf.random.normal((d_model, d_model))
Wk = tf.random.normal((d_model, d_model))
Wv = tf.random.normal((d_model, d_model))

# === ë°©ë²• 1: KV Cache ì—†ì´ (ë§¤ë²ˆ ì „ì²´ ì¬ê³„ì‚°) ===
def generate_no_cache(prompt, gen_len):
    tokens = tf.identity(prompt)  # [1, prompt_len, d]
    flops_total = 0
    for step in range(gen_len):
        S = tokens.shape[1]
        Q = tokens @ Wq  # ì „ì²´ ì‹œí€€ìŠ¤ Q
        K = tokens @ Wk  # ì „ì²´ ì‹œí€€ìŠ¤ K (ë§¤ë²ˆ ì¬ê³„ì‚°!)
        V = tokens @ Wv  # ì „ì²´ ì‹œí€€ìŠ¤ V (ë§¤ë²ˆ ì¬ê³„ì‚°!)
        attn = tf.nn.softmax(Q @ tf.transpose(K, [0, 2, 1]) / tf.sqrt(float(d_model)))
        out = attn @ V
        new_token = out[:, -1:, :]  # ë§ˆì§€ë§‰ í† í°ì˜ ì¶œë ¥
        tokens = tf.concat([tokens, new_token], axis=1)
        flops_total += S * S * d_model * 2  # ëŒ€ëµì  FLOPs
    return tokens, flops_total

# === ë°©ë²• 2: KV Cache ì‚¬ìš© ===
def generate_with_cache(prompt, gen_len):
    B = prompt.shape[0]
    # í”„ë¡¬í”„íŠ¸ K,V ë¯¸ë¦¬ ê³„ì‚° (Prefill)
    k_cache = prompt @ Wk  # [1, prompt_len, d]
    v_cache = prompt @ Wv
    tokens = tf.identity(prompt)
    flops_total = 0
    for step in range(gen_len):
        # ìƒˆ í† í°ì˜ Që§Œ ê³„ì‚°
        q_new = tokens[:, -1:, :] @ Wq  # [1, 1, d]
        k_new = tokens[:, -1:, :] @ Wk  # [1, 1, d]
        v_new = tokens[:, -1:, :] @ Wv
        # ìºì‹œì— ì¶”ê°€
        k_cache = tf.concat([k_cache, k_new], axis=1)
        v_cache = tf.concat([v_cache, v_new], axis=1)
        S = k_cache.shape[1]
        # Attention: ìƒˆ Q Ã— ì „ì²´ cached K
        attn = tf.nn.softmax(q_new @ tf.transpose(k_cache, [0, 2, 1]) / tf.sqrt(float(d_model)))
        out = attn @ v_cache  # [1, 1, d]
        tokens = tf.concat([tokens, out], axis=1)
        flops_total += S * d_model * 2  # SÃ—d (ìºì‹œ ë°©ì‹: S^2 â†’ S)
    return tokens, flops_total

prompt = tf.random.normal((1, seq_len, d_model))

# ì›Œë°ì—…
_, _ = generate_no_cache(prompt, 2)
_, _ = generate_with_cache(prompt, 2)

# ë²¤ì¹˜ë§ˆí¬
start = time.perf_counter()
_, flops_no = generate_no_cache(prompt, gen_len)
time_no = time.perf_counter() - start

start = time.perf_counter()
_, flops_with = generate_with_cache(prompt, gen_len)
time_with = time.perf_counter() - start

print("=" * 60)
print(f"Autoregressive ìƒì„± ë¹„êµ (í”„ë¡¬í”„íŠ¸={seq_len}, ìƒì„±={gen_len}í† í°)")
print("=" * 60)
print(f"{'ë°©ë²•':<25} | {'ì‹œê°„ (ms)':>12} | {'ëŒ€ëµ FLOPs':>15}")
print("-" * 60)
print(f"{'KV Cache ì—†ìŒ':<25} | {time_no*1000:>12.1f} | {flops_no:>15,}")
print(f"{'KV Cache ìˆìŒ':<25} | {time_with*1000:>12.1f} | {flops_with:>15,}")
print(f"{'ì†ë„ í–¥ìƒ':<25} | {time_no/time_with:>11.1f}x | {flops_no/flops_with:>14.1f}x")
print()
print("KV Cacheë¡œ ì—°ì‚°ëŸ‰ ëŒ€í­ ê°ì†Œ: ë§¤ ìŠ¤í… O(S^2) â†’ O(S)")"""),

# â”€â”€â”€ Cell 6: KV Cache ë©”ëª¨ë¦¬ ê³„ì‚° â”€â”€â”€
code(r"""# â”€â”€ Llama 3 8B KV Cache ë©”ëª¨ë¦¬ ê³„ì‚°ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤ì œ Llama 3 8B íŒŒë¼ë¯¸í„°ë¡œ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì˜ ë©”ëª¨ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤

def kv_cache_memory_bytes(n_layers, n_kv_heads, d_head, seq_len, batch_size, dtype_bytes=2):
    return 2 * n_layers * n_kv_heads * d_head * seq_len * batch_size * dtype_bytes

# Llama 3 8B íŒŒë¼ë¯¸í„°
L, H_kv, d_h = 32, 8, 128

print("=" * 70)
print("Llama 3 8B KV Cache ë©”ëª¨ë¦¬ ê³„ì‚° (FP16)")
print(f"  L={L}, H_kv={H_kv}, d_head={d_h}")
print("=" * 70)

seq_lengths = [512, 1024, 2048, 4096, 8192]
batch_sizes = [1, 4, 8, 16, 32]

# í‘œ í—¤ë”
header = f"{'S \\ B':<8}"
for b in batch_sizes:
    header += f" | {'B='+str(b):>8}"
print(header)
print("-" * (8 + 11 * len(batch_sizes)))

for s in seq_lengths:
    row = f"{s:<8}"
    for b in batch_sizes:
        mem = kv_cache_memory_bytes(L, H_kv, d_h, s, b)
        if mem >= 1e9:
            row += f" | {mem/1e9:>6.1f} GB"
        else:
            row += f" | {mem/1e6:>5.0f} MB "
        
    print(row)

print()
print("âš ï¸ ì£¼ì˜: ëª¨ë¸ ê°€ì¤‘ì¹˜(~16GB FP16) + KV Cache + í™œì„±í™” ë©”ëª¨ë¦¬ í•©ê³„ê°€ GPU VRAMì„ ì´ˆê³¼í•˜ë©´ OOM!")
print()

# 80GB A100 ì˜ˆì‹œ
model_weights_gb = 16  # Llama 3 8B FP16
vram_gb = 80
available_kv = vram_gb - model_weights_gb - 5  # 5GB ì—¬ìœ 

print(f"A100 80GB ê¸°ì¤€ ê°€ìš© KV ë©”ëª¨ë¦¬: ~{available_kv} GB")
max_batch_4096 = int(available_kv * 1e9 / kv_cache_memory_bytes(L, H_kv, d_h, 4096, 1))
print(f"  S=4096ì—ì„œ ìµœëŒ€ ë°°ì¹˜: ~{max_batch_4096}")
max_batch_8192 = int(available_kv * 1e9 / kv_cache_memory_bytes(L, H_kv, d_h, 8192, 1))
print(f"  S=8192ì—ì„œ ìµœëŒ€ ë°°ì¹˜: ~{max_batch_8192}")"""),

# â”€â”€â”€ Cell 7: ì„¹ì…˜3 â”€â”€â”€
md("""## 3. Rolling Buffer (Sliding Window) <a name='3.-Rolling-Buffer'></a>"""),

# â”€â”€â”€ Cell 8: Rolling Buffer êµ¬í˜„ â”€â”€â”€
code(r"""# â”€â”€ Rolling Buffer KV Cache êµ¬í˜„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³ ì • í¬ê¸° ë²„í¼ë¡œ ë©”ëª¨ë¦¬ë¥¼ ì œí•œí•˜ë©´ì„œ ìµœê·¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤

class RollingKVCache:
    # ê³ ì • í¬ê¸° Rolling Buffer KV Cache (Mistral ìŠ¤íƒ€ì¼)
    def __init__(self, max_size, d_model, n_layers=1):
        self.max_size = max_size
        self.d_model = d_model
        self.n_layers = n_layers
        # [n_layers, 2(K,V), max_size, d_model]
        self.buffer = np.zeros((n_layers, 2, max_size, d_model))
        self.write_pos = 0  # ë‹¤ìŒ ì“°ê¸° ìœ„ì¹˜ (circular)
        self.length = 0     # í˜„ì¬ ì €ì¥ëœ í† í° ìˆ˜

    def update(self, k_new, v_new, layer=0):
        # k_new, v_new: [1, d_model]
        pos = self.write_pos % self.max_size  # ìˆœí™˜ ìœ„ì¹˜
        self.buffer[layer, 0, pos] = k_new
        self.buffer[layer, 1, pos] = v_new
        self.write_pos += 1
        self.length = min(self.length + 1, self.max_size)
        return pos

    def get_kv(self, layer=0):
        # í˜„ì¬ ì €ì¥ëœ K,V ë°˜í™˜ (ìˆœì„œ ë³´ì •)
        if self.length < self.max_size:
            return self.buffer[layer, 0, :self.length], self.buffer[layer, 1, :self.length]
        else:
            # ìˆœí™˜ ë²„í¼: ê°€ì¥ ì˜¤ë˜ëœ ê²ƒë¶€í„° ìˆœì„œëŒ€ë¡œ
            start = self.write_pos % self.max_size
            indices = [(start + i) % self.max_size for i in range(self.max_size)]
            return self.buffer[layer, 0, indices], self.buffer[layer, 1, indices]

    def memory_bytes(self, dtype_bytes=2):
        return self.buffer.nbytes  # ì‹¤ì œ ê³ ì • ë©”ëª¨ë¦¬


# ì‹œë®¬ë ˆì´ì…˜: Rolling Buffer vs ë¬´ì œí•œ ìºì‹œ
d = 128
window_size = 64  # ìµœê·¼ 64 í† í°ë§Œ ìœ ì§€
total_tokens = 200

cache_rolling = RollingKVCache(max_size=window_size, d_model=d)
rolling_memory = []
unlimited_memory = []

for t in range(total_tokens):
    k_new = np.random.randn(d)
    v_new = np.random.randn(d)
    cache_rolling.update(k_new, v_new)
    
    rolling_memory.append(cache_rolling.length * d * 2 * 2)  # K+V, float16
    unlimited_memory.append((t + 1) * d * 2 * 2)

print("=" * 60)
print(f"Rolling Buffer KV Cache ì‹œë®¬ë ˆì´ì…˜ (window={window_size})")
print("=" * 60)
print(f"ì´ ìƒì„± í† í°: {total_tokens}")
print(f"Rolling ìµœì¢… ë©”ëª¨ë¦¬: {rolling_memory[-1]:,} bytes ({rolling_memory[-1]/1024:.1f} KB)")
print(f"ë¬´ì œí•œ ìµœì¢… ë©”ëª¨ë¦¬: {unlimited_memory[-1]:,} bytes ({unlimited_memory[-1]/1024:.1f} KB)")
print(f"ë©”ëª¨ë¦¬ ì ˆê°: {(1 - rolling_memory[-1]/unlimited_memory[-1])*100:.0f}%")
print()

# ì €ì¥ëœ í† í° í™•ì¸
k_stored, v_stored = cache_rolling.get_kv()
print(f"Rolling Buffer ì €ì¥ í† í° ìˆ˜: {len(k_stored)} (ìµœê·¼ {window_size}ê°œë§Œ)")"""),

# â”€â”€â”€ Cell 9: Rolling Buffer ì‹œê°í™” â”€â”€â”€
code(r"""# â”€â”€ Rolling Buffer vs ë¬´ì œí•œ ìºì‹œ ë©”ëª¨ë¦¬ ë¹„êµ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

fig, axes = plt.subplots(1, 2, figsize=(13, 5))

# ì™¼ìª½: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ
ax1 = axes[0]
tokens = np.arange(1, total_tokens + 1)
ax1.plot(tokens, np.array(unlimited_memory) / 1024, 'r-', lw=2.5, label='ë¬´ì œí•œ ìºì‹œ')
ax1.plot(tokens, np.array(rolling_memory) / 1024, 'b-', lw=2.5, label=f'Rolling Buffer (W={window_size})')
ax1.axhline(y=window_size * d * 2 * 2 / 1024, color='blue', ls='--', lw=1.5, alpha=0.5)
ax1.fill_between(tokens, np.array(rolling_memory) / 1024, np.array(unlimited_memory) / 1024,
                  alpha=0.15, color='red', label='ì ˆì•½ëœ ë©”ëª¨ë¦¬')
ax1.set_xlabel('ìƒì„±ëœ í† í° ìˆ˜', fontsize=11)
ax1.set_ylabel('KV Cache ë©”ëª¨ë¦¬ (KB)', fontsize=11)
ax1.set_title('KV Cache ë©”ëª¨ë¦¬ ì¦ê°€ íŒ¨í„´', fontweight='bold')
ax1.legend(fontsize=9)
ax1.grid(True, alpha=0.3)

# ì˜¤ë¥¸ìª½: Rolling Buffer ë™ì‘ ì›ë¦¬ (circular)
ax2 = axes[1]
n_slots = 8  # ì‹œê°í™”ìš© ì‘ì€ ë²„í¼
positions = np.arange(n_slots)
current_write = 5  # í˜„ì¬ ì“°ê¸° ìœ„ì¹˜

colors_slot = ['#43A047' if i < current_write else '#E0E0E0' for i in range(n_slots)]
colors_slot[current_write % n_slots] = '#E53935'  # ë‹¤ìŒ ì“°ê¸° ìœ„ì¹˜

bars = ax2.bar(positions, [1]*n_slots, color=colors_slot, edgecolor='black', lw=1.5)

for i in range(n_slots):
    if i < current_write:
        age = current_write - i
        ax2.text(i, 0.5, f't-{age}', ha='center', va='center', fontsize=9, fontweight='bold')
    elif i == current_write:
        ax2.text(i, 0.5, 'â†’next', ha='center', va='center', fontsize=8, color='white', fontweight='bold')

ax2.set_xlabel('ë²„í¼ ìŠ¬ë¡¯', fontsize=11)
ax2.set_title('Rolling Buffer ìˆœí™˜ êµ¬ì¡°', fontweight='bold')
ax2.set_yticks([])
ax2.set_xticks(positions)

# ë²”ë¡€ íŒ¨ì¹˜
import matplotlib.patches as mpatches
legend_elements = [
    mpatches.Patch(facecolor='#43A047', label='ìºì‹œëœ í† í°'),
    mpatches.Patch(facecolor='#E53935', label='ë‹¤ìŒ ì“°ê¸° ìœ„ì¹˜'),
    mpatches.Patch(facecolor='#E0E0E0', label='ë¹ˆ ìŠ¬ë¡¯'),
]
ax2.legend(handles=legend_elements, fontsize=9)
ax2.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('chapter12_modern_llms/kv_cache_rolling_buffer.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter12_modern_llms/kv_cache_rolling_buffer.png")"""),

# â”€â”€â”€ Cell 10: ì„¹ì…˜4 â”€â”€â”€
md("""## 4. Multi-Turn ëŒ€í™” ë©”ëª¨ë¦¬ ë¶„ì„ <a name='4.-Multi-Turn-ë¶„ì„'></a>"""),

# â”€â”€â”€ Cell 11: Multi-Turn ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€
code(r"""# â”€â”€ Multi-Turn ëŒ€í™”ì˜ KV Cache ë©”ëª¨ë¦¬ ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤ì œ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ í„´ë§ˆë‹¤ KV Cacheê°€ ì–´ë–»ê²Œ ì¦ê°€í•˜ëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤

# Llama 3 8B ê¸°ì¤€
L, H_kv, d_h = 32, 8, 128

def kv_memory_gb(seq_len, batch=1, dtype_bytes=2):
    return 2 * L * H_kv * d_h * seq_len * batch * dtype_bytes / 1e9

# ì‹œë‚˜ë¦¬ì˜¤: 5í„´ ëŒ€í™”
turns = [
    ("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", 200),
    ("ì‚¬ìš©ì ì§ˆë¬¸ 1", 50),
    ("AI ì‘ë‹µ 1", 300),
    ("ì‚¬ìš©ì ì§ˆë¬¸ 2", 80),
    ("AI ì‘ë‹µ 2", 500),
    ("ì‚¬ìš©ì ì§ˆë¬¸ 3", 60),
    ("AI ì‘ë‹µ 3", 800),
]

cumulative_tokens = 0
turn_data = []
print("=" * 70)
print("Multi-Turn ëŒ€í™” KV Cache ë©”ëª¨ë¦¬ ë¶„ì„ (Llama 3 8B, FP16, B=1)")
print("=" * 70)
print(f"{'í„´':<25} | {'í† í°':>6} | {'ëˆ„ì ':>6} | {'KV ë©”ëª¨ë¦¬':>10}")
print("-" * 70)

for name, tokens in turns:
    cumulative_tokens += tokens
    mem = kv_memory_gb(cumulative_tokens)
    turn_data.append((name, tokens, cumulative_tokens, mem))
    print(f"{name:<25} | {tokens:>6} | {cumulative_tokens:>6} | {mem*1000:>8.1f} MB")

print("-" * 70)
print(f"{'ì´ê³„':<25} | {cumulative_tokens:>6} |        | {kv_memory_gb(cumulative_tokens)*1000:>8.1f} MB")
print()
print("ë°°ì¹˜ í¬ê¸°ë³„ ìµœì¢… ë©”ëª¨ë¦¬:")
for b in [1, 4, 8, 16]:
    mem = kv_memory_gb(cumulative_tokens, batch=b)
    print(f"  B={b:>2}: {mem:.3f} GB")"""),

# â”€â”€â”€ Cell 12: Multi-Turn ì‹œê°í™” â”€â”€â”€
code(r"""# â”€â”€ Multi-Turn KV Cache ë©”ëª¨ë¦¬ ì¦ê°€ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

names = [d[0] for d in turn_data]
cumulative = [d[2] for d in turn_data]
memories = [d[3] * 1000 for d in turn_data]  # MB
tokens_per_turn = [d[1] for d in turn_data]

fig, axes = plt.subplots(1, 2, figsize=(13, 5))

# ì™¼ìª½: ëˆ„ì  KV Cache ë©”ëª¨ë¦¬
ax1 = axes[0]
colors_turn = ['#1565C0', '#43A047', '#E53935', '#43A047', '#E53935', '#43A047', '#E53935']
labels_turn = ['System', 'User', 'AI', 'User', 'AI', 'User', 'AI']

ax1.bar(range(len(turn_data)), memories, color=colors_turn, edgecolor='black', lw=1)
ax1.set_xticks(range(len(turn_data)))
ax1.set_xticklabels([f'Turn {i}' for i in range(len(turn_data))], fontsize=8, rotation=30)
ax1.set_ylabel('KV Cache ë©”ëª¨ë¦¬ (MB)', fontsize=11)
ax1.set_title('í„´ë³„ ëˆ„ì  KV Cache ë©”ëª¨ë¦¬', fontweight='bold')
ax1.grid(True, alpha=0.3, axis='y')

for i, (m, l) in enumerate(zip(memories, labels_turn)):
    ax1.text(i, m + 2, f'{m:.0f}MB\n({l})', ha='center', fontsize=7)

# ì˜¤ë¥¸ìª½: ë°°ì¹˜ë³„ ë©”ëª¨ë¦¬ (ìµœì¢… ìƒíƒœ)
ax2 = axes[1]
batch_sizes = [1, 2, 4, 8, 16, 32]
final_seq = cumulative[-1]
batch_memories = [kv_memory_gb(final_seq, b) for b in batch_sizes]

ax2.plot(batch_sizes, batch_memories, 'r-o', lw=2.5, ms=8)
ax2.axhline(y=80, color='gray', ls='--', lw=1.5, label='A100 80GB VRAM')
ax2.axhline(y=24, color='orange', ls='--', lw=1.5, label='RTX 4090 24GB VRAM')
ax2.fill_between(batch_sizes, batch_memories, 0, alpha=0.1, color='red')
ax2.set_xlabel('ë°°ì¹˜ í¬ê¸°', fontsize=11)
ax2.set_ylabel('KV Cache ë©”ëª¨ë¦¬ (GB)', fontsize=11)
ax2.set_title(f'ë°°ì¹˜ë³„ KV Cache (S={final_seq})', fontweight='bold')
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter12_modern_llms/kv_cache_multiturn.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter12_modern_llms/kv_cache_multiturn.png")"""),

# â”€â”€â”€ Cell 13: ì„¹ì…˜5 â”€â”€â”€
md("""## 5. Prefix Caching ì‹œë®¬ë ˆì´ì…˜ <a name='5.-Prefix-Caching'></a>"""),

# â”€â”€â”€ Cell 14: Prefix Caching â”€â”€â”€
code(r"""# â”€â”€ Prefix Caching ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë™ì¼í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ê³µìœ í•˜ëŠ” ë‹¤ìˆ˜ì˜ ìš”ì²­ì—ì„œ KV Cacheë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤

# ì‹œë‚˜ë¦¬ì˜¤: ë™ì¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(500 í† í°)ë¡œ 100ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬
system_prompt_tokens = 500
user_query_avg_tokens = 100
num_requests = 100

# Llama 3 8B ê¸°ì¤€
def kv_prefill_flops(seq_len, d_model=4096, n_layers=32):
    # ëŒ€ëµì : ê° ë ˆì´ì–´ì—ì„œ QKV projection + attention + FFN
    return n_layers * (3 * seq_len * d_model**2 + 2 * seq_len**2 * d_model)

# === ë°©ë²• 1: Prefix Caching ì—†ìŒ (ë§¤ë²ˆ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¬ê³„ì‚°) ===
flops_no_prefix = 0
for _ in range(num_requests):
    total_seq = system_prompt_tokens + user_query_avg_tokens
    flops_no_prefix += kv_prefill_flops(total_seq)

# === ë°©ë²• 2: Prefix Caching (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ 1íšŒë§Œ ê³„ì‚°) ===
flops_prefix = kv_prefill_flops(system_prompt_tokens)  # 1íšŒ
for _ in range(num_requests):
    # ì‚¬ìš©ì ì¿¼ë¦¬ë§Œ ì²˜ë¦¬ (ê¸°ì¡´ prefix ìºì‹œ ì¬ì‚¬ìš©)
    flops_prefix += kv_prefill_flops(user_query_avg_tokens)

# KV ë©”ëª¨ë¦¬ë„ ë¹„êµ
kv_per_request = kv_memory_gb(system_prompt_tokens + user_query_avg_tokens)
kv_shared_prefix = kv_memory_gb(system_prompt_tokens)  # ê³µìœ  ë¶€ë¶„
kv_per_query = kv_memory_gb(user_query_avg_tokens)

print("=" * 65)
print(f"Prefix Caching íš¨ê³¼ ë¶„ì„ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ {system_prompt_tokens}í† í°, {num_requests}ê°œ ìš”ì²­)")
print("=" * 65)
print(f"{'í•­ëª©':<30} | {'ìºì‹± ì—†ìŒ':>15} | {'Prefix ìºì‹±':>15}")
print("-" * 65)
print(f"{'ì´ Prefill FLOPs':<30} | {flops_no_prefix:>15.2e} | {flops_prefix:>15.2e}")
print(f"{'FLOPs ì ˆê°':<30} | {'-':>15} | {(1-flops_prefix/flops_no_prefix)*100:>13.1f}%")
print(f"{'ìš”ì²­ë‹¹ ì‹œìŠ¤í…œí”„ë¡¬í”„íŠ¸ ì¬ê³„ì‚°':<30} | {'ë§¤ë²ˆ':>15} | {'1íšŒë§Œ':>15}")
print()
print("Prefix Caching í•µì‹¬ ì›ë¦¬:")
print("  1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì˜ KVë¥¼ í•œ ë²ˆ ê³„ì‚° í›„ GPU ë©”ëª¨ë¦¬ì— ìœ ì§€")
print("  2. ìƒˆ ì‚¬ìš©ì ì¿¼ë¦¬ëŠ” prefix KVë¥¼ ë³µì‚¬(COW) í›„ ì´ì–´ì„œ ê³„ì‚°")
print("  3. vLLM, SGLang ë“± ì„œë¹™ í”„ë ˆì„ì›Œí¬ì—ì„œ ìë™ ì§€ì›")"""),

# â”€â”€â”€ Cell 15: ì •ë¦¬ â”€â”€â”€
md(r"""## 6. ì •ë¦¬ <a name='6.-ì •ë¦¬'></a>

### í•µì‹¬ ê°œë… ìš”ì•½

| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |
|------|------|--------|
| KV Cache | ì´ì „ í† í°ì˜ K,Vë¥¼ ì €ì¥í•˜ì—¬ ì¬ê³„ì‚° ë°©ì§€ â†’ ìƒì„± ì†ë„ $O(S^2) \to O(S)$ | â­â­â­ |
| KV ë©”ëª¨ë¦¬ ê³µì‹ | $M_{KV} = 2 \cdot L \cdot H_{kv} \cdot d_{head} \cdot S \cdot B \cdot \text{bytes}$ | â­â­â­ |
| Rolling Buffer | ê³ ì • í¬ê¸° ìˆœí™˜ ë²„í¼ë¡œ ë©”ëª¨ë¦¬ ìƒí•œ ì„¤ì • â†’ Mistral ìŠ¤íƒ€ì¼ | â­â­ |
| Prefix Caching | ê³µí†µ ì ‘ë‘ì‚¬(ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)ì˜ KVë¥¼ ê³µìœ  â†’ ì„œë¹™ ì²˜ë¦¬ëŸ‰ í–¥ìƒ | â­â­â­ |
| GQA + KV Cache | $H_{kv} \ll H_Q$ë¡œ ìºì‹œ ë©”ëª¨ë¦¬ë¥¼ $G/H$ë°°ë¡œ ì¤„ì„ | â­â­â­ |

### í•µì‹¬ ìˆ˜ì‹

$$M_{KV} = 2 \times L \times H_{kv} \times d_{head} \times S \times B \times \text{bytes}$$

Llama 3 8B ($L=32, H_{kv}=8, d_{head}=128$): $S=4096, B=1$ â†’ **512 MB**

### ë‹¤ìŒ ì±•í„° ì˜ˆê³ 
**Chapter 12-03: Rotary Position Embedding (RoPE)** â€” ë³µì†Œìˆ˜ í‰ë©´ì—ì„œì˜ ìœ„ì¹˜ ì¸ì½”ë”© ìˆ˜ì‹ ë„ì¶œ, ì¥ê±°ë¦¬ ì˜ì¡´ì„± ë³´ì¡´, YaRNì„ ì´ìš©í•œ ì»¨í…ìŠ¤íŠ¸ í™•ì¥ ì›ë¦¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤."""),
]

create_notebook(cells, 'chapter12_modern_llms/02_kv_cache_and_memory.ipynb')
