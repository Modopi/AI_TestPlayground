"""Generate chapter14_extreme_inference/03_speculative_decoding.ipynb"""
import sys, os
sys.path.insert(0, '/workspace/scripts')
from nb_helper import md, code, create_notebook

cells = []

# â”€â”€ Cell 1: Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md("""\
# Chapter 14: ê·¹ë‹¨ì  ì¶”ë¡  ìµœì í™” â€” Speculative Decoding

## í•™ìŠµ ëª©í‘œ
- Speculative Decodingì˜ **Draft-Verify íŒ¨ëŸ¬ë‹¤ì„**ì´ ì™œ Memory-bound Decodeë¥¼ ê°€ì†í•˜ëŠ”ì§€ ì´í•´í•œë‹¤
- ìˆ˜ìš©ë¥ (acceptance rate) $\\beta$ì™€ ë“œë˜í”„íŠ¸ ê¸¸ì´ $k$ë¡œë¶€í„° **ê¸°ëŒ€ ìˆ˜ìš© í† í° ìˆ˜ë¥¼ ìœ ë„**í•œë‹¤
- ê²€ì¦(Verification) ë‹¨ê³„ì˜ **ìˆ˜í•™ì  ì •í™•ì„± ë³´ì¥ ë©”ì»¤ë‹ˆì¦˜**ì„ ì´í•´í•œë‹¤
- Medusa, EAGLE ë“± **ë‹¤ì¤‘ í—¤ë“œ ë°©ì‹**ì˜ ì•„í‚¤í…ì²˜ì™€ Trade-offë¥¼ ë¹„êµí•œë‹¤
- TensorFlowë¡œ Draft-Verify ì‹œë®¬ë ˆì´ì…˜ì„ êµ¬í˜„í•˜ê³  **ì†ë„ í–¥ìƒì„ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦**í•œë‹¤

## ëª©ì°¨
1. [ìˆ˜í•™ì  ê¸°ì´ˆ: ìˆ˜ìš©ë¥ ê³¼ ê¸°ëŒ€ í† í° ìˆ˜](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)
2. [Draft-Verify ì‹œë®¬ë ˆì´ì…˜](#2.-Draft-Verify-ì‹œë®¬ë ˆì´ì…˜)
3. [ê¸°ëŒ€ ì†ë„ í–¥ìƒ ë¶„ì„](#3.-ì†ë„-í–¥ìƒ-ë¶„ì„)
4. [Medusa vs EAGLE ì•„í‚¤í…ì²˜ ë¹„êµ](#4.-Medusa-vs-EAGLE)
5. [í† í° ìˆ˜ìš© ì‹œê°í™”](#5.-í† í°-ìˆ˜ìš©-ì‹œê°í™”)
6. [ì •ë¦¬](#6.-ì •ë¦¬)"""))

# â”€â”€ Cell 2: Math foundations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""\
## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>

### Speculative Decoding í•µì‹¬ ì•„ì´ë””ì–´

Decode ë‹¨ê³„ëŠ” **Memory-bound**ì´ë¯€ë¡œ, ì‘ì€ Draft ëª¨ë¸ë¡œ $k$ê°œ í† í°ì„ ë¹ ë¥´ê²Œ ìƒì„±í•œ í›„
í° Target ëª¨ë¸ë¡œ **í•œ ë²ˆì˜ Forward Passë¡œ ë³‘ë ¬ ê²€ì¦**í•©ë‹ˆë‹¤.

### ìˆ˜ìš© í™•ë¥  (Acceptance Probability)

Draft ëª¨ë¸ì˜ ë¶„í¬ $q(x)$, Target ëª¨ë¸ì˜ ë¶„í¬ $p(x)$ì— ëŒ€í•´:

$$\alpha(x) = \min\left(1, \frac{p(x)}{q(x)}\right)$$

- $\alpha(x)$: í† í° $x$ì˜ ìˆ˜ìš© í™•ë¥ 
- $q(x) \leq p(x)$ì¸ í† í°ì€ í•­ìƒ ìˆ˜ìš©
- $q(x) > p(x)$ì¸ í† í°ì€ $p(x)/q(x)$ í™•ë¥ ë¡œ ìˆ˜ìš©

### ê¸°ëŒ€ ìˆ˜ìš© í† í° ìˆ˜

ë“œë˜í”„íŠ¸ ê¸¸ì´ $k$, í‰ê·  ìˆ˜ìš©ë¥  $\beta$ì¼ ë•Œ, ê¸°ëŒ€ ìˆ˜ìš© í† í° ìˆ˜:

$$E[\text{accepted}] = \frac{1 - \beta^{k+1}}{1 - \beta}$$

**ìœ ë„:**
- ì²« ë²ˆì§¸ í† í° ìˆ˜ìš© í™•ë¥ : $\beta$
- $i$ë²ˆì§¸ í† í°ê¹Œì§€ **ëª¨ë‘** ìˆ˜ìš©ë  í™•ë¥ : $\beta^i$
- ê¸°ëŒ€ ìˆ˜ìš© ìˆ˜: $\sum_{i=0}^{k} \beta^i = \frac{1 - \beta^{k+1}}{1 - \beta}$ (ë“±ë¹„ê¸‰ìˆ˜)

ê±°ë¶€ ì‹œ Target ëª¨ë¸ì˜ ìˆ˜ì •ëœ ë¶„í¬ì—ì„œ 1ê°œ í† í°ì„ ìƒ˜í”Œë§í•˜ë¯€ë¡œ, ìµœì†Œ 1ê°œ í† í°ì€ í•­ìƒ ìƒì„±ë©ë‹ˆë‹¤.

### Speedup ê³µì‹

$$\text{Speedup} = \frac{E[\text{accepted}]}{c \cdot k + 1}$$

- $c$: Draft ëª¨ë¸ì˜ ìƒëŒ€ì  ë¹„ìš© ($c = T_{draft} / T_{target}$, ë³´í†µ $c \approx 0.05 \sim 0.1$)
- $k$: ë“œë˜í”„íŠ¸ ê¸¸ì´
- ë¶„ëª¨ì˜ 1: Target ëª¨ë¸ ê²€ì¦ 1íšŒ

### ê²€ì¦ì˜ ì •í™•ì„±

Speculative Decodingì€ **Target ëª¨ë¸ì˜ ì¶œë ¥ ë¶„í¬ë¥¼ ì •í™•íˆ ë³´ì¡´**í•©ë‹ˆë‹¤:

ê±°ë¶€ ì‹œ ìˆ˜ì • ë¶„í¬: $p'(x) = \text{norm}\left(\max(0, p(x) - q(x))\right)$

$$\text{ìµœì¢… ë¶„í¬} = \alpha \cdot q(x) + (1-\alpha) \cdot p'(x) = p(x)$$

**ìš”ì•½ í‘œ:**

| ì§€í‘œ | ìˆ˜ì‹ | ì˜ë¯¸ |
|------|------|------|
| ìˆ˜ìš© í™•ë¥  | $\min(1, p(x)/q(x))$ | í† í°ë³„ ìˆ˜ìš©/ê±°ë¶€ ê²°ì • |
| ê¸°ëŒ€ í† í° ìˆ˜ | $(1-\beta^{k+1})/(1-\beta)$ | í•œ ë¼ìš´ë“œ í‰ê·  ìƒì„± ìˆ˜ |
| Speedup | $E[\text{acc}] / (ck + 1)$ | ì´ë¡ ì  ì†ë„ í–¥ìƒ |
| ìˆ˜ì • ë¶„í¬ | $\text{norm}(\max(0, p-q))$ | ë¶„í¬ ì •í™•ì„± ë³´ì¥ |"""))

# â”€â”€ Cell 3: ğŸ£ friendly explanation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md("""\
### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ Speculative Decoding ì¹œì ˆ ì„¤ëª…!

#### ğŸ”¢ Draft-Verifyê°€ ë­”ê°€ìš”?

> ğŸ’¡ **ë¹„ìœ **: ìˆ˜í•™ ì‹œí—˜ì—ì„œ **ì—°ìŠµì¥ì— ë¹ ë¥´ê²Œ ë‹µì„ ì“°ê³ **, ì„ ìƒë‹˜ì´ í•œêº¼ë²ˆì— ì±„ì í•˜ëŠ” ê²ƒ!

**ê¸°ì¡´ ë°©ì‹**: ì„ ìƒë‹˜(í° ëª¨ë¸)ì´ í•œ ë¬¸ì œì”© ì§ì ‘ í’€ì–´ìš”. ì •í™•í•˜ì§€ë§Œ ëŠë ¤ìš”! ğŸ¢

**Speculative Decoding**: 
1. í•™ìƒ(ì‘ì€ Draft ëª¨ë¸)ì´ ì—°ìŠµì¥ì— 5ë¬¸ì œë¥¼ ë¹ ë¥´ê²Œ í’€ì–´ìš” âœï¸
2. ì„ ìƒë‹˜(í° Target ëª¨ë¸)ì´ 5ë¬¸ì œë¥¼ **í•œ ë²ˆì—** ì±„ì í•´ìš” âœ…âŒ
3. ë§ì€ ë°ê¹Œì§€ ì±„íƒí•˜ê³ , í‹€ë¦° ë¬¸ì œë¶€í„° ì„ ìƒë‹˜ì´ ì§ì ‘ ë‹µì„ ì¨ìš”

ì„ ìƒë‹˜ì´ ì±„ì í•˜ëŠ” ì‹œê°„ = ë¬¸ì œ 1ê°œ í‘¸ëŠ” ì‹œê°„ì´ë‹ˆê¹Œ, í•™ìƒì´ ì˜ ë§ì¶œìˆ˜ë¡ ë¹¨ë¼ì ¸ìš”!

#### ğŸ“Š ìˆ˜ìš©ë¥ ì´ ë­”ê°€ìš”?

> ğŸ’¡ **ë¹„ìœ **: í•™ìƒì˜ **ì •ë‹µë¥ **ì´ì—ìš”!

- ìˆ˜ìš©ë¥  90% â†’ 10ë¬¸ì œ ì¤‘ 9ë¬¸ì œë¥¼ ë§ì¶°ìš” â†’ ê±°ì˜ 10ë°° ë¹¨ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”!
- ìˆ˜ìš©ë¥  50% â†’ 10ë¬¸ì œ ì¤‘ 5ë¬¸ì œë¥¼ ë§ì¶°ìš” â†’ ì•½ 2ë°° ë¹¨ë¼ì ¸ìš”
- ìˆ˜ìš©ë¥ ì´ ë‚®ìœ¼ë©´ ì˜¤íˆë ¤ í•™ìƒí•œí…Œ ì‹œí‚¤ëŠ” ê²ƒì´ ì†í•´ì˜ˆìš”

---"""))

# â”€â”€ Cell 4: ğŸ“ Exercises â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""\
### ğŸ“ ì—°ìŠµ ë¬¸ì œ

#### ë¬¸ì œ 1: ê¸°ëŒ€ í† í° ìˆ˜ ê³„ì‚°

$\beta = 0.8$, $k = 5$ì¼ ë•Œ ê¸°ëŒ€ ìˆ˜ìš© í† í° ìˆ˜ëŠ”?

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$$E = \frac{1 - 0.8^{5+1}}{1 - 0.8} = \frac{1 - 0.8^6}{0.2} = \frac{1 - 0.262144}{0.2} = \frac{0.737856}{0.2} = 3.689$$

â†’ í‰ê·  **3.69ê°œ** í† í°ì´ ìˆ˜ìš©ë©ë‹ˆë‹¤. (ìµœì†Œ 1ê°œ ë³´ì¥ì´ë¯€ë¡œ ì‹¤ì œë¡œëŠ” ë” ë†’ì„ ìˆ˜ ìˆìŒ)
</details>

#### ë¬¸ì œ 2: ìµœì  ë“œë˜í”„íŠ¸ ê¸¸ì´

$\beta = 0.7$, Draft ë¹„ìš© $c = 0.05$ì¼ ë•Œ, Speedupì„ ìµœëŒ€í™”í•˜ëŠ” $k$ëŠ”?

<details>
<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>

$k$ë³„ Speedup ê³„ì‚°:

| $k$ | $E[\text{acc}]$ | $ck+1$ | Speedup |
|-----|---------|--------|---------|
| 1 | $\frac{1-0.49}{0.3}=1.70$ | 1.05 | 1.62 |
| 3 | $\frac{1-0.7^4}{0.3}=2.37$ | 1.15 | 2.06 |
| 5 | $\frac{1-0.7^6}{0.3}=2.72$ | 1.25 | 2.17 |
| 7 | $\frac{1-0.7^8}{0.3}=2.89$ | 1.35 | 2.14 |
| 10 | $\frac{1-0.7^{11}}{0.3}=2.98$ | 1.50 | 1.99 |

â†’ $k=5$ ë¶€ê·¼ì—ì„œ Speedupì´ ìµœëŒ€ (**~2.17x**)! $k$ê°€ ë„ˆë¬´ í¬ë©´ Draft ë¹„ìš©ì´ ì¦ê°€í•˜ì—¬ ì—­íš¨ê³¼.
</details>

---"""))

# â”€â”€ Cell 5: Import cell â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code("""\
# â”€â”€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import tensorflow as tf
import time

np.random.seed(42)
print(f"TensorFlow ë²„ì „: {tf.__version__}")
print(f"NumPy ë²„ì „: {np.__version__}")"""))

# â”€â”€ Cell 6: Section 2 header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""\
## 2. Draft-Verify ì‹œë®¬ë ˆì´ì…˜ <a name='2.-Draft-Verify-ì‹œë®¬ë ˆì´ì…˜'></a>

Draft ëª¨ë¸ê³¼ Target ëª¨ë¸ì˜ ë¶„í¬ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ Speculative Decodingì˜ ë™ì‘ì„ ê²€ì¦í•©ë‹ˆë‹¤.

ê²€ì¦ ì•Œê³ ë¦¬ì¦˜:
1. Draft ëª¨ë¸ì—ì„œ $k$ê°œ í† í° $x_1, \ldots, x_k$ë¥¼ ìê¸°íšŒê·€ ìƒì„±
2. Target ëª¨ë¸ì—ì„œ $x_1, \ldots, x_k$ë¥¼ **í•œ ë²ˆì—** ê²€ì¦
3. $\alpha_i = \min(1, p(x_i)/q(x_i))$ë¡œ ê° í† í° ìˆ˜ìš©/ê±°ë¶€
4. ì²« ë²ˆì§¸ ê±°ë¶€ ìœ„ì¹˜ì—ì„œ ìˆ˜ì • ë¶„í¬ $p'$ì—ì„œ ìƒˆ í† í° ìƒ˜í”Œë§"""))

# â”€â”€ Cell 7: Draft-Verify simulation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code("""\
# â”€â”€ Draft-Verify ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
vocab_size = 100

def create_model_distribution(vocab_size, temperature=1.0):
    # ì‹œë®¬ë ˆì´ì…˜ìš©: ëœë¤ logitìœ¼ë¡œ ë¶„í¬ ìƒì„±
    logits = np.random.randn(vocab_size) / temperature
    probs = np.exp(logits) / np.sum(np.exp(logits))
    return probs

def speculative_decode_step(target_probs, draft_probs, k):
    # Draft ë‹¨ê³„: kê°œ í† í° ìƒì„±
    draft_tokens = []
    for _ in range(k):
        token = np.random.choice(len(draft_probs), p=draft_probs)
        draft_tokens.append(token)

    # Verify ë‹¨ê³„: Target ëª¨ë¸ë¡œ ê²€ì¦
    accepted = []
    for i, token in enumerate(draft_tokens):
        p = target_probs[token]
        q = draft_probs[token]
        alpha = min(1.0, p / q)

        if np.random.random() < alpha:
            accepted.append(token)
        else:
            # ìˆ˜ì • ë¶„í¬ì—ì„œ ìƒˆ í† í° ìƒ˜í”Œë§
            residual = np.maximum(0, target_probs - draft_probs)
            residual_sum = np.sum(residual)
            if residual_sum > 0:
                residual /= residual_sum
                bonus_token = np.random.choice(len(residual), p=residual)
            else:
                bonus_token = np.random.choice(len(target_probs), p=target_probs)
            accepted.append(bonus_token)
            break
    else:
        # ëª¨ë‘ ìˆ˜ìš©ëœ ê²½ìš°: Targetì—ì„œ ì¶”ê°€ 1ê°œ ìƒì„±
        bonus = np.random.choice(len(target_probs), p=target_probs)
        accepted.append(bonus)

    return accepted, len(draft_tokens)

# ë‹¤ì–‘í•œ ìˆ˜ìš©ë¥ ë¡œ ì‹¤í—˜
draft_temps = [0.5, 1.0, 2.0, 5.0]
k_values = [3, 5, 7]
n_trials = 2000

print(f"{'':=<75}")
print(f"  Speculative Decoding ì‹œë®¬ë ˆì´ì…˜ (vocab={vocab_size}, trials={n_trials})")
print(f"{'':=<75}")

target_probs = create_model_distribution(vocab_size, temperature=1.0)

for k in k_values:
    print(f"\\n  Draft ê¸¸ì´ k={k}:")
    print(f"  {'Draft Temp':>12} | {'í‰ê·  ìˆ˜ìš©':>8} | {'ìˆ˜ìš©ë¥  Î²':>8} | {'ì´ë¡  E[acc]':>12} | {'ì‹¤ì œ E[acc]':>12}")
    print(f"  {'-'*62}")

    for temp in draft_temps:
        draft_probs = create_model_distribution(vocab_size, temperature=temp)

        total_accepted = 0
        total_drafted = 0

        for _ in range(n_trials):
            accepted, drafted = speculative_decode_step(target_probs, draft_probs, k)
            total_accepted += len(accepted)
            total_drafted += drafted

        avg_accepted = total_accepted / n_trials
        beta = 1.0 - (total_drafted - total_accepted + n_trials) / (total_drafted + n_trials)
        beta = max(0.01, min(0.99, beta))
        theoretical = (1 - beta**(k+1)) / (1 - beta)

        print(f"  {temp:>12.1f} | {avg_accepted:>8.2f} | {beta:>8.3f} | {theoretical:>12.2f} | {avg_accepted:>12.2f}")

print(f"\\nê²°ë¡ : Draft ëª¨ë¸ì´ Targetì— ê°€ê¹Œìš¸ìˆ˜ë¡ (ì˜¨ë„ ìœ ì‚¬) ìˆ˜ìš©ë¥ ì´ ë†’ì•„ì§")"""))

# â”€â”€ Cell 8: Section 3 header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""\
## 3. ê¸°ëŒ€ ì†ë„ í–¥ìƒ ë¶„ì„ <a name='3.-ì†ë„-í–¥ìƒ-ë¶„ì„'></a>

ìˆ˜ìš©ë¥  $\beta$ì™€ ë“œë˜í”„íŠ¸ ê¸¸ì´ $k$ì— ë”°ë¥¸ ì´ë¡ ì  Speedupì„ ë¶„ì„í•©ë‹ˆë‹¤.

$$\text{Speedup}(\beta, k) = \frac{(1-\beta^{k+1}) / (1-\beta)}{c \cdot k + 1}$$"""))

# â”€â”€ Cell 9: Expected speedup vs acceptance rate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code("""\
# â”€â”€ ìˆ˜ìš©ë¥  vs ì†ë„ í–¥ìƒ ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
betas = np.linspace(0.01, 0.99, 200)
c = 0.05  # Draft ëª¨ë¸ ë¹„ìš© ë¹„ìœ¨

fig, axes = plt.subplots(1, 2, figsize=(13, 5))

ax1 = axes[0]
for k in [1, 3, 5, 7, 10, 15]:
    E_acc = (1 - betas**(k+1)) / (1 - betas)
    speedup = E_acc / (c * k + 1)
    ax1.plot(betas, speedup, lw=2, label=f'k={k}')

ax1.axhline(y=1.0, color='gray', ls='--', lw=1.5, alpha=0.5)
ax1.set_xlabel('Acceptance Rate (Î²)', fontsize=11)
ax1.set_ylabel('Speedup', fontsize=11)
ax1.set_title('Speedup vs Acceptance Rate (c=0.05)', fontweight='bold')
ax1.legend(fontsize=9)
ax1.grid(True, alpha=0.3)
ax1.set_xlim(0, 1)
ax1.set_ylim(0, 10)

# ìµœì  k ì°¾ê¸°
ax2 = axes[1]
k_range = np.arange(1, 21)
for beta in [0.5, 0.7, 0.8, 0.9, 0.95]:
    speedups = []
    for k in k_range:
        E_acc = (1 - beta**(k+1)) / (1 - beta)
        sp = E_acc / (c * k + 1)
        speedups.append(sp)
    optimal_k = k_range[np.argmax(speedups)]
    ax2.plot(k_range, speedups, '-o', lw=2, ms=4, label=f'Î²={beta} (optimal k={optimal_k})')

ax2.axhline(y=1.0, color='gray', ls='--', lw=1.5, alpha=0.5)
ax2.set_xlabel('Draft Length (k)', fontsize=11)
ax2.set_ylabel('Speedup', fontsize=11)
ax2.set_title('Speedup vs Draft Length (c=0.05)', fontweight='bold')
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter14_extreme_inference/speculative_speedup.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/speculative_speedup.png")

# ìµœì  k ìš”ì•½í‘œ
print(f"\\n{'Î²':>6} | {'ìµœì  k':>6} | {'ìµœëŒ€ Speedup':>14}")
print(f"{'-'*32}")
for beta in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:
    best_sp = 0
    best_k = 1
    for k in range(1, 30):
        E_acc = (1 - beta**(k+1)) / (1 - beta)
        sp = E_acc / (c * k + 1)
        if sp > best_sp:
            best_sp = sp
            best_k = k
    print(f"{beta:>6.2f} | {best_k:>6} | {best_sp:>14.2f}x")"""))

# â”€â”€ Cell 10: Section 4 header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md("""\
## 4. Medusa vs EAGLE ì•„í‚¤í…ì²˜ ë¹„êµ <a name='4.-Medusa-vs-EAGLE'></a>

ê¸°ì¡´ Speculative Decodingì€ ë³„ë„ Draft ëª¨ë¸ì´ í•„ìš”í•˜ì§€ë§Œ, **Medusa**ì™€ **EAGLE**ì€ 
Target ëª¨ë¸ ìì²´ì— ì¶”ê°€ í—¤ë“œë¥¼ ë¶€ì°©í•˜ì—¬ Draft ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

| ë°©ì‹ | êµ¬ì¡° | Draft ìƒì„± |
|------|------|-----------|
| ì „í†µ ë°©ì‹ | ë³„ë„ Draft ëª¨ë¸ | ìê¸°íšŒê·€ |
| Medusa | Target + ë‹¤ì¤‘ MLP í—¤ë“œ | ë³‘ë ¬ (ë¹„ìê¸°íšŒê·€) |
| EAGLE | Target + Feature ê¸°ë°˜ í—¤ë“œ | ìê¸°íšŒê·€ (feature-level) |"""))

# â”€â”€ Cell 11: Medusa vs EAGLE comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code("""\
# â”€â”€ Medusa vs EAGLE ë¹„êµí‘œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("=" * 95)
print("  Speculative Decoding ë°©ì‹ ë¹„êµ: ì „í†µ vs Medusa vs EAGLE")
print("=" * 95)

headers = ['í•­ëª©', 'ì „í†µ Spec. Decoding', 'Medusa (2024)', 'EAGLE (2024)']
rows = [
    ['ë…¼ë¬¸', 'Leviathan et al. 2023', 'Cai et al. 2024', 'Li et al. 2024'],
    ['Draft ì†ŒìŠ¤', 'ë³„ë„ ì†Œí˜• ëª¨ë¸', 'Target + MLP í—¤ë“œ', 'Target + Autoregressive í—¤ë“œ'],
    ['Draft ë°©ì‹', 'ìê¸°íšŒê·€ (ìˆœì°¨)', 'ë¹„ìê¸°íšŒê·€ (ë³‘ë ¬)', 'ìê¸°íšŒê·€ (feature-level)'],
    ['í† í° íŠ¸ë¦¬', 'ì„ í˜• ì²´ì¸', 'Tree Attention', 'Tree Attention'],
    ['ì¶”ê°€ íŒŒë¼ë¯¸í„°', 'ë³„ë„ ëª¨ë¸ ì „ì²´', '~0.6% (MLP heads)', '~0.2-2% (feature head)'],
    ['í•™ìŠµ í•„ìš”', 'Draft ëª¨ë¸ ì‚¬ì „í•™ìŠµ', 'MLP í—¤ë“œ í•™ìŠµ', 'Feature í—¤ë“œ í•™ìŠµ'],
    ['í•™ìŠµ ë°ì´í„°', 'ì¼ë°˜ ì½”í¼ìŠ¤', 'Target ì¶œë ¥', 'Target hidden states'],
    ['ë¶„í¬ ë³´ì¡´', 'ë³´ì¥ (rejection)', 'ê·¼ì‚¬ì ', 'ë³´ì¥ (rejection)'],
    ['ì†ë„ í–¥ìƒ', '~2-3x', '~2-3x', '~2.5-4x'],
    ['ë©”ëª¨ë¦¬ ì¶”ê°€', 'í¼ (Draft ëª¨ë¸)', 'ë§¤ìš° ì‘ìŒ', 'ì‘ìŒ'],
    ['í˜¸í™˜ì„±', 'ëª¨ë¸ ìŒ í•„ìš”', 'Targetë§Œ ìˆ˜ì •', 'Targetë§Œ ìˆ˜ì •'],
]

col_widths = [18, 22, 22, 25]
header_line = ' | '.join(h.ljust(w) for h, w in zip(headers, col_widths))
print(header_line)
print('-' * len(header_line))
for row in rows:
    line = ' | '.join(val.ljust(w) for val, w in zip(row, col_widths))
    print(line)

# ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”
methods = ['Autoregressive\\n(Baseline)', 'Spec. Decoding\\n(70B+7B)', 'Medusa\\n(70B+heads)', 'EAGLE\\n(70B+head)']
speedups = [1.0, 2.2, 2.5, 3.5]
extra_params = [0, 100, 0.6, 1.5]  # % of base model

fig, axes = plt.subplots(1, 2, figsize=(13, 5))

colors = ['#E0E0E0', '#90CAF9', '#A5D6A7', '#FFB74D']

ax1 = axes[0]
bars = ax1.bar(methods, speedups, color=colors, edgecolor='black', lw=0.5)
for bar, val in zip(bars, speedups):
    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.08,
             f'{val:.1f}x', ha='center', fontsize=11, fontweight='bold')
ax1.axhline(y=1.0, color='red', ls='--', lw=1.5, alpha=0.5)
ax1.set_ylabel('Speedup', fontsize=11)
ax1.set_title('Speculative Decoding ë°©ì‹ë³„ ì†ë„ í–¥ìƒ', fontweight='bold')
ax1.grid(True, alpha=0.3, axis='y')

ax2 = axes[1]
bars2 = ax2.bar(methods, extra_params, color=colors, edgecolor='black', lw=0.5)
for bar, val in zip(bars2, extra_params):
    label = f'{val:.1f}%' if val < 10 else f'{val:.0f}%'
    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1.5,
             label, ha='center', fontsize=11, fontweight='bold')
ax2.set_ylabel('Extra Parameters (% of Target)', fontsize=11)
ax2.set_title('ì¶”ê°€ íŒŒë¼ë¯¸í„° ì˜¤ë²„í—¤ë“œ', fontweight='bold')
ax2.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('chapter14_extreme_inference/speculative_methods_comparison.png', dpi=100, bbox_inches='tight')
plt.close()
print("\\nê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/speculative_methods_comparison.png")

print(f"\\ní•µì‹¬ ì¸ì‚¬ì´íŠ¸:")
print(f"  1. EAGLE: Feature-level ìê¸°íšŒê·€ â†’ ë†’ì€ ìˆ˜ìš©ë¥ ê³¼ ë¶„í¬ ë³´ì¡´")
print(f"  2. Medusa: ë¹„ìê¸°íšŒê·€ ë³‘ë ¬ â†’ ë¹ ë¥¸ Draft, í•˜ì§€ë§Œ ê·¼ì‚¬ì  ë¶„í¬")
print(f"  3. ì „í†µ ë°©ì‹: ë³„ë„ ëª¨ë¸ í•„ìš” â†’ ë©”ëª¨ë¦¬ ë¶€ë‹´ì´ í¬ì§€ë§Œ ë²”ìš©ì ")"""))

# â”€â”€ Cell 12: Section 5 header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md("""\
## 5. í† í° ìˆ˜ìš© ì‹œê°í™” <a name='5.-í† í°-ìˆ˜ìš©-ì‹œê°í™”'></a>

ì‹¤ì œ Speculative Decodingì—ì„œ í† í°ì´ ì–´ë–»ê²Œ ìˆ˜ìš©/ê±°ë¶€ë˜ëŠ”ì§€ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""))

# â”€â”€ Cell 13: Token acceptance visualization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(code("""\
# â”€â”€ í† í° ìˆ˜ìš©/ê±°ë¶€ íŒ¨í„´ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
np.random.seed(42)
vocab_size = 50
k = 7  # ë“œë˜í”„íŠ¸ ê¸¸ì´
n_rounds = 20

target_logits = np.random.randn(vocab_size) * 2
target_probs = np.exp(target_logits) / np.sum(np.exp(target_logits))

draft_logits = target_logits + np.random.randn(vocab_size) * 0.5
draft_probs = np.exp(draft_logits) / np.sum(np.exp(draft_logits))

acceptance_map = np.zeros((n_rounds, k + 1))
accepted_counts = []

for r in range(n_rounds):
    draft_tokens = [np.random.choice(vocab_size, p=draft_probs) for _ in range(k)]
    n_accepted = 0

    for i, token in enumerate(draft_tokens):
        p = target_probs[token]
        q = draft_probs[token]
        alpha = min(1.0, p / q)

        if np.random.random() < alpha:
            acceptance_map[r, i] = 1  # ìˆ˜ìš©
            n_accepted += 1
        else:
            acceptance_map[r, i] = -1  # ê±°ë¶€
            break
        if i < k - 1:
            for j in range(i + 2, k + 1):
                acceptance_map[r, j] = 0  # ë¯¸ë„ë‹¬

    # ë³´ë„ˆìŠ¤ í† í° (í•­ìƒ 1ê°œ)
    if n_accepted == k:
        acceptance_map[r, k] = 2  # ë³´ë„ˆìŠ¤

    accepted_counts.append(n_accepted + 1)  # +1 ë³´ë„ˆìŠ¤/ìˆ˜ì • í† í°

fig, axes = plt.subplots(1, 2, figsize=(13, 6))

# íˆíŠ¸ë§µ
ax1 = axes[0]
from matplotlib.colors import ListedColormap
cmap = ListedColormap(['#BDBDBD', '#EF5350', '#66BB6A', '#42A5F5'])
# -1=ê±°ë¶€(ë¹¨), 0=ë¯¸ë„ë‹¬(íšŒ), 1=ìˆ˜ìš©(ì´ˆ), 2=ë³´ë„ˆìŠ¤(íŒŒ)
mapped = np.zeros_like(acceptance_map)
mapped[acceptance_map == 0] = 0
mapped[acceptance_map == -1] = 1
mapped[acceptance_map == 1] = 2
mapped[acceptance_map == 2] = 3

im = ax1.imshow(mapped, cmap=cmap, aspect='auto', interpolation='nearest')
ax1.set_xlabel('Token Position', fontsize=11)
ax1.set_ylabel('Round', fontsize=11)
ax1.set_title(f'Token Acceptance Pattern (k={k})', fontweight='bold')
ax1.set_xticks(range(k + 1))
ax1.set_xticklabels([f'Draft {i+1}' for i in range(k)] + ['Bonus'])

legend_labels = ['Not Reached', 'Rejected', 'Accepted', 'Bonus']
legend_colors = ['#BDBDBD', '#EF5350', '#66BB6A', '#42A5F5']
patches = [plt.Rectangle((0, 0), 1, 1, fc=c) for c in legend_colors]
ax1.legend(patches, legend_labels, loc='lower right', fontsize=8)

# ìˆ˜ìš© í† í° ìˆ˜ ë¶„í¬
ax2 = axes[1]
bins = range(1, k + 3)
ax2.hist(accepted_counts, bins=bins, color='#42A5F5', edgecolor='black',
         alpha=0.8, align='left', rwidth=0.8)
ax2.axvline(x=np.mean(accepted_counts), color='red', ls='--', lw=2,
            label=f'Mean = {np.mean(accepted_counts):.1f}')
ax2.set_xlabel('Accepted Tokens per Round', fontsize=11)
ax2.set_ylabel('Count', fontsize=11)
ax2.set_title('Distribution of Accepted Tokens', fontweight='bold')
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('chapter14_extreme_inference/token_acceptance_pattern.png', dpi=100, bbox_inches='tight')
plt.close()
print("ê·¸ë˜í”„ ì €ì¥ë¨: chapter14_extreme_inference/token_acceptance_pattern.png")

avg_beta = np.mean([c - 1 for c in accepted_counts]) / k
theoretical_E = (1 - avg_beta**(k+1)) / (1 - avg_beta)
print(f"\\nì‹¤í—˜ ê²°ê³¼:")
print(f"  í‰ê·  ìˆ˜ìš© í† í°: {np.mean(accepted_counts):.2f}")
print(f"  ì¶”ì • ìˆ˜ìš©ë¥  Î²: {avg_beta:.3f}")
print(f"  ì´ë¡ ì  E[accepted]: {theoretical_E:.2f}")
print(f"  Draft ê¸¸ì´: {k}")
print(f"  ì˜ˆìƒ Speedup (c=0.05): {np.mean(accepted_counts) / (0.05 * k + 1):.2f}x")"""))

# â”€â”€ Cell 14: Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cells.append(md(r"""\
## 6. ì •ë¦¬ <a name='6.-ì •ë¦¬'></a>

### í•µì‹¬ ê°œë… ìš”ì•½

| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |
|------|------|--------|
| Draft-Verify | ì†Œí˜• ëª¨ë¸ ì¶”ì¸¡ + ëŒ€í˜• ëª¨ë¸ ë³‘ë ¬ ê²€ì¦ | â­â­â­ |
| ìˆ˜ìš©ë¥  $\beta$ | $\min(1, p(x)/q(x))$ â€” Draft í’ˆì§ˆ ì§€í‘œ | â­â­â­ |
| ê¸°ëŒ€ í† í° ìˆ˜ | $(1-\beta^{k+1})/(1-\beta)$ â€” ë“±ë¹„ê¸‰ìˆ˜ | â­â­â­ |
| ë¶„í¬ ë³´ì¡´ | ìˆ˜ì • ë¶„í¬ $\max(0, p-q)$ë¡œ ì •í™•ì„± ë³´ì¥ | â­â­â­ |
| Medusa | ë¹„ìê¸°íšŒê·€ ë‹¤ì¤‘ MLP í—¤ë“œ | â­â­ |
| EAGLE | Feature-level ìê¸°íšŒê·€ í—¤ë“œ, ìµœê³  ì„±ëŠ¥ | â­â­â­ |
| ìµœì  $k$ | $\beta$ì™€ $c$ì— ë”°ë¼ ìµœì ì  ì¡´ì¬ | â­â­ |

### í•µì‹¬ ìˆ˜ì‹

$$E[\text{accepted}] = \frac{1 - \beta^{k+1}}{1 - \beta}, \quad \text{Speedup} = \frac{E[\text{acc}]}{c \cdot k + 1}$$

$$\alpha(x) = \min\left(1, \frac{p(x)}{q(x)}\right), \quad p'(x) = \text{norm}\left(\max(0, p(x) - q(x))\right)$$

### ë‹¤ìŒ ì±•í„° ì˜ˆê³ 
**04_vllm_and_paged_attention.ipynb** â€” OSì˜ Page Table ê°œë…ì„ KV Cacheì— ì ìš©í•œ PagedAttention, Continuous Batching, ë™ì  KV Block ìŠ¤ì¼€ì¤„ë§ì„ í•™ìŠµí•©ë‹ˆë‹¤."""))

create_notebook(cells, 'chapter14_extreme_inference/03_speculative_decoding.ipynb')
