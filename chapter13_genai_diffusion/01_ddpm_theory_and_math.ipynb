{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: ìƒì„± AI ì‹¬í™” â€” DDPM ì´ë¡ ê³¼ ìˆ˜í•™\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- í™•ì‚° ëª¨ë¸(Diffusion Model)ì˜ **ë§ˆë¥´ì½”í”„ ì²´ì¸ ê¸°ë°˜ Forward/Reverse ê³¼ì •**ì„ ìˆ˜í•™ì ìœ¼ë¡œ ì´í•´í•œë‹¤\n",
    "- Reparameterization trickì„ ì‚¬ìš©í•˜ì—¬ **ì„ì˜ ì‹œì  $t$ì˜ ë…¸ì´ì¦ˆ ìƒ˜í”Œ** $x_t$ë¥¼ ì§ì ‘ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì„ ìœ ë„í•œë‹¤\n",
    "- ELBO(Evidence Lower Bound)ì—ì„œ **ë‹¨ìˆœí™”ëœ ì†ì‹¤ í•¨ìˆ˜** $\\|\\epsilon - \\epsilon_\\theta\\|^2$ì´ ë„ì¶œë˜ëŠ” ê³¼ì •ì„ ì „ê°œí•œë‹¤\n",
    "- TensorFlowë¡œ **ì„ í˜• ë² íƒ€ ìŠ¤ì¼€ì¤„**ê³¼ Forward Processë¥¼ êµ¬í˜„í•˜ê³  ì‹œê°í™”í•œë‹¤\n",
    "- **1D ë°ì´í„°ì— ëŒ€í•œ ê°„ë‹¨í•œ DDPM í•™ìŠµ ë£¨í”„**ë¥¼ ì§ì ‘ êµ¬í˜„í•˜ì—¬ ì—­ë°©í–¥ ìƒì„± ê³¼ì •ì„ ì²´í—˜í•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: Forward Process, Reverse Process, ELBO](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [ë² íƒ€ ìŠ¤ì¼€ì¤„ê³¼ ì•ŒíŒŒ ëˆ„ì ê³± êµ¬í˜„](#2.-ë² íƒ€-ìŠ¤ì¼€ì¤„-êµ¬í˜„)\n",
    "3. [Forward Noising ê³¼ì • ì‹œê°í™”](#3.-Forward-Noising-ì‹œê°í™”)\n",
    "4. [ë‹¤ì–‘í•œ íƒ€ì„ìŠ¤í…ì—ì„œì˜ ë…¸ì´ì¦ˆ ì‹œê°í™”](#4.-íƒ€ì„ìŠ¤í…ë³„-ë…¸ì´ì¦ˆ)\n",
    "5. [1D DDPM í•™ìŠµ ë£¨í”„ êµ¬í˜„](#5.-1D-DDPM-í•™ìŠµ)\n",
    "6. [ì •ë¦¬](#6.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>\n",
    "\n",
    "### Forward Process (í™•ì‚° ê³¼ì •)\n",
    "\n",
    "DDPMì˜ Forward ProcessëŠ” ê¹¨ë—í•œ ë°ì´í„° $x_0$ì— ì ì§„ì ìœ¼ë¡œ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” **ë§ˆë¥´ì½”í”„ ì²´ì¸**ì…ë‹ˆë‹¤:\n",
    "\n",
    "$$q(x_t \\mid x_{t-1}) = \\mathcal{N}\\!\\left(x_t;\\, \\sqrt{1-\\beta_t}\\,x_{t-1},\\, \\beta_t I\\right)$$\n",
    "\n",
    "- $x_t$: ì‹œì  $t$ì—ì„œì˜ ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ ë°ì´í„°\n",
    "- $\\beta_t \\in (0, 1)$: ì‹œì  $t$ì˜ ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ (ë¶„ì‚° í¬ê¸°)\n",
    "- $I$: ë‹¨ìœ„ í–‰ë ¬ (ê° ì°¨ì›ì— ë…ë¦½ì ì¸ ë…¸ì´ì¦ˆ)\n",
    "- $T$: ì´ í™•ì‚° ë‹¨ê³„ ìˆ˜ (ë³´í†µ 1000)\n",
    "\n",
    "**í•µì‹¬ ì •ì˜:**\n",
    "\n",
    "$$\\alpha_t = 1 - \\beta_t, \\quad \\bar{\\alpha}_t = \\prod_{s=1}^{t} \\alpha_s = \\prod_{s=1}^{t}(1 - \\beta_s)$$\n",
    "\n",
    "- $\\alpha_t$: ì‹œì  $t$ì—ì„œ ì›ë³¸ ì‹ í˜¸ì˜ ë³´ì¡´ ë¹„ìœ¨\n",
    "- $\\bar{\\alpha}_t$: ì‹œì  $0$ë¶€í„° $t$ê¹Œì§€ì˜ ëˆ„ì  ì‹ í˜¸ ë³´ì¡´ ë¹„ìœ¨ (monotonically decreasing)\n",
    "\n",
    "### Reparameterization Trick\n",
    "\n",
    "$T$ë²ˆì˜ ìˆœì°¨ì  ë…¸ì´ì¦ˆ ì¶”ê°€ ì—†ì´, **í•œ ë²ˆì—** $x_0$ì—ì„œ $x_t$ë¥¼ ìƒ˜í”Œë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "$$q(x_t \\mid x_0) = \\mathcal{N}\\!\\left(x_t;\\, \\sqrt{\\bar{\\alpha}_t}\\,x_0,\\, (1-\\bar{\\alpha}_t)I\\right)$$\n",
    "\n",
    "$$\\boxed{x_t = \\sqrt{\\bar{\\alpha}_t}\\,x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)}$$\n",
    "\n",
    "| ì‹œì  | $\\bar{\\alpha}_t$ | $\\sqrt{\\bar{\\alpha}_t}$ (ì‹ í˜¸ ê³„ìˆ˜) | $\\sqrt{1-\\bar{\\alpha}_t}$ (ë…¸ì´ì¦ˆ ê³„ìˆ˜) | ì˜ë¯¸ |\n",
    "|------|------------------|-----------------------------------|-----------------------------------------|------|\n",
    "| $t=0$ | $1.0$ | $1.0$ | $0.0$ | ì›ë³¸ ë°ì´í„° |\n",
    "| $t=T/2$ | $\\approx 0.1$ | $\\approx 0.32$ | $\\approx 0.95$ | ëŒ€ë¶€ë¶„ ë…¸ì´ì¦ˆ |\n",
    "| $t=T$ | $\\approx 0$ | $\\approx 0$ | $\\approx 1.0$ | ìˆœìˆ˜ ë…¸ì´ì¦ˆ |\n",
    "\n",
    "### Reverse Process (ì—­ë°©í–¥ ìƒì„±)\n",
    "\n",
    "ì‹ ê²½ë§ $\\epsilon_\\theta$ê°€ ë…¸ì´ì¦ˆë¥¼ ì˜ˆì¸¡í•˜ì—¬, ë…¸ì´ì¦ˆì—ì„œ ê¹¨ë—í•œ ë°ì´í„°ë¥¼ ë³µì›í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$p_\\theta(x_{t-1} \\mid x_t) = \\mathcal{N}\\!\\left(x_{t-1};\\, \\mu_\\theta(x_t, t),\\, \\sigma_t^2 I\\right)$$\n",
    "\n",
    "ì—¬ê¸°ì„œ í‰ê·  $\\mu_\\theta$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ë©ë‹ˆë‹¤:\n",
    "\n",
    "$$\\mu_\\theta(x_t, t) = \\frac{1}{\\sqrt{\\alpha_t}}\\left(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\epsilon_\\theta(x_t, t)\\right)$$\n",
    "\n",
    "- $\\epsilon_\\theta(x_t, t)$: ì‹ ê²½ë§ì´ ì˜ˆì¸¡í•œ ë…¸ì´ì¦ˆ\n",
    "- $\\sigma_t^2 = \\beta_t$ ë˜ëŠ” $\\sigma_t^2 = \\tilde{\\beta}_t = \\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t}\\beta_t$\n",
    "\n",
    "### ELBOì™€ Simple Loss\n",
    "\n",
    "DDPMì˜ ìµœì í™” ëª©í‘œëŠ” **ELBO(Evidence Lower Bound)**ì—ì„œ ìœ ë„ë©ë‹ˆë‹¤:\n",
    "\n",
    "$$\\mathcal{L}_{VLB} = \\mathbb{E}_q\\!\\left[\\underbrace{D_{KL}(q(x_T|x_0)\\|p(x_T))}_{L_T} + \\sum_{t=2}^{T}\\underbrace{D_{KL}(q(x_{t-1}|x_t,x_0)\\|p_\\theta(x_{t-1}|x_t))}_{L_{t-1}} - \\underbrace{\\log p_\\theta(x_0|x_1)}_{L_0}\\right]$$\n",
    "\n",
    "Ho et al. (2020)ì€ ì´ë¥¼ **Simple Loss**ë¡œ ë‹¨ìˆœí™”í–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "$$\\boxed{\\mathcal{L}_{simple}(\\theta) = \\mathbb{E}_{t \\sim U[1,T],\\, x_0,\\, \\epsilon}\\!\\left[\\|\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{\\alpha}_t}\\,x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon,\\, t)\\|^2\\right]}$$\n",
    "\n",
    "- $\\epsilon \\sim \\mathcal{N}(0, I)$: ì‹¤ì œ ì¶”ê°€ëœ ë…¸ì´ì¦ˆ\n",
    "- $\\epsilon_\\theta(\\cdot, t)$: ì‹ ê²½ë§ì´ ì˜ˆì¸¡í•œ ë…¸ì´ì¦ˆ\n",
    "- ì‹œì  $t$ëŠ” $\\{1, 2, \\ldots, T\\}$ì—ì„œ ê· ì¼í•˜ê²Œ ìƒ˜í”Œë§\n",
    "\n",
    "**ìš”ì•½ í‘œ:**\n",
    "\n",
    "| ê³¼ì • | ìˆ˜ì‹ | ì—­í•  |\n",
    "|------|------|------|\n",
    "| Forward | $x_t = \\sqrt{\\bar{\\alpha}_t}\\,x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon$ | ë°ì´í„°ì— ë…¸ì´ì¦ˆ ì¶”ê°€ |\n",
    "| Reverse | $x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar\\alpha_t}}\\epsilon_\\theta) + \\sigma_t z$ | ë…¸ì´ì¦ˆ ì œê±° (ìƒì„±) |\n",
    "| Simple Loss | $\\|\\epsilon - \\epsilon_\\theta(x_t, t)\\|^2$ | ë…¸ì´ì¦ˆ ì˜ˆì¸¡ í•™ìŠµ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ í™•ì‚° ëª¨ë¸ ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ”¢ í™•ì‚° ëª¨ë¸ì´ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: ê¹¨ë—í•œ ê·¸ë¦¼ ìœ„ì— **ëª¨ë˜ë¥¼ ì¡°ê¸ˆì”© ë¿Œë ¤ì„œ** ê²°êµ­ ì•„ë¬´ê²ƒë„ ì•ˆ ë³´ì´ê²Œ ë§Œë“œëŠ” ê³¼ì •(Forward)ì„ ìƒìƒí•´ ë³´ì„¸ìš”. í™•ì‚° ëª¨ë¸ì€ ì´ ê³¼ì •ì„ **ê±°ê¾¸ë¡œ** ë°°ì›Œì„œ, ëª¨ë˜ë”ë¯¸ì—ì„œ ê·¸ë¦¼ì„ ë³µì›í•˜ëŠ” ë§ˆë²•ì‚¬ì˜ˆìš”!\n",
    "\n",
    "1. **Forward Process (ëª¨ë˜ ë¿Œë¦¬ê¸°)**: ì˜ˆìœ ê³ ì–‘ì´ ì‚¬ì§„ì— ëª¨ë˜ë¥¼ 1000ë²ˆ ë¿Œë¦¬ë©´ ê²°êµ­ íšŒìƒ‰ ë…¸ì´ì¦ˆë§Œ ë‚¨ì•„ìš”\n",
    "2. **Reverse Process (ëª¨ë˜ ì¹˜ìš°ê¸°)**: AIê°€ \"ì´ ëª¨ë˜ë”ë¯¸ì—ì„œ ëª¨ë˜ë¥¼ í•œ ì›€í¼ ì¹˜ìš°ë©´ ì–´ë–¤ ëª¨ì–‘ì´ ë‚˜ì˜¬ê¹Œ?\"ë¥¼ í•™ìŠµí•´ìš”\n",
    "3. **ìƒì„±**: ì™„ì „íˆ ëœë¤í•œ ëª¨ë˜ë”ë¯¸ì—ì„œ ì‹œì‘í•´ì„œ, í•œ ì›€í¼ì”© ì¹˜ìš°ë‹¤ ë³´ë©´... ìƒˆë¡œìš´ ê³ ì–‘ì´ ì‚¬ì§„ì´ ë‚˜íƒ€ë‚˜ìš”! ğŸ±\n",
    "\n",
    "#### ğŸ² ì™œ $\\bar{\\alpha}_t$ê°€ ì¤‘ìš”í•œê°€ìš”?\n",
    "\n",
    "| ë‹¨ê³„ | ë¹„ìœ  | ìˆ˜í•™ |\n",
    "|------|------|------|\n",
    "| $t=0$ (ì²˜ìŒ) | ê¹¨ë—í•œ ê·¸ë¦¼ | $\\bar{\\alpha}_0 = 1$ â†’ ì›ë³¸ 100% |\n",
    "| $t=500$ (ì¤‘ê°„) | ê·¸ë¦¼ì´ íë¦¿ | $\\bar{\\alpha}_{500} \\approx 0.1$ â†’ ì›ë³¸ 10% |\n",
    "| $t=1000$ (ë) | ì™„ì „ ë…¸ì´ì¦ˆ | $\\bar{\\alpha}_{1000} \\approx 0$ â†’ ì›ë³¸ 0% |\n",
    "\n",
    "$\\bar{\\alpha}_t$ëŠ” \"**ì›ë³¸ ê·¸ë¦¼ì´ ì–¼ë§ˆë‚˜ ë‚¨ì•„ìˆëŠ”ì§€**\"ë¥¼ ì•Œë ¤ì£¼ëŠ” ìˆ«ìì˜ˆìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: Reparameterization ê³„ì‚°\n",
    "\n",
    "$\\beta_1 = 0.0001$, $\\beta_2 = 0.0002$ì¼ ë•Œ, $\\bar{\\alpha}_2$ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$$\\alpha_1 = 1 - 0.0001 = 0.9999$$\n",
    "$$\\alpha_2 = 1 - 0.0002 = 0.9998$$\n",
    "$$\\bar{\\alpha}_2 = \\alpha_1 \\cdot \\alpha_2 = 0.9999 \\times 0.9998 = 0.9997$$\n",
    "\n",
    "$t=2$ì—ì„œëŠ” ì›ë³¸ ì‹ í˜¸ê°€ **99.97%** ë³´ì¡´ë©ë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” ë…¸ì´ì¦ˆê°€ ë§¤ìš° ì²œì²œíˆ ì¶”ê°€ë©ë‹ˆë‹¤.\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: ë…¸ì´ì¦ˆ ê³„ìˆ˜ ë¹„êµ\n",
    "\n",
    "$\\bar{\\alpha}_t = 0.5$ì¼ ë•Œ, ì‹ í˜¸ ê³„ìˆ˜ $\\sqrt{\\bar{\\alpha}_t}$ì™€ ë…¸ì´ì¦ˆ ê³„ìˆ˜ $\\sqrt{1-\\bar{\\alpha}_t}$ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$$\\sqrt{\\bar{\\alpha}_t} = \\sqrt{0.5} \\approx 0.707$$\n",
    "$$\\sqrt{1 - \\bar{\\alpha}_t} = \\sqrt{0.5} \\approx 0.707$$\n",
    "\n",
    "ì‹ í˜¸ì™€ ë…¸ì´ì¦ˆê°€ **ì •í™•íˆ ê°™ì€ ë¹„ìœ¨**! ì´ ì‹œì ì—ì„œ ì›ë³¸ê³¼ ë…¸ì´ì¦ˆê°€ ì ˆë°˜ì”© ì„ì—¬ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³ **: $\\sqrt{\\bar{\\alpha}_t}^2 + \\sqrt{1-\\bar{\\alpha}_t}^2 = \\bar{\\alpha}_t + (1-\\bar{\\alpha}_t) = 1$ â†’ ë¶„ì‚°ì´ í•­ìƒ ë³´ì¡´ë©ë‹ˆë‹¤.\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 3: Simple Loss í•´ì„\n",
    "\n",
    "Simple Loss $\\|\\epsilon - \\epsilon_\\theta(x_t, t)\\|^2$ì—ì„œ, ì™„ë²½í•œ ëª¨ë¸($\\epsilon_\\theta = \\epsilon$)ì¼ ë•Œ ì†ì‹¤ê°’ì€?\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$$\\mathcal{L} = \\|\\epsilon - \\epsilon\\|^2 = \\|0\\|^2 = 0$$\n",
    "\n",
    "ì†ì‹¤ì´ 0ì´ë©´ ëª¨ë¸ì´ ë…¸ì´ì¦ˆë¥¼ **ì™„ë²½í•˜ê²Œ ì˜ˆì¸¡**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” 0ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸ì´ë©°, í•™ìŠµ ì´ˆê¸°ì—ëŠ” ê°’ì´ í¬ê³  ì ì  ì¤„ì–´ë“­ë‹ˆë‹¤.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n",
    "print(f\"GPU ì‚¬ìš© ê°€ëŠ¥: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë² íƒ€ ìŠ¤ì¼€ì¤„ê³¼ ì•ŒíŒŒ ëˆ„ì ê³± êµ¬í˜„ <a name='2.-ë² íƒ€-ìŠ¤ì¼€ì¤„-êµ¬í˜„'></a>\n",
    "\n",
    "DDPM ì›ë…¼ë¬¸(Ho et al., 2020; arxiv 2006.11239)ì—ì„œ ì‚¬ìš©í•œ **ì„ í˜•(linear) ë² íƒ€ ìŠ¤ì¼€ì¤„**ì„ êµ¬í˜„í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$\\beta_t = \\beta_{\\min} + \\frac{t-1}{T-1}(\\beta_{\\max} - \\beta_{\\min}), \\quad t = 1, \\ldots, T$$\n",
    "\n",
    "ì›ë…¼ë¬¸ ì„¤ì •: $\\beta_{\\min} = 10^{-4}$, $\\beta_{\\max} = 0.02$, $T = 1000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ì„ í˜• ë² íƒ€ ìŠ¤ì¼€ì¤„ ë° ì•ŒíŒŒ ëˆ„ì ê³± ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "T = 1000\n",
    "beta_min = 1e-4\n",
    "beta_max = 0.02\n",
    "\n",
    "# ì„ í˜• ìŠ¤ì¼€ì¤„: beta_1 = beta_min, beta_T = beta_max\n",
    "betas = np.linspace(beta_min, beta_max, T)\n",
    "alphas = 1.0 - betas\n",
    "alpha_bars = np.cumprod(alphas)\n",
    "\n",
    "print(f\"ë² íƒ€ ìŠ¤ì¼€ì¤„ (ì„ í˜•)\")\n",
    "print(f\"  Î²_1   = {betas[0]:.6f}\")\n",
    "print(f\"  Î²_500 = {betas[499]:.6f}\")\n",
    "print(f\"  Î²_T   = {betas[-1]:.6f}\")\n",
    "print()\n",
    "print(f\"ì•ŒíŒŒ ëˆ„ì ê³± (Î±Ì„_t)\")\n",
    "print(f\"  á¾±_1   = {alpha_bars[0]:.6f}  (ì›ë³¸ {alpha_bars[0]*100:.2f}% ë³´ì¡´)\")\n",
    "print(f\"  á¾±_250 = {alpha_bars[249]:.6f}  (ì›ë³¸ {alpha_bars[249]*100:.2f}% ë³´ì¡´)\")\n",
    "print(f\"  á¾±_500 = {alpha_bars[499]:.6f}  (ì›ë³¸ {alpha_bars[499]*100:.4f}% ë³´ì¡´)\")\n",
    "print(f\"  á¾±_750 = {alpha_bars[749]:.6f}  (ì›ë³¸ {alpha_bars[749]*100:.6f}% ë³´ì¡´)\")\n",
    "print(f\"  á¾±_T   = {alpha_bars[-1]:.8f}  (ì›ë³¸ ê±°ì˜ 0%)\")\n",
    "print()\n",
    "print(f\"ì‹ í˜¸ ê³„ìˆ˜ âˆšá¾±_T   = {np.sqrt(alpha_bars[-1]):.6f}\")\n",
    "print(f\"ë…¸ì´ì¦ˆ ê³„ìˆ˜ âˆš(1-á¾±_T) = {np.sqrt(1-alpha_bars[-1]):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ë² íƒ€ ìŠ¤ì¼€ì¤„ ë° ì•ŒíŒŒ ëˆ„ì ê³± ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# (1) ë² íƒ€ ìŠ¤ì¼€ì¤„\n",
    "ax1 = axes[0]\n",
    "ax1.plot(range(1, T+1), betas, 'b-', lw=2)\n",
    "ax1.set_xlabel('Timestep $t$', fontsize=11)\n",
    "ax1.set_ylabel(r'$\\beta_t$', fontsize=11)\n",
    "ax1.set_title(r'Linear $\\beta$ Schedule', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# (2) ì•ŒíŒŒ ëˆ„ì ê³±\n",
    "ax2 = axes[1]\n",
    "ax2.plot(range(1, T+1), alpha_bars, 'r-', lw=2)\n",
    "ax2.set_xlabel('Timestep $t$', fontsize=11)\n",
    "ax2.set_ylabel(r'$\\bar{\\alpha}_t$', fontsize=11)\n",
    "ax2.set_title(r'Cumulative $\\bar{\\alpha}_t$', fontweight='bold')\n",
    "ax2.axhline(y=0.5, color='gray', ls='--', lw=1, label=r'$\\bar{\\alpha}_t = 0.5$')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# (3) ì‹ í˜¸/ë…¸ì´ì¦ˆ ê³„ìˆ˜\n",
    "ax3 = axes[2]\n",
    "ax3.plot(range(1, T+1), np.sqrt(alpha_bars), 'g-', lw=2, label=r'Signal: $\\sqrt{\\bar{\\alpha}_t}$')\n",
    "ax3.plot(range(1, T+1), np.sqrt(1 - alpha_bars), 'm-', lw=2, label=r'Noise: $\\sqrt{1-\\bar{\\alpha}_t}$')\n",
    "ax3.set_xlabel('Timestep $t$', fontsize=11)\n",
    "ax3.set_ylabel('Coefficient', fontsize=11)\n",
    "ax3.set_title('Signal vs Noise Coefficients', fontweight='bold')\n",
    "ax3.legend(fontsize=9)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('beta_schedule.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/beta_schedule.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward Noising ê³¼ì • ì‹œê°í™” <a name='3.-Forward-Noising-ì‹œê°í™”'></a>\n",
    "\n",
    "2D ê°€ìš°ì‹œì•ˆ ë¶„í¬ì—ì„œ ì‹œì‘í•˜ì—¬ Forward Processê°€ ì–´ë–»ê²Œ ë°ì´í„°ë¥¼ ìˆœìˆ˜ ë…¸ì´ì¦ˆë¡œ ë³€í™˜í•˜ëŠ”ì§€ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$x_t = \\sqrt{\\bar{\\alpha}_t}\\,x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Forward Process: 2D ê°€ìš°ì‹œì•ˆì— ë…¸ì´ì¦ˆ ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2D ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸ (ì›ë³¸ ë°ì´í„°)\n",
    "n_samples = 2000\n",
    "\n",
    "# 3ê°œì˜ ê°€ìš°ì‹œì•ˆ í´ëŸ¬ìŠ¤í„°ë¡œ \"ë°ì´í„° ë¶„í¬\" ìƒì„±\n",
    "centers = np.array([[2.0, 2.0], [-2.0, 2.0], [0.0, -2.0]])\n",
    "x0_list = []\n",
    "for c in centers:\n",
    "    samples = np.random.randn(n_samples // 3, 2) * 0.4 + c\n",
    "    x0_list.append(samples)\n",
    "x0 = np.concatenate(x0_list, axis=0).astype(np.float32)\n",
    "\n",
    "# Forward Process ì ìš©: ì—¬ëŸ¬ ì‹œì ì—ì„œì˜ x_t\n",
    "timesteps_to_show = [0, 50, 200, 500, 800, 999]\n",
    "noised_samples = {}\n",
    "\n",
    "for t in timesteps_to_show:\n",
    "    if t == 0:\n",
    "        noised_samples[t] = x0.copy()\n",
    "    else:\n",
    "        abar = alpha_bars[t - 1]\n",
    "        eps = np.random.randn(*x0.shape).astype(np.float32)\n",
    "        x_t = np.sqrt(abar) * x0 + np.sqrt(1 - abar) * eps\n",
    "        noised_samples[t] = x_t\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
    "\n",
    "for idx, t in enumerate(timesteps_to_show):\n",
    "    ax = axes[idx]\n",
    "    data = noised_samples[t]\n",
    "    ax.scatter(data[:, 0], data[:, 1], s=1, alpha=0.3, c='steelblue')\n",
    "    abar_val = 1.0 if t == 0 else alpha_bars[t - 1]\n",
    "    ax.set_title(f'$t={t}$\\n' + r'$\\bar{\\alpha}=$' + f'{abar_val:.4f}', fontweight='bold', fontsize=9)\n",
    "    ax.set_xlim(-5, 5)\n",
    "    ax.set_ylim(-5, 5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Forward Diffusion Process on 2D Gaussian Mixture', fontweight='bold', fontsize=12, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig('forward_noising.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/forward_noising.png\")\n",
    "print(f\"\\nì‹œì ë³„ ë°ì´í„° í†µê³„:\")\n",
    "for t in timesteps_to_show:\n",
    "    d = noised_samples[t]\n",
    "    print(f\"  t={t:4d} | í‰ê· : ({d[:,0].mean():.3f}, {d[:,1].mean():.3f}) | í‘œì¤€í¸ì°¨: ({d[:,0].std():.3f}, {d[:,1].std():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë‹¤ì–‘í•œ íƒ€ì„ìŠ¤í…ì—ì„œì˜ ë…¸ì´ì¦ˆ ì‹œê°í™” <a name='4.-íƒ€ì„ìŠ¤í…ë³„-ë…¸ì´ì¦ˆ'></a>\n",
    "\n",
    "1D ì‹ í˜¸ì— ëŒ€í•´ Forward Processë¥¼ ì ìš©í•˜ì—¬, ì‹œì ë³„ **ì‹ í˜¸ ëŒ€ ë…¸ì´ì¦ˆ ë¹„ìœ¨(SNR)**ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "$$\\text{SNR}(t) = \\frac{\\bar{\\alpha}_t}{1 - \\bar{\\alpha}_t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 1D ì‹ í˜¸ì— ëŒ€í•œ íƒ€ì„ìŠ¤í…ë³„ ë…¸ì´ì¦ˆ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1D ì›ë³¸ ì‹ í˜¸: ì‚¬ì¸íŒŒ\n",
    "x_axis = np.linspace(0, 4 * np.pi, 200)\n",
    "signal = np.sin(x_axis).astype(np.float32)\n",
    "\n",
    "timesteps_demo = [0, 100, 300, 500, 700, 999]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 7))\n",
    "\n",
    "for idx, t in enumerate(timesteps_demo):\n",
    "    row, col = divmod(idx, 3)\n",
    "    ax = axes[row][col]\n",
    "\n",
    "    if t == 0:\n",
    "        noised = signal.copy()\n",
    "        abar = 1.0\n",
    "    else:\n",
    "        abar = alpha_bars[t - 1]\n",
    "        eps = np.random.randn(*signal.shape).astype(np.float32)\n",
    "        noised = np.sqrt(abar) * signal + np.sqrt(1 - abar) * eps\n",
    "\n",
    "    ax.plot(x_axis, signal, 'b-', alpha=0.3, lw=1, label='ì›ë³¸ ì‹ í˜¸')\n",
    "    ax.plot(x_axis, noised, 'r-', lw=1.5, label=f'$x_t$ (t={t})')\n",
    "\n",
    "    snr = abar / (1 - abar + 1e-10)\n",
    "    ax.set_title(f't={t} | ' + r'$\\bar{\\alpha}$=' + f'{abar:.4f} | SNR={snr:.2f}', fontweight='bold', fontsize=9)\n",
    "    ax.legend(fontsize=8, loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(-3.5, 3.5)\n",
    "\n",
    "plt.suptitle('Forward Process: 1D ì‚¬ì¸íŒŒì— ëŒ€í•œ íƒ€ì„ìŠ¤í…ë³„ ë…¸ì´ì¦ˆ', fontweight='bold', fontsize=12, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('timestep_noise.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/timestep_noise.png\")\n",
    "\n",
    "# SNR ë¶„ì„\n",
    "print(\"\\níƒ€ì„ìŠ¤í…ë³„ SNR (Signal-to-Noise Ratio):\")\n",
    "print(f\"{'ì‹œì ':>6} | {'á¾±_t':>10} | {'SNR':>10} | {'SNR(dB)':>10}\")\n",
    "print(\"-\" * 48)\n",
    "for t in [1, 100, 250, 500, 750, 1000]:\n",
    "    abar = alpha_bars[t-1]\n",
    "    snr = abar / (1 - abar + 1e-10)\n",
    "    snr_db = 10 * np.log10(snr + 1e-10)\n",
    "    print(f\"  t={t:4d} | {abar:10.6f} | {snr:10.4f} | {snr_db:10.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 1D DDPM í•™ìŠµ ë£¨í”„ êµ¬í˜„ <a name='5.-1D-DDPM-í•™ìŠµ'></a>\n",
    "\n",
    "ê°„ë‹¨í•œ 1D ë°ì´í„° ë¶„í¬(ê°€ìš°ì‹œì•ˆ í˜¼í•©)ì— ëŒ€í•´ DDPMì˜ í•™ìŠµê³¼ ìƒ˜í”Œë§ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ (Algorithm 1 from Ho et al.):**\n",
    "1. $x_0 \\sim q(x_0)$ì—ì„œ ë°ì´í„° ìƒ˜í”Œë§\n",
    "2. $t \\sim \\text{Uniform}\\{1, \\ldots, T\\}$ì—ì„œ ì‹œì  ìƒ˜í”Œë§\n",
    "3. $\\epsilon \\sim \\mathcal{N}(0, I)$ì—ì„œ ë…¸ì´ì¦ˆ ìƒ˜í”Œë§\n",
    "4. ê·¸ë˜ë””ì–¸íŠ¸ ìŠ¤í…: $\\nabla_\\theta \\|\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{\\alpha}_t}\\,x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon,\\, t)\\|^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 1D DDPM í•™ìŠµ ë° ìƒ˜í”Œë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "T_steps = 200\n",
    "beta_min_1d = 1e-4\n",
    "beta_max_1d = 0.02\n",
    "betas_1d = np.linspace(beta_min_1d, beta_max_1d, T_steps).astype(np.float32)\n",
    "alphas_1d = 1.0 - betas_1d\n",
    "alpha_bars_1d = np.cumprod(alphas_1d).astype(np.float32)\n",
    "\n",
    "# 1D ë°ì´í„° ë¶„í¬: 2ê°œì˜ ê°€ìš°ì‹œì•ˆ í˜¼í•©\n",
    "def sample_data(n):\n",
    "    mix = np.random.choice([0, 1], size=n)\n",
    "    samples = np.where(mix == 0,\n",
    "                       np.random.randn(n) * 0.5 + 3.0,\n",
    "                       np.random.randn(n) * 0.5 - 3.0)\n",
    "    return samples.astype(np.float32)\n",
    "\n",
    "# ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ëª¨ë¸ (ê°„ë‹¨í•œ MLP)\n",
    "class NoisePredictor(tf.keras.Model):\n",
    "    # 1D ë…¸ì´ì¦ˆ ì˜ˆì¸¡ MLP: (x_t, t_embedding) -> epsilon\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time_embed = tf.keras.layers.Dense(64, activation='swish')\n",
    "        self.net = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='swish'),\n",
    "            tf.keras.layers.Dense(128, activation='swish'),\n",
    "            tf.keras.layers.Dense(64, activation='swish'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, x_t, t):\n",
    "        t_emb = self.time_embed(tf.cast(t[:, None], tf.float32) / T_steps)\n",
    "        x_input = tf.concat([x_t[:, None], t_emb], axis=-1)\n",
    "        return self.net(x_input)[:, 0]\n",
    "\n",
    "model = NoisePredictor()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "alpha_bars_tf = tf.constant(alpha_bars_1d)\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„\n",
    "losses = []\n",
    "n_epochs = 300\n",
    "batch_size = 512\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    x0_batch = sample_data(batch_size)\n",
    "    t_batch = np.random.randint(0, T_steps, size=batch_size)\n",
    "    eps_batch = np.random.randn(batch_size).astype(np.float32)\n",
    "\n",
    "    abar_t = alpha_bars_1d[t_batch]\n",
    "    x_t = np.sqrt(abar_t) * x0_batch + np.sqrt(1 - abar_t) * eps_batch\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        eps_pred = model(tf.constant(x_t), tf.constant(t_batch))\n",
    "        loss = tf.reduce_mean((tf.constant(eps_batch) - eps_pred) ** 2)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    losses.append(float(loss))\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1:4d}/{n_epochs} | Loss: {float(loss):.4f}\")\n",
    "\n",
    "print(f\"\\nìµœì¢… í•™ìŠµ Loss: {losses[-1]:.4f}\")\n",
    "print(f\"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(np.prod(v.shape) for v in model.trainable_variables):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ DDPM ìƒ˜í”Œë§ (ì—­ë°©í–¥ ê³¼ì •) ë° ê²°ê³¼ ë¹„êµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Reverse Process: x_T ~ N(0,1) â†’ x_0\n",
    "n_gen = 3000\n",
    "x_t = np.random.randn(n_gen).astype(np.float32)\n",
    "\n",
    "# ì—­ë°©í–¥ ìƒ˜í”Œë§\n",
    "for t in reversed(range(T_steps)):\n",
    "    t_tensor = tf.constant(np.full(n_gen, t, dtype=np.int32))\n",
    "    eps_pred = model(tf.constant(x_t), t_tensor).numpy()\n",
    "\n",
    "    alpha_t = alphas_1d[t]\n",
    "    abar_t = alpha_bars_1d[t]\n",
    "    beta_t = betas_1d[t]\n",
    "\n",
    "    # í‰ê·  ê³„ì‚°: mu_theta\n",
    "    mu = (1.0 / np.sqrt(alpha_t)) * (x_t - (beta_t / np.sqrt(1 - abar_t)) * eps_pred)\n",
    "\n",
    "    if t > 0:\n",
    "        z = np.random.randn(n_gen).astype(np.float32)\n",
    "        sigma = np.sqrt(beta_t)\n",
    "        x_t = mu + sigma * z\n",
    "    else:\n",
    "        x_t = mu\n",
    "\n",
    "generated = x_t\n",
    "\n",
    "# ì‹œê°í™”: ì›ë³¸ ë¶„í¬ vs ìƒì„± ë¶„í¬\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# (1) í•™ìŠµ Loss ê³¡ì„ \n",
    "ax1 = axes[0]\n",
    "ax1.plot(losses, 'b-', lw=1, alpha=0.5)\n",
    "window = 20\n",
    "smoothed = np.convolve(losses, np.ones(window)/window, mode='valid')\n",
    "ax1.plot(range(window-1, len(losses)), smoothed, 'r-', lw=2, label=f'{window}-ì—í­ ì´ë™í‰ê· ')\n",
    "ax1.set_xlabel('Epoch', fontsize=11)\n",
    "ax1.set_ylabel('Loss', fontsize=11)\n",
    "ax1.set_title('í•™ìŠµ Loss ê³¡ì„ ', fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# (2) ì›ë³¸ vs ìƒì„± ë¶„í¬\n",
    "real_data = sample_data(n_gen)\n",
    "ax2 = axes[1]\n",
    "ax2.hist(real_data, bins=80, density=True, alpha=0.6, color='steelblue', label='ì›ë³¸ ë¶„í¬')\n",
    "ax2.hist(generated, bins=80, density=True, alpha=0.6, color='coral', label='ìƒì„± ë¶„í¬')\n",
    "ax2.set_xlabel('x', fontsize=11)\n",
    "ax2.set_ylabel('Density', fontsize=11)\n",
    "ax2.set_title('ì›ë³¸ vs DDPM ìƒì„± ë¶„í¬', fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# (3) í•™ìŠµ ê³¡ì„  (ë¡œê·¸ ìŠ¤ì¼€ì¼)\n",
    "ax3 = axes[2]\n",
    "ax3.semilogy(smoothed, 'r-', lw=2)\n",
    "ax3.set_xlabel('Epoch', fontsize=11)\n",
    "ax3.set_ylabel('Loss (log)', fontsize=11)\n",
    "ax3.set_title('Loss ê³¡ì„  (ë¡œê·¸ ìŠ¤ì¼€ì¼)', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ddpm_1d_result.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/ddpm_1d_result.png\")\n",
    "\n",
    "# í†µê³„ ë¹„êµ\n",
    "print(f\"\\në¶„í¬ í†µê³„ ë¹„êµ:\")\n",
    "print(f\"{'':>12} | {'í‰ê· ':>8} | {'í‘œì¤€í¸ì°¨':>8} | {'ìµœì†Œ':>8} | {'ìµœëŒ€':>8}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'ì›ë³¸ ë¶„í¬':>12} | {real_data.mean():>8.3f} | {real_data.std():>8.3f} | {real_data.min():>8.3f} | {real_data.max():>8.3f}\")\n",
    "print(f\"{'ìƒì„± ë¶„í¬':>12} | {generated.mean():>8.3f} | {generated.std():>8.3f} | {generated.min():>8.3f} | {generated.max():>8.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì •ë¦¬ <a name='6.-ì •ë¦¬'></a>\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |\n",
    "|------|------|--------|\n",
    "| Forward Process | $q(x_t \\mid x_0) = \\mathcal{N}(\\sqrt{\\bar\\alpha_t}x_0, (1-\\bar\\alpha_t)I)$ â€” ë°ì´í„°ì— ì ì§„ì  ë…¸ì´ì¦ˆ ì¶”ê°€ | â­â­â­ |\n",
    "| Reparameterization | $x_t = \\sqrt{\\bar\\alpha_t}x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon$ â€” í•œ ë²ˆì— $x_t$ ê³„ì‚° | â­â­â­ |\n",
    "| Reverse Process | $\\mu_\\theta = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar\\alpha_t}}\\epsilon_\\theta)$ â€” ë…¸ì´ì¦ˆ ì œê±° | â­â­â­ |\n",
    "| Simple Loss | $\\|\\epsilon - \\epsilon_\\theta(x_t, t)\\|^2$ â€” ELBOì—ì„œ ìœ ë„ëœ ë‹¨ìˆœí™” ëª©ì í•¨ìˆ˜ | â­â­â­ |\n",
    "| ë² íƒ€ ìŠ¤ì¼€ì¤„ | $\\beta_t$ì˜ ìŠ¤ì¼€ì¤„ì´ ìƒì„± í’ˆì§ˆì— ê²°ì •ì  ì˜í–¥ | â­â­ |\n",
    "| $\\bar\\alpha_t$ ëˆ„ì ê³± | Forward Processì˜ í•µì‹¬ â€” ì›ë³¸ ì‹ í˜¸ ë³´ì¡´ ë¹„ìœ¨ | â­â­â­ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$q(x_t \\mid x_0) = \\mathcal{N}\\!\\left(x_t;\\, \\sqrt{\\bar\\alpha_t}\\,x_0,\\, (1-\\bar\\alpha_t)I\\right)$$\n",
    "\n",
    "$$\\mathcal{L}_{simple} = \\mathbb{E}_{t,x_0,\\epsilon}\\!\\left[\\|\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar\\alpha_t}\\,x_0 + \\sqrt{1-\\bar\\alpha_t}\\,\\epsilon,\\, t)\\|^2\\right]$$\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**02_noise_schedules_and_samplers** â€” Linear/Cosine/EDM ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„ ë¹„êµì™€ DDIM ê°€ì† ìƒ˜í”Œë§ì„ ë‹¤ë£¹ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}