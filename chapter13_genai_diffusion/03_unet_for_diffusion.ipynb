{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: ìƒì„± AI ì‹¬í™” â€” í™•ì‚° ëª¨ë¸ìš© UNet ì•„í‚¤í…ì²˜\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- **Sinusoidal Time Embedding**ì˜ ìˆ˜ì‹ê³¼ êµ¬í˜„ì„ ì´í•´í•˜ê³  ì‹œê°„ ì •ë³´ê°€ ëª¨ë¸ì— ì£¼ì…ë˜ëŠ” ì›ë¦¬ë¥¼ íŒŒì•…í•œë‹¤\n",
    "- **ì”ì°¨ ë¸”ë¡(Residual Block)**ì— ì‹œê°„ ì¡°ê±´ì„ ê²°í•©í•˜ëŠ” ë°©ë²•ì„ êµ¬í˜„í•œë‹¤\n",
    "- **Cross-Attention** ë©”ì»¤ë‹ˆì¦˜ì´ í…ìŠ¤íŠ¸/í´ë˜ìŠ¤ ì¡°ê±´ ì •ë³´ë¥¼ UNetì— ì „ë‹¬í•˜ëŠ” ê³¼ì •ì„ ì´í•´í•œë‹¤\n",
    "- MNIST(28Ã—28)ìš© **ê°„ë‹¨í•œ UNet ì•„í‚¤í…ì²˜**ë¥¼ ë°‘ë°”ë‹¥ë¶€í„° TensorFlowë¡œ êµ¬í˜„í•œë‹¤\n",
    "- UNetì˜ **ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°**ì™€ **Skip Connection**ì´ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ì— ì¤‘ìš”í•œ ì´ìœ ë¥¼ ë¶„ì„í•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: ì‹œê°„ ì„ë² ë”©ê³¼ Cross-Attention](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [Sinusoidal Time Embedding êµ¬í˜„](#2.-ì‹œê°„-ì„ë² ë”©)\n",
    "3. [ì”ì°¨ ë¸”ë¡ê³¼ ì‹œê°„ ì¡°ê±´ ì£¼ì…](#3.-ì”ì°¨-ë¸”ë¡)\n",
    "4. [28Ã—28 MNISTìš© UNet êµ¬í˜„](#4.-UNet-êµ¬í˜„)\n",
    "5. [UNet íŠ¹ì§• ë§µ ê°œë… ì‹œê°í™”](#5.-íŠ¹ì§•-ë§µ-ì‹œê°í™”)\n",
    "6. [ì •ë¦¬](#6.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>\n",
    "\n",
    "### Sinusoidal Time Embedding\n",
    "\n",
    "Transformerì˜ ìœ„ì¹˜ ì¸ì½”ë”©(Vaswani et al., 2017)ì„ ì‹œê°„ $t$ì— ì ìš©í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$PE(t, 2i) = \\sin\\!\\left(\\frac{t}{10000^{2i/d}}\\right), \\quad PE(t, 2i+1) = \\cos\\!\\left(\\frac{t}{10000^{2i/d}}\\right)$$\n",
    "\n",
    "- $t$: í˜„ì¬ í™•ì‚° íƒ€ì„ìŠ¤í… (ì •ìˆ˜)\n",
    "- $d$: ì„ë² ë”© ì°¨ì› (ë³´í†µ 128 ë˜ëŠ” 256)\n",
    "- $i = 0, 1, \\ldots, d/2 - 1$: ì£¼íŒŒìˆ˜ ì¸ë±ìŠ¤\n",
    "- $10000^{2i/d}$: ì£¼íŒŒìˆ˜ê°€ $i$ì— ë”°ë¼ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€ â†’ ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì˜ ì‹œê°„ ì •ë³´ ì¸ì½”ë”©\n",
    "\n",
    "**ì™œ ì‚¬ì¸/ì½”ì‚¬ì¸ì¸ê°€?**\n",
    "\n",
    "| íŠ¹ì„± | ì„¤ëª… |\n",
    "|------|------|\n",
    "| ìœ ì¼ì„± | ëª¨ë“  $t$ì— ëŒ€í•´ ê³ ìœ í•œ ë²¡í„° ìƒì„± |\n",
    "| ì—°ì†ì„± | ì¸ì ‘ $t$ ê°’ì˜ ì„ë² ë”©ì´ ìœ ì‚¬ |\n",
    "| ì£¼ê¸°ì„± | ì €ì°¨ì›: ë¹ ë¥¸ ì§„ë™ (ë¯¸ì„¸ ì‹œê°„), ê³ ì°¨ì›: ëŠë¦° ì§„ë™ (ê±°ì‹œ ì‹œê°„) |\n",
    "| ì™¸ì‚½ | í•™ìŠµ ì‹œ ë³´ì§€ ëª»í•œ $t$ ê°’ì—ë„ ì˜ë¯¸ ìˆëŠ” ì„ë² ë”© ì œê³µ |\n",
    "\n",
    "### Cross-Attention (ì¡°ê±´ ì£¼ì…)\n",
    "\n",
    "í…ìŠ¤íŠ¸/í´ë˜ìŠ¤ ë“± ì™¸ë¶€ ì¡°ê±´ $c$ë¥¼ UNet ì¤‘ê°„ íŠ¹ì§•ì— ì£¼ì…í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\!\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "**Self-Attention vs Cross-Attention:**\n",
    "\n",
    "| êµ¬ë¶„ | Q ì¶œì²˜ | K, V ì¶œì²˜ |\n",
    "|------|--------|-----------|\n",
    "| Self-Attention | ì´ë¯¸ì§€ íŠ¹ì§• $h$ | ì´ë¯¸ì§€ íŠ¹ì§• $h$ |\n",
    "| Cross-Attention | ì´ë¯¸ì§€ íŠ¹ì§• $h$ | ì¡°ê±´ ì„ë² ë”© $c$ (í…ìŠ¤íŠ¸ ë“±) |\n",
    "\n",
    "$$Q = hW^Q, \\quad K = cW^K, \\quad V = cW^V$$\n",
    "\n",
    "- $h \\in \\mathbb{R}^{HW \\times d}$: UNet ì¤‘ê°„ì¸µ íŠ¹ì§• ë§µ (flatten)\n",
    "- $c \\in \\mathbb{R}^{L \\times d_c}$: ì¡°ê±´ ì‹œí€€ìŠ¤ (í…ìŠ¤íŠ¸ í† í° ì„ë² ë”© ë“±)\n",
    "- $W^Q \\in \\mathbb{R}^{d \\times d_k}$, $W^K \\in \\mathbb{R}^{d_c \\times d_k}$, $W^V \\in \\mathbb{R}^{d_c \\times d_v}$\n",
    "\n",
    "### DDPM UNet ì „ì²´ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "ì…ë ¥ x_t (noisy image) + t (timestep)\n",
    "    â”‚\n",
    "    â–¼\n",
    "[Sinusoidal Embedding(t)] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚                                        â”‚ (ì‹œê°„ ì¡°ê±´)\n",
    "    â–¼                                        â”‚\n",
    "[Encoder Block 1] â”€â”€â”€ skip â”€â”€â”€â”€â”€â”€â”€â”         â”‚\n",
    "    â”‚ â†“ Downsample                â”‚         â”‚\n",
    "[Encoder Block 2] â”€â”€â”€ skip â”€â”€â”   â”‚         â”‚\n",
    "    â”‚ â†“ Downsample            â”‚   â”‚         â”‚\n",
    "[Bottleneck (Attention)]      â”‚   â”‚    t_embâ”‚\n",
    "    â”‚ â†‘ Upsample              â”‚   â”‚         â”‚\n",
    "[Decoder Block 2] â† concat â”€â”€â”˜   â”‚         â”‚\n",
    "    â”‚ â†‘ Upsample                  â”‚         â”‚\n",
    "[Decoder Block 1] â† concat â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "    â”‚                                        â”‚\n",
    "    â–¼                                        â”‚\n",
    "[ì¶œë ¥ Conv] â†’ Îµ_Î¸(x_t, t) (ì˜ˆì¸¡ ë…¸ì´ì¦ˆ)    â”‚\n",
    "```\n",
    "\n",
    "**ìš”ì•½ í‘œ:**\n",
    "\n",
    "| êµ¬ì„± ìš”ì†Œ | ìˆ˜ì‹/ì—­í•  | MNIST UNet ì„¤ì • |\n",
    "|-----------|-----------|----------------|\n",
    "| Time Embedding | $\\sin/\\cos$ + MLP | $d=128$ |\n",
    "| Residual Block | $h + F(h, t_{emb})$ | Conv3Ã—3 + GroupNorm |\n",
    "| Skip Connection | Encoder â†’ Decoder concat | ì±„ë„ ì¶• ì—°ê²° |\n",
    "| Cross-Attention | $\\text{softmax}(QK^T/\\sqrt{d})V$ | (ì˜µì…˜) ì¡°ê±´ë¶€ ìƒì„± ì‹œ |\n",
    "| Down/Upsample | MaxPool / UpSampling2D | 2Ã— ìŠ¤ì¼€ì¼ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ UNet ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ”¢ UNetì´ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: UNetì€ **ëª¨ë˜ì‹œê³„** ëª¨ì–‘ì˜ ì‹ ê²½ë§ì´ì—ìš”!\n",
    "> - **ìœ„ìª½ (ì¸ì½”ë”)**: ê·¸ë¦¼ì„ ì ì  **ì‘ê²Œ ì¤„ì´ë©´ì„œ** í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•´ìš” (ì••ì¶•)\n",
    "> - **ê°€ìš´ë° (ë³‘ëª©)**: ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë§Œ ë‚¨ì•„ìš”\n",
    "> - **ì•„ë˜ìª½ (ë””ì½”ë”)**: ë‹¤ì‹œ **í¬ê²Œ í‚¤ìš°ë©´ì„œ** ì„¸ë¶€ ì‚¬í•­ì„ ë³µì›í•´ìš”\n",
    "> - **ê±´ë„ˆë›°ê¸° ì—°ê²°**: ìœ„ìª½ì—ì„œ ì•„ë˜ìª½ìœ¼ë¡œ **ì§€ë¦„ê¸¸**ì„ ë§Œë“¤ì–´, ì„¸ë¶€ ì •ë³´ê°€ ì‚¬ë¼ì§€ì§€ ì•Šê²Œ í•´ìš”!\n",
    "\n",
    "#### â° ì‹œê°„ ì„ë² ë”©ì€ ì™œ í•„ìš”í•œê°€ìš”?\n",
    "\n",
    "| ì§ˆë¬¸ | ë‹µë³€ |\n",
    "|------|------|\n",
    "| ì™œ? | UNetì´ \"ì§€ê¸ˆ $t=100$ì´ì•¼\" vs \"$t=900$ì´ì•¼\"ë¥¼ êµ¬ë¶„í•´ì•¼ í•´ìš” |\n",
    "| ì–´ë–»ê²Œ? | ì‹œê°„ $t$ë¥¼ ì‚¬ì¸/ì½”ì‚¬ì¸ íŒŒë™ íŒ¨í„´ìœ¼ë¡œ ë°”ê¿”ì„œ ëª¨ë“  ì¸µì— ì•Œë ¤ì¤˜ìš” |\n",
    "| ë¹„ìœ  | ì‹œí—˜ì§€ì— **ëª‡ êµì‹œì¸ì§€** ì í˜€ ìˆì–´ì•¼ ì–´ë–¤ ê³¼ëª©ì¸ì§€ ì•„ëŠ” ê²ƒê³¼ ê°™ì•„ìš”! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: Sinusoidal Embedding ê³„ì‚°\n",
    "\n",
    "$t=50$, $d=4$ì¼ ë•Œ, ì‹œê°„ ì„ë² ë”© ë²¡í„°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$d=4$ì´ë¯€ë¡œ $i = 0, 1$ (ì£¼íŒŒìˆ˜ ì¸ë±ìŠ¤ 2ê°œ)\n",
    "\n",
    "$$PE(50, 0) = \\sin\\!\\left(\\frac{50}{10000^{0/4}}\\right) = \\sin(50) \\approx -0.2624$$\n",
    "\n",
    "$$PE(50, 1) = \\cos\\!\\left(\\frac{50}{10000^{0/4}}\\right) = \\cos(50) \\approx 0.9649$$\n",
    "\n",
    "$$PE(50, 2) = \\sin\\!\\left(\\frac{50}{10000^{2/4}}\\right) = \\sin(0.5) \\approx 0.4794$$\n",
    "\n",
    "$$PE(50, 3) = \\cos\\!\\left(\\frac{50}{10000^{2/4}}\\right) = \\cos(0.5) \\approx 0.8776$$\n",
    "\n",
    "ì„ë² ë”© ë²¡í„°: $[-0.2624,\\, 0.9649,\\, 0.4794,\\, 0.8776]$\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: Skip Connectionì˜ ì—­í• \n",
    "\n",
    "UNetì—ì„œ Skip Connectionì„ ì œê±°í•˜ë©´ ì–´ë–¤ ë¬¸ì œê°€ ë°œìƒí• ê¹Œìš”?\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "Skip Connection ì—†ì´ëŠ”:\n",
    "1. ë””ì½”ë”ê°€ ì¸ì½”ë”ì—ì„œ ì†ì‹¤ëœ **ê³ í•´ìƒë„ ì„¸ë¶€ ì •ë³´**(ì—£ì§€, í…ìŠ¤ì²˜)ë¥¼ ë³µì›í•˜ê¸° ì–´ë ¤ì›€\n",
    "2. ë…¸ì´ì¦ˆ ì˜ˆì¸¡ $\\epsilon_\\theta$ì˜ **ê³µê°„ì  ì •ë°€ë„** ì €í•˜\n",
    "3. ìƒì„±ëœ ì´ë¯¸ì§€ê°€ **íë¦¿í•˜ê³  ë””í…Œì¼ ë¶€ì¡±**\n",
    "\n",
    "Skip Connectionì€ ì¸ì½”ë”ì˜ ê³ í•´ìƒë„ íŠ¹ì§•ì„ ë””ì½”ë”ì— ì§ì ‘ ì „ë‹¬í•˜ì—¬, **ìœ„ì¹˜ ì •ë°€ë„**ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "ì´ëŠ” ì›ë˜ ì˜ë£Œ ì˜ìƒ ë¶„í• (Ronneberger et al., 2015)ì„ ìœ„í•´ ì„¤ê³„ëœ UNetì˜ í•µì‹¬ ê¸°ì—¬ì…ë‹ˆë‹¤.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sinusoidal Time Embedding êµ¬í˜„ <a name='2.-ì‹œê°„-ì„ë² ë”©'></a>\n",
    "\n",
    "ê° í™•ì‚° íƒ€ì„ìŠ¤í… $t$ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. Transformer ìœ„ì¹˜ ì¸ì½”ë”©ê³¼ ë™ì¼í•œ ì›ë¦¬ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Sinusoidal Time Embedding êµ¬í˜„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def sinusoidal_embedding(t, dim):\n",
    "    # t: (batch,) ì •ìˆ˜ í…ì„œ, dim: ì„ë² ë”© ì°¨ì›\n",
    "    half_dim = dim // 2\n",
    "    freqs = tf.exp(\n",
    "        -tf.math.log(10000.0) * tf.range(half_dim, dtype=tf.float32) / half_dim\n",
    "    )\n",
    "    # të¥¼ floatë¡œ ë³€í™˜í•˜ì—¬ ì™¸ì  ê³„ì‚°\n",
    "    t_float = tf.cast(t, tf.float32)\n",
    "    args = t_float[:, None] * freqs[None, :]  # (batch, half_dim)\n",
    "    embedding = tf.concat([tf.sin(args), tf.cos(args)], axis=-1)  # (batch, dim)\n",
    "    return embedding\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_t = tf.constant([0, 50, 100, 500, 999])\n",
    "test_emb = sinusoidal_embedding(test_t, dim=128)\n",
    "print(f\"ì…ë ¥ íƒ€ì„ìŠ¤í…: {test_t.numpy()}\")\n",
    "print(f\"ì„ë² ë”© shape: {test_emb.shape}\")\n",
    "print(f\"\\nt=0   ì„ë² ë”© (ì²˜ìŒ 8ê°œ): {test_emb[0, :8].numpy().round(4)}\")\n",
    "print(f\"t=50  ì„ë² ë”© (ì²˜ìŒ 8ê°œ): {test_emb[1, :8].numpy().round(4)}\")\n",
    "print(f\"t=500 ì„ë² ë”© (ì²˜ìŒ 8ê°œ): {test_emb[3, :8].numpy().round(4)}\")\n",
    "print(f\"t=999 ì„ë² ë”© (ì²˜ìŒ 8ê°œ): {test_emb[4, :8].numpy().round(4)}\")\n",
    "\n",
    "# ì„ë² ë”© ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "def cosine_sim(a, b):\n",
    "    return float(tf.reduce_sum(a * b) / (tf.norm(a) * tf.norm(b)))\n",
    "\n",
    "print(f\"\\nì½”ì‚¬ì¸ ìœ ì‚¬ë„:\")\n",
    "print(f\"  sim(t=0,   t=50)  = {cosine_sim(test_emb[0], test_emb[1]):.4f}\")\n",
    "print(f\"  sim(t=50,  t=100) = {cosine_sim(test_emb[1], test_emb[2]):.4f}\")\n",
    "print(f\"  sim(t=0,   t=999) = {cosine_sim(test_emb[0], test_emb[4]):.4f}\")\n",
    "print(f\"  sim(t=500, t=999) = {cosine_sim(test_emb[3], test_emb[4]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ì‹œê°„ ì„ë² ë”© íˆíŠ¸ë§µ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "all_t = tf.range(0, 1000)\n",
    "all_emb = sinusoidal_embedding(all_t, dim=128).numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# (1) íˆíŠ¸ë§µ: ì „ì²´ ì„ë² ë”©\n",
    "ax1 = axes[0]\n",
    "im = ax1.imshow(all_emb.T, aspect='auto', cmap='RdBu_r',\n",
    "                extent=[0, 1000, 128, 0], vmin=-1, vmax=1)\n",
    "ax1.set_xlabel('Timestep $t$', fontsize=11)\n",
    "ax1.set_ylabel('Embedding Dimension', fontsize=11)\n",
    "ax1.set_title('Sinusoidal Time Embedding (d=128)', fontweight='bold')\n",
    "plt.colorbar(im, ax=ax1, fraction=0.046, pad=0.04)\n",
    "\n",
    "# (2) ê°œë³„ ì°¨ì›ì˜ íŒŒë™\n",
    "ax2 = axes[1]\n",
    "dims_to_show = [0, 1, 16, 32, 63]\n",
    "t_range = np.arange(1000)\n",
    "for d_idx in dims_to_show:\n",
    "    ax2.plot(t_range, all_emb[:, d_idx], lw=1.5, label=f'dim {d_idx}', alpha=0.8)\n",
    "ax2.set_xlabel('Timestep $t$', fontsize=11)\n",
    "ax2.set_ylabel('Value', fontsize=11)\n",
    "ax2.set_title('Individual Dimension Waveforms', fontweight='bold')\n",
    "ax2.legend(fontsize=9, ncol=2)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter13_genai_diffusion/time_embedding.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/time_embedding.png\")\n",
    "print(f\"ì €ì°¨ì›(dim 0): ë¹ ë¥¸ ì§„ë™ â†’ ë¯¸ì„¸ ì‹œê°„ êµ¬ë¶„\")\n",
    "print(f\"ê³ ì°¨ì›(dim 63): ëŠë¦° ì§„ë™ â†’ ê±°ì‹œ ì‹œê°„ êµ¬ë¶„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì”ì°¨ ë¸”ë¡ê³¼ ì‹œê°„ ì¡°ê±´ ì£¼ì… <a name='3.-ì”ì°¨-ë¸”ë¡'></a>\n",
    "\n",
    "DDPM UNetì˜ ê¸°ë³¸ êµ¬ì„± ë‹¨ìœ„ì¸ **Residual Block**ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì‹œê°„ ì„ë² ë”© $t_{emb}$ê°€ ë¸”ë¡ ë‚´ë¶€ì— ì£¼ì…ë©ë‹ˆë‹¤:\n",
    "\n",
    "$$h' = \\text{Conv}(\\text{GN}(\\text{SiLU}(h))) + W_t \\cdot t_{emb}$$\n",
    "$$\\text{output} = h + \\text{Conv}(\\text{GN}(\\text{SiLU}(h')))$$\n",
    "\n",
    "- GN: Group Normalization (ë°°ì¹˜ í¬ê¸°ì— ë…ë¦½ì )\n",
    "- SiLU: $\\text{SiLU}(x) = x \\cdot \\sigma(x)$ (Swish í™œì„±í™”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ì”ì°¨ ë¸”ë¡ + ì‹œê°„ ì¡°ê±´ ì£¼ì… êµ¬í˜„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class ResidualBlock(layers.Layer):\n",
    "    # Conv â†’ GroupNorm â†’ SiLU â†’ Conv, with time embedding injection\n",
    "    def __init__(self, out_channels, n_groups=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.out_channels = out_channels\n",
    "        self.norm1 = layers.GroupNormalization(groups=n_groups)\n",
    "        self.conv1 = layers.Conv2D(out_channels, 3, padding='same')\n",
    "        self.time_proj = layers.Dense(out_channels)\n",
    "        self.norm2 = layers.GroupNormalization(groups=n_groups)\n",
    "        self.conv2 = layers.Conv2D(out_channels, 3, padding='same')\n",
    "        self.skip_conv = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if input_shape[-1] != self.out_channels:\n",
    "            self.skip_conv = layers.Conv2D(self.out_channels, 1)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x, t_emb):\n",
    "        residual = x\n",
    "\n",
    "        h = self.norm1(x)\n",
    "        h = tf.nn.silu(h)\n",
    "        h = self.conv1(h)\n",
    "\n",
    "        # ì‹œê°„ ì„ë² ë”© ì£¼ì…: (batch, dim) â†’ (batch, 1, 1, channels)\n",
    "        t_proj = tf.nn.silu(t_emb)\n",
    "        t_proj = self.time_proj(t_proj)[:, None, None, :]\n",
    "        h = h + t_proj\n",
    "\n",
    "        h = self.norm2(h)\n",
    "        h = tf.nn.silu(h)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        if self.skip_conv is not None:\n",
    "            residual = self.skip_conv(residual)\n",
    "\n",
    "        return h + residual\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_input = tf.random.normal([2, 28, 28, 1])\n",
    "test_t_emb = sinusoidal_embedding(tf.constant([100, 500]), dim=128)\n",
    "\n",
    "res_block = ResidualBlock(64)\n",
    "output = res_block(test_input, test_t_emb)\n",
    "print(f\"ResidualBlock í…ŒìŠ¤íŠ¸:\")\n",
    "print(f\"  ì…ë ¥ shape:  {test_input.shape}\")\n",
    "print(f\"  t_emb shape: {test_t_emb.shape}\")\n",
    "print(f\"  ì¶œë ¥ shape:  {output.shape}\")\n",
    "print(f\"  íŒŒë¼ë¯¸í„° ìˆ˜: {sum(np.prod(v.shape) for v in res_block.trainable_variables):,}\")\n",
    "print(f\"  ì¶œë ¥ í†µê³„: í‰ê· ={float(tf.reduce_mean(output)):.4f}, í‘œì¤€í¸ì°¨={float(tf.math.reduce_std(output)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 28Ã—28 MNISTìš© UNet êµ¬í˜„ <a name='4.-UNet-êµ¬í˜„'></a>\n",
    "\n",
    "MNIST(28Ã—28Ã—1)ì— ì í•©í•œ **ì†Œí˜• UNet**ì„ êµ¬í˜„í•©ë‹ˆë‹¤. êµ¬ì¡°:\n",
    "\n",
    "| ë‹¨ê³„ | í•´ìƒë„ | ì±„ë„ ìˆ˜ |\n",
    "|------|--------|---------|\n",
    "| ì…ë ¥ | 28Ã—28 | 1 |\n",
    "| Encoder 1 | 28Ã—28 â†’ 14Ã—14 | 32 |\n",
    "| Encoder 2 | 14Ã—14 â†’ 7Ã—7 | 64 |\n",
    "| Bottleneck | 7Ã—7 | 128 |\n",
    "| Decoder 2 | 7Ã—7 â†’ 14Ã—14 | 64 |\n",
    "| Decoder 1 | 14Ã—14 â†’ 28Ã—28 | 32 |\n",
    "| ì¶œë ¥ | 28Ã—28 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ MNIST 28x28 UNet ì•„í‚¤í…ì²˜ êµ¬í˜„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class SimpleUNet(keras.Model):\n",
    "    # Encoder-Bottleneck-Decoder with skip connections and time conditioning\n",
    "    def __init__(self, time_dim=128, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.time_dim = time_dim\n",
    "\n",
    "        # ì‹œê°„ ì„ë² ë”© MLP\n",
    "        self.time_mlp = keras.Sequential([\n",
    "            layers.Dense(time_dim, activation='swish'),\n",
    "            layers.Dense(time_dim),\n",
    "        ])\n",
    "\n",
    "        # ì…ë ¥ í”„ë¡œì ì…˜\n",
    "        self.input_conv = layers.Conv2D(32, 3, padding='same')\n",
    "\n",
    "        # ì¸ì½”ë”\n",
    "        self.enc1 = ResidualBlock(32)\n",
    "        self.down1 = layers.MaxPooling2D(2)   # 28â†’14\n",
    "        self.enc2 = ResidualBlock(64)\n",
    "        self.down2 = layers.MaxPooling2D(2)   # 14â†’7\n",
    "\n",
    "        # ë³‘ëª©\n",
    "        self.bottleneck1 = ResidualBlock(128)\n",
    "        self.bottleneck2 = ResidualBlock(128)\n",
    "\n",
    "        # ë””ì½”ë”\n",
    "        self.up2 = layers.UpSampling2D(2)     # 7â†’14\n",
    "        self.dec2 = ResidualBlock(64)\n",
    "        self.up1 = layers.UpSampling2D(2)     # 14â†’28\n",
    "        self.dec1 = ResidualBlock(32)\n",
    "\n",
    "        # ì¶œë ¥\n",
    "        self.output_norm = layers.GroupNormalization(groups=8)\n",
    "        self.output_conv = layers.Conv2D(1, 1)\n",
    "\n",
    "    def call(self, x, t):\n",
    "        # ì‹œê°„ ì„ë² ë”©\n",
    "        t_emb = sinusoidal_embedding(t, self.time_dim)\n",
    "        t_emb = self.time_mlp(t_emb)\n",
    "\n",
    "        # ì…ë ¥\n",
    "        h = self.input_conv(x)\n",
    "\n",
    "        # ì¸ì½”ë”\n",
    "        h1 = self.enc1(h, t_emb)          # 28Ã—28Ã—32\n",
    "        h = self.down1(h1)                  # 14Ã—14Ã—32\n",
    "        h2 = self.enc2(h, t_emb)           # 14Ã—14Ã—64\n",
    "        h = self.down2(h2)                  # 7Ã—7Ã—64\n",
    "\n",
    "        # ë³‘ëª©\n",
    "        h = self.bottleneck1(h, t_emb)     # 7Ã—7Ã—128\n",
    "        h = self.bottleneck2(h, t_emb)     # 7Ã—7Ã—128\n",
    "\n",
    "        # ë””ì½”ë” + Skip Connection\n",
    "        h = self.up2(h)                     # 14Ã—14Ã—128\n",
    "        h = tf.concat([h, h2], axis=-1)    # 14Ã—14Ã—192\n",
    "        h = self.dec2(h, t_emb)            # 14Ã—14Ã—64\n",
    "        h = self.up1(h)                     # 28Ã—28Ã—64\n",
    "        h = tf.concat([h, h1], axis=-1)    # 28Ã—28Ã—96\n",
    "        h = self.dec1(h, t_emb)            # 28Ã—28Ã—32\n",
    "\n",
    "        # ì¶œë ¥\n",
    "        h = self.output_norm(h)\n",
    "        h = tf.nn.silu(h)\n",
    "        return self.output_conv(h)          # 28Ã—28Ã—1\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸\n",
    "model = SimpleUNet(time_dim=128)\n",
    "\n",
    "# Forward pass í…ŒìŠ¤íŠ¸\n",
    "dummy_x = tf.random.normal([4, 28, 28, 1])\n",
    "dummy_t = tf.constant([0, 250, 500, 999])\n",
    "dummy_out = model(dummy_x, dummy_t)\n",
    "\n",
    "print(f\"SimpleUNet ì•„í‚¤í…ì²˜ í…ŒìŠ¤íŠ¸:\")\n",
    "print(f\"  ì…ë ¥ x shape: {dummy_x.shape}\")\n",
    "print(f\"  ì…ë ¥ t:       {dummy_t.numpy()}\")\n",
    "print(f\"  ì¶œë ¥ shape:   {dummy_out.shape}\")\n",
    "print(f\"  ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(np.prod(v.shape) for v in model.trainable_variables):,}\")\n",
    "print(f\"  ì¶œë ¥ í†µê³„: í‰ê· ={float(tf.reduce_mean(dummy_out)):.4f}, í‘œì¤€í¸ì°¨={float(tf.math.reduce_std(dummy_out)):.4f}\")\n",
    "\n",
    "# ë ˆì´ì–´ë³„ íŒŒë¼ë¯¸í„° ìˆ˜\n",
    "print(f\"\\në ˆì´ì–´ë³„ íŒŒë¼ë¯¸í„° ìˆ˜:\")\n",
    "layer_params = {}\n",
    "for v in model.trainable_variables:\n",
    "    layer_name = v.name.split('/')[0]\n",
    "    cnt = int(np.prod(v.shape))\n",
    "    layer_params[layer_name] = layer_params.get(layer_name, 0) + cnt\n",
    "\n",
    "for name, cnt in sorted(layer_params.items()):\n",
    "    print(f\"  {name:<30s}: {cnt:>8,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. UNet íŠ¹ì§• ë§µ ê°œë… ì‹œê°í™” <a name='5.-íŠ¹ì§•-ë§µ-ì‹œê°í™”'></a>\n",
    "\n",
    "UNetì˜ ì¸ì½”ë”ê°€ ì„œë¡œ ë‹¤ë¥¸ í•´ìƒë„ì—ì„œ ì–´ë–¤ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ì‹œê°„ ì„ë² ë”©ì— ë”°ë¼ ì¶œë ¥ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ UNet ì¶œë ¥: ì‹œê°„ ì¡°ê±´ì— ë”°ë¥¸ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ë³€í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ (ëŒ€ê°ì„  íŒ¨í„´)\n",
    "test_img = np.zeros((1, 28, 28, 1), dtype=np.float32)\n",
    "for i in range(28):\n",
    "    test_img[0, i, i, 0] = 1.0\n",
    "    if i + 1 < 28:\n",
    "        test_img[0, i, i+1, 0] = 0.5\n",
    "    if i - 1 >= 0:\n",
    "        test_img[0, i, i-1, 0] = 0.5\n",
    "\n",
    "# ë‹¤ì–‘í•œ íƒ€ì„ìŠ¤í…ì—ì„œì˜ UNet ì¶œë ¥ ë¹„êµ\n",
    "timesteps_test = [0, 100, 300, 500, 700, 999]\n",
    "\n",
    "fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "\n",
    "# ì²« ë²ˆì§¸ í–‰: ì…ë ¥ (ì‹œê°„ì— ë”°ë¼ ë…¸ì´ì¦ˆ ì¶”ê°€ëœ ì´ë¯¸ì§€)\n",
    "T_test = 1000\n",
    "beta_test = np.linspace(1e-4, 0.02, T_test)\n",
    "alpha_test = 1.0 - beta_test\n",
    "abar_test = np.cumprod(alpha_test)\n",
    "\n",
    "for idx, t in enumerate(timesteps_test):\n",
    "    # Forward processë¡œ ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "    if t == 0:\n",
    "        noisy = test_img.copy()\n",
    "    else:\n",
    "        abar = abar_test[t-1]\n",
    "        eps = np.random.randn(*test_img.shape).astype(np.float32)\n",
    "        noisy = np.sqrt(abar) * test_img + np.sqrt(1 - abar) * eps\n",
    "\n",
    "    axes[0][idx].imshow(noisy[0, :, :, 0], cmap='gray', vmin=-2, vmax=2)\n",
    "    axes[0][idx].set_title(f'ì…ë ¥: $t={t}$', fontsize=9, fontweight='bold')\n",
    "    axes[0][idx].axis('off')\n",
    "\n",
    "    # UNet ì˜ˆì¸¡\n",
    "    t_tensor = tf.constant([t])\n",
    "    pred = model(tf.constant(noisy), t_tensor).numpy()\n",
    "    axes[1][idx].imshow(pred[0, :, :, 0], cmap='RdBu_r')\n",
    "    axes[1][idx].set_title(f'UNet ì¶œë ¥: $t={t}$', fontsize=9, fontweight='bold')\n",
    "    axes[1][idx].axis('off')\n",
    "\n",
    "axes[0][0].set_ylabel('ë…¸ì´ì¦ˆ ì…ë ¥', fontsize=11)\n",
    "axes[1][0].set_ylabel('ì˜ˆì¸¡ ë…¸ì´ì¦ˆ', fontsize=11)\n",
    "plt.suptitle('UNet: íƒ€ì„ìŠ¤í…ì— ë”°ë¥¸ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ (ì´ˆê¸°í™” ì§í›„, í•™ìŠµ ì „)', fontweight='bold', y=1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter13_genai_diffusion/unet_feature_maps.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter13_genai_diffusion/unet_feature_maps.png\")\n",
    "print(\"ì°¸ê³ : í•™ìŠµ ì „ì´ë¯€ë¡œ UNet ì¶œë ¥ì€ ë¬´ì‘ìœ„ì— ê°€ê¹ìŠµë‹ˆë‹¤.\")\n",
    "print(\"í•™ìŠµ í›„ì—ëŠ” ì…ë ¥ ë…¸ì´ì¦ˆë¥¼ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ê²Œ ë©ë‹ˆë‹¤.\")\n",
    "\n",
    "# UNet ì¶œë ¥ í†µê³„\n",
    "print(f\"\\níƒ€ì„ìŠ¤í…ë³„ UNet ì¶œë ¥ í†µê³„ (í•™ìŠµ ì „):\")\n",
    "print(f\"{'ì‹œì ':>6} | {'í‰ê· ':>10} | {'í‘œì¤€í¸ì°¨':>10} | {'ìµœì†Œ':>10} | {'ìµœëŒ€':>10}\")\n",
    "print(\"-\" * 55)\n",
    "for t in timesteps_test:\n",
    "    if t == 0:\n",
    "        noisy_t = test_img\n",
    "    else:\n",
    "        abar = abar_test[t-1]\n",
    "        eps = np.random.randn(*test_img.shape).astype(np.float32)\n",
    "        noisy_t = np.sqrt(abar) * test_img + np.sqrt(1 - abar) * eps\n",
    "    pred = model(tf.constant(noisy_t), tf.constant([t])).numpy()\n",
    "    print(f\"  t={t:4d} | {pred.mean():>10.4f} | {pred.std():>10.4f} | {pred.min():>10.4f} | {pred.max():>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì •ë¦¬ <a name='6.-ì •ë¦¬'></a>\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |\n",
    "|------|------|--------|\n",
    "| Sinusoidal Embedding | $PE(t,2i) = \\sin(t/10000^{2i/d})$ â€” ì‹œê°„ ì •ë³´ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ | â­â­â­ |\n",
    "| Residual Block | $h + F(h, t_{emb})$ â€” ì‹œê°„ ì¡°ê±´ì´ ì£¼ì…ëœ ì”ì°¨ í•™ìŠµ | â­â­â­ |\n",
    "| Skip Connection | ì¸ì½”ë” â†’ ë””ì½”ë” ì§ì ‘ ì—°ê²° â€” ê³ í•´ìƒë„ ì •ë³´ ë³´ì¡´ | â­â­â­ |\n",
    "| Cross-Attention | $\\text{softmax}(QK^T/\\sqrt{d})V$ â€” í…ìŠ¤íŠ¸/í´ë˜ìŠ¤ ì¡°ê±´ ì£¼ì… | â­â­â­ |\n",
    "| GroupNorm | ë°°ì¹˜ í¬ê¸° ë…ë¦½ì  ì •ê·œí™” â€” ì†Œë°°ì¹˜ì—ì„œë„ ì•ˆì •ì  | â­â­ |\n",
    "| UNet êµ¬ì¡° | ì¸ì½”ë”-ë³‘ëª©-ë””ì½”ë” with skip â€” ë…¸ì´ì¦ˆ ì˜ˆì¸¡ì˜ í‘œì¤€ ì•„í‚¤í…ì²˜ | â­â­â­ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$PE(t, 2i) = \\sin\\!\\left(\\frac{t}{10000^{2i/d}}\\right), \\quad PE(t, 2i+1) = \\cos\\!\\left(\\frac{t}{10000^{2i/d}}\\right)$$\n",
    "\n",
    "$$\\text{Cross-Attention}(Q, K, V) = \\text{softmax}\\!\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**04_conditional_diffusion_cfg** â€” Classifier-Free Guidance(CFG)ë¥¼ í†µí•´ í´ë˜ìŠ¤/í…ìŠ¤íŠ¸ ì¡°ê±´ë¶€ ìƒì„±ì„ êµ¬í˜„í•˜ê³ , ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ì— ë”°ë¥¸ í’ˆì§ˆ-ë‹¤ì–‘ì„± íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}