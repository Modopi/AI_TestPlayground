{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-04-01",
   "metadata": {},
   "source": [
    "# Chapter 08-04: 성능 최적화 기법\n",
    "\n",
    "## 학습 목표\n",
    "- Mixed Precision Training으로 학습 속도를 높이고 메모리를 절약한다\n",
    "- `@tf.function` 데코레이터로 Python 코드를 TensorFlow 그래프로 컴파일한다\n",
    "- `tf.data` 파이프라인 최적화로 데이터 병목을 제거한다\n",
    "- GPU 메모리 증가 설정과 분산 학습 전략의 기초를 이해한다\n",
    "\n",
    "## 목차\n",
    "1. Mixed Precision Training\n",
    "2. `@tf.function` 그래프 최적화\n",
    "3. `tf.data` 파이프라인 최적화\n",
    "4. GPU 메모리 설정\n",
    "5. MirroredStrategy (분산 학습)\n",
    "6. 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
    "print(f\"사용 가능한 GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# MNIST 데이터 로드\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test  = X_test.astype('float32') / 255.0\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test  = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04-03-md",
   "metadata": {},
   "source": [
    "## 1. Mixed Precision Training\n",
    "\n",
    "Mixed Precision은 float16(빠른 연산)과 float32(수치 안정성)를 함께 사용한다.\n",
    "\n",
    "- **순전파·역전파**: float16 (VRAM 절반, 텐서 코어 2배 빠름)\n",
    "- **가중치 업데이트**: float32 (수치 안정성 보장)\n",
    "- NVIDIA Volta(V100), Ampere(A100) 아키텍처에서 가장 큰 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# 현재 기본 정책 확인\n",
    "print(f\"기본 정책: {mixed_precision.global_policy()}\")\n",
    "\n",
    "# Mixed Precision 정책 전역 설정\n",
    "# 'mixed_float16': GPU 환경\n",
    "# 'mixed_bfloat16': TPU 환경 또는 일부 CPU (bfloat16은 float32와 동일한 지수 범위)\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "print(f\"변경된 정책: {mixed_precision.global_policy()}\")\n",
    "\n",
    "# Mixed Precision 모델 구성 시 주의: 출력 레이어는 float32 유지\n",
    "def build_mixed_precision_model():\n",
    "    \"\"\"Mixed Precision 학습용 모델 (출력을 float32로 강제 캐스팅)\"\"\"\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    # softmax 출력: float32로 캐스팅 (수치 안정성 - 손실 함수 계산 정밀도)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax', dtype='float32')(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "mp_model = build_mixed_precision_model()\n",
    "mp_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 가중치 dtype 확인\n",
    "print(\"\\n레이어별 compute dtype:\")\n",
    "for layer in mp_model.layers:\n",
    "    if hasattr(layer, 'compute_dtype'):\n",
    "        print(f\"  {layer.name:<25} compute_dtype={layer.compute_dtype}\")\n",
    "\n",
    "# 짧은 학습으로 동작 확인\n",
    "mp_model.fit(X_train[:2000], y_train[:2000], epochs=2, batch_size=128, verbose=1)\n",
    "\n",
    "# 정책을 float32로 되돌림 (이후 셀에 영향 방지)\n",
    "mixed_precision.set_global_policy('float32')\n",
    "print(f\"\\n정책 복원: {mixed_precision.global_policy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04-04-md",
   "metadata": {},
   "source": [
    "## 2. `@tf.function` 그래프 최적화\n",
    "\n",
    "`@tf.function`은 Python 함수를 TensorFlow 정적 그래프로 컴파일(트레이싱)하여 실행 속도를 높인다.\n",
    "\n",
    "- 첫 호출 시 **트레이싱**(파이썬 코드 → 그래프 변환) 발생\n",
    "- 이후 호출은 컴파일된 그래프를 재사용 → 빠름\n",
    "- 입력 형상/dtype이 바뀌면 **재트레이싱** 발생 (오버헤드 주의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교용 모델 생성\n",
    "bench_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 일반 Python 함수 (eager 모드)\n",
    "def predict_eager(images):\n",
    "    \"\"\"Eager 모드 추론 (그래프 컴파일 없음)\"\"\"\n",
    "    return bench_model(images, training=False)\n",
    "\n",
    "# @tf.function 데코레이터로 그래프 모드 활성화\n",
    "@tf.function\n",
    "def predict_graph(images):\n",
    "    \"\"\"그래프 모드 추론 (@tf.function 적용)\"\"\"\n",
    "    return bench_model(images, training=False)\n",
    "\n",
    "# 워밍업 (트레이싱 비용 제외)\n",
    "sample = X_test[:256]\n",
    "_ = predict_eager(sample)\n",
    "_ = predict_graph(sample)  # 최초 호출: 트레이싱 발생\n",
    "\n",
    "# 속도 비교 (100회 반복)\n",
    "N = 100\n",
    "\n",
    "# Eager 모드 시간 측정\n",
    "start = time.perf_counter()\n",
    "for _ in range(N):\n",
    "    predict_eager(sample)\n",
    "eager_time = (time.perf_counter() - start) / N * 1000\n",
    "\n",
    "# Graph 모드 시간 측정\n",
    "start = time.perf_counter()\n",
    "for _ in range(N):\n",
    "    predict_graph(sample)\n",
    "graph_time = (time.perf_counter() - start) / N * 1000\n",
    "\n",
    "print(f\"Eager 모드 평균 시간: {eager_time:.3f} ms\")\n",
    "print(f\"Graph 모드 평균 시간: {graph_time:.3f} ms\")\n",
    "print(f\"속도 향상: {eager_time/graph_time:.2f}x\")\n",
    "\n",
    "# tf.function 사용 시 주의사항 예시\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None, 28, 28, 1], dtype=tf.float32)])\n",
    "def predict_with_signature(images):\n",
    "    \"\"\"input_signature로 재트레이싱을 방지하는 패턴\"\"\"\n",
    "    return bench_model(images, training=False)\n",
    "\n",
    "result = predict_with_signature(sample)\n",
    "print(f\"\\ninput_signature 버전 결과 형상: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04-05-md",
   "metadata": {},
   "source": [
    "## 3. `tf.data` 파이프라인 최적화\n",
    "\n",
    "데이터 로딩이 학습보다 느리면 GPU가 유휴 상태가 된다.\n",
    "`tf.data`의 최적화 기법으로 데이터 병목을 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE  # TensorFlow가 자동으로 병렬화 수준 결정\n",
    "\n",
    "# 데이터 증강 레이어 (tf.data map에서 사용)\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# ── 비최적화 파이프라인 (비교 기준) ──────────────────────────────\n",
    "def make_baseline_dataset(images, labels, batch_size=128):\n",
    "    \"\"\"최적화 없는 기본 파이프라인 (순차 처리)\"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.shuffle(1000)\n",
    "    ds = ds.map(lambda x, y: (augmentation(x[tf.newaxis], training=True)[0], y))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "# ── 최적화 파이프라인 ───────────────────────────────────────────\n",
    "def make_optimized_dataset(images, labels, batch_size=128):\n",
    "    \"\"\"\n",
    "    최적화 파이프라인:\n",
    "    - cache()       : 첫 에포크 후 데이터를 메모리에 캐시 (디스크 I/O 제거)\n",
    "    - map + AUTOTUNE: 병렬 전처리 (CPU 코어 자동 활용)\n",
    "    - prefetch()    : GPU 연산 중 다음 배치 미리 준비 (CPU-GPU 파이프라이닝)\n",
    "    \"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.cache()  # 데이터를 메모리에 캐시\n",
    "    ds = ds.shuffle(1000)\n",
    "    # num_parallel_calls=AUTOTUNE: 병렬 처리 수준 자동 결정\n",
    "    ds = ds.map(\n",
    "        lambda x, y: (augmentation(x[tf.newaxis], training=True)[0], y),\n",
    "        num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(AUTOTUNE)  # 다음 배치 비동기 준비\n",
    "    return ds\n",
    "\n",
    "# 파이프라인 구성\n",
    "baseline_ds  = make_baseline_dataset(X_train[:5000], y_train[:5000])\n",
    "optimized_ds = make_optimized_dataset(X_train[:5000], y_train[:5000])\n",
    "\n",
    "# 파이프라인 요소 수 확인\n",
    "print(f\"배치 수 (baseline) : {sum(1 for _ in baseline_ds)}\")\n",
    "print(f\"배치 수 (optimized): {sum(1 for _ in optimized_ds)}\")\n",
    "\n",
    "# 간단한 모델로 속도 비교\n",
    "def make_train_model():\n",
    "    m = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    m.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    return m\n",
    "\n",
    "# 비최적화 파이프라인 학습 시간\n",
    "m1 = make_train_model()\n",
    "start = time.perf_counter()\n",
    "m1.fit(baseline_ds, epochs=2, verbose=0)\n",
    "baseline_time = time.perf_counter() - start\n",
    "\n",
    "# 최적화 파이프라인 학습 시간\n",
    "m2 = make_train_model()\n",
    "start = time.perf_counter()\n",
    "m2.fit(optimized_ds, epochs=2, verbose=0)\n",
    "optimized_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"\\n비최적화 파이프라인: {baseline_time:.2f}초\")\n",
    "print(f\"최적화 파이프라인 : {optimized_time:.2f}초\")\n",
    "print(f\"속도 향상         : {baseline_time/optimized_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04-06-md",
   "metadata": {},
   "source": [
    "## 4. GPU 메모리 증가 설정\n",
    "\n",
    "기본적으로 TensorFlow는 사용 가능한 GPU 메모리 전체를 할당한다.\n",
    "`set_memory_growth(True)`를 설정하면 실제 필요한 만큼만 점진적으로 할당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 디바이스 목록 조회\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # 각 GPU에 대해 메모리 증가 설정 활성화\n",
    "        # 주의: 반드시 다른 TF 연산 이전에 설정해야 한다\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"{len(gpus)}개 GPU에 memory growth 설정 완료\")\n",
    "\n",
    "        # 특정 GPU에 최대 메모리 한도 설정 (선택 사항)\n",
    "        # tf.config.set_logical_device_configuration(\n",
    "        #     gpus[0],\n",
    "        #     [tf.config.LogicalDeviceConfiguration(memory_limit=4096)]  # 4GB\n",
    "        # )\n",
    "    except RuntimeError as e:\n",
    "        # 이미 TF 연산이 실행된 후에는 설정 변경 불가\n",
    "        print(f\"메모리 설정 오류 (이미 초기화됨): {e}\")\nelse:\n",
    "    print(\"GPU를 찾을 수 없습니다. CPU 환경에서 실행 중입니다.\")\n",
    "    print(\"권장 스크립트 시작부에 아래 코드를 배치하세요:\")\n",
    "    print(\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "# GPU 메모리 증가 설정 (프로그램 시작 시 최초로 실행)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \"\"\")\n",
    "\n",
    "# CPU/GPU 디바이스 정보 출력\n",
    "print(\"\\n현재 가용 디바이스:\")\n",
    "for d in tf.config.list_logical_devices():\n",
    "    print(f\"  {d.device_type}: {d.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04-07-md",
   "metadata": {},
   "source": [
    "## 5. MirroredStrategy - 멀티 GPU 분산 학습\n",
    "\n",
    "`tf.distribute.MirroredStrategy`는 단일 머신의 여러 GPU에 학습을 분산한다.\n",
    "\n",
    "- 각 GPU에 모델의 **복사본(replica)**을 배치\n",
    "- 배치를 GPU 수만큼 분할하여 병렬 처리\n",
    "- 그래디언트는 **All-Reduce** 알고리즘으로 모든 GPU에서 동기화\n",
    "- `strategy.scope()` 내부에서 모델 생성 및 컴파일만 하면 나머지는 자동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MirroredStrategy 초기화\n",
    "# GPU가 없으면 자동으로 CPU로 폴백\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(f\"복제본(Replica) 수: {strategy.num_replicas_in_sync}\")\n",
    "print(f\"(GPU가 없으면 1, GPU 2개면 2로 표시)\")\n",
    "\n",
    "# 분산 학습의 핵심: strategy.scope() 내에서 모델 생성\n",
    "with strategy.scope():\n",
    "    # 이 블록 안에서 생성된 변수들은 모든 GPU에 미러링됨\n",
    "    dist_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    dist_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "# 분산 학습 시 배치 크기는 전체 배치 크기\n",
    "# (GPU당 배치 크기 × GPU 수 = 전체 배치 크기)\n",
    "GLOBAL_BATCH_SIZE = 128 * strategy.num_replicas_in_sync\n",
    "print(f\"\\n전체 배치 크기: {GLOBAL_BATCH_SIZE}\")\n",
    "\n",
    "# 실제 학습 (MirroredStrategy는 model.fit과 완전 호환)\n",
    "dist_model.fit(\n",
    "    X_train[:5000], y_train[:5000],\n",
    "    validation_data=(X_test[:1000], y_test[:1000]),\n",
    "    batch_size=GLOBAL_BATCH_SIZE,\n",
    "    epochs=2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== 다른 분산 전략 소개 ===\")\n",
    "print(\"MirroredStrategy     : 단일 머신 멀티 GPU (동기식)\")\n",
    "print(\"MultiWorkerMirrored  : 멀티 머신 멀티 GPU (동기식)\")\n",
    "print(\"TPUStrategy          : Google TPU 분산 학습\")\n",
    "print(\"ParameterServerStrategy: 파라미터 서버 방식 (비동기식)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04-08",
   "metadata": {},
   "source": [
    "## 6. 정리\n",
    "\n",
    "### 성능 최적화 기법 요약\n",
    "\n",
    "| 기법 | 효과 | 적용 난이도 | 주요 API |\n",
    "|------|------|-------------|----------|\n",
    "| Mixed Precision | VRAM 절반, 속도 1.5–3x | 낮음 | `set_global_policy('mixed_float16')` |\n",
    "| `@tf.function` | 추론 속도 향상 | 낮음 | `@tf.function` 데코레이터 |\n",
    "| `tf.data` 최적화 | 데이터 병목 제거 | 중간 | `cache()`, `prefetch()`, `map(num_parallel_calls=AUTOTUNE)` |\n",
    "| 메모리 증가 | OOM 방지 | 낮음 | `set_memory_growth(True)` |\n",
    "| MirroredStrategy | 선형 스케일 학습 | 낮음 | `strategy.scope()` |\n",
    "\n",
    "### 최적화 체크리스트\n",
    "\n",
    "```\n",
    "[ ] GPU 메모리 증가 설정 (프로그램 시작 시)\n",
    "[ ] tf.data 파이프라인에 cache() + prefetch(AUTOTUNE) 적용\n",
    "[ ] map()에 num_parallel_calls=AUTOTUNE 설정\n",
    "[ ] Mixed Precision 활성화 (GPU가 있는 경우)\n",
    "[ ] 커스텀 학습 스텝에 @tf.function 적용\n",
    "[ ] 멀티 GPU 환경에서 MirroredStrategy 사용\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
