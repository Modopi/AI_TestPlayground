{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-03-01",
   "metadata": {},
   "source": [
    "# Chapter 08-03: TensorFlow Lite 변환과 양자화\n",
    "\n",
    "## 학습 목표\n",
    "- TFLite로 모델을 변환하여 모바일/엣지 디바이스에 배포하는 흐름을 이해한다\n",
    "- Post-Training Quantization의 세 가지 방식(Dynamic, Float16, Int8)을 구분한다\n",
    "- TFLite 인터프리터로 직접 추론을 실행한다\n",
    "- 모델 크기와 추론 속도를 비교·분석한다\n",
    "\n",
    "## 목차\n",
    "1. 양자화 수학적 원리\n",
    "2. MNIST 모델 학습 및 저장\n",
    "3. TFLite 기본 변환\n",
    "4. Dynamic Range Quantization\n",
    "5. Float16 Quantization\n",
    "6. TFLite 인터프리터 추론\n",
    "7. 모델 크기 비교\n",
    "8. 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
    "\n",
    "# MNIST 데이터 로드 및 전처리\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test  = X_test.astype('float32') / 255.0\n",
    "X_train = X_train[..., np.newaxis]  # (60000, 28, 28, 1)\n",
    "X_test  = X_test[..., np.newaxis]   # (10000, 28, 28, 1)\n",
    "\n",
    "# TFLite 파일 저장 경로\n",
    "TFLITE_DIR = '/tmp/tflite_models'\n",
    "os.makedirs(TFLITE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"학습 데이터: {X_train.shape}\")\n",
    "print(f\"TFLite 저장 경로: {TFLITE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-03",
   "metadata": {},
   "source": [
    "## 1. 양자화(Quantization) 수학적 원리\n",
    "\n",
    "양자화는 부동소수점(float32)을 정수(int8/int16)로 압축하여 모델 크기와 연산 비용을 줄인다.\n",
    "\n",
    "### 선형 양자화 공식\n",
    "\n",
    "**양자화 (float → int)**\n",
    "\n",
    "$$x_{int} = \\text{round}\\left(\\frac{x_{float}}{s}\\right) + z$$\n",
    "\n",
    "**역양자화 (int → float)**\n",
    "\n",
    "$$x_{float} \\approx s\\,(x_{int} - z)$$\n",
    "\n",
    "- $s$ (scale): 부동소수점 범위를 정수 범위로 매핑하는 스케일 계수\n",
    "- $z$ (zero-point): 0.0 을 표현하는 정수 값 (비대칭 양자화)\n",
    "\n",
    "### 방식별 비교\n",
    "\n",
    "| 방식 | 가중치 | 활성화 | 크기 감소 | 속도 향상 | 정확도 손실 |\n",
    "|------|--------|--------|-----------|-----------|-------------|\n",
    "| Float32 (원본) | float32 | float32 | 기준 | 기준 | 없음 |\n",
    "| Dynamic Range | int8 | float32 (추론 시) | ~75% | ~2–3x | 매우 작음 |\n",
    "| Float16 | float16 | float16 | ~50% | GPU에서 향상 | 매우 작음 |\n",
    "| Full Int8 | int8 | int8 | ~75% | ~3–4x | 작음 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-04-md",
   "metadata": {},
   "source": [
    "## 2. 간단한 MNIST 모델 학습 후 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 분류 CNN 모델 구성\n",
    "def build_mnist_model():\n",
    "    \"\"\"TFLite 변환 실습용 MNIST CNN 모델\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ], name='mnist_cnn')\n",
    "    return model\n",
    "\n",
    "model = build_mnist_model()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# 빠른 학습 (에포크 3회)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=3,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 테스트 평가\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n원본 모델 테스트 정확도: {test_acc:.4f}\")\n",
    "\n",
    "# .keras 형식으로 저장\n",
    "keras_path = os.path.join(TFLITE_DIR, 'mnist_original.keras')\n",
    "model.save(keras_path)\n",
    "print(f\"원본 모델 저장: {keras_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-05-md",
   "metadata": {},
   "source": [
    "## 3. TFLite 기본 변환 (양자화 없음)\n",
    "\n",
    "`TFLiteConverter`는 Keras 모델, SavedModel 등 다양한 소스에서 TFLite 파일을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras 모델에서 TFLite 컨버터 생성\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# 기본 변환 (양자화 없이 float32 유지)\n",
    "tflite_model_fp32 = converter.convert()\n",
    "\n",
    "# .tflite 파일로 저장\n",
    "path_fp32 = os.path.join(TFLITE_DIR, 'mnist_fp32.tflite')\n",
    "with open(path_fp32, 'wb') as f:\n",
    "    f.write(tflite_model_fp32)\n",
    "\n",
    "size_fp32 = os.path.getsize(path_fp32)\n",
    "print(f\"FP32 TFLite 모델 크기: {size_fp32:,} bytes ({size_fp32/1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-06-md",
   "metadata": {},
   "source": [
    "## 4. Post-Training Dynamic Range Quantization\n",
    "\n",
    "가중치를 int8로 양자화하고, 활성화는 추론 시점에 동적으로 양자화한다.\n",
    "별도의 보정 데이터 없이 적용 가능하므로 가장 간단한 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Range Quantization 설정\n",
    "converter_dynamic = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# 최적화 플래그: DEFAULT → Dynamic Range Quantization 활성화\n",
    "converter_dynamic.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# 변환 실행\n",
    "tflite_model_dynamic = converter_dynamic.convert()\n",
    "\n",
    "# 저장\n",
    "path_dynamic = os.path.join(TFLITE_DIR, 'mnist_dynamic_quant.tflite')\n",
    "with open(path_dynamic, 'wb') as f:\n",
    "    f.write(tflite_model_dynamic)\n",
    "\n",
    "size_dynamic = os.path.getsize(path_dynamic)\n",
    "print(f\"Dynamic Quant 모델 크기: {size_dynamic:,} bytes ({size_dynamic/1024:.1f} KB)\")\n",
    "print(f\"크기 감소율: {(1 - size_dynamic/size_fp32)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-07-md",
   "metadata": {},
   "source": [
    "## 5. Post-Training Float16 Quantization\n",
    "\n",
    "가중치와 연산을 float16으로 변환한다.\n",
    "GPU를 탑재한 모바일 기기(예: iPhone Neural Engine)에서 성능 이점이 크다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float16 Quantization 설정\n",
    "converter_fp16 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter_fp16.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# 지원 타입을 float16으로 제한\n",
    "converter_fp16.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# 변환 실행\n",
    "tflite_model_fp16 = converter_fp16.convert()\n",
    "\n",
    "# 저장\n",
    "path_fp16 = os.path.join(TFLITE_DIR, 'mnist_fp16_quant.tflite')\n",
    "with open(path_fp16, 'wb') as f:\n",
    "    f.write(tflite_model_fp16)\n",
    "\n",
    "size_fp16 = os.path.getsize(path_fp16)\n",
    "print(f\"Float16 Quant 모델 크기: {size_fp16:,} bytes ({size_fp16/1024:.1f} KB)\")\n",
    "print(f\"크기 감소율 (vs FP32): {(1 - size_fp16/size_fp32)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-08-md",
   "metadata": {},
   "source": [
    "## 6. TFLite 인터프리터로 추론\n",
    "\n",
    "`tf.lite.Interpreter`를 사용하면 변환된 `.tflite` 파일을 로드하고 추론을 실행할 수 있다.\n",
    "모바일 기기에서의 동작을 PC에서 시뮬레이션하는 용도로도 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tflite_inference(tflite_path, test_images, test_labels, num_samples=500):\n",
    "    \"\"\"\n",
    "    TFLite 인터프리터로 추론을 실행하고 정확도와 평균 추론 시간을 반환한다.\n",
    "\n",
    "    Args:\n",
    "        tflite_path: .tflite 파일 경로\n",
    "        test_images: 테스트 이미지 배열\n",
    "        test_labels: 정답 레이블 배열\n",
    "        num_samples: 평가할 샘플 수\n",
    "    Returns:\n",
    "        accuracy (float), avg_time_ms (float)\n",
    "    \"\"\"\n",
    "    # 인터프리터 초기화\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()  # 텐서 메모리 할당\n",
    "\n",
    "    # 입출력 텐서 정보 조회\n",
    "    input_details  = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    correct = 0\n",
    "    total_time = 0.0\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # 단일 이미지 배치 형태로 준비 [1, 28, 28, 1]\n",
    "        input_data = np.expand_dims(test_images[i], axis=0)\n",
    "\n",
    "        # 입력 텐서에 데이터 설정\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "        # 추론 실행 + 시간 측정\n",
    "        start = time.perf_counter()\n",
    "        interpreter.invoke()\n",
    "        total_time += (time.perf_counter() - start) * 1000  # ms 단위\n",
    "\n",
    "        # 출력 텐서에서 결과 가져오기\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        pred = np.argmax(output_data[0])\n",
    "\n",
    "        if pred == test_labels[i]:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / num_samples\n",
    "    avg_time = total_time / num_samples\n",
    "    return accuracy, avg_time\n",
    "\n",
    "# 입출력 텐서 정보 출력\n",
    "interp = tf.lite.Interpreter(model_path=path_fp32)\n",
    "interp.allocate_tensors()\n",
    "print(\"입력 텐서 정보:\")\n",
    "for d in interp.get_input_details():\n",
    "    print(f\"  name={d['name']}, shape={d['shape']}, dtype={d['dtype']}\")\n",
    "print(\"출력 텐서 정보:\")\n",
    "for d in interp.get_output_details():\n",
    "    print(f\"  name={d['name']}, shape={d['shape']}, dtype={d['dtype']}\")\n",
    "\n",
    "print(\"\\n추론 실행 중... (각 500개 샘플)\")\n",
    "acc_fp32,    time_fp32    = run_tflite_inference(path_fp32,    X_test, y_test)\n",
    "acc_dynamic, time_dynamic = run_tflite_inference(path_dynamic, X_test, y_test)\n",
    "acc_fp16,    time_fp16    = run_tflite_inference(path_fp16,    X_test, y_test)\n",
    "\n",
    "print(f\"\\nFP32    - 정확도: {acc_fp32:.4f}, 평균 추론 시간: {time_fp32:.3f} ms\")\n",
    "print(f\"Dynamic - 정확도: {acc_dynamic:.4f}, 평균 추론 시간: {time_dynamic:.3f} ms\")\n",
    "print(f\"FP16    - 정확도: {acc_fp16:.4f}, 평균 추론 시간: {time_fp16:.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-09-md",
   "metadata": {},
   "source": [
    "## 7. 모델 크기 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 Keras 모델 크기 포함 전체 비교\n",
    "original_size = os.path.getsize(keras_path)\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'형식':<22} {'크기(KB)':>10} {'감소율':>10} {'정확도':>10}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'원본 .keras':<22} {original_size/1024:>10.1f} {'기준':>10} {test_acc:>10.4f}\")\n",
    "print(f\"{'TFLite FP32':<22} {size_fp32/1024:>10.1f} {0.0:>9.1f}% {acc_fp32:>10.4f}\")\n",
    "print(f\"{'TFLite Dynamic Quant':<22} {size_dynamic/1024:>10.1f} {(1-size_dynamic/size_fp32)*100:>9.1f}% {acc_dynamic:>10.4f}\")\n",
    "print(f\"{'TFLite FP16 Quant':<22} {size_fp16/1024:>10.1f} {(1-size_fp16/size_fp32)*100:>9.1f}% {acc_fp16:>10.4f}\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# 파일 목록 확인\n",
    "print(\"\\n생성된 파일 목록:\")\n",
    "for fname in sorted(os.listdir(TFLITE_DIR)):\n",
    "    fpath = os.path.join(TFLITE_DIR, fname)\n",
    "    print(f\"  {fname:<35} {os.path.getsize(fpath)/1024:>8.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-03-10",
   "metadata": {},
   "source": [
    "## 8. 정리 - 양자화 방식 비교\n",
    "\n",
    "### 양자화 방식 선택 기준\n",
    "\n",
    "| 양자화 방식 | 보정 데이터 필요 | 크기 감소 | 추천 대상 |\n",
    "|-------------|-----------------|-----------|----------|\n",
    "| 없음 (FP32) | 불필요 | 없음 | 변환 검증, 디버깅 |\n",
    "| Dynamic Range | 불필요 | ~75% | CPU 엣지 디바이스, 빠른 배포 |\n",
    "| Float16 | 불필요 | ~50% | GPU/NPU 탑재 디바이스 |\n",
    "| Full Int8 | **필요** (대표 데이터 100~500개) | ~75% | 최고 성능이 필요한 경우 |\n",
    "\n",
    "### TFLite 변환 핵심 API\n",
    "\n",
    "```python\n",
    "# 변환\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]   # 양자화 활성화\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# 추론\n",
    "interp = tf.lite.Interpreter(model_path='model.tflite')\n",
    "interp.allocate_tensors()\n",
    "interp.set_tensor(input_idx, input_data)\n",
    "interp.invoke()\n",
    "output = interp.get_tensor(output_idx)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_study)",
   "language": "python",
   "name": "tf_study"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
