{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: ìµœì‹  LLM ì•„í‚¤í…ì²˜ â€” MoE ë¼ìš°íŒ…ê³¼ ë¶€í•˜ ê· í˜•\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- Mixture of Experts(MoE)ì˜ **Top-k ê²Œì´íŒ… ìˆ˜ì‹**ê³¼ ë™ì‘ ì›ë¦¬ë¥¼ ì´í•´í•œë‹¤\n",
    "- **Softmax ê²Œì´íŒ…**ê³¼ **Linear ê²Œì´íŒ…**ì˜ ì°¨ì´ë¥¼ ë¹„êµí•˜ê³  êµ¬í˜„í•œë‹¤\n",
    "- **Auxiliary Loss (ë³´ì¡° ì†ì‹¤)**ì˜ ìˆ˜í•™ì  ë„ì¶œê³¼ ë¶€í•˜ ê· í˜• íš¨ê³¼ë¥¼ ê²€ì¦í•œë‹¤\n",
    "- **Expert Capacity Factor**ê°€ MoE ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹¤í—˜í•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: MoE ê²Œì´íŒ…ê³¼ Auxiliary Loss](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [Top-k ë¼ìš°í„° êµ¬í˜„](#2.-Top-k-ë¼ìš°í„°)\n",
    "3. [Auxiliary Lossì™€ ë¶€í•˜ ê· í˜•](#3.-Auxiliary-Loss)\n",
    "4. [Expert Capacity Factor ì‹¤í—˜](#4.-Expert-Capacity)\n",
    "5. [ì •ë¦¬](#5.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>\n",
    "\n",
    "### MoE ê²Œì´íŒ… ë©”ì»¤ë‹ˆì¦˜\n",
    "\n",
    "MoE ë ˆì´ì–´ëŠ” $N$ê°œì˜ ì „ë¬¸ê°€(Expert) ì¤‘ **Top-kê°œë§Œ í™œì„±í™”**í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$y = \\sum_{i \\in \\text{Top-k}} g_i \\cdot E_i(x)$$\n",
    "\n",
    "**ê²Œì´íŒ… ê°€ì¤‘ì¹˜ ê³„ì‚°:**\n",
    "\n",
    "$$\\mathbf{h} = x \\cdot W_g, \\quad W_g \\in \\mathbb{R}^{d_{model} \\times N}$$\n",
    "\n",
    "$$g_i = \\frac{e^{h_i}}{\\sum_{j \\in \\text{Top-k}} e^{h_j}} \\quad (\\text{Top-k ì„ íƒ í›„ ì¬ì •ê·œí™”})$$\n",
    "\n",
    "- $x$: ì…ë ¥ í† í° íˆë“  ë²¡í„°\n",
    "- $W_g$: ê²Œì´íŒ… ê°€ì¤‘ì¹˜ (ë¼ìš°í„°)\n",
    "- $E_i$: $i$ë²ˆì§¸ ì „ë¬¸ê°€ FFN\n",
    "- $g_i$: $i$ë²ˆì§¸ ì „ë¬¸ê°€ì˜ ê¸°ì—¬ ê°€ì¤‘ì¹˜\n",
    "\n",
    "### Auxiliary Loss (ë¶€í•˜ ê· í˜• ë³´ì¡° ì†ì‹¤)\n",
    "\n",
    "ì „ë¬¸ê°€ì—ê²Œ í† í°ì´ **ê· ë“±í•˜ê²Œ ë¶„ë°°**ë˜ë„ë¡ ìœ ë„í•˜ëŠ” ì†ì‹¤:\n",
    "\n",
    "$$L_{aux} = \\alpha \\cdot N \\sum_{i=1}^{N} f_i \\cdot P_i$$\n",
    "\n",
    "- $f_i = \\frac{\\text{expert } i\\text{ì— ë¼ìš°íŒ…ëœ í† í° ìˆ˜}}{\\text{ì „ì²´ í† í° ìˆ˜}}$ (ì‹¤ì œ ë¶„ë°° ë¹„ìœ¨)\n",
    "- $P_i = \\frac{1}{T}\\sum_{x \\in \\mathcal{B}} p_i(x)$ (ë¼ìš°íŒ… í™•ë¥  í‰ê· , $p_i(x) = \\text{softmax}(h)_i$)\n",
    "- $\\alpha$: ë³´ì¡° ì†ì‹¤ ê³„ìˆ˜ (ë³´í†µ $10^{-2}$)\n",
    "- $N$: ì „ë¬¸ê°€ ìˆ˜\n",
    "\n",
    "**ê· ë“± ë¶„ë°° ì‹œ ìµœì†Ÿê°’:** $f_i = P_i = 1/N$ â†’ $L_{aux} = \\alpha \\cdot N \\cdot N \\cdot (1/N)^2 = \\alpha$\n",
    "\n",
    "**ìš”ì•½ í‘œ:**\n",
    "\n",
    "| í•­ëª© | ìˆ˜ì‹ | ì„¤ëª… |\n",
    "|------|------|------|\n",
    "| ê²Œì´íŒ… | $g_i = \\text{softmax}(\\text{Top-k}(xW_g))_i$ | kê°œ ì „ë¬¸ê°€ ì„ íƒ |\n",
    "| Expert ì¶œë ¥ | $y = \\sum_{i \\in \\text{Top-k}} g_i \\cdot E_i(x)$ | ê°€ì¤‘ í•©ì‚° |\n",
    "| Aux Loss | $L_{aux} = \\alpha N \\sum f_i P_i$ | ë¶€í•˜ ê· í˜• |\n",
    "| Capacity Factor | $C = \\frac{k \\cdot T}{N}$ | ì „ë¬¸ê°€ë‹¹ ìµœëŒ€ í† í° |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ MoE ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ³ MoEê°€ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: **ë·”í˜ ë ˆìŠ¤í† ë‘**ì„ ìƒìƒí•´ë³´ì„¸ìš”!\n",
    "> - ìš”ë¦¬ì‚¬(Expert) 8ëª…ì´ ê°ê° ë‹¤ë¥¸ ìš”ë¦¬ë¥¼ ì „ë¬¸ìœ¼ë¡œ í•´ìš”\n",
    "> - ì†ë‹˜(Token)ì´ ì˜¤ë©´ **2ëª…ì˜ ìš”ë¦¬ì‚¬ë§Œ ê³¨ë¼ì„œ** ìŒì‹ì„ ë°›ì•„ìš” (Top-2)\n",
    "> - ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë“  ìš”ë¦¬ì‚¬ê°€ ë™ì‹œì— ì¼í•˜ì§€ ì•Šì•„ë„ ë˜ë‹ˆê¹Œ ë¹ ë¥´ê³  íš¨ìœ¨ì !\n",
    "\n",
    "#### âš–ï¸ Auxiliary LossëŠ” ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: ë§Œì•½ ëª¨ë“  ì†ë‹˜ì´ **í”¼ì ìš”ë¦¬ì‚¬ë§Œ ì°¾ì•„ê°€ë©´** ë‹¤ë¥¸ ìš”ë¦¬ì‚¬ëŠ” ë†€ê³  ìˆì–ì•„ìš”!\n",
    "> Auxiliary LossëŠ” \"ì†ë‹˜ì„ ê³¨ê³ ë£¨ ë‚˜ëˆ ì£¼ì„¸ìš”!\"ë¼ê³  ì•Œë ¤ì£¼ëŠ” **ê³µì • ë¶„ë°° ê·œì¹™**ì´ì—ìš”.\n",
    "\n",
    "| ìƒí™© | ë¹„ìœ  | ê²°ê³¼ |\n",
    "|------|------|------|\n",
    "| Aux Loss ì—†ìŒ | ì¸ê¸° ìˆëŠ” ìš”ë¦¬ì‚¬ë§Œ ë°”ì¨ | ë¶ˆê· í˜• â†’ ì„±ëŠ¥â†“ |\n",
    "| Aux Loss ìˆìŒ | ì†ë‹˜ì„ ê³¨ê³ ë£¨ ë°°ë¶„ | ê· í˜• â†’ íš¨ìœ¨â†‘ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: Top-2 ê²Œì´íŒ… ê³„ì‚°\n",
    "\n",
    "ì…ë ¥ $h = [2.0, 1.0, 0.5, 3.0]$ (ì „ë¬¸ê°€ 4ëª…)ì—ì„œ Top-2ë¥¼ ì„ íƒí•˜ê³  ê²Œì´íŒ… ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ì‹œì˜¤.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "Top-2 ì„ íƒ: Expert 3 ($h_3=3.0$), Expert 0 ($h_0=2.0$)\n",
    "\n",
    "ì¬ì •ê·œí™”: $g_3 = \\frac{e^{3.0}}{e^{3.0}+e^{2.0}} = \\frac{20.09}{20.09+7.39} = 0.731$\n",
    "\n",
    "$g_0 = \\frac{e^{2.0}}{e^{3.0}+e^{2.0}} = \\frac{7.39}{27.48} = 0.269$\n",
    "\n",
    "ì¶œë ¥: $y = 0.731 \\cdot E_3(x) + 0.269 \\cdot E_0(x)$\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: Auxiliary Loss ê³„ì‚°\n",
    "\n",
    "ì „ë¬¸ê°€ 4ëª…, $\\alpha=0.01$, ë°°ì¹˜ ë‚´ ë¶„ë°°: $f=[0.5, 0.1, 0.1, 0.3]$, $P=[0.4, 0.2, 0.1, 0.3]$ì¼ ë•Œ $L_{aux}$ë¥¼ ê³„ì‚°í•˜ì‹œì˜¤.\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$$L_{aux} = 0.01 \\times 4 \\times (0.5 \\times 0.4 + 0.1 \\times 0.2 + 0.1 \\times 0.1 + 0.3 \\times 0.3)$$\n",
    "$$= 0.04 \\times (0.20 + 0.02 + 0.01 + 0.09) = 0.04 \\times 0.32 = 0.0128$$\n",
    "\n",
    "ê· ë“± ë¶„ë°° ì‹œ: $0.01 \\times 4 \\times 4 \\times (1/4)^2 = 0.01$ â†’ í˜„ì¬ ë¶ˆê· í˜•!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Top-k ë¼ìš°í„° êµ¬í˜„ <a name='2.-Top-k-ë¼ìš°í„°'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Top-k MoE ë¼ìš°í„° êµ¬í˜„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Top-k ê²Œì´íŒ…ìœ¼ë¡œ ì „ë¬¸ê°€ë¥¼ ì„ íƒí•˜ê³  ì¶œë ¥ì„ í•©ì‚°í•©ë‹ˆë‹¤\n",
    "\n",
    "class MoERouter(tf.keras.layers.Layer):\n",
    "    # Top-k MoE Router with gating\n",
    "    def __init__(self, d_model, n_experts, top_k=2):\n",
    "        super().__init__()\n",
    "        self.n_experts = n_experts\n",
    "        self.top_k = top_k\n",
    "        self.gate = tf.keras.layers.Dense(n_experts, use_bias=False, name='gate')\n",
    "\n",
    "    def call(self, x):\n",
    "        # x: [B, S, d_model]\n",
    "        logits = self.gate(x)  # [B, S, n_experts]\n",
    "        \n",
    "        # Top-k ì„ íƒ\n",
    "        top_k_logits, top_k_indices = tf.math.top_k(logits, k=self.top_k)\n",
    "        \n",
    "        # Top-kì— ëŒ€í•´ì„œë§Œ softmax (ì¬ì •ê·œí™”)\n",
    "        top_k_gates = tf.nn.softmax(top_k_logits, axis=-1)  # [B, S, k]\n",
    "        \n",
    "        # ë¼ìš°íŒ… í™•ë¥  (ì „ì²´ softmax, Aux Loss ê³„ì‚°ìš©)\n",
    "        routing_probs = tf.nn.softmax(logits, axis=-1)  # [B, S, N]\n",
    "        \n",
    "        return top_k_gates, top_k_indices, routing_probs\n",
    "\n",
    "\n",
    "class MoELayer(tf.keras.layers.Layer):\n",
    "    # Mixture of Experts Layer\n",
    "    def __init__(self, d_model, d_ff, n_experts, top_k=2):\n",
    "        super().__init__()\n",
    "        self.n_experts = n_experts\n",
    "        self.top_k = top_k\n",
    "        self.router = MoERouter(d_model, n_experts, top_k)\n",
    "        # ê° ExpertëŠ” ê°„ë‹¨í•œ FFN\n",
    "        self.experts = [\n",
    "            tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(d_ff, activation='relu'),\n",
    "                tf.keras.layers.Dense(d_model)\n",
    "            ], name=f'expert_{i}')\n",
    "            for i in range(n_experts)\n",
    "        ]\n",
    "\n",
    "    def call(self, x):\n",
    "        B, S, D = x.shape\n",
    "        gates, indices, routing_probs = self.router(x)\n",
    "        \n",
    "        # ê° í† í°ì— ëŒ€í•´ ì„ íƒëœ Expert ì¶œë ¥ì„ ê°€ì¤‘ í•©ì‚°\n",
    "        # (ì‹¤ì œ êµ¬í˜„ì€ scatter/gather ìµœì í™”, ì—¬ê¸°ì„œëŠ” ëª…ì‹œì  ë£¨í”„)\n",
    "        output = tf.zeros_like(x)\n",
    "        \n",
    "        for k_idx in range(self.top_k):\n",
    "            expert_indices = indices[:, :, k_idx]   # [B, S]\n",
    "            expert_gates = gates[:, :, k_idx:k_idx+1]  # [B, S, 1]\n",
    "            \n",
    "            for e_idx in range(self.n_experts):\n",
    "                mask = tf.cast(tf.equal(expert_indices, e_idx), tf.float32)\n",
    "                mask = mask[:, :, tf.newaxis]  # [B, S, 1]\n",
    "                \n",
    "                if tf.reduce_sum(mask) > 0:\n",
    "                    expert_out = self.experts[e_idx](x)  # [B, S, D]\n",
    "                    output += expert_out * mask * expert_gates\n",
    "        \n",
    "        return output, routing_probs\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "d_model, d_ff, n_experts, top_k = 256, 512, 8, 2\n",
    "moe = MoELayer(d_model, d_ff, n_experts, top_k)\n",
    "\n",
    "x_test = tf.random.normal((2, 32, d_model))\n",
    "output, probs = moe(x_test)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"MoE Layer (N={n_experts} experts, Top-{top_k})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ì…ë ¥ shape:  {x_test.shape}\")\n",
    "print(f\"ì¶œë ¥ shape:  {output.shape}\")\n",
    "print()\n",
    "\n",
    "# ë¼ìš°íŒ… í†µê³„\n",
    "gates, indices, _ = moe.router(x_test)\n",
    "flat_indices = tf.reshape(indices, [-1]).numpy()\n",
    "\n",
    "print(\"ë¼ìš°íŒ… ë¶„í¬:\")\n",
    "for i in range(n_experts):\n",
    "    count = np.sum(flat_indices == i)\n",
    "    pct = count / len(flat_indices) * 100\n",
    "    bar = '#' * int(pct / 2)\n",
    "    print(f\"  Expert {i}: {count:>4} tokens ({pct:>5.1f}%) {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ê²Œì´íŒ… ê°€ì¤‘ì¹˜ ë¶„í¬ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# ì™¼ìª½: Expertë³„ ë¼ìš°íŒ… ë¹ˆë„\n",
    "ax1 = axes[0]\n",
    "expert_counts = [np.sum(flat_indices == i) for i in range(n_experts)]\n",
    "colors_exp = plt.cm.Set3(np.linspace(0, 1, n_experts))\n",
    "bars = ax1.bar(range(n_experts), expert_counts, color=colors_exp, edgecolor='black', lw=1)\n",
    "ax1.axhline(y=len(flat_indices) / n_experts, color='red', ls='--', lw=2, label='ê· ë“± ë¶„ë°°')\n",
    "ax1.set_xlabel('Expert ì¸ë±ìŠ¤', fontsize=11)\n",
    "ax1.set_ylabel('ë¼ìš°íŒ…ëœ í† í° ìˆ˜', fontsize=11)\n",
    "ax1.set_title(f'Expertë³„ ë¼ìš°íŒ… ë¹ˆë„ (Top-{top_k})', fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# ì˜¤ë¥¸ìª½: ê²Œì´íŒ… ê°€ì¤‘ì¹˜ ë¶„í¬\n",
    "ax2 = axes[1]\n",
    "gate_values = gates.numpy().flatten()\n",
    "ax2.hist(gate_values, bins=30, color='#1E88E5', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0.5, color='red', ls='--', lw=2, label='ê· ë“± (0.5)')\n",
    "ax2.set_xlabel('ê²Œì´íŒ… ê°€ì¤‘ì¹˜ g_i', fontsize=11)\n",
    "ax2.set_ylabel('ë¹ˆë„', fontsize=11)\n",
    "ax2.set_title('Top-2 ê²Œì´íŒ… ê°€ì¤‘ì¹˜ ë¶„í¬', fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter12_modern_llms/moe_routing.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter12_modern_llms/moe_routing.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Auxiliary Lossì™€ ë¶€í•˜ ê· í˜• <a name='3.-Auxiliary-Loss'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Auxiliary Loss êµ¬í˜„ ë° íš¨ê³¼ ê²€ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Aux Lossê°€ Expert ë¶€í•˜ ê· í˜•ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤\n",
    "\n",
    "def compute_aux_loss(routing_probs, indices, n_experts, alpha=0.01):\n",
    "    # routing_probs: [B, S, N] - ì „ì²´ softmax í™•ë¥ \n",
    "    # indices: [B, S, k] - ì„ íƒëœ expert ì¸ë±ìŠ¤\n",
    "    B, S, N = routing_probs.shape\n",
    "    T = B * S  # ì „ì²´ í† í° ìˆ˜\n",
    "    \n",
    "    # f_i: expert iì— ì‹¤ì œ ë¼ìš°íŒ…ëœ í† í° ë¹„ìœ¨\n",
    "    flat_indices = tf.reshape(indices, [-1])\n",
    "    f = tf.zeros(N)\n",
    "    for i in range(N):\n",
    "        f_i = tf.reduce_sum(tf.cast(tf.equal(flat_indices, i), tf.float32))\n",
    "        f = tf.tensor_scatter_nd_update(f, [[i]], [f_i / tf.cast(T, tf.float32)])\n",
    "    \n",
    "    # P_i: expert iì˜ í‰ê·  ë¼ìš°íŒ… í™•ë¥ \n",
    "    P = tf.reduce_mean(routing_probs, axis=[0, 1])  # [N]\n",
    "    \n",
    "    # L_aux = alpha * N * sum(f_i * P_i)\n",
    "    loss = alpha * tf.cast(N, tf.float32) * tf.reduce_sum(f * P)\n",
    "    return loss, f, P\n",
    "\n",
    "# ë¶ˆê· í˜• vs ê· í˜• ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ\n",
    "print(\"=\" * 65)\n",
    "print(\"Auxiliary Loss íš¨ê³¼ ë¶„ì„\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# ì‹œë‚˜ë¦¬ì˜¤ 1: Aux Loss ì—†ì´ í•™ìŠµ (ë¶ˆê· í˜• ë°œìƒ)\n",
    "# ì¸ìœ„ì ìœ¼ë¡œ ë¶ˆê· í˜•í•œ ë¼ìš°íŒ… ìƒì„±\n",
    "logits_biased = tf.constant([[\n",
    "    [5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # Expert 0 ì„ í˜¸\n",
    "    [4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [4.5, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "] * 8])  # [1, 32, 8]\n",
    "probs_biased = tf.nn.softmax(logits_biased, axis=-1)\n",
    "_, indices_biased = tf.math.top_k(logits_biased, k=2)\n",
    "loss_biased, f_biased, P_biased = compute_aux_loss(probs_biased, indices_biased, n_experts=8)\n",
    "\n",
    "# ì‹œë‚˜ë¦¬ì˜¤ 2: ê· í˜• ì¡íŒ ë¼ìš°íŒ…\n",
    "logits_balanced = tf.random.normal((1, 32, 8))\n",
    "probs_balanced = tf.nn.softmax(logits_balanced, axis=-1)\n",
    "_, indices_balanced = tf.math.top_k(logits_balanced, k=2)\n",
    "loss_balanced, f_balanced, P_balanced = compute_aux_loss(probs_balanced, indices_balanced, n_experts=8)\n",
    "\n",
    "print(f\"{'ì‹œë‚˜ë¦¬ì˜¤':<20} | {'Aux Loss':>12} | {'f ìµœëŒ€/ìµœì†Œ':>15} | {'ë¶ˆê· í˜•ë„':>10}\")\n",
    "print(\"-\" * 65)\n",
    "f_b = f_biased.numpy()\n",
    "f_bl = f_balanced.numpy()\n",
    "print(f\"{'ë¶ˆê· í˜• (í¸í–¥)':<20} | {loss_biased.numpy():>12.4f} | {f_b.max():.3f}/{f_b.min():.3f} | {'ë†’ìŒ':>10}\")\n",
    "print(f\"{'ê· í˜• (ëœë¤)':<20} | {loss_balanced.numpy():>12.4f} | {f_bl.max():.3f}/{f_bl.min():.3f} | {'ë‚®ìŒ':>10}\")\n",
    "print()\n",
    "print(\"Aux Lossê°€ ë†’ì„ìˆ˜ë¡ ë¶ˆê· í˜• â†’ Lossë¥¼ ìµœì†Œí™”í•˜ë©´ ìë™ìœ¼ë¡œ ê· í˜• ìœ ë„!\")\n",
    "print()\n",
    "\n",
    "# Expertë³„ ë¶„ë°° ë¹„êµ\n",
    "print(\"Expertë³„ í† í° ë¶„ë°° ë¹„ìœ¨ (f_i):\")\n",
    "print(f\"  {'Expert':<10}\", end='')\n",
    "for i in range(8):\n",
    "    print(f\" | {i:>6}\", end='')\n",
    "print()\n",
    "print(f\"  {'ë¶ˆê· í˜•':<10}\", end='')\n",
    "for v in f_b:\n",
    "    print(f\" | {v:>5.1%}\", end='')\n",
    "print()\n",
    "print(f\"  {'ê· í˜•':<10}\", end='')\n",
    "for v in f_bl:\n",
    "    print(f\" | {v:>5.1%}\", end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Expert Capacity Factor ì‹¤í—˜ <a name='4.-Expert-Capacity'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Expert Capacity Factor ì‹¤í—˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Capacityê°€ Expert í™œìš©ë¥ ê³¼ í† í° ë“œë¡­ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤\n",
    "\n",
    "def simulate_capacity(n_tokens, n_experts, top_k, capacity_factor):\n",
    "    # Capacity: ê° Expertê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ í† í° ìˆ˜\n",
    "    capacity = int(capacity_factor * top_k * n_tokens / n_experts)\n",
    "    \n",
    "    # ëœë¤ ë¼ìš°íŒ… (ì•½ê°„ì˜ í¸í–¥ í¬í•¨)\n",
    "    logits = np.random.randn(n_tokens, n_experts)\n",
    "    logits[:, 0] += 1.0  # Expert 0ì— ì•½ê°„ì˜ í¸í–¥\n",
    "    \n",
    "    top_k_indices = np.argsort(-logits, axis=-1)[:, :top_k]\n",
    "    \n",
    "    # Expertë³„ í• ë‹¹ (Capacity ì œí•œ)\n",
    "    expert_counts = np.zeros(n_experts, dtype=int)\n",
    "    assigned = 0\n",
    "    dropped = 0\n",
    "    \n",
    "    for token in range(n_tokens):\n",
    "        for k in range(top_k):\n",
    "            e = top_k_indices[token, k]\n",
    "            if expert_counts[e] < capacity:\n",
    "                expert_counts[e] += 1\n",
    "                assigned += 1\n",
    "            else:\n",
    "                dropped += 1\n",
    "    \n",
    "    total_assignments = n_tokens * top_k\n",
    "    utilization = assigned / total_assignments\n",
    "    drop_rate = dropped / total_assignments\n",
    "    \n",
    "    return capacity, utilization, drop_rate, expert_counts\n",
    "\n",
    "n_tokens = 1024\n",
    "n_experts = 8\n",
    "top_k = 2\n",
    "\n",
    "capacity_factors = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]\n",
    "results = []\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Expert Capacity Factor ì‹¤í—˜ (T={n_tokens}, N={n_experts}, k={top_k})\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'CF':>5} | {'Capacity':>10} | {'í™œìš©ë¥ ':>8} | {'ë“œë¡­ë¥ ':>8} | {'Expert ë¶„í¬ í¸ì°¨':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for cf in capacity_factors:\n",
    "    cap, util, drop, counts = simulate_capacity(n_tokens, n_experts, top_k, cf)\n",
    "    std = np.std(counts)\n",
    "    results.append((cf, cap, util, drop, std))\n",
    "    print(f\"{cf:>5.2f} | {cap:>10} | {util:>7.1%} | {drop:>7.1%} | {std:>15.1f}\")\n",
    "\n",
    "print()\n",
    "print(\"í•µì‹¬ ê´€ì°°:\")\n",
    "print(\"  â€¢ CF < 1.0: ìš©ëŸ‰ ë¶€ì¡± â†’ í† í° ë“œë¡­ ë°œìƒ (ì •ë³´ ì†ì‹¤)\")\n",
    "print(\"  â€¢ CF = 1.0: ì´ë¡ ìƒ ë”± ë§ì§€ë§Œ, ë¶ˆê· í˜• ì‹œ ì¼ë¶€ ë“œë¡­\")\n",
    "print(\"  â€¢ CF > 1.0: ì—¬ìœ  ìˆì§€ë§Œ, ë©”ëª¨ë¦¬/ì—°ì‚° ë‚­ë¹„ ì¦ê°€\")\n",
    "print(\"  â€¢ ì‹¤ì „ ê¶Œì¥: CF = 1.0~1.25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Capacity Factor ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# ì™¼ìª½: CFë³„ í™œìš©ë¥ /ë“œë¡­ë¥ \n",
    "ax1 = axes[0]\n",
    "cfs = [r[0] for r in results]\n",
    "utils = [r[2] for r in results]\n",
    "drops = [r[3] for r in results]\n",
    "\n",
    "ax1.plot(cfs, utils, 'b-o', lw=2.5, ms=8, label='í™œìš©ë¥ ')\n",
    "ax1.plot(cfs, drops, 'r-s', lw=2.5, ms=8, label='ë“œë¡­ë¥ ')\n",
    "ax1.axvline(x=1.0, color='gray', ls='--', lw=1.5, label='CF=1.0')\n",
    "ax1.set_xlabel('Capacity Factor', fontsize=11)\n",
    "ax1.set_ylabel('ë¹„ìœ¨', fontsize=11)\n",
    "ax1.set_title('CFë³„ Expert í™œìš©ë¥  vs ë“œë¡­ë¥ ', fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ì˜¤ë¥¸ìª½: Expertë³„ í† í° ë¶„ë°° (CF=1.0 vs CF=1.5)\n",
    "ax2 = axes[1]\n",
    "_, _, _, counts_1 = simulate_capacity(n_tokens, n_experts, top_k, 1.0)\n",
    "_, _, _, counts_15 = simulate_capacity(n_tokens, n_experts, top_k, 1.5)\n",
    "\n",
    "x_pos = np.arange(n_experts)\n",
    "width = 0.35\n",
    "ax2.bar(x_pos - width/2, counts_1, width, label='CF=1.0', color='#1E88E5', edgecolor='black')\n",
    "ax2.bar(x_pos + width/2, counts_15, width, label='CF=1.5', color='#43A047', edgecolor='black')\n",
    "ax2.axhline(y=n_tokens * top_k / n_experts, color='red', ls='--', lw=2, label='ì´ìƒì  ê· ë“±')\n",
    "ax2.set_xlabel('Expert ì¸ë±ìŠ¤', fontsize=11)\n",
    "ax2.set_ylabel('í• ë‹¹ëœ í† í° ìˆ˜', fontsize=11)\n",
    "ax2.set_title('CFë³„ Expert í† í° ë¶„ë°°', fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('chapter12_modern_llms/moe_capacity.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter12_modern_llms/moe_capacity.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì •ë¦¬ <a name='5.-ì •ë¦¬'></a>\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |\n",
    "|------|------|--------|\n",
    "| Top-k ê²Œì´íŒ… | $N$ê°œ Expert ì¤‘ $k$ê°œë§Œ í™œì„±í™” â†’ ì—°ì‚° íš¨ìœ¨ | â­â­â­ |\n",
    "| Auxiliary Loss | $L_{aux} = \\alpha N \\sum f_i P_i$ â†’ Expert ë¶€í•˜ ê· í˜• ìœ ë„ | â­â­â­ |\n",
    "| Capacity Factor | Expertë‹¹ ìµœëŒ€ í† í° ìˆ˜ ì œí•œ â†’ ë©”ëª¨ë¦¬/ë“œë¡­ íŠ¸ë ˆì´ë“œì˜¤í”„ | â­â­ |\n",
    "| Softmax ê²Œì´íŒ… | Top-k ì„ íƒ í›„ ì¬ì •ê·œí™” â†’ ë¶€ë“œëŸ¬ìš´ ê°€ì¤‘ì¹˜ | â­â­ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$y = \\sum_{i \\in \\text{Top-k}} g_i \\cdot E_i(x), \\quad g_i = \\frac{e^{h_i}}{\\sum_{j \\in \\text{Top-k}} e^{h_j}}$$\n",
    "\n",
    "$$L_{aux} = \\alpha \\cdot N \\sum_{i=1}^{N} f_i \\cdot P_i$$\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**Chapter 12-05: DeepSeek-V3 MoE ì•„í‚¤í…ì²˜** â€” Shared Expert, Auxiliary-Loss-Free ë¡œë“œë°¸ëŸ°ì‹±, Multi-Token Prediction ë“± ìµœì‹  MoE í˜ì‹ ì„ ë‹¤ë£¹ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}