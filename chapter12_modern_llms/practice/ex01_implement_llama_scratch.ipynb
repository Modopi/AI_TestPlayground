{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‹¤ìŠµ í€´ì¦ˆ: Llama ì•„í‚¤í…ì²˜ ë°‘ë°”ë‹¥ êµ¬í˜„\n",
    "\n",
    "## ì‚¬ìš© ë°©ë²•\n",
    "- ê° ë¬¸ì œ ì…€ì„ ì½ê³ , **ì§ì ‘ ë‹µì„ ì˜ˆì¸¡í•œ í›„** í’€ì´ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”\n",
    "- ì½”ë“œ ì‹¤í–‰ ì „ì— ì¢…ì´ì— ê³„ì‚°í•´ë³´ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "- [Q1: RMSNorm ì§ì ‘ êµ¬í˜„](#q1)\n",
    "- [Q2: RoPE ì ìš© í›„ Attention Score ê³„ì‚°](#q2)\n",
    "- [Q3: SwiGLU FFN Forward Pass](#q3)\n",
    "- [Q4: GQA Attention êµ¬í˜„](#q4)\n",
    "- [ì¢…í•© ë„ì „: ì†Œí˜• Llama Block ëª¨ë“ˆ ì¡°ë¦½](#bonus)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ í™˜ê²½ ì„¤ì •\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n",
    "print(\"í€´ì¦ˆ í™˜ê²½ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"ê° ë¬¸ì œë¥¼ í’€ê¸° ì „ì— ë¨¼ì € ë‹µì„ ì˜ˆì¸¡í•´ë³´ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q1: RMSNorm ì§ì ‘ êµ¬í˜„ <a name='q1'></a>\n",
    "\n",
    "### ë¬¸ì œ\n",
    "\n",
    "ë‹¤ìŒ ì¡°ê±´ìœ¼ë¡œ RMSNormì„ êµ¬í˜„í•˜ì„¸ìš”:\n",
    "- ì…ë ¥: $x = [1.0, 2.0, 3.0, 4.0]$\n",
    "- ê²Œì¸: $g = [1.0, 1.0, 1.0, 1.0]$\n",
    "- $\\epsilon = 10^{-6}$\n",
    "\n",
    "$$\\text{RMSNorm}(x_i) = \\frac{x_i}{\\sqrt{\\frac{1}{n}\\sum_j x_j^2 + \\epsilon}} \\cdot g_i$$\n",
    "\n",
    "**ì—¬ëŸ¬ë¶„ì˜ ì˜ˆì¸¡:** RMSNorm ì¶œë ¥ì˜ L2 normì€ `?` ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Q1 í’€ì´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=\" * 45)\n",
    "print(\"Q1 í’€ì´: RMSNorm ì§ì ‘ êµ¬í˜„\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "x = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "g = tf.constant([1.0, 1.0, 1.0, 1.0])\n",
    "eps = 1e-6\n",
    "\n",
    "# RMS ê³„ì‚°\n",
    "rms = tf.sqrt(tf.reduce_mean(tf.square(x)) + eps)\n",
    "print(f\"ì…ë ¥ x: {x.numpy()}\")\n",
    "print(f\"x^2: {tf.square(x).numpy()}\")\n",
    "print(f\"mean(x^2): {tf.reduce_mean(tf.square(x)).numpy():.4f}\")\n",
    "print(f\"RMS = sqrt(mean(x^2) + eps) = {rms.numpy():.6f}\")\n",
    "\n",
    "# ì •ê·œí™”\n",
    "output = (x / rms) * g\n",
    "print(f\"\\nRMSNorm ì¶œë ¥: {output.numpy()}\")\n",
    "print(f\"ì¶œë ¥ L2 norm: {tf.norm(output).numpy():.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"[í•´ì„¤]\")\n",
    "print(f\"  RMS = sqrt((1+4+9+16)/4) = sqrt(30/4) = sqrt(7.5) = {np.sqrt(7.5):.4f}\")\n",
    "print(\"  RMSNormì€ ë²¡í„°ë¥¼ sqrt(n) í¬ê¸°ë¡œ ì •ê·œí™”\")\n",
    "print(f\"  ì¶œë ¥ L2 norm â‰ˆ sqrt(n) = sqrt(4) = 2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q2: RoPE ì ìš© í›„ Attention Score <a name='q2'></a>\n",
    "\n",
    "### ë¬¸ì œ\n",
    "\n",
    "2D ë²¡í„° $q = [1, 0]$, $k = [1, 0]$ì— RoPE($\\theta = \\pi/4$)ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
    "- Q ìœ„ì¹˜: $m = 0$\n",
    "- K ìœ„ì¹˜: $n = 2$\n",
    "\n",
    "RoPE ì ìš© í›„ $q \\cdot k$ (ë‚´ì )ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n",
    "\n",
    "**ì—¬ëŸ¬ë¶„ì˜ ì˜ˆì¸¡:** ë‚´ì  ê°’ì€ `?` ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Q2 í’€ì´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=\" * 45)\n",
    "print(\"Q2 í’€ì´: RoPE ì ìš© í›„ Attention Score\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "theta = np.pi / 4  # 45ë„\n",
    "q = np.array([1.0, 0.0])\n",
    "k = np.array([1.0, 0.0])\n",
    "m, n = 0, 2\n",
    "\n",
    "# RoPE íšŒì „ ì ìš©\n",
    "def rotate_2d(vec, angle):\n",
    "    cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "    return np.array([vec[0]*cos_a - vec[1]*sin_a,\n",
    "                     vec[0]*sin_a + vec[1]*cos_a])\n",
    "\n",
    "q_rot = rotate_2d(q, m * theta)  # m=0ì´ë¯€ë¡œ íšŒì „ ì—†ìŒ\n",
    "k_rot = rotate_2d(k, n * theta)  # n=2, ê°ë„=pi/2\n",
    "\n",
    "dot = np.dot(q_rot, k_rot)\n",
    "\n",
    "print(f\"q = {q}, m = {m}\")\n",
    "print(f\"k = {k}, n = {n}\")\n",
    "print(f\"theta = pi/4 = {theta:.4f}\")\n",
    "print()\n",
    "print(f\"q íšŒì „ (m*theta = {m*theta:.2f}): {q_rot}\")\n",
    "print(f\"k íšŒì „ (n*theta = {n*theta:.2f}): {k_rot}\")\n",
    "print(f\"ë‚´ì  q_rot Â· k_rot = {dot:.4f}\")\n",
    "print()\n",
    "print(\"[í•´ì„¤]\")\n",
    "print(f\"  qëŠ” 0ë„ íšŒì „ (ê·¸ëŒ€ë¡œ): [1, 0]\")\n",
    "print(f\"  këŠ” pi/2 íšŒì „: [cos(pi/2), sin(pi/2)] = [0, 1]\")\n",
    "print(f\"  ë‚´ì  = 1*0 + 0*1 = 0\")\n",
    "print(f\"  ìƒëŒ€ ê±°ë¦¬ |m-n|=2 â†’ ê°ë„ ì°¨ì´ = 2*pi/4 = pi/2 â†’ ì§êµ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q3: SwiGLU FFN Forward Pass <a name='q3'></a>\n",
    "\n",
    "### ë¬¸ì œ\n",
    "\n",
    "SwiGLU FFNì˜ ì¤‘ê°„ ì¶œë ¥ì„ ê³„ì‚°í•˜ì„¸ìš”:\n",
    "- $x = [1.0, -1.0]$, $d_{model} = 2$, $d_{ff} = 3$\n",
    "- $W_1 = [[1, 0, -1], [0, 1, 0]]$ (gate)\n",
    "- $W_2 = [[0, 1, 1], [1, 0, -1]]$ (up)\n",
    "- Swish = SiLU: $x \\cdot \\sigma(x)$\n",
    "\n",
    "**ì—¬ëŸ¬ë¶„ì˜ ì˜ˆì¸¡:** $\\text{Swish}(xW_1) \\otimes (xW_2)$ì˜ ê²°ê³¼ëŠ” `?` ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Q3 í’€ì´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=\" * 45)\n",
    "print(\"Q3 í’€ì´: SwiGLU FFN Forward Pass\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "x = np.array([[1.0, -1.0]])\n",
    "W1 = np.array([[1, 0, -1], [0, 1, 0]])  # gate\n",
    "W2 = np.array([[0, 1, 1], [1, 0, -1]])  # up\n",
    "\n",
    "# Step 1: xW1 (gate projection)\n",
    "gate_linear = x @ W1\n",
    "print(f\"x = {x[0]}\")\n",
    "print(f\"xW1 (gate) = {gate_linear[0]}\")\n",
    "\n",
    "# Step 2: Swish(xW1)\n",
    "def swish(z):\n",
    "    return z * (1 / (1 + np.exp(-z)))\n",
    "\n",
    "gate = swish(gate_linear)\n",
    "print(f\"Swish(xW1)  = {gate[0]}\")\n",
    "\n",
    "# Step 3: xW2 (up projection)\n",
    "up = x @ W2\n",
    "print(f\"xW2 (up)    = {up[0]}\")\n",
    "\n",
    "# Step 4: element-wise product\n",
    "swiglu_out = gate * up\n",
    "print(f\"Gate âŠ— Up   = {swiglu_out[0]}\")\n",
    "print()\n",
    "\n",
    "print(\"[í•´ì„¤]\")\n",
    "print(\"  1. xW1 = [1*1+(-1)*0, 1*0+(-1)*1, 1*(-1)+(-1)*0] = [1, -1, -1]\")\n",
    "print(f\"  2. Swish([1,-1,-1]) = [1*Ïƒ(1), -1*Ïƒ(-1), -1*Ïƒ(-1)]\")\n",
    "print(f\"     = [{1*0.7311:.4f}, {-1*0.2689:.4f}, {-1*0.2689:.4f}]\")\n",
    "print(\"  3. xW2 = [0+1, 1+0, 1-(-1)] = [-1, 1, 2]\")\n",
    "print(f\"  4. Gate âŠ— Up = element-wise product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q4: GQA Attention êµ¬í˜„ <a name='q4'></a>\n",
    "\n",
    "### ë¬¸ì œ\n",
    "\n",
    "$H_Q = 4, H_{KV} = 2, d_{head} = 4$ì¼ ë•Œ:\n",
    "1. Q ê·¸ë£¹ ìˆ˜ëŠ”?\n",
    "2. Q í”„ë¡œì ì…˜ íŒŒë¼ë¯¸í„° ìˆ˜ vs KV í”„ë¡œì ì…˜ íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„ìœ¨ì€?\n",
    "\n",
    "**ì—¬ëŸ¬ë¶„ì˜ ì˜ˆì¸¡:** ê·¸ë£¹ ìˆ˜ëŠ” `?`, íŒŒë¼ë¯¸í„° ë¹„ìœ¨ì€ `?` ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Q4 í’€ì´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=\" * 45)\n",
    "print(\"Q4 í’€ì´: GQA Attention êµ¬í˜„\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "H_Q, H_KV, d_head = 4, 2, 4\n",
    "d_model = H_Q * d_head  # 16\n",
    "\n",
    "n_groups = H_Q // H_KV\n",
    "print(f\"H_Q = {H_Q}, H_KV = {H_KV}, d_head = {d_head}\")\n",
    "print(f\"d_model = H_Q * d_head = {d_model}\")\n",
    "print(f\"Q ê·¸ë£¹ ìˆ˜ = H_Q / H_KV = {n_groups}\")\n",
    "print()\n",
    "\n",
    "# íŒŒë¼ë¯¸í„° ìˆ˜\n",
    "wq_params = d_model * (H_Q * d_head)    # Q projection\n",
    "wk_params = d_model * (H_KV * d_head)   # K projection\n",
    "wv_params = d_model * (H_KV * d_head)   # V projection\n",
    "wo_params = d_model * d_model            # O projection\n",
    "\n",
    "print(f\"Wq íŒŒë¼ë¯¸í„°: d_model Ã— (H_Q Ã— d_head) = {d_model} Ã— {H_Q * d_head} = {wq_params}\")\n",
    "print(f\"Wk íŒŒë¼ë¯¸í„°: d_model Ã— (H_KV Ã— d_head) = {d_model} Ã— {H_KV * d_head} = {wk_params}\")\n",
    "print(f\"Wv íŒŒë¼ë¯¸í„°: d_model Ã— (H_KV Ã— d_head) = {d_model} Ã— {H_KV * d_head} = {wv_params}\")\n",
    "print(f\"Wo íŒŒë¼ë¯¸í„°: d_model Ã— d_model = {d_model} Ã— {d_model} = {wo_params}\")\n",
    "print()\n",
    "print(f\"Q / KV íŒŒë¼ë¯¸í„° ë¹„ìœ¨: {wq_params} / {wk_params} = {wq_params/wk_params:.1f}x\")\n",
    "print(f\"MHA ëŒ€ë¹„ KV ì ˆê°ë¥ : {(1 - H_KV/H_Q)*100:.0f}%\")\n",
    "print()\n",
    "\n",
    "# ì‹¤ì œ GQA ì—°ì‚° ì‹œë®¬ë ˆì´ì…˜\n",
    "x = tf.random.normal((1, 8, d_model))\n",
    "Wq = tf.random.normal((d_model, H_Q * d_head))\n",
    "Wk = tf.random.normal((d_model, H_KV * d_head))\n",
    "\n",
    "Q = tf.reshape(x @ Wq, (1, 8, H_Q, d_head))\n",
    "K = tf.reshape(x @ Wk, (1, 8, H_KV, d_head))\n",
    "\n",
    "# KV repeat\n",
    "K_repeated = tf.repeat(K, repeats=n_groups, axis=2)\n",
    "\n",
    "print(f\"Q shape: {Q.shape} â†’ [B, S, H_Q, d_head]\")\n",
    "print(f\"K shape (ì›ë³¸): {K.shape} â†’ [B, S, H_KV, d_head]\")\n",
    "print(f\"K shape (ë°˜ë³µ): {K_repeated.shape} â†’ [B, S, H_Q, d_head]\")\n",
    "print()\n",
    "print(\"[í•´ì„¤]\")\n",
    "print(f\"  GQAì—ì„œ {H_KV}ê°œì˜ KV í—¤ë“œë¥¼ {n_groups}ë²ˆ ë°˜ë³µí•˜ì—¬ {H_Q}ê°œì˜ Q í—¤ë“œì— ë§¤ì¹­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì¢…í•© ë„ì „: ì†Œí˜• Llama Block ëª¨ë“ˆ ì¡°ë¦½ <a name='bonus'></a>\n",
    "\n",
    "### ë¬¸ì œ\n",
    "\n",
    "ë‹¤ìŒ êµ¬ì„± ìš”ì†Œë¥¼ ëª¨ë‘ ì¡°í•©í•˜ì—¬ **ì™„ì „í•œ Llama Decoder Block**ì„ êµ¬í˜„í•˜ì„¸ìš”:\n",
    "1. Pre-Norm: RMSNorm\n",
    "2. Attention: GQA (H_Q=8, H_KV=2)\n",
    "3. FFN: SwiGLU (d_ff = 8/3 * d_model)\n",
    "4. Residual Connection\n",
    "\n",
    "ì„¤ì •: `d_model=64, seq_len=16, batch=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ ì¢…í•© ë„ì „ í’€ì´: ì†Œí˜• Llama Block ì¡°ë¦½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=\" * 55)\n",
    "print(\"ì¢…í•© ë„ì „: ì†Œí˜• Llama Decoder Block\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# êµ¬ì„± ìš”ì†Œ ì •ì˜\n",
    "class RMSNorm(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.g = self.add_weight(name='gain', shape=(dim,), initializer='ones')\n",
    "    def call(self, x):\n",
    "        rms = tf.sqrt(tf.reduce_mean(tf.square(x), axis=-1, keepdims=True) + self.eps)\n",
    "        return (x / rms) * self.g\n",
    "\n",
    "class GQAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_q_heads, n_kv_heads):\n",
    "        super().__init__()\n",
    "        self.n_q = n_q_heads\n",
    "        self.n_kv = n_kv_heads\n",
    "        self.d_h = d_model // n_q_heads\n",
    "        self.groups = n_q_heads // n_kv_heads\n",
    "        self.wq = tf.keras.layers.Dense(n_q_heads * self.d_h, use_bias=False)\n",
    "        self.wk = tf.keras.layers.Dense(n_kv_heads * self.d_h, use_bias=False)\n",
    "        self.wv = tf.keras.layers.Dense(n_kv_heads * self.d_h, use_bias=False)\n",
    "        self.wo = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        B, S, _ = x.shape\n",
    "        q = tf.reshape(self.wq(x), (B, S, self.n_q, self.d_h))\n",
    "        k = tf.reshape(self.wk(x), (B, S, self.n_kv, self.d_h))\n",
    "        v = tf.reshape(self.wv(x), (B, S, self.n_kv, self.d_h))\n",
    "        k = tf.repeat(k, self.groups, axis=2)\n",
    "        v = tf.repeat(v, self.groups, axis=2)\n",
    "        q, k, v = [tf.transpose(t, [0, 2, 1, 3]) for t in [q, k, v]]\n",
    "        attn = tf.nn.softmax(tf.matmul(q, k, transpose_b=True) / tf.sqrt(float(self.d_h)))\n",
    "        return self.wo(tf.reshape(tf.transpose(tf.matmul(attn, v), [0, 2, 1, 3]), (B, S, -1)))\n",
    "\n",
    "class SwiGLUFFN(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.w1 = tf.keras.layers.Dense(d_ff, use_bias=False)\n",
    "        self.w2 = tf.keras.layers.Dense(d_ff, use_bias=False)\n",
    "        self.w3 = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "    def call(self, x):\n",
    "        return self.w3(tf.nn.silu(self.w1(x)) * self.w2(x))\n",
    "\n",
    "class LlamaBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_q, n_kv, d_ff):\n",
    "        super().__init__()\n",
    "        self.norm1 = RMSNorm(d_model)\n",
    "        self.attn = GQAttention(d_model, n_q, n_kv)\n",
    "        self.norm2 = RMSNorm(d_model)\n",
    "        self.ffn = SwiGLUFFN(d_model, d_ff)\n",
    "    def call(self, x):\n",
    "        x = x + self.attn(self.norm1(x))   # Pre-Norm + Residual\n",
    "        x = x + self.ffn(self.norm2(x))     # Pre-Norm + Residual\n",
    "        return x\n",
    "\n",
    "# ì¡°ë¦½ ë° í…ŒìŠ¤íŠ¸\n",
    "d_model = 64\n",
    "block = LlamaBlock(d_model=d_model, n_q=8, n_kv=2, d_ff=int(8/3*d_model))\n",
    "x = tf.random.normal((2, 16, d_model))\n",
    "out = block(x)\n",
    "\n",
    "total_params = sum(tf.size(v).numpy() for v in block.trainable_variables)\n",
    "\n",
    "print(f\"ì„¤ì •: d_model={d_model}, H_Q=8, H_KV=2, d_ff={int(8/3*d_model)}\")\n",
    "print(f\"ì…ë ¥: {x.shape}\")\n",
    "print(f\"ì¶œë ¥: {out.shape}\")\n",
    "print(f\"Shape ë³´ì¡´: {x.shape == out.shape}\")\n",
    "print(f\"ì´ íŒŒë¼ë¯¸í„°: {total_params:,}\")\n",
    "print()\n",
    "print(\"ì•„í‚¤í…ì²˜:\")\n",
    "print(\"  x â†’ RMSNorm â†’ GQA (H_Q=8, H_KV=2) â†’ + residual\")\n",
    "print(\"    â†’ RMSNorm â†’ SwiGLU FFN â†’ + residual â†’ output\")\n",
    "print()\n",
    "print(\"ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! Llama 3 ìŠ¤íƒ€ì¼ Decoder Blockì„ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}