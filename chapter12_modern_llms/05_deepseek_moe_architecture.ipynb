{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: ìµœì‹  LLM ì•„í‚¤í…ì²˜ â€” DeepSeek-V3 MoE ì•„í‚¤í…ì²˜\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- DeepSeek-V3ì˜ **Shared Expert + Routed Expert** ë¶„ë¦¬ ì„¤ê³„ì˜ ìˆ˜í•™ì  ì›ë¦¬ë¥¼ ì´í•´í•œë‹¤\n",
    "- **Auxiliary-Loss-Free ë¡œë“œë°¸ëŸ°ì‹±**(í¸í–¥ ë³´ì •) ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•œë‹¤\n",
    "- **Multi-Token Prediction(MTP)** ìˆ˜ì‹ì„ ë„ì¶œí•˜ê³  ì‹œë®¬ë ˆì´ì…˜í•œë‹¤\n",
    "- DeepSeek-V3ì˜ ì‹¤ì œ ì•„í‚¤í…ì²˜ ìŠ¤í™(671B, 256 Experts)ì„ ë¶„ì„í•œë‹¤\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [ìˆ˜í•™ì  ê¸°ì´ˆ: DeepSeekMoEì™€ MTP](#1.-ìˆ˜í•™ì -ê¸°ì´ˆ)\n",
    "2. [DeepSeekMoE ë ˆì´ì–´ êµ¬í˜„](#2.-DeepSeekMoE)\n",
    "3. [Auxiliary-Loss-Free ë¡œë“œë°¸ëŸ°ì‹±](#3.-Aux-Free-Balance)\n",
    "4. [Multi-Token Prediction (MTP)](#4.-MTP)\n",
    "5. [ì •ë¦¬](#5.-ì •ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ìˆ˜í•™ì  ê¸°ì´ˆ <a name='1.-ìˆ˜í•™ì -ê¸°ì´ˆ'></a>\n",
    "\n",
    "### DeepSeekMoE: Shared Expert + Routed Expert\n",
    "\n",
    "DeepSeek-V3ëŠ” ê¸°ì¡´ MoEì™€ ë‹¬ë¦¬ **ê³µìœ  ì „ë¬¸ê°€(Shared Expert)**ë¥¼ ë„ì…í•©ë‹ˆë‹¤:\n",
    "\n",
    "$$y = \\underbrace{E_s(x)}_{\\text{Shared Expert}} + \\sum_{i \\in \\text{Top-k}} g_i \\cdot E_i^r(x)$$\n",
    "\n",
    "- $E_s$: Shared Expert â€” **ëª¨ë“  í† í°**ì´ ë°˜ë“œì‹œ ê±°ì¹˜ëŠ” ì „ë¬¸ê°€ (ê³µí†µ ì§€ì‹)\n",
    "- $E_i^r$: Routed Expert â€” Top-kë¡œ **ì„ íƒëœ** ì „ë¬¸ê°€ (ì „ë¬¸ ì§€ì‹)\n",
    "- $g_i$: ë¼ìš°íŒ… ê²Œì´íŠ¸ ê°€ì¤‘ì¹˜\n",
    "\n",
    "**DeepSeek-V3 ì‹¤ì œ ìŠ¤í™** (arxiv:2412.19437):\n",
    "\n",
    "| í•­ëª© | ê°’ |\n",
    "|------|-----|\n",
    "| ì´ íŒŒë¼ë¯¸í„° | 671B |\n",
    "| í™œì„± íŒŒë¼ë¯¸í„°/í† í° | 37B |\n",
    "| ë ˆì´ì–´ ìˆ˜ | 61 |\n",
    "| Shared Expert | 1ê°œ |\n",
    "| Routed Expert | 256ê°œ |\n",
    "| Top-k | 8 |\n",
    "| íˆë“  ì°¨ì› | 7,168 |\n",
    "\n",
    "### Auxiliary-Loss-Free ë¡œë“œë°¸ëŸ°ì‹±\n",
    "\n",
    "ê¸°ì¡´ Aux Loss($L_{aux}$)ëŠ” ëª¨ë¸ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¤ëŠ” ë¶€ì‘ìš©ì´ ìˆì—ˆìŠµë‹ˆë‹¤. DeepSeek-V3ëŠ” **í¸í–¥(bias) í•­**ìœ¼ë¡œ ëŒ€ì²´:\n",
    "\n",
    "$$g_i' = g_i + b_i$$\n",
    "\n",
    "- $b_i$: Expert $i$ì˜ í¸í–¥ í•­ (í•™ìŠµí•˜ì§€ ì•ŠìŒ!)\n",
    "- **ì—…ë°ì´íŠ¸ ê·œì¹™**: Expert $i$ê°€ ê³¼ë„í•˜ê²Œ ì‚¬ìš©ë˜ë©´ $b_i$ ê°ì†Œ, ì ê²Œ ì‚¬ìš©ë˜ë©´ $b_i$ ì¦ê°€\n",
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„° $\\gamma$ê°€ í¸í–¥ ì—…ë°ì´íŠ¸ ì†ë„ë¥¼ ì œì–´\n",
    "\n",
    "$$b_i \\leftarrow b_i + \\gamma \\cdot (\\bar{f} - f_i)$$\n",
    "\n",
    "ì—¬ê¸°ì„œ $\\bar{f} = 1/N$ (ì´ìƒì  ê· ë“± ë¹„ìœ¨), $f_i$ = ì‹¤ì œ ë¹„ìœ¨\n",
    "\n",
    "### Multi-Token Prediction (MTP)\n",
    "\n",
    "ê¸°ì¡´ LLMì€ ë‹¤ìŒ 1ê°œ í† í°ë§Œ ì˜ˆì¸¡í•˜ì§€ë§Œ, MTPëŠ” **ì—¬ëŸ¬ ë¯¸ë˜ í† í°ì„ ë™ì‹œ ì˜ˆì¸¡**:\n",
    "\n",
    "$$\\mathcal{L}_{MTP} = -\\frac{1}{D} \\sum_{k=1}^{D} \\sum_{t=1}^{T-k} \\log P_\\theta(x_{t+k} | x_{\\leq t})$$\n",
    "\n",
    "- $D$: ì˜ˆì¸¡ ê¹Šì´ (depth) â€” DeepSeek-V3ëŠ” $D=1$ (2í† í° ë™ì‹œ)\n",
    "- í•™ìŠµ ì‹œ ì¶”ê°€ ì˜ˆì¸¡ í—¤ë“œ ì‚¬ìš©, ì¶”ë¡  ì‹œ Speculative Decodingì— í™œìš©\n",
    "\n",
    "**ìš”ì•½ í‘œ:**\n",
    "\n",
    "| í˜ì‹  | ìˆ˜ì‹ | íš¨ê³¼ |\n",
    "|------|------|------|\n",
    "| Shared Expert | $y = E_s(x) + \\sum g_i E_i^r(x)$ | ê³µí†µ ì§€ì‹ ë³´ì¡´ |\n",
    "| Aux-Free Balance | $g_i' = g_i + b_i$ | ì„±ëŠ¥ ì €í•˜ ì—†ëŠ” ê· í˜• |\n",
    "| MTP | $\\mathcal{L} = \\sum_{k=1}^{D} \\mathcal{L}_k$ | í‘œí˜„ë ¥ í–¥ìƒ + Spec. Decoding |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ£ ì´ˆë“±í•™ìƒì„ ìœ„í•œ DeepSeek MoE ì¹œì ˆ ì„¤ëª…!\n",
    "\n",
    "#### ğŸ« Shared Expertê°€ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: **í•™êµ ìˆ˜ì—…**ì„ ìƒê°í•´ë³´ì„¸ìš”!\n",
    "> - **ê³µí†µ ìˆ˜ì—…**(êµ­ì–´, ìˆ˜í•™) = Shared Expert â†’ ëª¨ë“  í•™ìƒì´ ë“¤ì–´ì•¼ í•¨\n",
    "> - **ì„ íƒ ê³¼ëª©**(ë¯¸ìˆ , ìŒì•…, ì½”ë”©) = Routed Expert â†’ ê°ì ì›í•˜ëŠ” 2ê°œë§Œ ì„ íƒ\n",
    ">\n",
    "> ê³µí†µ ì§€ì‹ì€ ëª¨ë‘ê°€ ë°°ìš°ê³ , ì „ë¬¸ ì§€ì‹ì€ í•„ìš”í•œ í•™ìƒë§Œ!\n",
    "\n",
    "#### âš–ï¸ Auxiliary-Loss-Freeê°€ ë­”ê°€ìš”?\n",
    "\n",
    "> ğŸ’¡ **ë¹„ìœ **: ê¸°ì¡´ ë°©ë²•ì€ \"ë°˜ì¥ì´ ë²Œì ì„ ì¤˜ì„œ\" ê³¨ê³ ë£¨ ë‚˜ëˆ´ëŠ”ë°, DeepSeek ë°©ë²•ì€ \"ê° ì„ íƒ ê³¼ëª©ì˜ ì¸ê¸°ë„ë¥¼ ë³´ê³  ìë™ìœ¼ë¡œ ì‹œê°„í‘œë¥¼ ì¡°ì •\"í•´ìš”. ë²Œì (Loss)ì´ í•„ìš” ì—†ì–´ì„œ í•™ìŠµì´ ë” ì˜ ë©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ“ ì—°ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ë¬¸ì œ 1: DeepSeek-V3 í™œì„± íŒŒë¼ë¯¸í„°\n",
    "\n",
    "DeepSeek-V3ì—ì„œ 1ê°œ Shared Expert + Top-8 Routed Expertê°€ í™œì„±í™”ë©ë‹ˆë‹¤. ì „ì²´ 256ê°œ Routed Expert ì¤‘ í™œì„±í™” ë¹„ìœ¨ì€?\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "ì´ í™œì„± Expert: $1 (\\text{shared}) + 8 (\\text{routed}) = 9$\n",
    "\n",
    "Routed Expert í™œì„± ë¹„ìœ¨: $8 / 256 = 3.125\\%$\n",
    "\n",
    "ì „ì²´ Expert í™œì„± ë¹„ìœ¨: $9 / 257 = 3.5\\%$\n",
    "\n",
    "â†’ ì „ì²´ 671B ì¤‘ 37Bë§Œ í™œì„±í™” = $37/671 = 5.5\\%$\n",
    "\n",
    "ë‚˜ë¨¸ì§€ íŒŒë¼ë¯¸í„°ëŠ” ì„ë² ë”©, Attention ë“±ì— ì‚¬ìš©\n",
    "</details>\n",
    "\n",
    "#### ë¬¸ì œ 2: í¸í–¥ ë³´ì • ì‹œë®¬ë ˆì´ì…˜\n",
    "\n",
    "Expert 4ê°œ, í˜„ì¬ ë¶„ë°° $f = [0.4, 0.3, 0.2, 0.1]$, $\\gamma=0.1$ì¼ ë•Œ í¸í–¥ ì—…ë°ì´íŠ¸ í›„ ìƒˆ $b$ë¥¼ ê³„ì‚°í•˜ì‹œì˜¤ (ì´ˆê¸° $b=[0,0,0,0]$).\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ í’€ì´ í™•ì¸</summary>\n",
    "\n",
    "$\\bar{f} = 1/4 = 0.25$\n",
    "\n",
    "$b_0 = 0 + 0.1 \\times (0.25 - 0.4) = -0.015$ (ê³¼ë‹¤ â†’ ê°ì†Œ)\n",
    "\n",
    "$b_1 = 0 + 0.1 \\times (0.25 - 0.3) = -0.005$\n",
    "\n",
    "$b_2 = 0 + 0.1 \\times (0.25 - 0.2) = +0.005$ (ê³¼ì†Œ â†’ ì¦ê°€)\n",
    "\n",
    "$b_3 = 0 + 0.1 \\times (0.25 - 0.1) = +0.015$\n",
    "\n",
    "í¸í–¥ìœ¼ë¡œ ì¸í•´ Expert 0,1ì€ ì„ íƒ í™•ë¥  ê°ì†Œ, Expert 2,3ì€ ì¦ê°€ â†’ ê· í˜•ìœ¼ë¡œ ìˆ˜ë ´!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DeepSeekMoE ë ˆì´ì–´ êµ¬í˜„ <a name='2.-DeepSeekMoE'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ DeepSeekMoE ë ˆì´ì–´ êµ¬í˜„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Shared Expert 1ê°œ + Routed Expert Nê°œì˜ DeepSeek ìŠ¤íƒ€ì¼ MoE\n",
    "\n",
    "class DeepSeekMoELayer(tf.keras.layers.Layer):\n",
    "    # DeepSeek-V3 ìŠ¤íƒ€ì¼ MoE: Shared Expert + Routed Experts\n",
    "    def __init__(self, d_model, d_ff, n_routed_experts, top_k=2, n_shared=1):\n",
    "        super().__init__()\n",
    "        self.n_routed = n_routed_experts\n",
    "        self.n_shared = n_shared\n",
    "        self.top_k = top_k\n",
    "        \n",
    "        # Shared Expert(s)\n",
    "        self.shared_experts = [\n",
    "            tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(d_ff, activation='relu'),\n",
    "                tf.keras.layers.Dense(d_model)\n",
    "            ], name=f'shared_{i}')\n",
    "            for i in range(n_shared)\n",
    "        ]\n",
    "        \n",
    "        # Routed Experts\n",
    "        self.routed_experts = [\n",
    "            tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(d_ff, activation='relu'),\n",
    "                tf.keras.layers.Dense(d_model)\n",
    "            ], name=f'routed_{i}')\n",
    "            for i in range(n_routed_experts)\n",
    "        ]\n",
    "        \n",
    "        # Router (Routed Expertsì— ëŒ€í•´ì„œë§Œ)\n",
    "        self.gate = tf.keras.layers.Dense(n_routed_experts, use_bias=False, name='router')\n",
    "        \n",
    "        # Bias terms for Aux-Free balancing (non-trainable)\n",
    "        self.expert_bias = tf.Variable(\n",
    "            tf.zeros(n_routed_experts), trainable=False, name='expert_bias'\n",
    "        )\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        B, S, D = x.shape\n",
    "        \n",
    "        # 1. Shared Expert ì¶œë ¥ (ëª¨ë“  í† í°)\n",
    "        shared_out = tf.zeros_like(x)\n",
    "        for expert in self.shared_experts:\n",
    "            shared_out += expert(x)\n",
    "        \n",
    "        # 2. Router ë¡œì§“ + í¸í–¥\n",
    "        logits = self.gate(x)  # [B, S, N_routed]\n",
    "        if not training:\n",
    "            logits_biased = logits + self.expert_bias\n",
    "        else:\n",
    "            logits_biased = logits + self.expert_bias\n",
    "        \n",
    "        # Top-k ì„ íƒ\n",
    "        top_k_logits, top_k_indices = tf.math.top_k(logits_biased, k=self.top_k)\n",
    "        top_k_gates = tf.nn.softmax(top_k_logits, axis=-1)  # [B, S, k]\n",
    "        \n",
    "        # 3. Routed Expert ì¶œë ¥\n",
    "        routed_out = tf.zeros_like(x)\n",
    "        for k_idx in range(self.top_k):\n",
    "            expert_indices = top_k_indices[:, :, k_idx]\n",
    "            expert_gates = top_k_gates[:, :, k_idx:k_idx+1]\n",
    "            \n",
    "            for e_idx in range(self.n_routed):\n",
    "                mask = tf.cast(tf.equal(expert_indices, e_idx), tf.float32)\n",
    "                mask = mask[:, :, tf.newaxis]\n",
    "                if tf.reduce_sum(mask) > 0:\n",
    "                    e_out = self.routed_experts[e_idx](x)\n",
    "                    routed_out += e_out * mask * expert_gates\n",
    "        \n",
    "        # 4. í•©ì‚°: Shared + Routed\n",
    "        output = shared_out + routed_out\n",
    "        \n",
    "        return output, top_k_indices, tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "\n",
    "# ë°ëª¨ (ì¶•ì†Œ ë²„ì „)\n",
    "d_model, d_ff = 256, 512\n",
    "n_routed, top_k = 8, 2\n",
    "\n",
    "moe = DeepSeekMoELayer(d_model, d_ff, n_routed, top_k, n_shared=1)\n",
    "x_test = tf.random.normal((2, 16, d_model))\n",
    "output, indices, probs = moe(x_test)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"DeepSeekMoE Layer\")\n",
    "print(f\"  Shared Experts: 1, Routed Experts: {n_routed}, Top-{top_k}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ì…ë ¥ shape:  {x_test.shape}\")\n",
    "print(f\"ì¶œë ¥ shape:  {output.shape}\")\n",
    "print()\n",
    "\n",
    "# íŒŒë¼ë¯¸í„° ë¶„ì„\n",
    "shared_params = sum(tf.size(v).numpy() for exp in moe.shared_experts for v in exp.trainable_variables)\n",
    "routed_params = sum(tf.size(v).numpy() for exp in moe.routed_experts for v in exp.trainable_variables)\n",
    "router_params = sum(tf.size(v).numpy() for v in moe.gate.trainable_variables)\n",
    "\n",
    "print(f\"{'êµ¬ì„± ìš”ì†Œ':<25} | {'íŒŒë¼ë¯¸í„°':>12}\")\n",
    "print(\"-\" * 42)\n",
    "print(f\"{'Shared Expert (1ê°œ)':<25} | {shared_params:>12,}\")\n",
    "print(f\"{'Routed Experts (8ê°œ)':<25} | {routed_params:>12,}\")\n",
    "print(f\"{'Router':<25} | {router_params:>12,}\")\n",
    "print(f\"{'ì´ê³„':<25} | {shared_params+routed_params+router_params:>12,}\")\n",
    "print(f\"{'í™œì„± íŒŒë¼ë¯¸í„° (1+2)':<25} | {shared_params + routed_params//n_routed*top_k + router_params:>12,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Auxiliary-Loss-Free ë¡œë“œë°¸ëŸ°ì‹± <a name='3.-Aux-Free-Balance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Auxiliary-Loss-Free ë¡œë“œë°¸ëŸ°ì‹± ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# í¸í–¥ ë³´ì • ë°©ì‹ìœ¼ë¡œ Expert ë¶€í•˜ë¥¼ ê· í˜•ì‹œí‚¤ëŠ” ê³¼ì •ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤\n",
    "\n",
    "def simulate_aux_free_balancing(n_experts=8, n_tokens=256, n_steps=50, gamma=0.1, top_k=2):\n",
    "    # í¸í–¥ì´ ì ì§„ì ìœ¼ë¡œ ê· í˜•ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •\n",
    "    biases = np.zeros(n_experts)\n",
    "    \n",
    "    # Expert 0, 1ì— í¸í–¥ëœ ì´ˆê¸° ë¼ìš°í„° ê°€ì¤‘ì¹˜\n",
    "    router_w = np.random.randn(64, n_experts) * 0.1\n",
    "    router_w[:, 0] += 0.5  # Expert 0 ì„ í˜¸\n",
    "    router_w[:, 1] += 0.3  # Expert 1 ì•½ê°„ ì„ í˜¸\n",
    "    \n",
    "    history = {'step': [], 'balance': [], 'max_load': [], 'min_load': []}\n",
    "    load_history = []\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        # í† í° ë¼ìš°íŒ… ì‹œë®¬ë ˆì´ì…˜\n",
    "        x = np.random.randn(n_tokens, 64)\n",
    "        logits = x @ router_w + biases  # í¸í–¥ ì¶”ê°€\n",
    "        \n",
    "        # Top-k ì„ íƒ\n",
    "        top_k_idx = np.argsort(-logits, axis=-1)[:, :top_k]\n",
    "        \n",
    "        # Expertë³„ ë¡œë“œ ê³„ì‚°\n",
    "        loads = np.zeros(n_experts)\n",
    "        for e in range(n_experts):\n",
    "            loads[e] = np.sum(top_k_idx == e) / (n_tokens * top_k)\n",
    "        \n",
    "        # í¸í–¥ ì—…ë°ì´íŠ¸: f_bar - f_i\n",
    "        f_bar = 1.0 / n_experts\n",
    "        biases += gamma * (f_bar - loads)\n",
    "        \n",
    "        history['step'].append(step)\n",
    "        history['balance'].append(np.std(loads))\n",
    "        history['max_load'].append(np.max(loads))\n",
    "        history['min_load'].append(np.min(loads))\n",
    "        load_history.append(loads.copy())\n",
    "    \n",
    "    return history, load_history, biases\n",
    "\n",
    "history, load_hist, final_biases = simulate_aux_free_balancing()\n",
    "\n",
    "print(\"=\" * 65)\n",
    "print(\"Auxiliary-Loss-Free ë¡œë“œë°¸ëŸ°ì‹± ì‹œë®¬ë ˆì´ì…˜\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'Step':<8} | {'ë¶€í•˜ í‘œì¤€í¸ì°¨':>12} | {'ìµœëŒ€ ë¡œë“œ':>10} | {'ìµœì†Œ ë¡œë“œ':>10}\")\n",
    "print(\"-\" * 50)\n",
    "for i in [0, 5, 10, 20, 49]:\n",
    "    print(f\"{i:<8} | {history['balance'][i]:>12.4f} | \"\n",
    "          f\"{history['max_load'][i]:>9.1%} | {history['min_load'][i]:>9.1%}\")\n",
    "print()\n",
    "print(\"ìµœì¢… í¸í–¥ ê°’:\")\n",
    "for i, b in enumerate(final_biases):\n",
    "    print(f\"  Expert {i}: b={b:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Aux-Free ë¡œë“œë°¸ëŸ°ì‹± ìˆ˜ë ´ ê³¼ì • ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# ì™¼ìª½: ë¶€í•˜ í¸ì°¨ ìˆ˜ë ´\n",
    "ax1 = axes[0]\n",
    "ax1.plot(history['step'], history['balance'], 'b-', lw=2.5, label='ë¶€í•˜ í‘œì¤€í¸ì°¨')\n",
    "ax1.fill_between(history['step'], history['min_load'], history['max_load'],\n",
    "                  alpha=0.2, color='orange', label='ìµœëŒ€-ìµœì†Œ ë¡œë“œ ë²”ìœ„')\n",
    "ax1.axhline(y=0, color='gray', ls='--', lw=1)\n",
    "ax1.set_xlabel('í•™ìŠµ ìŠ¤í…', fontsize=11)\n",
    "ax1.set_ylabel('ë¶€í•˜ í¸ì°¨ / ë¡œë“œ', fontsize=11)\n",
    "ax1.set_title('Aux-Free ë¡œë“œë°¸ëŸ°ì‹± ìˆ˜ë ´', fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ì˜¤ë¥¸ìª½: Expertë³„ ë¡œë“œ ë³€í™”\n",
    "ax2 = axes[1]\n",
    "load_arr = np.array(load_hist)\n",
    "for e in range(8):\n",
    "    ax2.plot(range(len(load_hist)), load_arr[:, e], lw=1.5, \n",
    "             label=f'Expert {e}', alpha=0.7)\n",
    "ax2.axhline(y=1/8, color='red', ls='--', lw=2, label='ì´ìƒì  (12.5%)')\n",
    "ax2.set_xlabel('í•™ìŠµ ìŠ¤í…', fontsize=11)\n",
    "ax2.set_ylabel('Expert ë¡œë“œ ë¹„ìœ¨', fontsize=11)\n",
    "ax2.set_title('Expertë³„ ë¶€í•˜ ë³€í™”', fontweight='bold')\n",
    "ax2.legend(fontsize=8, ncol=3)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('deepseek_auxfree.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ë¨: chapter12_modern_llms/deepseek_auxfree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Token Prediction (MTP) <a name='4.-MTP'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Multi-Token Prediction ì‹œë®¬ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ë‹¤ìŒ 1ê°œ í† í° ì˜ˆì¸¡(NTP) vs ë‹¤ì¤‘ í† í° ì˜ˆì¸¡(MTP)ì˜ í•™ìŠµ ì‹ í˜¸ ë¹„êµ\n",
    "\n",
    "# ê°„ë‹¨í•œ ì‹œí€€ìŠ¤ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤\n",
    "vocab_size = 100\n",
    "seq_len = 32\n",
    "d_model = 128\n",
    "\n",
    "# ëœë¤ ì‹œí€€ìŠ¤\n",
    "sequence = np.random.randint(0, vocab_size, size=seq_len)\n",
    "\n",
    "# NTP: ê° ìœ„ì¹˜ì—ì„œ ë‹¤ìŒ 1í† í° ì˜ˆì¸¡\n",
    "ntp_targets = sequence[1:]  # T-1ê°œì˜ íƒ€ê²Ÿ\n",
    "ntp_loss_terms = len(ntp_targets)\n",
    "\n",
    "# MTP (depth=2): ê° ìœ„ì¹˜ì—ì„œ ë‹¤ìŒ 2í† í° ì˜ˆì¸¡\n",
    "mtp_depth = 2\n",
    "mtp_loss_terms = 0\n",
    "for d in range(1, mtp_depth + 1):\n",
    "    mtp_loss_terms += max(0, seq_len - d)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Multi-Token Prediction (MTP) vs Next-Token Prediction (NTP)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ì‹œí€€ìŠ¤ ê¸¸ì´: {seq_len}\")\n",
    "print()\n",
    "print(f\"{'ë°©ë²•':<20} | {'ì˜ˆì¸¡ ê¹Šì´':>10} | {'Loss í•­ ìˆ˜':>12} | {'í•™ìŠµ ì‹ í˜¸':>10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'NTP (ê¸°ì¡´)':<20} | {'D=1':>10} | {ntp_loss_terms:>12} | {'ê¸°ì¤€':>10}\")\n",
    "print(f\"{'MTP (DeepSeek)':<20} | {f'D={mtp_depth}':>10} | {mtp_loss_terms:>12} | {f'{mtp_loss_terms/ntp_loss_terms:.1f}x':>10}\")\n",
    "print()\n",
    "\n",
    "# MTP êµ¬ì¡° ì‹œê°í™” (í…ìŠ¤íŠ¸)\n",
    "print(\"MTP ë™ì‘ ì˜ˆì‹œ (D=2):\")\n",
    "print(\"=\" * 50)\n",
    "example_seq = \"ë‚˜ëŠ” ì˜¤ëŠ˜ í•™êµì— ê°”ë‹¤\".split()\n",
    "for t in range(min(4, len(example_seq)-2)):\n",
    "    context = \" \".join(example_seq[:t+1])\n",
    "    target1 = example_seq[t+1] if t+1 < len(example_seq) else \"?\"\n",
    "    target2 = example_seq[t+2] if t+2 < len(example_seq) else \"?\"\n",
    "    print(f\"  ì…ë ¥: [{context}]\")\n",
    "    print(f\"    â†’ NTP ì˜ˆì¸¡: {target1}\")\n",
    "    print(f\"    â†’ MTP ì˜ˆì¸¡: {target1}, {target2}\")\n",
    "    print()\n",
    "\n",
    "print(\"MTP ì¥ì :\")\n",
    "print(\"  1. í•™ìŠµ ì‹ í˜¸ ì¦ê°€ â†’ ë™ì¼ ë°ì´í„°ë¡œ ë” ë§ì€ í•™ìŠµ\")\n",
    "print(\"  2. ì¶”ë¡  ì‹œ MTP í—¤ë“œë¥¼ Draft Modelë¡œ í™œìš© â†’ Speculative Decoding\")\n",
    "print(\"  3. DeepSeek-V3: D=1 (2í† í° ë™ì‹œ ì˜ˆì¸¡)ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì •ë¦¬ <a name='5.-ì •ë¦¬'></a>\n",
    "\n",
    "### í•µì‹¬ ê°œë… ìš”ì•½\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ì¤‘ìš”ë„ |\n",
    "|------|------|--------|\n",
    "| Shared Expert | ëª¨ë“  í† í°ì´ ê±°ì¹˜ëŠ” ê³µìœ  ì „ë¬¸ê°€ â†’ ê³µí†µ ì§€ì‹ ë³´ì¡´ | â­â­â­ |\n",
    "| Aux-Free Balance | í¸í–¥ í•­ $b_i$ë¡œ ë¶€í•˜ ê· í˜• â†’ ì„±ëŠ¥ ì €í•˜ ì—†ìŒ | â­â­â­ |\n",
    "| MTP | ë‹¤ì¤‘ ë¯¸ë˜ í† í° ë™ì‹œ ì˜ˆì¸¡ â†’ í•™ìŠµ íš¨ìœ¨ + Speculative Decoding | â­â­â­ |\n",
    "| DeepSeek-V3 ìŠ¤ì¼€ì¼ | 671B (37B active), 256 Routed + 1 Shared, Top-8 | â­â­ |\n",
    "\n",
    "### í•µì‹¬ ìˆ˜ì‹\n",
    "\n",
    "$$y = E_s(x) + \\sum_{i \\in \\text{Top-k}} g_i \\cdot E_i^r(x)$$\n",
    "\n",
    "$$b_i \\leftarrow b_i + \\gamma(\\bar{f} - f_i) \\quad \\text{(Aux-Free Balance)}$$\n",
    "\n",
    "$$\\mathcal{L}_{MTP} = -\\frac{1}{D}\\sum_{k=1}^{D}\\sum_{t} \\log P(x_{t+k}|x_{\\leq t})$$\n",
    "\n",
    "### DeepSeek-V3 í•µì‹¬ ìŠ¤í™\n",
    "\n",
    "| í•­ëª© | ê°’ |\n",
    "|------|-----|\n",
    "| ì´ íŒŒë¼ë¯¸í„° | 671B |\n",
    "| í™œì„±/í† í° | 37B |\n",
    "| Shared Expert | 1 |\n",
    "| Routed Expert | 256 |\n",
    "| Top-k | 8 |\n",
    "| í•™ìŠµ ë°ì´í„° | 14.8T í† í° |\n",
    "| í•™ìŠµ ë¹„ìš© | 2.788M H800 GPU-hours |\n",
    "| ì •ë°€ë„ | FP8 í˜¼í•© ì •ë°€ë„ |\n",
    "\n",
    "### ë‹¤ìŒ ì±•í„° ì˜ˆê³ \n",
    "**Chapter 13: ìƒì„± AI ì‹¬í™” â€” í™•ì‚° ëª¨ë¸ê³¼ SDE** â€” DDPMì˜ ìˆ˜í•™ì  ê¸°ì´ˆë¶€í„° ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„, DDIM ìƒ˜í”ŒëŸ¬, CFG, Score Matchingê¹Œì§€ í™•ì‚° ëª¨ë¸ì˜ ì „ ì´ë¡  ì²´ê³„ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}